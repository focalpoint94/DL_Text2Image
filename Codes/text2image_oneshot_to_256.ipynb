{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Final Proejct: Text to Image Synthesis (Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For understanding of this work, please carefully look at given PPT file.**\n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the training process **</font> so that TAs can grade both your code and results.  \n",
    "**The TA will set a config file as 'eval_birds.yml' when evaluating the code using 'hidden test dataset'. Thus, please make sure that your code can generate proper data to measure inception score and R-precision of 'hidden test dataset'.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load datasets\n",
    "The Birds dataset will be downloaded automatically if it is not located in the *data* directory. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os, nltk\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "import numpy as np\n",
    "import scipy\n",
    "from utils.data_utils import CUBDataset\n",
    "from utils.loss import cosine_similarity\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "\n",
    "#################################################\n",
    "# DO NOT CHANGE \n",
    "from utils.model import CNN_ENCODER, RNN_ENCODER, GENERATOR, DISCRIMINATOR\n",
    "#################################################\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'BATCH_SIZE': 64,\n",
      " 'CHECKPOINT_DIR': './checkpoint',\n",
      " 'CHECKPOINT_NAME': 'model.ckpt',\n",
      " 'CNN': {'EMBEDDING_DIM': 0, 'H_DIM': 0},\n",
      " 'CONFIG_NAME': 'text-to-image',\n",
      " 'CUDA': False,\n",
      " 'DATASET_NAME': 'birds',\n",
      " 'DATA_DIR': 'data/birds',\n",
      " 'EMBEDDING_TYPE': 'cnn-rnn',\n",
      " 'GAN': {'B_ATTENTION': False,\n",
      "         'B_CONDITION': False,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 0,\n",
      "         'DF_DIM': 0,\n",
      "         'EMBEDDING_DIM': 0,\n",
      "         'GF_DIM': 0,\n",
      "         'R_NUM': 0,\n",
      "         'Z_DIM': 512},\n",
      " 'GPU_ID': '0',\n",
      " 'IMAGE_SIZE': 256,\n",
      " 'NUM_BATCH_FOR_TEST': 0,\n",
      " 'RANDOM_SEED': 0,\n",
      " 'RNN': {'EMBEDDING_DIM': 0,\n",
      "         'H_DIM': 0,\n",
      "         'TYPE': '',\n",
      "         'VOCAB_SIZE': 0,\n",
      "         'WORD_EMBEDDING_DIM': 0},\n",
      " 'R_PRECISION_DIR': './evaluation',\n",
      " 'R_PRECISION_FILE': 'r_precision.npz',\n",
      " 'R_PRECISION_FILE_HIDDEN': 'r_precision_hidden.npz',\n",
      " 'TEST': {'B_EXAMPLE': False,\n",
      "          'GENERATED_HIDDEN_TEST_IMAGES': './evaluation/generated_images_hidden',\n",
      "          'GENERATED_TEST_IMAGES': './evaluation/generated_images'},\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 128, 'WORDS_NUM': 20},\n",
      " 'TRAIN': {'CNN_ENCODER': '',\n",
      "           'COEFF': {'COLOR_LOSS': 0.0, 'KL': 0.0, 'UNCOND_LOSS': 0.0},\n",
      "           'DISCRIMINATOR': '',\n",
      "           'DISCRIMINATOR_LR': 0.0,\n",
      "           'FLAG': True,\n",
      "           'GENERATOR': '',\n",
      "           'GENERATOR_LR': 0.0,\n",
      "           'MAX_EPOCH': 600,\n",
      "           'RNN_ENCODER': '',\n",
      "           'SNAPSHOT_INTERVAL': 0},\n",
      " 'WORKERS': 4,\n",
      " 'WRONG_CAPTION': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/final-project-deep-learning-19-tf/miscc/config.py:121: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "# Set a config file as 'train_birds.yml' in training, as 'eval_birds.yml' for evaluation\n",
    "cfg_from_file('cfg/train_birds.yml') # eval_birds.yml\n",
    "\n",
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cfg.GPU_ID\n",
    "\n",
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "output_dir = 'sample/%s_%s_%s' % (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf\n",
      "\n",
      "self.data_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds\n",
      "\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011.tgz\n",
      "\n",
      "Dataset already exists\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011/images\n",
      "\n",
      "Load from:  data/birds/captions.pickle\n",
      "self.current_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf\n",
      "\n",
      "self.data_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds\n",
      "\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011.tgz\n",
      "\n",
      "Dataset already exists\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011/images\n",
      "\n",
      "Load from:  data/birds/captions.pickle\n",
      "\n",
      "train data directory:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/train\n",
      "test data directory:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/test\n",
      "\n",
      "# of train filenames:(8855,)\n",
      "# of test filenames:(2933,)\n",
      "\n",
      "example of filename of train image:002.Laysan_Albatross/Laysan_Albatross_0002_1027\n",
      "example of filename of valid image:001.Black_footed_Albatross/Black_Footed_Albatross_0046_18\n",
      "\n",
      "example of caption and its ids:\n",
      "['a', 'bird', 'with', 'a', 'very', 'long', 'wing', 'span', 'and', 'a', 'long', 'pointed', 'beak']\n",
      "[ 1  2  3  1  4  5  6  7  8  1  5  9 10  0  0  0  0  0  0  0]\n",
      "\n",
      "example of caption and its ids:\n",
      "['light', 'tan', 'colored', 'bird', 'with', 'a', 'white', 'head', 'and', 'an', 'orange', 'beak']\n",
      "[ 67 106  89   2   3   1  14  25   8  28  52  10   0   0   0   0   0   0\n",
      "   0   0]\n",
      "\n",
      "# of train captions:(88550,)\n",
      "# of test captions:(29330,)\n",
      "\n",
      "# of train caption ids:(88550, 20)\n",
      "# of test caption ids:(29330, 20)\n",
      "\n",
      "# of train images:(8855, 256, 256, 3)\n",
      "# of test images:(2933, 256, 256, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CUBDataset(cfg.DATA_DIR, split='train')\n",
    "test_dataset = CUBDataset(cfg.DATA_DIR, split='test')\n",
    "\n",
    "print(f'\\ntrain data directory:\\n{train_dataset.split_dir}')\n",
    "print(f'test data directory:\\n{test_dataset.split_dir}\\n')\n",
    "\n",
    "print(f'# of train filenames:{train_dataset.filenames.shape}')\n",
    "print(f'# of test filenames:{test_dataset.filenames.shape}\\n')\n",
    "\n",
    "print(f'example of filename of train image:{train_dataset.filenames[0]}')\n",
    "print(f'example of filename of valid image:{test_dataset.filenames[0]}\\n')\n",
    "\n",
    "print(f'example of caption and its ids:\\n{train_dataset.captions[0]}\\n{train_dataset.captions_ids[0]}\\n')\n",
    "print(f'example of caption and its ids:\\n{test_dataset.captions[0]}\\n{test_dataset.captions_ids[0]}\\n')\n",
    "\n",
    "print(f'# of train captions:{np.asarray(train_dataset.captions).shape}')\n",
    "print(f'# of test captions:{np.asarray(test_dataset.captions).shape}\\n')\n",
    "\n",
    "print(f'# of train caption ids:{np.asarray(train_dataset.captions_ids).shape}')\n",
    "print(f'# of test caption ids:{np.asarray(test_dataset.captions_ids).shape}\\n')\n",
    "\n",
    "print(f'# of train images:{train_dataset.images.shape}')\n",
    "print(f'# of test images:{test_dataset.images.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8855, 256, 256, 3)\n",
      "(2933, 256, 256, 3)\n",
      "(88550, 20)\n",
      "(29330, 20)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_dataset.images\n",
    "test_images = test_dataset.images\n",
    "train_captions = np.asarray(train_dataset.captions_ids)\n",
    "test_captions = np.asarray(test_dataset.captions_ids)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(train_captions.shape)\n",
    "print(test_captions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_captions_train = len(train_captions)\n",
    "n_captions_per_image = 10\n",
    "n_images_train = len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import threading\n",
    "import scipy.ndimage as ndi\n",
    "from skimage import transform\n",
    "from skimage import exposure\n",
    "import skimage\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def sent2ID(sample_sentence):\n",
    "    caption = []\n",
    "    cap = sample_sentence\n",
    "    if len(cap) == 0:\n",
    "        exit()\n",
    "    cap = cap.replace(\"\\ufffd\\ufffd\", \" \")\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(cap.lower())\n",
    "    tokens_new = []\n",
    "    for t in tokens:\n",
    "        t = t.encode('ascii', 'ignore').decode('ascii')\n",
    "        if len(t) > 0:\n",
    "            tokens_new.append(t)\n",
    "    caption.append(tokens_new)\n",
    "    caption_new = []\n",
    "    t = caption[0]\n",
    "    rev = []\n",
    "    for w in t:\n",
    "        if w in train_dataset.wordtoix:\n",
    "            rev.append(train_dataset.wordtoix[w])\n",
    "    x, x_len = train_dataset.get_caption(rev)\n",
    "    caption_new.append(np.squeeze(x, axis=1))\n",
    "    return caption_new\n",
    "\n",
    "def ID2sent(sample_caption):\n",
    "    sentence = []\n",
    "    for ID in sample_caption:\n",
    "        if ID != train_dataset.ixtoword['<PAD>']:\n",
    "            sentence.append(train_dataset.ixtoword[ID])\n",
    "    return sentence\n",
    "\n",
    "def get_random_int(min=0, max=10, number=5):\n",
    "    return [random.randint(min,max) for p in range(0,number)]\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "    return img\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return scipy.misc.imsave(path, merge(images, size))\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(images, size, image_path)\n",
    "\n",
    "def threading_data(data=None, fn=None, **kwargs):\n",
    "    def apply_fn(results, i, data, kwargs):\n",
    "        results[i] = fn(data, **kwargs)\n",
    "    results = [None] * len(data)\n",
    "    threads = []\n",
    "    for i in range(len(data)):\n",
    "        t = threading.Thread(\n",
    "                        name='threading_and_return',\n",
    "                        target=apply_fn,\n",
    "                        args=(results, i, data[i], kwargs)\n",
    "                        )\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    return np.asarray(results)\n",
    "\n",
    "def apply_transform(x, transform_matrix, channel_index=2, fill_mode='nearest', cval=0., order=1):\n",
    "    x = np.rollaxis(x, channel_index, 0)\n",
    "    final_affine_matrix = transform_matrix[:2, :2]\n",
    "    final_offset = transform_matrix[:2, 2]\n",
    "    channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n",
    "                      final_offset, order=order, mode=fill_mode, cval=cval) for x_channel in x]\n",
    "    x = np.stack(channel_images, axis=0)\n",
    "    x = np.rollaxis(x, 0, channel_index + 1)\n",
    "    return x\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 + 0.5\n",
    "    o_y = float(y) / 2 + 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "def rotation(x, rg=20, is_random=False, row_index=0, col_index=1, channel_index=2,\n",
    "                    fill_mode='nearest', cval=0.):\n",
    "    if is_random:\n",
    "        theta = np.pi / 180 * np.random.uniform(-rg, rg)\n",
    "    else:\n",
    "        theta = np.pi / 180 * rg\n",
    "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                [np.sin(theta), np.cos(theta), 0],\n",
    "                                [0, 0, 1]])\n",
    "    h, w = x.shape[row_index], x.shape[col_index]\n",
    "    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\n",
    "    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n",
    "    return x\n",
    "\n",
    "def crop(x, wrg, hrg, is_random=False, row_index=0, col_index=1, channel_index=2):\n",
    "    h, w = x.shape[row_index], x.shape[col_index]\n",
    "    assert (h > hrg) and (w > wrg), \"The size of cropping should smaller than the original image\"\n",
    "    if is_random:\n",
    "        h_offset = int(np.random.uniform(0, h-hrg) - 1)\n",
    "        w_offset = int(np.random.uniform(0, w-wrg) - 1)\n",
    "        return x[h_offset: hrg + h_offset ,w_offset: wrg + w_offset]\n",
    "    else:\n",
    "        h_offset = int(np.floor((h - hrg)/ 2.))\n",
    "        w_offset = int(np.floor((w - wrg)/ 2.))\n",
    "        h_end = h_offset + hrg\n",
    "        w_end = w_offset + wrg\n",
    "        return x[h_offset: h_end, w_offset: w_end]\n",
    "\n",
    "def flip_axis(x, axis, is_random=False):\n",
    "    if is_random:\n",
    "        factor = np.random.uniform(-1, 1)\n",
    "        if factor > 0:\n",
    "            x = np.asarray(x).swapaxes(axis, 0)\n",
    "            x = x[::-1, ...]\n",
    "            x = x.swapaxes(0, axis)\n",
    "            return x\n",
    "        else:\n",
    "            return x\n",
    "    else:\n",
    "        x = np.asarray(x).swapaxes(axis, 0)\n",
    "        x = x[::-1, ...]\n",
    "        x = x.swapaxes(0, axis)\n",
    "        return x\n",
    "\n",
    "def imresize(x, size=[100, 100], interp='bilinear', mode=None):\n",
    "    if x.shape[-1] == 1:\n",
    "        x = scipy.misc.imresize(x[:, :, 0], size, interp=interp, mode=mode)\n",
    "        return x[:, :, np.newaxis]\n",
    "    elif x.shape[-1] == 3:\n",
    "        return scipy.misc.imresize(x, size, interp=interp, mode=mode)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported channel %d\" % x.shape[-1])\n",
    "\n",
    "def prepro_img(x, mode=None):\n",
    "    if mode=='train':\n",
    "        x = flip_axis(x, axis=1, is_random=True)\n",
    "        x = rotation(x, rg=16, is_random=True, fill_mode='nearest')\n",
    "        x = imresize(x, size=[256 + 60, 256 + 60], interp='bilinear', mode=None)\n",
    "        x = crop(x, wrg=256, hrg=256, is_random=True)\n",
    "        x = x / (255. / 2.)\n",
    "        x = x - 1.\n",
    "    return x\n",
    "\n",
    "def combine_and_save_image_sets(image_sets, directory):\n",
    "    for i in range(len(image_sets[0])):\n",
    "        combined_image = []\n",
    "        for set_no in range(len(image_sets)):\n",
    "            combined_image.append(image_sets[set_no][i])\n",
    "            combined_image.append(np.zeros((image_sets[set_no][i].shape[0], 5, 3)))\n",
    "        combined_image = np.concatenate(combined_image, axis = 1)\n",
    "        scipy.misc.imsave(os.path.join(directory, 'combined_{}.jpg'.format(i)), combined_image)\n",
    "\n",
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print('The checkpoint has been created.')\n",
    "\n",
    "def load(saver, sess, ckpt_path):\n",
    "    saver.restore(sess, ckpt_path)\n",
    "    print(\"Restored model parameters from {}\".format(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 20)\n"
     ]
    }
   ],
   "source": [
    "train_samples_dir = 'train_samples_1217_b'\n",
    "if os.path.exists(train_samples_dir) == False:\n",
    "    os.makedirs(train_samples_dir)\n",
    "\n",
    "lr = 2e-4\n",
    "lr_decay = 0.5      \n",
    "decay_every = 80\n",
    "beta1 = 0.5\n",
    "checkpoint_dir = './checkpoint_1217_b'\n",
    "z_dim = 512\n",
    "image_size = 256\n",
    "c_dim = 3\n",
    "batch_size = 16\n",
    "ni = 4\n",
    "\n",
    "sample_size = batch_size\n",
    "sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, z_dim)).astype(np.float32)\n",
    "sample_sentence = [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a medium sized black bird, with a white belly, and webbed feet.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this is a white bird with black webbed feet and a black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a small dully colored bird that has a grey head and nape, an oatmeal colored breast, belly and yellow and oatmeal-grey colored wings and tail.\"] * int(sample_size/ni)\n",
    "for i, sent in enumerate(sample_sentence):\n",
    "    sample_sentence[i] = sent2ID(sent)\n",
    "sample_sentence = np.asarray(sample_sentence)\n",
    "sample_sentence = np.reshape(sample_sentence, (sample_size, 20))\n",
    "print(sample_sentence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Text2Img:\n",
    "    def __init__(self):\n",
    "        \"\"\" Information \"\"\"\n",
    "        self.lr = 2e-4\n",
    "        self.lr_decay = 0.5\n",
    "        self.decay_every = 80\n",
    "        self.beta1 = 0.5\n",
    "        self.z_dim = 512\n",
    "        self.image_size = 256\n",
    "        self.c_dim = 3\n",
    "        self.batch_size = 16\n",
    "        self.alpha = 0.2\n",
    "        \n",
    "        \"\"\" Place Holders \"\"\"\n",
    "        self.t_real_image = tf.placeholder('float32', [self.batch_size, self.image_size, image_size, 3], name = 'real_image')\n",
    "        self.t_wrong_image = tf.placeholder('float32', [self.batch_size ,self.image_size, image_size, 3], name = 'wrong_image')\n",
    "        self.t_real_caption = tf.placeholder(dtype=tf.int64, shape=[self.batch_size, None], name='real_caption_input')\n",
    "        self.t_wrong_caption = tf.placeholder(dtype=tf.int64, shape=[self.batch_size, None], name='wrong_caption_input')\n",
    "        self.t_z = tf.placeholder(tf.float32, [self.batch_size, self.z_dim], name='z_noise')\n",
    "        \n",
    "        \"\"\" Training Phase - CNN - RNN mapping \"\"\"\n",
    "        net_cnn = CNN_ENCODER(self.t_real_image, is_training=True, reuse=False)\n",
    "        x = net_cnn.outputs\n",
    "        v = RNN_ENCODER(self.t_real_caption, is_training=True, reuse=False).outputs\n",
    "        x_w = CNN_ENCODER(self.t_wrong_image, is_training=True, reuse=True).outputs\n",
    "        v_w = RNN_ENCODER(self.t_wrong_caption, is_training=True, reuse=True).outputs\n",
    "        self.rnn_loss = tf.reduce_mean(tf.maximum(0., self.alpha - cosine_similarity(x, v) + cosine_similarity(x, v_w))) + \\\n",
    "                    tf.reduce_mean(tf.maximum(0., self.alpha - cosine_similarity(x, v) + cosine_similarity(x_w, v)))\n",
    "        \n",
    "        \"\"\" Training Phase - GAN \"\"\"\n",
    "        self.net_rnn = RNN_ENCODER(self.t_real_caption, is_training=False, reuse=True)\n",
    "        net_fake_image = GENERATOR(self.t_z, self.net_rnn.outputs, is_training=True, reuse=False)\n",
    "        net_disc_fake = DISCRIMINATOR(net_fake_image.outputs, self.net_rnn.outputs, is_training=True, reuse=False)\n",
    "        disc_fake_logits = net_disc_fake.logits\n",
    "        net_disc_real = DISCRIMINATOR(self.t_real_image, self.net_rnn.outputs, is_training=True, reuse=True)\n",
    "        disc_real_logits = net_disc_real.logits\n",
    "        net_disc_mismatch = DISCRIMINATOR(self.t_real_image, RNN_ENCODER(self.t_wrong_caption, is_training=False, reuse=True).outputs,\n",
    "                                        is_training=True, reuse=True)\n",
    "        disc_mismatch_logits = net_disc_mismatch.logits\n",
    "        d_loss1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_real_logits,     labels=tf.ones_like(disc_real_logits),      name='d1'))\n",
    "        d_loss2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_mismatch_logits, labels=tf.zeros_like(disc_mismatch_logits), name='d2'))\n",
    "        d_loss3 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits,     labels=tf.zeros_like(disc_fake_logits),     name='d3'))\n",
    "        self.d_loss = d_loss1 + (d_loss2 + d_loss3) * 0.5\n",
    "        self.g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits, labels=tf.ones_like(disc_fake_logits), name='g'))\n",
    "        \n",
    "        \"\"\" Testing Phase \"\"\"\n",
    "        self.net_g = GENERATOR(self.t_z, RNN_ENCODER(self.t_real_caption, is_training=False, reuse=True).outputs,\n",
    "                            is_training=False, reuse=True)\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        rnn_vars = [var for var in tf.trainable_variables() if 'rnnencoder' in var.name]\n",
    "        cnn_vars = [var for var in tf.trainable_variables() if 'cnnencoder' in var.name]\n",
    "        d_vars = [var for var in tf.trainable_variables() if 'discriminator' in var.name]\n",
    "        g_vars = [var for var in tf.trainable_variables() if 'generator' in var.name]\n",
    "        update_ops_CNN = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'cnnencoder' in var.name]\n",
    "        update_ops_D = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'discriminator' in var.name]\n",
    "        update_ops_G = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'generator' in var.name]\n",
    "        with tf.variable_scope('learning_rate'):\n",
    "            self.lr_v = tf.Variable(self.lr, trainable=False)\n",
    "        with tf.control_dependencies(update_ops_CNN):\n",
    "            grads, _ = tf.clip_by_global_norm(tf.gradients(self.rnn_loss, rnn_vars + cnn_vars), 10)\n",
    "            optimizer = tf.train.AdamOptimizer(self.lr_v, beta1=self.beta1)\n",
    "            self.rnn_optim = optimizer.apply_gradients(zip(grads, rnn_vars + cnn_vars))\n",
    "        with tf.control_dependencies(update_ops_D):\n",
    "            self.d_optim = tf.train.AdamOptimizer(self.lr_v, beta1=self.beta1).minimize(self.d_loss, var_list=d_vars)\n",
    "        with tf.control_dependencies(update_ops_G):\n",
    "            self.g_optim = tf.train.AdamOptimizer(self.lr_v, beta1=self.beta1).minimize(self.g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chszerg/final-project-deep-learning-19-tf/utils/model.py:371: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "no checkpoints find.\n",
      " ** init lr: 0.000200  decay_every_epoch: 80, lr_decay: 0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py:142: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [54/553] time: 1.0883s, d_loss: 1.38705206, g_loss: 2.33708286, rnn_loss: 0.39775246\n",
      "step: [109/553] time: 1.1793s, d_loss: 1.40180385, g_loss: 2.37959051, rnn_loss: 0.41016191\n",
      "step: [164/553] time: 1.1602s, d_loss: 1.22278309, g_loss: 3.04673719, rnn_loss: 0.41547209\n",
      "step: [219/553] time: 1.1197s, d_loss: 1.32913947, g_loss: 1.37585688, rnn_loss: 0.34253895\n",
      "step: [274/553] time: 1.1239s, d_loss: 1.48694444, g_loss: 0.89430153, rnn_loss: 0.37854373\n",
      "step: [329/553] time: 1.1006s, d_loss: 1.39764833, g_loss: 1.29283631, rnn_loss: 0.25592062\n",
      "step: [384/553] time: 1.0748s, d_loss: 1.52042508, g_loss: 0.85741961, rnn_loss: 0.30551744\n",
      "step: [439/553] time: 1.1590s, d_loss: 1.42676139, g_loss: 1.05569386, rnn_loss: 0.35273051\n",
      "step: [494/553] time: 1.0931s, d_loss: 1.49748445, g_loss: 3.45876074, rnn_loss: 0.31753987\n",
      "step: [549/553] time: 1.0401s, d_loss: 1.23707390, g_loss: 2.00257349, rnn_loss: 0.31394351\n",
      " ** Epoch 0 took 651.239169s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [54/553] time: 1.1203s, d_loss: 1.59152234, g_loss: 1.62561071, rnn_loss: 0.32082531\n",
      "step: [109/553] time: 1.0630s, d_loss: 1.45342231, g_loss: 1.13815093, rnn_loss: 0.22740696\n",
      "step: [164/553] time: 1.1392s, d_loss: 1.33295417, g_loss: 2.22067022, rnn_loss: 0.36073905\n",
      "step: [219/553] time: 1.1728s, d_loss: 1.31358576, g_loss: 1.69726622, rnn_loss: 0.42920411\n",
      "step: [274/553] time: 1.1479s, d_loss: 1.62550175, g_loss: 1.50648594, rnn_loss: 0.41849706\n",
      "step: [329/553] time: 1.1384s, d_loss: 1.09215355, g_loss: 2.29267073, rnn_loss: 0.31957024\n",
      "step: [384/553] time: 1.1188s, d_loss: 1.17970443, g_loss: 1.81818390, rnn_loss: 0.28850502\n",
      "step: [439/553] time: 1.0654s, d_loss: 1.65111971, g_loss: 1.80784965, rnn_loss: 0.32400593\n",
      "step: [494/553] time: 1.0639s, d_loss: 1.01173282, g_loss: 2.97288942, rnn_loss: 0.33005697\n",
      "step: [549/553] time: 1.1143s, d_loss: 1.03128195, g_loss: 3.07012033, rnn_loss: 0.26643181\n",
      " ** Epoch 1 took 623.828323s\n",
      "step: [54/553] time: 1.1081s, d_loss: 1.23430276, g_loss: 0.95483136, rnn_loss: 0.18231107\n",
      "step: [109/553] time: 1.1378s, d_loss: 1.33304858, g_loss: 1.05747390, rnn_loss: 0.21099415\n",
      "step: [164/553] time: 1.1632s, d_loss: 1.24205589, g_loss: 1.03855371, rnn_loss: 0.28669977\n",
      "step: [219/553] time: 1.1357s, d_loss: 1.43461561, g_loss: 0.96219021, rnn_loss: 0.27469534\n",
      "step: [274/553] time: 1.1089s, d_loss: 1.19659126, g_loss: 1.56447792, rnn_loss: 0.23989770\n",
      "step: [329/553] time: 1.1571s, d_loss: 1.21757054, g_loss: 1.31243849, rnn_loss: 0.25883436\n",
      "step: [384/553] time: 1.1429s, d_loss: 1.17706454, g_loss: 1.77728629, rnn_loss: 0.22103916\n",
      "step: [439/553] time: 1.0966s, d_loss: 1.15605557, g_loss: 1.09140718, rnn_loss: 0.19458044\n",
      "step: [494/553] time: 1.1385s, d_loss: 1.45326996, g_loss: 1.21979046, rnn_loss: 0.31501937\n",
      "step: [549/553] time: 1.1341s, d_loss: 1.16024351, g_loss: 1.89994097, rnn_loss: 0.32526180\n",
      " ** Epoch 2 took 624.901070s\n",
      "step: [54/553] time: 1.1480s, d_loss: 1.10827196, g_loss: 1.43113041, rnn_loss: 0.29379541\n",
      "step: [109/553] time: 1.1460s, d_loss: 1.11623275, g_loss: 1.25059557, rnn_loss: 0.20253724\n",
      "step: [164/553] time: 1.1425s, d_loss: 1.36317790, g_loss: 0.97381306, rnn_loss: 0.34341580\n",
      "step: [219/553] time: 1.1257s, d_loss: 1.41246355, g_loss: 1.69578958, rnn_loss: 0.31588626\n",
      "step: [274/553] time: 1.1081s, d_loss: 1.32042408, g_loss: 0.69016778, rnn_loss: 0.27401438\n",
      "step: [329/553] time: 1.1406s, d_loss: 1.04608035, g_loss: 2.22580171, rnn_loss: 0.23509808\n",
      "step: [384/553] time: 1.1409s, d_loss: 1.13323128, g_loss: 1.14867187, rnn_loss: 0.26244658\n",
      "step: [439/553] time: 1.1003s, d_loss: 1.45114005, g_loss: 0.62114882, rnn_loss: 0.18982127\n",
      "step: [494/553] time: 1.1646s, d_loss: 1.28440857, g_loss: 0.74111760, rnn_loss: 0.29728785\n",
      "step: [549/553] time: 1.0893s, d_loss: 1.53633142, g_loss: 1.80121613, rnn_loss: 0.19181530\n",
      " ** Epoch 3 took 622.870999s\n",
      "step: [54/553] time: 1.1149s, d_loss: 1.71052790, g_loss: 1.26468754, rnn_loss: 0.30570370\n",
      "step: [109/553] time: 1.1710s, d_loss: 1.26284122, g_loss: 0.91339141, rnn_loss: 0.35032248\n",
      "step: [164/553] time: 1.0941s, d_loss: 1.20078230, g_loss: 1.53110337, rnn_loss: 0.18545645\n",
      "step: [219/553] time: 1.1244s, d_loss: 0.91324967, g_loss: 1.44451618, rnn_loss: 0.10280046\n",
      "step: [274/553] time: 1.1327s, d_loss: 1.34967327, g_loss: 0.80640709, rnn_loss: 0.26392367\n",
      "step: [329/553] time: 1.1332s, d_loss: 1.07951570, g_loss: 1.08049047, rnn_loss: 0.18889104\n",
      "step: [384/553] time: 1.1338s, d_loss: 1.07069325, g_loss: 1.72246468, rnn_loss: 0.28371578\n",
      "step: [439/553] time: 1.1190s, d_loss: 1.12116289, g_loss: 1.62254977, rnn_loss: 0.22637457\n",
      "step: [494/553] time: 1.0185s, d_loss: 1.38988888, g_loss: 1.54950047, rnn_loss: 0.23491324\n",
      "step: [549/553] time: 1.1989s, d_loss: 1.19938934, g_loss: 1.35197735, rnn_loss: 0.22759110\n",
      " ** Epoch 4 took 623.749593s\n",
      "step: [54/553] time: 1.1040s, d_loss: 1.15531480, g_loss: 1.38920677, rnn_loss: 0.27071637\n",
      "step: [109/553] time: 1.1073s, d_loss: 1.12360597, g_loss: 2.12669230, rnn_loss: 0.32000986\n",
      "step: [164/553] time: 1.0705s, d_loss: 1.17561710, g_loss: 2.08097887, rnn_loss: 0.26542699\n",
      "step: [219/553] time: 1.1135s, d_loss: 0.84950197, g_loss: 1.11435878, rnn_loss: 0.18023469\n",
      "step: [274/553] time: 1.1620s, d_loss: 1.41452146, g_loss: 1.72449517, rnn_loss: 0.24648538\n",
      "step: [329/553] time: 1.0873s, d_loss: 1.14035571, g_loss: 1.66537547, rnn_loss: 0.26405573\n",
      "step: [384/553] time: 1.0928s, d_loss: 1.21389079, g_loss: 0.88520503, rnn_loss: 0.22299965\n",
      "step: [439/553] time: 1.0965s, d_loss: 0.81245375, g_loss: 1.67650759, rnn_loss: 0.26765761\n",
      "step: [494/553] time: 1.0620s, d_loss: 1.43444395, g_loss: 1.28143871, rnn_loss: 0.21263468\n",
      "step: [549/553] time: 1.1539s, d_loss: 1.21067810, g_loss: 1.95527530, rnn_loss: 0.16705415\n",
      " ** Epoch 5 took 622.055002s\n",
      "step: [54/553] time: 1.1483s, d_loss: 1.25030279, g_loss: 1.72896612, rnn_loss: 0.25271279\n",
      "step: [109/553] time: 1.1827s, d_loss: 1.11819470, g_loss: 1.28589392, rnn_loss: 0.32567480\n",
      "step: [164/553] time: 1.1866s, d_loss: 1.35267532, g_loss: 0.55105317, rnn_loss: 0.26909620\n",
      "step: [219/553] time: 1.1246s, d_loss: 1.73701966, g_loss: 0.72039223, rnn_loss: 0.16601680\n",
      "step: [274/553] time: 1.1516s, d_loss: 0.82968771, g_loss: 1.86638451, rnn_loss: 0.18419783\n",
      "step: [329/553] time: 1.0807s, d_loss: 1.37838316, g_loss: 1.42297840, rnn_loss: 0.40728617\n",
      "step: [384/553] time: 1.0984s, d_loss: 1.01394761, g_loss: 0.91824937, rnn_loss: 0.21018931\n",
      "step: [439/553] time: 1.1458s, d_loss: 0.85635746, g_loss: 1.12441778, rnn_loss: 0.23351312\n",
      "step: [494/553] time: 1.1670s, d_loss: 0.94126952, g_loss: 0.90872574, rnn_loss: 0.14172786\n",
      "step: [549/553] time: 1.1544s, d_loss: 0.81511837, g_loss: 1.78875852, rnn_loss: 0.14655396\n",
      " ** Epoch 6 took 624.296614s\n",
      "step: [54/553] time: 1.0829s, d_loss: 0.83601129, g_loss: 2.91274309, rnn_loss: 0.23859739\n",
      "step: [109/553] time: 1.0480s, d_loss: 0.95560682, g_loss: 1.95356345, rnn_loss: 0.32036614\n",
      "step: [164/553] time: 1.1080s, d_loss: 1.15535069, g_loss: 1.19942784, rnn_loss: 0.27548930\n",
      "step: [219/553] time: 1.0695s, d_loss: 0.94594723, g_loss: 1.91403008, rnn_loss: 0.24780047\n",
      "step: [274/553] time: 1.1775s, d_loss: 1.56522322, g_loss: 3.81433678, rnn_loss: 0.20415071\n",
      "step: [329/553] time: 1.0688s, d_loss: 1.35668242, g_loss: 0.78610909, rnn_loss: 0.23782334\n",
      "step: [384/553] time: 1.1033s, d_loss: 0.86659062, g_loss: 1.88312101, rnn_loss: 0.23198619\n",
      "step: [439/553] time: 1.1630s, d_loss: 0.92584312, g_loss: 0.87268472, rnn_loss: 0.28252771\n",
      "step: [494/553] time: 1.2157s, d_loss: 1.09759045, g_loss: 2.78912473, rnn_loss: 0.13947037\n",
      "step: [549/553] time: 1.1048s, d_loss: 0.72458053, g_loss: 1.99824429, rnn_loss: 0.24127518\n",
      " ** Epoch 7 took 623.976710s\n",
      "step: [54/553] time: 1.1679s, d_loss: 1.25453246, g_loss: 1.16777277, rnn_loss: 0.21725482\n",
      "step: [109/553] time: 1.1569s, d_loss: 1.00453007, g_loss: 1.73352396, rnn_loss: 0.29975584\n",
      "step: [164/553] time: 1.1282s, d_loss: 1.03658700, g_loss: 1.53517127, rnn_loss: 0.24607024\n",
      "step: [219/553] time: 1.1385s, d_loss: 0.77258146, g_loss: 1.32967782, rnn_loss: 0.17930658\n",
      "step: [274/553] time: 1.1278s, d_loss: 1.03663921, g_loss: 1.39550591, rnn_loss: 0.13400370\n",
      "step: [329/553] time: 1.1349s, d_loss: 0.79829067, g_loss: 1.88269103, rnn_loss: 0.18848270\n",
      "step: [384/553] time: 1.1276s, d_loss: 0.70670360, g_loss: 3.29227972, rnn_loss: 0.15364838\n",
      "step: [439/553] time: 1.1405s, d_loss: 0.73156869, g_loss: 1.85657644, rnn_loss: 0.20713663\n",
      "step: [494/553] time: 1.1074s, d_loss: 0.84544730, g_loss: 2.49039221, rnn_loss: 0.18565741\n",
      "step: [549/553] time: 1.0952s, d_loss: 1.41499305, g_loss: 2.46726656, rnn_loss: 0.13881683\n",
      " ** Epoch 8 took 624.524496s\n",
      "step: [54/553] time: 1.2109s, d_loss: 1.39228094, g_loss: 2.97369766, rnn_loss: 0.20517008\n",
      "step: [109/553] time: 1.1452s, d_loss: 1.05972409, g_loss: 1.23374176, rnn_loss: 0.26342577\n",
      "step: [164/553] time: 1.0695s, d_loss: 1.49192667, g_loss: 2.22622490, rnn_loss: 0.23889878\n",
      "step: [219/553] time: 1.0684s, d_loss: 1.08763373, g_loss: 1.92256916, rnn_loss: 0.23925538\n",
      "step: [274/553] time: 1.1030s, d_loss: 1.34581435, g_loss: 1.00248492, rnn_loss: 0.17544705\n",
      "step: [329/553] time: 1.1063s, d_loss: 1.11320436, g_loss: 1.83056641, rnn_loss: 0.36906737\n",
      "step: [384/553] time: 1.1820s, d_loss: 0.67185813, g_loss: 2.90363288, rnn_loss: 0.24225280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [439/553] time: 1.0997s, d_loss: 0.70003021, g_loss: 1.00389922, rnn_loss: 0.16693904\n",
      "step: [494/553] time: 1.1639s, d_loss: 1.17514050, g_loss: 1.34944046, rnn_loss: 0.24238808\n",
      "step: [549/553] time: 1.1266s, d_loss: 0.49326220, g_loss: 3.26184893, rnn_loss: 0.19770797\n",
      " ** Epoch 9 took 625.747466s\n",
      "step: [54/553] time: 1.1142s, d_loss: 1.87345552, g_loss: 1.53210413, rnn_loss: 0.15464528\n",
      "step: [109/553] time: 1.1793s, d_loss: 0.78972495, g_loss: 2.02489138, rnn_loss: 0.18320416\n",
      "step: [164/553] time: 1.1570s, d_loss: 1.39493406, g_loss: 3.08536673, rnn_loss: 0.22798181\n",
      "step: [219/553] time: 1.1143s, d_loss: 0.55716228, g_loss: 2.88692713, rnn_loss: 0.25208831\n",
      "step: [274/553] time: 1.1639s, d_loss: 1.41824663, g_loss: 0.76048839, rnn_loss: 0.19994226\n",
      "step: [329/553] time: 1.2401s, d_loss: 0.69169760, g_loss: 2.70644093, rnn_loss: 0.24406528\n",
      "step: [384/553] time: 1.1880s, d_loss: 0.28116792, g_loss: 2.10066581, rnn_loss: 0.21540102\n",
      "step: [439/553] time: 1.0952s, d_loss: 0.84401226, g_loss: 1.14620280, rnn_loss: 0.29091647\n",
      "step: [494/553] time: 1.1355s, d_loss: 0.80442387, g_loss: 2.10567188, rnn_loss: 0.14753589\n",
      "step: [549/553] time: 1.1000s, d_loss: 0.94904715, g_loss: 1.71597528, rnn_loss: 0.23489910\n",
      " ** Epoch 10 took 629.751682s\n",
      "step: [54/553] time: 1.1104s, d_loss: 1.17114675, g_loss: 1.25401545, rnn_loss: 0.16023070\n",
      "step: [109/553] time: 1.2047s, d_loss: 0.70196390, g_loss: 2.45521832, rnn_loss: 0.25972837\n",
      "step: [164/553] time: 1.1648s, d_loss: 0.65653890, g_loss: 1.80962896, rnn_loss: 0.15932564\n",
      "step: [219/553] time: 1.0968s, d_loss: 1.09769940, g_loss: 1.62769032, rnn_loss: 0.24367715\n",
      "step: [274/553] time: 1.1503s, d_loss: 0.94854605, g_loss: 1.05804253, rnn_loss: 0.25941217\n",
      "step: [329/553] time: 1.1796s, d_loss: 1.27414882, g_loss: 2.00238848, rnn_loss: 0.14600421\n",
      "step: [384/553] time: 1.1080s, d_loss: 0.93089283, g_loss: 2.22979927, rnn_loss: 0.23197101\n",
      "step: [439/553] time: 1.1466s, d_loss: 0.37336200, g_loss: 2.53848338, rnn_loss: 0.21121529\n",
      "step: [494/553] time: 1.1563s, d_loss: 0.45342216, g_loss: 3.21331000, rnn_loss: 0.12081677\n",
      "step: [549/553] time: 1.1624s, d_loss: 0.51707381, g_loss: 2.21959162, rnn_loss: 0.16223773\n",
      " ** Epoch 11 took 626.144446s\n",
      "step: [54/553] time: 1.2007s, d_loss: 0.77277386, g_loss: 1.12015510, rnn_loss: 0.23149033\n",
      "step: [109/553] time: 1.1960s, d_loss: 0.95483363, g_loss: 1.86916351, rnn_loss: 0.29663262\n",
      "step: [164/553] time: 1.2217s, d_loss: 0.34111506, g_loss: 3.11149406, rnn_loss: 0.22625196\n",
      "step: [219/553] time: 1.0816s, d_loss: 0.51614010, g_loss: 3.52566361, rnn_loss: 0.23758367\n",
      "step: [274/553] time: 1.1154s, d_loss: 0.67726111, g_loss: 2.29851294, rnn_loss: 0.19130333\n",
      "step: [329/553] time: 1.1620s, d_loss: 0.79013401, g_loss: 1.99895155, rnn_loss: 0.23124418\n",
      "step: [384/553] time: 1.1089s, d_loss: 0.43718091, g_loss: 2.30156183, rnn_loss: 0.14973232\n",
      "step: [439/553] time: 1.1223s, d_loss: 0.98853308, g_loss: 0.58405131, rnn_loss: 0.11426730\n",
      "step: [494/553] time: 1.0775s, d_loss: 0.46835166, g_loss: 2.91801572, rnn_loss: 0.24885553\n",
      "step: [549/553] time: 1.0659s, d_loss: 0.34347296, g_loss: 2.10098839, rnn_loss: 0.14382620\n",
      " ** Epoch 12 took 628.159892s\n",
      "step: [54/553] time: 1.1278s, d_loss: 0.43434718, g_loss: 2.96328187, rnn_loss: 0.11471371\n",
      "step: [109/553] time: 1.1017s, d_loss: 1.31656039, g_loss: 3.92820597, rnn_loss: 0.16488074\n",
      "step: [164/553] time: 1.2035s, d_loss: 0.56683445, g_loss: 2.93608451, rnn_loss: 0.16734672\n",
      "step: [219/553] time: 1.0862s, d_loss: 0.75939584, g_loss: 1.41916919, rnn_loss: 0.18954381\n",
      "step: [274/553] time: 1.1621s, d_loss: 2.36549711, g_loss: 0.61301517, rnn_loss: 0.09482315\n",
      "step: [329/553] time: 1.2421s, d_loss: 0.78414071, g_loss: 0.71734309, rnn_loss: 0.18877880\n",
      "step: [384/553] time: 1.1754s, d_loss: 1.76744878, g_loss: 1.12209272, rnn_loss: 0.20384020\n",
      "step: [439/553] time: 1.1379s, d_loss: 0.42832392, g_loss: 2.02287960, rnn_loss: 0.19412698\n",
      "step: [494/553] time: 1.1304s, d_loss: 0.75385058, g_loss: 1.49013996, rnn_loss: 0.19476789\n",
      "step: [549/553] time: 1.1468s, d_loss: 0.60041487, g_loss: 2.57520700, rnn_loss: 0.14524126\n",
      " ** Epoch 13 took 625.993252s\n",
      "step: [54/553] time: 1.1338s, d_loss: 1.67276645, g_loss: 1.91342509, rnn_loss: 0.20255616\n",
      "step: [109/553] time: 1.1880s, d_loss: 0.71454918, g_loss: 3.12852812, rnn_loss: 0.20452361\n",
      "step: [164/553] time: 1.1824s, d_loss: 0.50005400, g_loss: 3.34139252, rnn_loss: 0.21882004\n",
      "step: [219/553] time: 1.0272s, d_loss: 0.57991511, g_loss: 2.40209961, rnn_loss: 0.30323428\n",
      "step: [274/553] time: 1.1474s, d_loss: 0.30708763, g_loss: 2.71057844, rnn_loss: 0.23075722\n",
      "step: [329/553] time: 1.1314s, d_loss: 0.69203746, g_loss: 1.91792917, rnn_loss: 0.19620374\n",
      "step: [384/553] time: 1.1397s, d_loss: 1.21821105, g_loss: 3.14400554, rnn_loss: 0.31741726\n",
      "step: [439/553] time: 1.1072s, d_loss: 0.44129527, g_loss: 1.25075495, rnn_loss: 0.17578468\n",
      "step: [494/553] time: 1.1186s, d_loss: 3.25438285, g_loss: 0.03088582, rnn_loss: 0.20945428\n",
      "step: [549/553] time: 1.1500s, d_loss: 1.03416300, g_loss: 4.55779457, rnn_loss: 0.23781607\n",
      " ** Epoch 14 took 622.111297s\n",
      "step: [54/553] time: 1.1308s, d_loss: 0.17096031, g_loss: 3.11093736, rnn_loss: 0.14914221\n",
      "step: [109/553] time: 1.0479s, d_loss: 0.20672971, g_loss: 3.63330865, rnn_loss: 0.14724442\n",
      "step: [164/553] time: 1.1108s, d_loss: 0.26186320, g_loss: 2.38696575, rnn_loss: 0.14132744\n",
      "step: [219/553] time: 1.1498s, d_loss: 0.19809030, g_loss: 2.21795940, rnn_loss: 0.12320574\n",
      "step: [274/553] time: 1.0754s, d_loss: 0.53764951, g_loss: 2.28634214, rnn_loss: 0.17455384\n",
      "step: [329/553] time: 1.0901s, d_loss: 0.56397676, g_loss: 2.34538126, rnn_loss: 0.18402246\n",
      "step: [384/553] time: 1.1302s, d_loss: 0.76214248, g_loss: 2.61784482, rnn_loss: 0.17644098\n",
      "step: [439/553] time: 1.1249s, d_loss: 0.40858629, g_loss: 2.85480785, rnn_loss: 0.14203462\n",
      "step: [494/553] time: 1.0758s, d_loss: 0.66785479, g_loss: 1.58334351, rnn_loss: 0.25344661\n",
      "step: [549/553] time: 1.1689s, d_loss: 0.62045503, g_loss: 3.14816332, rnn_loss: 0.28073940\n",
      " ** Epoch 15 took 622.248645s\n",
      "step: [54/553] time: 1.1269s, d_loss: 0.38436452, g_loss: 2.74425530, rnn_loss: 0.15177733\n",
      "step: [109/553] time: 1.1141s, d_loss: 0.49547830, g_loss: 1.17899024, rnn_loss: 0.30548802\n",
      "step: [164/553] time: 1.1358s, d_loss: 0.45014197, g_loss: 2.57921505, rnn_loss: 0.20026816\n",
      "step: [219/553] time: 1.1221s, d_loss: 1.59516335, g_loss: 2.80289650, rnn_loss: 0.21568368\n",
      "step: [274/553] time: 1.0627s, d_loss: 0.49817145, g_loss: 2.67401838, rnn_loss: 0.30058199\n",
      "step: [329/553] time: 1.1963s, d_loss: 0.83798802, g_loss: 3.34156513, rnn_loss: 0.21814573\n",
      "step: [384/553] time: 1.2062s, d_loss: 0.56122726, g_loss: 2.04659176, rnn_loss: 0.20257899\n",
      "step: [439/553] time: 1.0875s, d_loss: 1.49551618, g_loss: 0.47649500, rnn_loss: 0.24677545\n",
      "step: [494/553] time: 1.1130s, d_loss: 0.41034442, g_loss: 2.44171476, rnn_loss: 0.19020897\n",
      "step: [549/553] time: 1.1069s, d_loss: 1.77934194, g_loss: 2.98843098, rnn_loss: 0.30223227\n",
      " ** Epoch 16 took 621.735163s\n",
      "step: [54/553] time: 1.0853s, d_loss: 0.48426172, g_loss: 2.42205238, rnn_loss: 0.25156084\n",
      "step: [109/553] time: 1.0844s, d_loss: 0.97628212, g_loss: 2.97976017, rnn_loss: 0.25408566\n",
      "step: [164/553] time: 1.0857s, d_loss: 0.81125498, g_loss: 2.62129164, rnn_loss: 0.12106997\n",
      "step: [219/553] time: 1.1237s, d_loss: 2.06065631, g_loss: 0.19740079, rnn_loss: 0.24782470\n",
      "step: [274/553] time: 1.0752s, d_loss: 0.65104020, g_loss: 2.30005360, rnn_loss: 0.19992274\n",
      "step: [329/553] time: 1.1755s, d_loss: 0.63117266, g_loss: 2.15548325, rnn_loss: 0.23646471\n",
      "step: [384/553] time: 1.1566s, d_loss: 0.22363585, g_loss: 4.01458073, rnn_loss: 0.14244807\n",
      "step: [439/553] time: 1.0950s, d_loss: 0.27978206, g_loss: 3.23486876, rnn_loss: 0.12727967\n",
      "step: [494/553] time: 1.1756s, d_loss: 0.49305251, g_loss: 3.03842044, rnn_loss: 0.17505494\n",
      "step: [549/553] time: 1.0758s, d_loss: 0.39056852, g_loss: 3.28043795, rnn_loss: 0.07907663\n",
      " ** Epoch 17 took 619.803947s\n",
      "step: [54/553] time: 1.0800s, d_loss: 1.25054920, g_loss: 2.34061337, rnn_loss: 0.34116560\n",
      "step: [109/553] time: 1.1051s, d_loss: 0.41070276, g_loss: 2.58158088, rnn_loss: 0.09171584\n",
      "step: [164/553] time: 1.1775s, d_loss: 0.67766899, g_loss: 1.47375655, rnn_loss: 0.18765548\n",
      "step: [219/553] time: 1.0536s, d_loss: 0.34674704, g_loss: 2.05098724, rnn_loss: 0.24715708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [274/553] time: 1.0933s, d_loss: 0.50810707, g_loss: 2.83283257, rnn_loss: 0.12709168\n",
      "step: [329/553] time: 1.1882s, d_loss: 0.78469259, g_loss: 0.89090025, rnn_loss: 0.19501498\n",
      "step: [384/553] time: 1.1374s, d_loss: 0.67215109, g_loss: 2.44412279, rnn_loss: 0.19060840\n",
      "step: [439/553] time: 1.0843s, d_loss: 0.14133199, g_loss: 4.73547697, rnn_loss: 0.09170498\n",
      "step: [494/553] time: 1.1566s, d_loss: 2.03409266, g_loss: 0.24171549, rnn_loss: 0.13137811\n",
      "step: [549/553] time: 1.0980s, d_loss: 0.37840790, g_loss: 4.09710979, rnn_loss: 0.11918177\n",
      " ** Epoch 18 took 614.188199s\n",
      "step: [54/553] time: 1.0824s, d_loss: 0.21985233, g_loss: 2.19679451, rnn_loss: 0.11280283\n",
      "step: [109/553] time: 1.0811s, d_loss: 0.34114468, g_loss: 2.68562841, rnn_loss: 0.07294194\n",
      "step: [164/553] time: 1.1632s, d_loss: 1.35287404, g_loss: 1.89048016, rnn_loss: 0.15313247\n",
      "step: [219/553] time: 1.0907s, d_loss: 0.72429633, g_loss: 3.77879310, rnn_loss: 0.19281697\n",
      "step: [274/553] time: 1.0957s, d_loss: 0.25220945, g_loss: 2.61607170, rnn_loss: 0.17711243\n",
      "step: [329/553] time: 1.1397s, d_loss: 0.28540552, g_loss: 2.98293447, rnn_loss: 0.16221276\n",
      "step: [384/553] time: 1.2262s, d_loss: 0.19164339, g_loss: 3.54848385, rnn_loss: 0.12776124\n",
      "step: [439/553] time: 1.1279s, d_loss: 0.24918629, g_loss: 3.46792936, rnn_loss: 0.19660929\n",
      "step: [494/553] time: 1.1260s, d_loss: 0.58755612, g_loss: 2.40492916, rnn_loss: 0.18279216\n",
      "step: [549/553] time: 1.1465s, d_loss: 1.87421536, g_loss: 2.30625391, rnn_loss: 0.17452319\n",
      " ** Epoch 19 took 622.435364s\n",
      "step: [54/553] time: 1.0924s, d_loss: 0.55880964, g_loss: 4.91809988, rnn_loss: 0.26502156\n",
      "step: [109/553] time: 1.1309s, d_loss: 0.79812378, g_loss: 6.23853493, rnn_loss: 0.16470970\n",
      "step: [164/553] time: 1.0728s, d_loss: 0.47834805, g_loss: 3.94406462, rnn_loss: 0.14158678\n",
      "step: [219/553] time: 1.1635s, d_loss: 0.92927557, g_loss: 1.14452326, rnn_loss: 0.19313177\n",
      "step: [274/553] time: 1.0897s, d_loss: 0.33161315, g_loss: 2.70864773, rnn_loss: 0.19980627\n",
      "step: [329/553] time: 1.1222s, d_loss: 0.28650284, g_loss: 1.26062441, rnn_loss: 0.28540048\n",
      "step: [384/553] time: 1.1022s, d_loss: 0.45037919, g_loss: 2.87999701, rnn_loss: 0.17184961\n",
      "step: [439/553] time: 1.0475s, d_loss: 0.45745781, g_loss: 2.49165916, rnn_loss: 0.08485712\n",
      "step: [494/553] time: 1.0738s, d_loss: 0.80972564, g_loss: 1.64813828, rnn_loss: 0.19081879\n",
      "step: [549/553] time: 1.0914s, d_loss: 0.45243737, g_loss: 4.41302872, rnn_loss: 0.15227243\n",
      " ** Epoch 20 took 620.681164s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "step: [54/553] time: 1.1257s, d_loss: 0.26288223, g_loss: 5.00224924, rnn_loss: 0.15645155\n",
      "step: [109/553] time: 1.1446s, d_loss: 0.92258638, g_loss: 0.94209707, rnn_loss: 0.22055049\n",
      "step: [164/553] time: 1.1492s, d_loss: 0.19096094, g_loss: 3.26393318, rnn_loss: 0.12511826\n",
      "step: [219/553] time: 1.1055s, d_loss: 1.31972599, g_loss: 4.37760925, rnn_loss: 0.14794651\n",
      "step: [274/553] time: 1.0951s, d_loss: 1.01023090, g_loss: 1.13196301, rnn_loss: 0.11439326\n",
      "step: [329/553] time: 1.2110s, d_loss: 1.06983173, g_loss: 1.58314908, rnn_loss: 0.21812460\n",
      "step: [384/553] time: 1.1117s, d_loss: 0.25268969, g_loss: 3.15320635, rnn_loss: 0.22511511\n",
      "step: [439/553] time: 1.1091s, d_loss: 0.28047740, g_loss: 3.22600174, rnn_loss: 0.16355488\n",
      "step: [494/553] time: 1.1753s, d_loss: 1.19018292, g_loss: 1.13739014, rnn_loss: 0.09141796\n",
      "step: [549/553] time: 1.1087s, d_loss: 0.25941041, g_loss: 2.27266121, rnn_loss: 0.21190727\n",
      " ** Epoch 21 took 624.389101s\n",
      "step: [54/553] time: 1.1257s, d_loss: 0.33490455, g_loss: 1.98532343, rnn_loss: 0.14533016\n",
      "step: [109/553] time: 1.0741s, d_loss: 0.58407778, g_loss: 2.08734202, rnn_loss: 0.14252187\n",
      "step: [164/553] time: 1.1449s, d_loss: 0.29904827, g_loss: 3.90805197, rnn_loss: 0.21723163\n",
      "step: [219/553] time: 1.0821s, d_loss: 0.48690635, g_loss: 2.00862527, rnn_loss: 0.21204597\n",
      "step: [274/553] time: 1.1390s, d_loss: 0.25656664, g_loss: 4.22406101, rnn_loss: 0.12388477\n",
      "step: [329/553] time: 1.1460s, d_loss: 0.30193859, g_loss: 2.94191003, rnn_loss: 0.17317314\n",
      "step: [384/553] time: 1.1263s, d_loss: 0.13756664, g_loss: 2.40553331, rnn_loss: 0.15989697\n",
      "step: [439/553] time: 1.1527s, d_loss: 0.74243635, g_loss: 5.01162195, rnn_loss: 0.14244455\n",
      "step: [494/553] time: 1.0731s, d_loss: 1.96908426, g_loss: 0.23623532, rnn_loss: 0.25836304\n",
      "step: [549/553] time: 1.1066s, d_loss: 0.34709302, g_loss: 2.46628284, rnn_loss: 0.09755448\n",
      " ** Epoch 22 took 617.015232s\n",
      "step: [54/553] time: 1.1739s, d_loss: 0.44540283, g_loss: 4.45683336, rnn_loss: 0.16020881\n",
      "step: [109/553] time: 1.0624s, d_loss: 1.31255543, g_loss: 8.28043079, rnn_loss: 0.15325809\n",
      "step: [164/553] time: 1.1383s, d_loss: 0.14895189, g_loss: 2.20787954, rnn_loss: 0.18168493\n",
      "step: [219/553] time: 1.1275s, d_loss: 0.91792601, g_loss: 1.08417726, rnn_loss: 0.13266417\n",
      "step: [274/553] time: 1.1132s, d_loss: 0.56127077, g_loss: 2.08122730, rnn_loss: 0.32459110\n",
      "step: [329/553] time: 1.1628s, d_loss: 0.21430716, g_loss: 5.79133701, rnn_loss: 0.27000237\n",
      "step: [384/553] time: 1.1167s, d_loss: 0.28270465, g_loss: 2.93551040, rnn_loss: 0.22742783\n",
      "step: [439/553] time: 1.0843s, d_loss: 0.96685028, g_loss: 5.70521545, rnn_loss: 0.18647486\n",
      "step: [494/553] time: 1.1846s, d_loss: 0.17018181, g_loss: 2.74984217, rnn_loss: 0.21355285\n",
      "step: [549/553] time: 1.0892s, d_loss: 0.22634257, g_loss: 4.33625793, rnn_loss: 0.20187534\n",
      " ** Epoch 23 took 617.589604s\n",
      "step: [54/553] time: 1.1159s, d_loss: 0.33866149, g_loss: 2.94864655, rnn_loss: 0.13499010\n",
      "step: [109/553] time: 1.1143s, d_loss: 0.55102336, g_loss: 3.53910875, rnn_loss: 0.23582448\n",
      "step: [164/553] time: 1.1487s, d_loss: 2.16355944, g_loss: 3.08639717, rnn_loss: 0.38890904\n",
      "step: [219/553] time: 1.1479s, d_loss: 0.34798390, g_loss: 2.22674203, rnn_loss: 0.13517165\n",
      "step: [274/553] time: 1.0917s, d_loss: 0.36950472, g_loss: 6.32965755, rnn_loss: 0.19145986\n",
      "step: [329/553] time: 1.0829s, d_loss: 0.36307874, g_loss: 2.93215656, rnn_loss: 0.08266265\n",
      "step: [384/553] time: 1.0517s, d_loss: 0.22939846, g_loss: 2.68970633, rnn_loss: 0.21227893\n",
      "step: [439/553] time: 1.0842s, d_loss: 0.23195535, g_loss: 2.76526737, rnn_loss: 0.16054024\n",
      "step: [494/553] time: 1.1301s, d_loss: 0.31254402, g_loss: 6.03628540, rnn_loss: 0.18828124\n",
      "step: [549/553] time: 1.1522s, d_loss: 0.61180753, g_loss: 2.48847246, rnn_loss: 0.19922847\n",
      " ** Epoch 24 took 618.809534s\n",
      "step: [54/553] time: 1.1076s, d_loss: 0.63427812, g_loss: 1.69153750, rnn_loss: 0.15210041\n",
      "step: [109/553] time: 1.0808s, d_loss: 1.06818116, g_loss: 2.64290047, rnn_loss: 0.25189823\n",
      "step: [164/553] time: 1.1738s, d_loss: 0.83967835, g_loss: 4.26960802, rnn_loss: 0.16926196\n",
      "step: [219/553] time: 1.0550s, d_loss: 0.11249550, g_loss: 4.80143213, rnn_loss: 0.10514609\n",
      "step: [274/553] time: 1.1429s, d_loss: 0.41846696, g_loss: 3.65663981, rnn_loss: 0.20506023\n",
      "step: [329/553] time: 1.1510s, d_loss: 0.46716040, g_loss: 3.65361381, rnn_loss: 0.20630026\n",
      "step: [384/553] time: 1.1733s, d_loss: 0.46945038, g_loss: 3.08688450, rnn_loss: 0.14698716\n",
      "step: [439/553] time: 1.0893s, d_loss: 0.16396630, g_loss: 2.78919816, rnn_loss: 0.16510344\n",
      "step: [494/553] time: 1.1221s, d_loss: 0.37898946, g_loss: 1.66833556, rnn_loss: 0.24522506\n",
      "step: [549/553] time: 1.1777s, d_loss: 0.46390808, g_loss: 5.24316883, rnn_loss: 0.17409483\n",
      " ** Epoch 25 took 619.582224s\n",
      "step: [54/553] time: 1.1347s, d_loss: 0.14475811, g_loss: 2.86970997, rnn_loss: 0.16576628\n",
      "step: [109/553] time: 1.0901s, d_loss: 1.17183959, g_loss: 1.94645345, rnn_loss: 0.22072005\n",
      "step: [164/553] time: 1.0711s, d_loss: 0.21113519, g_loss: 5.67333126, rnn_loss: 0.19069050\n",
      "step: [219/553] time: 1.0639s, d_loss: 0.47250286, g_loss: 3.54885125, rnn_loss: 0.19221154\n",
      "step: [274/553] time: 1.0946s, d_loss: 0.26689774, g_loss: 4.36062145, rnn_loss: 0.19827083\n",
      "step: [329/553] time: 1.1405s, d_loss: 0.48546207, g_loss: 4.40752935, rnn_loss: 0.11155096\n",
      "step: [384/553] time: 1.0873s, d_loss: 0.35170677, g_loss: 2.87686419, rnn_loss: 0.09652481\n",
      "step: [439/553] time: 1.1409s, d_loss: 0.12133574, g_loss: 4.15110064, rnn_loss: 0.15679818\n",
      "step: [494/553] time: 1.1027s, d_loss: 0.11541421, g_loss: 4.37738132, rnn_loss: 0.24359827\n",
      "step: [549/553] time: 1.0844s, d_loss: 0.65217805, g_loss: 1.04152346, rnn_loss: 0.16561753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** Epoch 26 took 622.200602s\n",
      "step: [54/553] time: 1.1401s, d_loss: 0.36114478, g_loss: 3.30445766, rnn_loss: 0.17201045\n",
      "step: [109/553] time: 1.1532s, d_loss: 0.47916013, g_loss: 4.15983486, rnn_loss: 0.06942438\n",
      "step: [164/553] time: 1.1128s, d_loss: 0.61543113, g_loss: 4.76545715, rnn_loss: 0.20744178\n",
      "step: [219/553] time: 1.1247s, d_loss: 0.30364072, g_loss: 2.36711383, rnn_loss: 0.08983407\n",
      "step: [274/553] time: 1.1161s, d_loss: 0.62864381, g_loss: 4.54120493, rnn_loss: 0.15475062\n",
      "step: [329/553] time: 1.1702s, d_loss: 0.26278439, g_loss: 4.85251808, rnn_loss: 0.17785177\n",
      "step: [384/553] time: 1.0476s, d_loss: 0.46184981, g_loss: 4.90346909, rnn_loss: 0.10858870\n",
      "step: [439/553] time: 1.1450s, d_loss: 0.16138335, g_loss: 3.59154844, rnn_loss: 0.08557019\n",
      "step: [494/553] time: 1.0655s, d_loss: 0.25810504, g_loss: 6.28621674, rnn_loss: 0.07678013\n",
      "step: [549/553] time: 1.1093s, d_loss: 0.63640499, g_loss: 3.61862803, rnn_loss: 0.23555005\n",
      " ** Epoch 27 took 620.423441s\n",
      "step: [54/553] time: 1.1020s, d_loss: 0.96692735, g_loss: 4.19360447, rnn_loss: 0.14805095\n",
      "step: [109/553] time: 1.1298s, d_loss: 1.08733284, g_loss: 4.80669594, rnn_loss: 0.13181362\n",
      "step: [164/553] time: 1.1219s, d_loss: 0.29681709, g_loss: 4.03151846, rnn_loss: 0.12356334\n",
      "step: [219/553] time: 1.1630s, d_loss: 0.36352199, g_loss: 3.87528753, rnn_loss: 0.26179671\n",
      "step: [274/553] time: 1.0768s, d_loss: 0.59756112, g_loss: 4.94342136, rnn_loss: 0.23650824\n",
      "step: [329/553] time: 1.1300s, d_loss: 0.31006545, g_loss: 3.72691655, rnn_loss: 0.25360471\n",
      "step: [384/553] time: 1.1306s, d_loss: 0.16007456, g_loss: 4.63764000, rnn_loss: 0.08306578\n",
      "step: [439/553] time: 1.2157s, d_loss: 0.09286363, g_loss: 5.84258747, rnn_loss: 0.22808379\n",
      "step: [494/553] time: 1.1444s, d_loss: 0.46056986, g_loss: 3.24493694, rnn_loss: 0.11290333\n",
      "step: [549/553] time: 1.1830s, d_loss: 1.11012697, g_loss: 6.62926340, rnn_loss: 0.17841198\n",
      " ** Epoch 28 took 620.575514s\n",
      "step: [54/553] time: 1.1126s, d_loss: 0.33820373, g_loss: 4.35668564, rnn_loss: 0.19243705\n",
      "step: [109/553] time: 1.1071s, d_loss: 0.10647094, g_loss: 3.98142123, rnn_loss: 0.18034042\n",
      "step: [164/553] time: 1.0894s, d_loss: 0.06268664, g_loss: 4.80052853, rnn_loss: 0.16872978\n",
      "step: [219/553] time: 1.1083s, d_loss: 0.40641585, g_loss: 2.90882158, rnn_loss: 0.18023911\n",
      "step: [274/553] time: 1.1141s, d_loss: 0.55384123, g_loss: 3.35348248, rnn_loss: 0.17951235\n",
      "step: [329/553] time: 1.1023s, d_loss: 0.35871214, g_loss: 4.78833866, rnn_loss: 0.15024462\n",
      "step: [384/553] time: 1.1063s, d_loss: 0.38998967, g_loss: 2.22490597, rnn_loss: 0.14684114\n",
      "step: [439/553] time: 1.1500s, d_loss: 1.41593504, g_loss: 5.57437611, rnn_loss: 0.19368711\n",
      "step: [494/553] time: 1.1486s, d_loss: 0.06882774, g_loss: 3.73794675, rnn_loss: 0.28924862\n",
      "step: [549/553] time: 1.0286s, d_loss: 0.27167094, g_loss: 5.59655094, rnn_loss: 0.15499388\n",
      " ** Epoch 29 took 622.042230s\n",
      "step: [54/553] time: 1.1541s, d_loss: 2.01162839, g_loss: 8.81200314, rnn_loss: 0.21477479\n",
      "step: [109/553] time: 1.1535s, d_loss: 0.16742946, g_loss: 5.67431498, rnn_loss: 0.16513135\n",
      "step: [164/553] time: 1.0963s, d_loss: 0.77363122, g_loss: 6.37114811, rnn_loss: 0.16661772\n",
      "step: [219/553] time: 1.1177s, d_loss: 0.18711402, g_loss: 4.81274843, rnn_loss: 0.16569151\n",
      "step: [274/553] time: 1.1001s, d_loss: 0.85074943, g_loss: 1.30762100, rnn_loss: 0.08664398\n",
      "step: [329/553] time: 1.0642s, d_loss: 0.74394512, g_loss: 1.61573410, rnn_loss: 0.18580489\n",
      "step: [384/553] time: 1.0998s, d_loss: 0.38277927, g_loss: 3.88338232, rnn_loss: 0.16497892\n",
      "step: [439/553] time: 1.1360s, d_loss: 0.16523515, g_loss: 2.51638651, rnn_loss: 0.17005704\n",
      "step: [494/553] time: 1.1199s, d_loss: 0.13351408, g_loss: 4.40591621, rnn_loss: 0.16544527\n",
      "step: [549/553] time: 1.1752s, d_loss: 0.26392424, g_loss: 3.98639464, rnn_loss: 0.17387548\n",
      " ** Epoch 30 took 619.742534s\n",
      "step: [54/553] time: 1.1172s, d_loss: 0.37945309, g_loss: 6.29972506, rnn_loss: 0.09021944\n",
      "step: [109/553] time: 1.1649s, d_loss: 0.13576026, g_loss: 3.15994787, rnn_loss: 0.11863594\n",
      "step: [164/553] time: 1.1167s, d_loss: 0.49771088, g_loss: 4.01700306, rnn_loss: 0.22126000\n",
      "step: [219/553] time: 1.0911s, d_loss: 0.10281569, g_loss: 6.19627571, rnn_loss: 0.20479751\n",
      "step: [274/553] time: 1.1290s, d_loss: 0.79480171, g_loss: 1.21534479, rnn_loss: 0.09904681\n",
      "step: [329/553] time: 1.1573s, d_loss: 0.19987084, g_loss: 2.79912043, rnn_loss: 0.14221202\n",
      "step: [384/553] time: 1.1474s, d_loss: 0.88443255, g_loss: 3.54160762, rnn_loss: 0.16072661\n",
      "step: [439/553] time: 1.1373s, d_loss: 1.25460279, g_loss: 0.94630635, rnn_loss: 0.21130002\n",
      "step: [494/553] time: 1.1252s, d_loss: 0.60754383, g_loss: 3.56374431, rnn_loss: 0.18508537\n",
      "step: [549/553] time: 1.1099s, d_loss: 0.32335207, g_loss: 3.43225479, rnn_loss: 0.11014803\n",
      " ** Epoch 31 took 622.108206s\n",
      "step: [54/553] time: 1.0905s, d_loss: 0.37966442, g_loss: 2.55304098, rnn_loss: 0.21791598\n",
      "step: [109/553] time: 1.1137s, d_loss: 0.10728826, g_loss: 4.23446798, rnn_loss: 0.24926259\n",
      "step: [164/553] time: 1.1043s, d_loss: 0.36548400, g_loss: 2.78169966, rnn_loss: 0.09590793\n",
      "step: [219/553] time: 1.1301s, d_loss: 0.04372236, g_loss: 6.87707138, rnn_loss: 0.12610143\n",
      "step: [274/553] time: 1.0405s, d_loss: 0.83280766, g_loss: 5.47686291, rnn_loss: 0.12126073\n",
      "step: [329/553] time: 1.1192s, d_loss: 0.29786572, g_loss: 5.29276752, rnn_loss: 0.14647061\n",
      "step: [384/553] time: 1.0637s, d_loss: 0.09861508, g_loss: 5.02555084, rnn_loss: 0.15701498\n",
      "step: [439/553] time: 1.0875s, d_loss: 1.14347136, g_loss: 0.91543800, rnn_loss: 0.13654056\n",
      "step: [494/553] time: 1.0760s, d_loss: 0.26778403, g_loss: 3.47266245, rnn_loss: 0.20809752\n",
      "step: [549/553] time: 1.1264s, d_loss: 0.82963675, g_loss: 4.02294254, rnn_loss: 0.17161722\n",
      " ** Epoch 32 took 620.887034s\n",
      "step: [54/553] time: 1.1207s, d_loss: 0.79084694, g_loss: 1.11750579, rnn_loss: 0.16435644\n",
      "step: [109/553] time: 1.1465s, d_loss: 0.41542870, g_loss: 3.61047602, rnn_loss: 0.08841287\n",
      "step: [164/553] time: 1.0566s, d_loss: 0.64087188, g_loss: 4.62403774, rnn_loss: 0.36526835\n",
      "step: [219/553] time: 1.1618s, d_loss: 0.56844658, g_loss: 5.24210930, rnn_loss: 0.05680029\n",
      "step: [274/553] time: 1.1136s, d_loss: 0.63986212, g_loss: 2.77149439, rnn_loss: 0.11906788\n",
      "step: [329/553] time: 1.1910s, d_loss: 0.35575622, g_loss: 2.49612546, rnn_loss: 0.14424416\n",
      "step: [384/553] time: 1.1345s, d_loss: 1.86656356, g_loss: 9.69270325, rnn_loss: 0.11634841\n",
      "step: [439/553] time: 1.1425s, d_loss: 2.25418210, g_loss: 0.10358231, rnn_loss: 0.18698522\n",
      "step: [494/553] time: 1.0958s, d_loss: 0.14509115, g_loss: 6.04776144, rnn_loss: 0.15410087\n",
      "step: [549/553] time: 1.1372s, d_loss: 0.67008334, g_loss: 6.55441666, rnn_loss: 0.15762737\n",
      " ** Epoch 33 took 618.863778s\n",
      "step: [54/553] time: 1.1064s, d_loss: 0.33833766, g_loss: 2.36815166, rnn_loss: 0.22449878\n",
      "step: [109/553] time: 1.1303s, d_loss: 0.41181946, g_loss: 2.64559889, rnn_loss: 0.19209230\n",
      "step: [164/553] time: 1.1547s, d_loss: 0.28163779, g_loss: 3.93802357, rnn_loss: 0.15624823\n",
      "step: [219/553] time: 1.0805s, d_loss: 1.29211903, g_loss: 0.50260299, rnn_loss: 0.11714083\n",
      "step: [274/553] time: 1.0935s, d_loss: 2.33254194, g_loss: 1.60451603, rnn_loss: 0.21751264\n",
      "step: [329/553] time: 1.0357s, d_loss: 0.14440335, g_loss: 7.38844633, rnn_loss: 0.15468374\n",
      "step: [384/553] time: 1.1838s, d_loss: 0.07350875, g_loss: 5.97594452, rnn_loss: 0.09997608\n",
      "step: [439/553] time: 1.1552s, d_loss: 0.02372058, g_loss: 6.89956856, rnn_loss: 0.05058298\n",
      "step: [494/553] time: 1.0761s, d_loss: 1.00218344, g_loss: 1.83620811, rnn_loss: 0.23120958\n",
      "step: [549/553] time: 1.0880s, d_loss: 0.15714288, g_loss: 3.57392621, rnn_loss: 0.09748151\n",
      " ** Epoch 34 took 620.422005s\n",
      "step: [54/553] time: 1.1198s, d_loss: 0.48111695, g_loss: 2.55136561, rnn_loss: 0.11054815\n",
      "step: [109/553] time: 1.0973s, d_loss: 0.21769911, g_loss: 3.45636845, rnn_loss: 0.14430101\n",
      "step: [164/553] time: 1.1021s, d_loss: 1.56043231, g_loss: 7.54063702, rnn_loss: 0.17568085\n",
      "step: [219/553] time: 1.1329s, d_loss: 0.15097880, g_loss: 2.84825230, rnn_loss: 0.10977802\n",
      "step: [274/553] time: 1.1831s, d_loss: 0.91066110, g_loss: 1.15858984, rnn_loss: 0.23187745\n",
      "step: [329/553] time: 1.1630s, d_loss: 0.58336222, g_loss: 4.20404768, rnn_loss: 0.12683949\n",
      "step: [384/553] time: 1.1636s, d_loss: 0.13921265, g_loss: 4.19729662, rnn_loss: 0.12662242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [439/553] time: 1.1465s, d_loss: 0.46757692, g_loss: 2.94859076, rnn_loss: 0.13107812\n",
      "step: [494/553] time: 1.0591s, d_loss: 0.99767947, g_loss: 3.87669706, rnn_loss: 0.12469649\n",
      "step: [549/553] time: 1.1115s, d_loss: 0.37915301, g_loss: 5.26974392, rnn_loss: 0.20506689\n",
      " ** Epoch 35 took 623.194785s\n",
      "step: [54/553] time: 1.1304s, d_loss: 0.15011901, g_loss: 3.76051664, rnn_loss: 0.08691207\n",
      "step: [109/553] time: 1.1548s, d_loss: 0.15914884, g_loss: 4.62452221, rnn_loss: 0.22891343\n",
      "step: [164/553] time: 1.1735s, d_loss: 0.19211984, g_loss: 5.55153370, rnn_loss: 0.25615343\n",
      "step: [219/553] time: 1.1447s, d_loss: 0.18458055, g_loss: 3.55968380, rnn_loss: 0.14217053\n",
      "step: [274/553] time: 1.1262s, d_loss: 0.15518099, g_loss: 3.46976733, rnn_loss: 0.09222329\n",
      "step: [329/553] time: 1.0909s, d_loss: 0.11025024, g_loss: 5.35719776, rnn_loss: 0.13234779\n",
      "step: [384/553] time: 1.1122s, d_loss: 0.13502529, g_loss: 4.45042086, rnn_loss: 0.16232164\n",
      "step: [439/553] time: 1.1389s, d_loss: 0.43768555, g_loss: 6.00348759, rnn_loss: 0.16879341\n",
      "step: [494/553] time: 1.1744s, d_loss: 0.22669226, g_loss: 3.42610073, rnn_loss: 0.16917199\n",
      "step: [549/553] time: 1.0791s, d_loss: 1.93541861, g_loss: 0.61477065, rnn_loss: 0.23803526\n",
      " ** Epoch 36 took 625.080393s\n",
      "step: [54/553] time: 1.1328s, d_loss: 2.75342107, g_loss: 1.27237773, rnn_loss: 0.21607526\n",
      "step: [109/553] time: 1.1208s, d_loss: 0.44814640, g_loss: 2.68873978, rnn_loss: 0.09793301\n",
      "step: [164/553] time: 1.0902s, d_loss: 0.12524644, g_loss: 4.43024921, rnn_loss: 0.15773901\n",
      "step: [219/553] time: 1.1418s, d_loss: 1.12044859, g_loss: 1.93662739, rnn_loss: 0.08636782\n",
      "step: [274/553] time: 1.2475s, d_loss: 0.35706857, g_loss: 5.97230196, rnn_loss: 0.08646563\n",
      "step: [329/553] time: 1.1736s, d_loss: 1.25939775, g_loss: 2.95417309, rnn_loss: 0.20413965\n",
      "step: [384/553] time: 1.1374s, d_loss: 0.80438137, g_loss: 4.41084862, rnn_loss: 0.14004907\n",
      "step: [439/553] time: 1.2375s, d_loss: 0.39402092, g_loss: 3.27688503, rnn_loss: 0.24780940\n",
      "step: [494/553] time: 1.1109s, d_loss: 0.14512694, g_loss: 4.99109888, rnn_loss: 0.14470574\n",
      "step: [549/553] time: 1.2831s, d_loss: 2.97140336, g_loss: 0.77073622, rnn_loss: 0.13649295\n",
      " ** Epoch 37 took 624.671074s\n",
      "step: [54/553] time: 1.0533s, d_loss: 0.70246947, g_loss: 3.71875906, rnn_loss: 0.11444835\n",
      "step: [109/553] time: 1.1448s, d_loss: 0.42456365, g_loss: 4.55783081, rnn_loss: 0.12021168\n",
      "step: [164/553] time: 1.1661s, d_loss: 0.27277550, g_loss: 2.32647514, rnn_loss: 0.23422575\n",
      "step: [219/553] time: 1.1124s, d_loss: 0.15093741, g_loss: 7.71436119, rnn_loss: 0.18409042\n",
      "step: [274/553] time: 1.1701s, d_loss: 0.17623316, g_loss: 4.30406284, rnn_loss: 0.13340937\n",
      "step: [329/553] time: 1.0623s, d_loss: 0.16337553, g_loss: 4.44437790, rnn_loss: 0.20095848\n",
      "step: [384/553] time: 1.1305s, d_loss: 0.38829827, g_loss: 6.26626635, rnn_loss: 0.16564354\n",
      "step: [439/553] time: 1.0894s, d_loss: 0.28232217, g_loss: 4.69528627, rnn_loss: 0.19893745\n",
      "step: [494/553] time: 1.1821s, d_loss: 0.71163368, g_loss: 0.58978015, rnn_loss: 0.15044561\n",
      "step: [549/553] time: 1.1726s, d_loss: 0.67072701, g_loss: 2.63425899, rnn_loss: 0.16489965\n",
      " ** Epoch 38 took 625.553443s\n",
      "step: [54/553] time: 1.2022s, d_loss: 0.21193859, g_loss: 3.53451109, rnn_loss: 0.09155028\n",
      "step: [109/553] time: 1.1848s, d_loss: 1.28689098, g_loss: 2.84882498, rnn_loss: 0.19436690\n",
      "step: [164/553] time: 1.1087s, d_loss: 0.14769973, g_loss: 4.99754620, rnn_loss: 0.14989251\n",
      "step: [219/553] time: 1.0867s, d_loss: 1.68068230, g_loss: 5.45787621, rnn_loss: 0.13790070\n",
      "step: [274/553] time: 1.1468s, d_loss: 0.38051087, g_loss: 3.89947367, rnn_loss: 0.23899366\n",
      "step: [329/553] time: 1.1267s, d_loss: 0.70629865, g_loss: 1.95768976, rnn_loss: 0.19862135\n",
      "step: [384/553] time: 1.0907s, d_loss: 0.55002105, g_loss: 6.07596397, rnn_loss: 0.14892627\n",
      "step: [439/553] time: 1.0865s, d_loss: 0.16844034, g_loss: 3.83635616, rnn_loss: 0.24451035\n",
      "step: [494/553] time: 1.1039s, d_loss: 0.39931625, g_loss: 4.89775372, rnn_loss: 0.34652215\n",
      "step: [549/553] time: 1.1307s, d_loss: 0.25702244, g_loss: 6.05862761, rnn_loss: 0.17790778\n",
      " ** Epoch 39 took 624.288259s\n",
      "step: [54/553] time: 1.0992s, d_loss: 0.74046725, g_loss: 1.31262434, rnn_loss: 0.14203019\n",
      "step: [109/553] time: 1.1259s, d_loss: 1.02921665, g_loss: 1.78773797, rnn_loss: 0.15843743\n",
      "step: [164/553] time: 1.1046s, d_loss: 0.45882672, g_loss: 4.11056519, rnn_loss: 0.18414176\n",
      "step: [219/553] time: 1.1195s, d_loss: 0.47061551, g_loss: 3.45970869, rnn_loss: 0.14442812\n",
      "step: [274/553] time: 1.1466s, d_loss: 0.23037875, g_loss: 5.08446836, rnn_loss: 0.16927545\n",
      "step: [329/553] time: 1.0750s, d_loss: 0.26911134, g_loss: 4.13182735, rnn_loss: 0.14173920\n",
      "step: [384/553] time: 1.1106s, d_loss: 0.06494734, g_loss: 4.07731819, rnn_loss: 0.14537460\n",
      "step: [439/553] time: 1.1087s, d_loss: 0.07595998, g_loss: 4.90416241, rnn_loss: 0.18850130\n",
      "step: [494/553] time: 1.0847s, d_loss: 0.35040000, g_loss: 6.07864571, rnn_loss: 0.15763770\n",
      "step: [549/553] time: 1.1043s, d_loss: 0.83937955, g_loss: 1.89848053, rnn_loss: 0.14930537\n",
      " ** Epoch 40 took 617.456170s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "step: [54/553] time: 1.1212s, d_loss: 0.16460478, g_loss: 3.62266397, rnn_loss: 0.13764027\n",
      "step: [109/553] time: 1.0683s, d_loss: 0.51064903, g_loss: 3.95415616, rnn_loss: 0.22804700\n",
      "step: [164/553] time: 1.0863s, d_loss: 0.12074842, g_loss: 4.75402355, rnn_loss: 0.13028005\n",
      "step: [219/553] time: 1.1203s, d_loss: 0.11300234, g_loss: 3.66268682, rnn_loss: 0.16847029\n",
      "step: [274/553] time: 1.2030s, d_loss: 0.81568658, g_loss: 3.74776268, rnn_loss: 0.05511343\n",
      "step: [329/553] time: 1.1976s, d_loss: 0.17724723, g_loss: 3.65076780, rnn_loss: 0.17081186\n",
      "step: [384/553] time: 1.1147s, d_loss: 0.13268609, g_loss: 5.99224663, rnn_loss: 0.12430663\n",
      "step: [439/553] time: 1.1401s, d_loss: 0.36360151, g_loss: 4.54625034, rnn_loss: 0.19514014\n",
      "step: [494/553] time: 1.1563s, d_loss: 0.29929569, g_loss: 5.61242914, rnn_loss: 0.08952039\n",
      "step: [549/553] time: 1.0335s, d_loss: 1.81773520, g_loss: 4.53988552, rnn_loss: 0.09404990\n",
      " ** Epoch 41 took 616.875786s\n",
      "step: [54/553] time: 1.1174s, d_loss: 0.16936097, g_loss: 5.28996563, rnn_loss: 0.17899689\n",
      "step: [109/553] time: 1.0802s, d_loss: 0.19841059, g_loss: 1.71475291, rnn_loss: 0.06674246\n",
      "step: [164/553] time: 1.1025s, d_loss: 0.06952944, g_loss: 5.65093899, rnn_loss: 0.12010397\n",
      "step: [219/553] time: 1.1603s, d_loss: 0.07382101, g_loss: 5.37564468, rnn_loss: 0.15798837\n",
      "step: [274/553] time: 1.0963s, d_loss: 0.08398166, g_loss: 4.47006083, rnn_loss: 0.16931334\n",
      "step: [329/553] time: 1.1276s, d_loss: 0.00958364, g_loss: 6.34347534, rnn_loss: 0.09644736\n",
      "step: [384/553] time: 1.1724s, d_loss: 2.23877120, g_loss: 1.49599957, rnn_loss: 0.19580942\n",
      "step: [439/553] time: 1.1641s, d_loss: 0.13062572, g_loss: 5.05783463, rnn_loss: 0.08867821\n",
      "step: [494/553] time: 1.0588s, d_loss: 1.39483881, g_loss: 0.37824500, rnn_loss: 0.13391940\n",
      "step: [549/553] time: 1.0603s, d_loss: 0.25151441, g_loss: 2.50888968, rnn_loss: 0.08647616\n",
      " ** Epoch 42 took 617.495492s\n",
      "step: [54/553] time: 1.1425s, d_loss: 0.06609370, g_loss: 4.22152281, rnn_loss: 0.19244769\n",
      "step: [109/553] time: 1.1121s, d_loss: 0.23629686, g_loss: 2.92344975, rnn_loss: 0.12118917\n",
      "step: [164/553] time: 1.0602s, d_loss: 0.23709373, g_loss: 5.84099770, rnn_loss: 0.11806761\n",
      "step: [219/553] time: 1.1217s, d_loss: 0.21463326, g_loss: 2.85036063, rnn_loss: 0.25742075\n",
      "step: [274/553] time: 1.1126s, d_loss: 0.70584476, g_loss: 2.95279121, rnn_loss: 0.24075243\n",
      "step: [329/553] time: 1.0581s, d_loss: 0.60898626, g_loss: 5.71141481, rnn_loss: 0.21981913\n",
      "step: [384/553] time: 1.1246s, d_loss: 0.16732055, g_loss: 5.02521229, rnn_loss: 0.11501041\n",
      "step: [439/553] time: 1.1656s, d_loss: 0.47517985, g_loss: 0.75894618, rnn_loss: 0.06616461\n",
      "step: [494/553] time: 1.0523s, d_loss: 0.52325529, g_loss: 4.61699581, rnn_loss: 0.13402444\n",
      "step: [549/553] time: 1.1584s, d_loss: 0.10493643, g_loss: 4.69694328, rnn_loss: 0.11033027\n",
      " ** Epoch 43 took 613.764701s\n",
      "step: [54/553] time: 1.0739s, d_loss: 0.06222048, g_loss: 4.59555197, rnn_loss: 0.09135415\n",
      "step: [109/553] time: 1.0677s, d_loss: 0.23063847, g_loss: 7.97144461, rnn_loss: 0.24624911\n",
      "step: [164/553] time: 1.1285s, d_loss: 0.17268042, g_loss: 3.61104512, rnn_loss: 0.18196809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [219/553] time: 1.0990s, d_loss: 1.49093318, g_loss: 5.81655455, rnn_loss: 0.18731730\n",
      "step: [274/553] time: 1.1578s, d_loss: 0.12075916, g_loss: 2.80299997, rnn_loss: 0.22481544\n",
      "step: [329/553] time: 1.0754s, d_loss: 0.27003527, g_loss: 3.74594259, rnn_loss: 0.11344445\n",
      "step: [384/553] time: 1.1293s, d_loss: 0.26935437, g_loss: 5.62710810, rnn_loss: 0.14604051\n",
      "step: [439/553] time: 1.0369s, d_loss: 0.60750091, g_loss: 4.14641857, rnn_loss: 0.17096931\n",
      "step: [494/553] time: 1.1371s, d_loss: 0.10606676, g_loss: 4.02872276, rnn_loss: 0.13905196\n",
      "step: [549/553] time: 1.0502s, d_loss: 0.46994638, g_loss: 5.14419842, rnn_loss: 0.26606834\n",
      " ** Epoch 44 took 610.059262s\n",
      "step: [54/553] time: 1.0912s, d_loss: 0.53564399, g_loss: 6.27490044, rnn_loss: 0.13789123\n",
      "step: [109/553] time: 1.1025s, d_loss: 0.18390572, g_loss: 2.80620241, rnn_loss: 0.16462666\n",
      "step: [164/553] time: 1.1064s, d_loss: 0.58504754, g_loss: 5.16242313, rnn_loss: 0.17378914\n",
      "step: [219/553] time: 1.0428s, d_loss: 0.25307170, g_loss: 2.52735448, rnn_loss: 0.18325019\n",
      "step: [274/553] time: 1.0441s, d_loss: 1.96443415, g_loss: 3.19935632, rnn_loss: 0.18331054\n",
      "step: [329/553] time: 1.0579s, d_loss: 0.33759546, g_loss: 4.37608767, rnn_loss: 0.15629898\n",
      "step: [384/553] time: 1.0829s, d_loss: 1.06213140, g_loss: 5.52121067, rnn_loss: 0.18246558\n",
      "step: [439/553] time: 1.1092s, d_loss: 1.01614630, g_loss: 6.05501938, rnn_loss: 0.12704507\n",
      "step: [494/553] time: 1.0429s, d_loss: 0.11404015, g_loss: 6.06224966, rnn_loss: 0.19471340\n",
      "step: [549/553] time: 1.0648s, d_loss: 0.19509175, g_loss: 4.44860172, rnn_loss: 0.13979574\n",
      " ** Epoch 45 took 608.854360s\n",
      "step: [54/553] time: 1.0914s, d_loss: 0.10144365, g_loss: 3.10879135, rnn_loss: 0.13951667\n",
      "step: [109/553] time: 1.1314s, d_loss: 0.68314528, g_loss: 1.34741426, rnn_loss: 0.17251056\n",
      "step: [164/553] time: 1.1580s, d_loss: 0.14138952, g_loss: 4.40658569, rnn_loss: 0.11608008\n",
      "step: [219/553] time: 1.0980s, d_loss: 0.07878353, g_loss: 5.66948128, rnn_loss: 0.13549194\n",
      "step: [274/553] time: 1.0296s, d_loss: 0.44783968, g_loss: 5.69194078, rnn_loss: 0.09795155\n",
      "step: [329/553] time: 1.0871s, d_loss: 0.07858875, g_loss: 5.41580820, rnn_loss: 0.18274955\n",
      "step: [384/553] time: 1.0837s, d_loss: 0.19605020, g_loss: 3.47294474, rnn_loss: 0.10780229\n",
      "step: [439/553] time: 1.1003s, d_loss: 0.26570195, g_loss: 3.95760155, rnn_loss: 0.12265225\n",
      "step: [494/553] time: 1.0642s, d_loss: 0.66483748, g_loss: 5.31098080, rnn_loss: 0.13041872\n",
      "step: [549/553] time: 1.0578s, d_loss: 0.09613413, g_loss: 5.45023727, rnn_loss: 0.16829085\n",
      " ** Epoch 46 took 606.743965s\n",
      "step: [54/553] time: 1.1168s, d_loss: 0.79162449, g_loss: 3.28230715, rnn_loss: 0.07728013\n",
      "step: [109/553] time: 1.0740s, d_loss: 0.40755689, g_loss: 2.45661473, rnn_loss: 0.22948979\n",
      "step: [164/553] time: 1.0792s, d_loss: 0.47515872, g_loss: 4.98824549, rnn_loss: 0.25911474\n",
      "step: [219/553] time: 1.1140s, d_loss: 0.29619187, g_loss: 7.82268906, rnn_loss: 0.12717937\n",
      "step: [274/553] time: 1.0681s, d_loss: 0.20176190, g_loss: 4.18648958, rnn_loss: 0.25925130\n",
      "step: [329/553] time: 1.0891s, d_loss: 0.31792799, g_loss: 2.15673494, rnn_loss: 0.19478536\n",
      "step: [384/553] time: 1.0541s, d_loss: 0.03979721, g_loss: 5.63712168, rnn_loss: 0.12066892\n",
      "step: [439/553] time: 1.1052s, d_loss: 0.12528569, g_loss: 3.15411949, rnn_loss: 0.18290976\n",
      "step: [494/553] time: 1.1464s, d_loss: 0.71470815, g_loss: 6.85336256, rnn_loss: 0.13940148\n",
      "step: [549/553] time: 1.0811s, d_loss: 0.11453967, g_loss: 4.15149307, rnn_loss: 0.09869158\n",
      " ** Epoch 47 took 603.352819s\n",
      "step: [54/553] time: 1.1159s, d_loss: 0.04118728, g_loss: 8.34600449, rnn_loss: 0.10123315\n",
      "step: [109/553] time: 1.1190s, d_loss: 1.02788436, g_loss: 2.91087890, rnn_loss: 0.25151655\n",
      "step: [164/553] time: 1.1569s, d_loss: 0.31254426, g_loss: 2.74469757, rnn_loss: 0.10670087\n",
      "step: [219/553] time: 1.0407s, d_loss: 1.78998148, g_loss: 1.81079888, rnn_loss: 0.15171665\n",
      "step: [274/553] time: 1.0627s, d_loss: 0.11673557, g_loss: 7.19880104, rnn_loss: 0.13329770\n",
      "step: [329/553] time: 1.0504s, d_loss: 0.05729605, g_loss: 8.33523655, rnn_loss: 0.08483218\n",
      "step: [384/553] time: 1.0346s, d_loss: 0.27697051, g_loss: 2.96013498, rnn_loss: 0.21070389\n",
      "step: [439/553] time: 1.1025s, d_loss: 1.27242887, g_loss: 4.91880274, rnn_loss: 0.17206693\n",
      "step: [494/553] time: 1.1418s, d_loss: 0.19802725, g_loss: 3.35150814, rnn_loss: 0.12003796\n",
      "step: [549/553] time: 1.0822s, d_loss: 0.21530665, g_loss: 5.50442410, rnn_loss: 0.17358187\n",
      " ** Epoch 48 took 607.276867s\n",
      "step: [54/553] time: 1.0583s, d_loss: 0.05803299, g_loss: 5.93541622, rnn_loss: 0.20144971\n",
      "step: [109/553] time: 1.0445s, d_loss: 0.07536472, g_loss: 3.77791762, rnn_loss: 0.04670900\n",
      "step: [164/553] time: 1.1061s, d_loss: 0.81924480, g_loss: 2.82837439, rnn_loss: 0.16386935\n",
      "step: [219/553] time: 1.0917s, d_loss: 1.09550416, g_loss: 4.96732807, rnn_loss: 0.08192844\n",
      "step: [274/553] time: 1.1195s, d_loss: 1.27834260, g_loss: 2.96101046, rnn_loss: 0.20288408\n",
      "step: [329/553] time: 1.0929s, d_loss: 0.76041406, g_loss: 0.47288492, rnn_loss: 0.12916304\n",
      "step: [384/553] time: 1.0568s, d_loss: 1.07372522, g_loss: 4.87003279, rnn_loss: 0.12547366\n",
      "step: [439/553] time: 1.1270s, d_loss: 0.04419412, g_loss: 4.37672901, rnn_loss: 0.09073213\n",
      "step: [494/553] time: 1.0808s, d_loss: 0.09078238, g_loss: 3.35185218, rnn_loss: 0.21182361\n",
      "step: [549/553] time: 1.1406s, d_loss: 0.11009898, g_loss: 7.74600983, rnn_loss: 0.18481250\n",
      " ** Epoch 49 took 611.867797s\n",
      "step: [54/553] time: 1.1431s, d_loss: 0.49794731, g_loss: 5.96117163, rnn_loss: 0.12471032\n",
      "step: [109/553] time: 1.0576s, d_loss: 0.06232192, g_loss: 5.17884254, rnn_loss: 0.14358599\n",
      "step: [164/553] time: 1.1576s, d_loss: 0.01528252, g_loss: 9.90076447, rnn_loss: 0.16312535\n",
      "step: [219/553] time: 1.1203s, d_loss: 0.16890982, g_loss: 5.33355522, rnn_loss: 0.08776301\n",
      "step: [274/553] time: 1.0407s, d_loss: 0.10478589, g_loss: 3.69102812, rnn_loss: 0.19234182\n",
      "step: [329/553] time: 1.1128s, d_loss: 0.09923214, g_loss: 5.56001091, rnn_loss: 0.12447356\n",
      "step: [384/553] time: 1.0381s, d_loss: 0.32476676, g_loss: 5.54781008, rnn_loss: 0.04215327\n",
      "step: [439/553] time: 1.1033s, d_loss: 0.49728906, g_loss: 0.70775914, rnn_loss: 0.15006076\n",
      "step: [494/553] time: 1.1453s, d_loss: 0.06583314, g_loss: 3.44925833, rnn_loss: 0.19187763\n",
      "step: [549/553] time: 1.1635s, d_loss: 0.27113318, g_loss: 3.82218885, rnn_loss: 0.12889621\n",
      " ** Epoch 50 took 614.565964s\n",
      "step: [54/553] time: 1.1074s, d_loss: 0.16954920, g_loss: 3.15840626, rnn_loss: 0.06777236\n",
      "step: [109/553] time: 1.0561s, d_loss: 0.05536921, g_loss: 3.08054209, rnn_loss: 0.09030248\n",
      "step: [164/553] time: 1.1028s, d_loss: 0.17036831, g_loss: 4.03295326, rnn_loss: 0.14737347\n",
      "step: [219/553] time: 1.1414s, d_loss: 0.49290100, g_loss: 4.74275732, rnn_loss: 0.17491135\n",
      "step: [274/553] time: 1.1316s, d_loss: 1.29837894, g_loss: 8.01504898, rnn_loss: 0.15919942\n",
      "step: [329/553] time: 1.1259s, d_loss: 1.51228857, g_loss: 0.58440787, rnn_loss: 0.17513441\n",
      "step: [384/553] time: 1.1024s, d_loss: 0.38821948, g_loss: 5.44821930, rnn_loss: 0.13170624\n",
      "step: [439/553] time: 1.1722s, d_loss: 0.24254610, g_loss: 3.35561037, rnn_loss: 0.11167450\n",
      "step: [494/553] time: 1.0334s, d_loss: 0.15976214, g_loss: 3.99825954, rnn_loss: 0.23234533\n",
      "step: [549/553] time: 1.0876s, d_loss: 0.24998091, g_loss: 4.84811974, rnn_loss: 0.13493104\n",
      " ** Epoch 51 took 611.083081s\n",
      "step: [54/553] time: 1.1162s, d_loss: 0.06261348, g_loss: 4.21275234, rnn_loss: 0.19672760\n",
      "step: [109/553] time: 1.1640s, d_loss: 2.39924812, g_loss: 0.98125952, rnn_loss: 0.17725319\n",
      "step: [164/553] time: 1.1199s, d_loss: 0.35171628, g_loss: 4.14946795, rnn_loss: 0.10961490\n",
      "step: [219/553] time: 1.1008s, d_loss: 0.75629175, g_loss: 1.10691309, rnn_loss: 0.19780770\n",
      "step: [274/553] time: 1.0669s, d_loss: 1.59975922, g_loss: 4.31227970, rnn_loss: 0.18060592\n",
      "step: [329/553] time: 1.1370s, d_loss: 0.39417279, g_loss: 3.02483940, rnn_loss: 0.29762530\n",
      "step: [384/553] time: 1.0600s, d_loss: 0.47226146, g_loss: 3.71455979, rnn_loss: 0.15621334\n",
      "step: [439/553] time: 1.1420s, d_loss: 0.16313902, g_loss: 3.04576898, rnn_loss: 0.16363388\n",
      "step: [494/553] time: 1.0095s, d_loss: 0.06504489, g_loss: 7.31503201, rnn_loss: 0.18501784\n",
      "step: [549/553] time: 1.1973s, d_loss: 0.13529868, g_loss: 6.06048679, rnn_loss: 0.17184070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** Epoch 52 took 614.755042s\n",
      "step: [54/553] time: 1.1400s, d_loss: 0.12795842, g_loss: 2.00323296, rnn_loss: 0.17842087\n",
      "step: [109/553] time: 1.1137s, d_loss: 0.11075994, g_loss: 2.92646718, rnn_loss: 0.16196865\n",
      "step: [164/553] time: 1.1491s, d_loss: 0.26028189, g_loss: 7.75607967, rnn_loss: 0.10364932\n",
      "step: [219/553] time: 1.2100s, d_loss: 0.13190362, g_loss: 5.01979256, rnn_loss: 0.03807469\n",
      "step: [274/553] time: 1.1253s, d_loss: 0.37158963, g_loss: 6.13444567, rnn_loss: 0.13675097\n",
      "step: [329/553] time: 1.0972s, d_loss: 0.11060577, g_loss: 3.27454519, rnn_loss: 0.17352235\n",
      "step: [384/553] time: 1.1111s, d_loss: 0.01052710, g_loss: 8.65362167, rnn_loss: 0.10426150\n",
      "step: [439/553] time: 1.1317s, d_loss: 0.06399741, g_loss: 3.26033354, rnn_loss: 0.21085273\n",
      "step: [494/553] time: 1.1462s, d_loss: 0.30294192, g_loss: 5.87197399, rnn_loss: 0.13479081\n",
      "step: [549/553] time: 1.1583s, d_loss: 0.09920631, g_loss: 3.61588407, rnn_loss: 0.03312340\n",
      " ** Epoch 53 took 611.568812s\n",
      "step: [54/553] time: 1.0340s, d_loss: 0.09712301, g_loss: 4.25225496, rnn_loss: 0.21856804\n",
      "step: [109/553] time: 1.0770s, d_loss: 0.19257984, g_loss: 6.07324648, rnn_loss: 0.10570318\n",
      "step: [164/553] time: 1.0861s, d_loss: 0.11552922, g_loss: 3.15108728, rnn_loss: 0.06907426\n",
      "step: [219/553] time: 1.0673s, d_loss: 0.07549454, g_loss: 2.90054035, rnn_loss: 0.16762535\n",
      "step: [274/553] time: 1.1108s, d_loss: 0.02925590, g_loss: 9.61796761, rnn_loss: 0.17735106\n",
      "step: [329/553] time: 1.0705s, d_loss: 0.04456399, g_loss: 2.79359651, rnn_loss: 0.04803290\n",
      "step: [384/553] time: 1.1113s, d_loss: 0.12658142, g_loss: 3.28373837, rnn_loss: 0.13669088\n",
      "step: [439/553] time: 1.0247s, d_loss: 0.43401119, g_loss: 4.49937248, rnn_loss: 0.12690374\n",
      "step: [494/553] time: 1.0766s, d_loss: 0.72691405, g_loss: 3.44083762, rnn_loss: 0.18786353\n",
      "step: [549/553] time: 1.0825s, d_loss: 0.00975633, g_loss: 7.11214352, rnn_loss: 0.14486986\n",
      " ** Epoch 54 took 610.152385s\n",
      "step: [54/553] time: 1.0381s, d_loss: 0.17937189, g_loss: 3.99403524, rnn_loss: 0.17724040\n",
      "step: [109/553] time: 1.1352s, d_loss: 0.47739133, g_loss: 2.93406296, rnn_loss: 0.16039425\n",
      "step: [164/553] time: 1.0963s, d_loss: 0.25617641, g_loss: 4.75597858, rnn_loss: 0.13776231\n",
      "step: [219/553] time: 1.1602s, d_loss: 0.79894674, g_loss: 4.22547817, rnn_loss: 0.05336219\n",
      "step: [274/553] time: 1.0661s, d_loss: 0.13118774, g_loss: 2.12538815, rnn_loss: 0.11235765\n",
      "step: [329/553] time: 1.0327s, d_loss: 0.02054338, g_loss: 5.21750832, rnn_loss: 0.09775275\n",
      "step: [384/553] time: 1.0767s, d_loss: 0.36724812, g_loss: 3.40778065, rnn_loss: 0.14170790\n",
      "step: [439/553] time: 1.0949s, d_loss: 0.09937334, g_loss: 2.68175077, rnn_loss: 0.13521953\n",
      "step: [494/553] time: 1.0676s, d_loss: 0.91444468, g_loss: 1.27463841, rnn_loss: 0.04397474\n",
      "step: [549/553] time: 1.0766s, d_loss: 0.10119734, g_loss: 4.08054447, rnn_loss: 0.13909516\n",
      " ** Epoch 55 took 602.046460s\n",
      "step: [54/553] time: 1.1088s, d_loss: 0.05653064, g_loss: 4.45368528, rnn_loss: 0.10738190\n",
      "step: [109/553] time: 1.0520s, d_loss: 0.24617903, g_loss: 4.43694592, rnn_loss: 0.12767793\n",
      "step: [164/553] time: 1.0926s, d_loss: 0.13321026, g_loss: 5.46672726, rnn_loss: 0.10896932\n",
      "step: [219/553] time: 1.1531s, d_loss: 0.09062291, g_loss: 3.61786103, rnn_loss: 0.04716058\n",
      "step: [274/553] time: 1.0373s, d_loss: 0.68188435, g_loss: 2.76026964, rnn_loss: 0.15294841\n",
      "step: [329/553] time: 1.0680s, d_loss: 0.04233871, g_loss: 5.20946455, rnn_loss: 0.15271586\n",
      "step: [384/553] time: 1.0573s, d_loss: 0.10194775, g_loss: 5.07738972, rnn_loss: 0.06766850\n",
      "step: [439/553] time: 1.0852s, d_loss: 0.30390960, g_loss: 2.33235455, rnn_loss: 0.08575545\n",
      "step: [494/553] time: 1.0449s, d_loss: 0.25854543, g_loss: 5.15058851, rnn_loss: 0.06232046\n",
      "step: [549/553] time: 1.1068s, d_loss: 0.17836381, g_loss: 7.71846581, rnn_loss: 0.13056593\n",
      " ** Epoch 56 took 603.271300s\n",
      "step: [54/553] time: 1.0765s, d_loss: 0.05590253, g_loss: 6.54962492, rnn_loss: 0.06445061\n",
      "step: [109/553] time: 1.1363s, d_loss: 0.18025708, g_loss: 5.13940096, rnn_loss: 0.07517213\n",
      "step: [164/553] time: 1.0813s, d_loss: 0.08509573, g_loss: 4.81431484, rnn_loss: 0.16402471\n",
      "step: [219/553] time: 1.1212s, d_loss: 1.09283531, g_loss: 5.69734573, rnn_loss: 0.18892634\n",
      "step: [274/553] time: 1.1206s, d_loss: 0.70087463, g_loss: 1.29412508, rnn_loss: 0.13118632\n",
      "step: [329/553] time: 1.1525s, d_loss: 0.48578554, g_loss: 3.94132948, rnn_loss: 0.19053598\n",
      "step: [384/553] time: 1.0624s, d_loss: 0.13440908, g_loss: 3.58809900, rnn_loss: 0.18254736\n",
      "step: [439/553] time: 1.0959s, d_loss: 0.28641301, g_loss: 3.32189274, rnn_loss: 0.16427028\n",
      "step: [494/553] time: 1.0192s, d_loss: 0.12792648, g_loss: 3.47079420, rnn_loss: 0.10116401\n",
      "step: [549/553] time: 1.0784s, d_loss: 0.05841548, g_loss: 3.81479931, rnn_loss: 0.14270721\n",
      " ** Epoch 57 took 603.729633s\n",
      "step: [54/553] time: 1.0687s, d_loss: 0.19054991, g_loss: 4.04013348, rnn_loss: 0.16070385\n",
      "step: [109/553] time: 1.1183s, d_loss: 0.09064509, g_loss: 4.99964523, rnn_loss: 0.17244183\n",
      "step: [164/553] time: 1.0426s, d_loss: 0.08861607, g_loss: 3.33217335, rnn_loss: 0.16135596\n",
      "step: [219/553] time: 1.0251s, d_loss: 0.58897907, g_loss: 3.42806244, rnn_loss: 0.14213097\n",
      "step: [274/553] time: 1.0794s, d_loss: 0.16514069, g_loss: 3.45866346, rnn_loss: 0.11163972\n",
      "step: [329/553] time: 1.1450s, d_loss: 0.10102715, g_loss: 4.39746380, rnn_loss: 0.15899724\n",
      "step: [384/553] time: 1.1104s, d_loss: 0.03140915, g_loss: 3.61037540, rnn_loss: 0.26929283\n",
      "step: [439/553] time: 1.0175s, d_loss: 0.23229526, g_loss: 5.16485405, rnn_loss: 0.15669835\n",
      "step: [494/553] time: 1.0597s, d_loss: 0.23438460, g_loss: 3.94577241, rnn_loss: 0.10690062\n",
      "step: [549/553] time: 1.1042s, d_loss: 0.20069732, g_loss: 4.07664204, rnn_loss: 0.12737206\n",
      " ** Epoch 58 took 601.658712s\n",
      "step: [54/553] time: 1.1588s, d_loss: 0.06804976, g_loss: 6.12213516, rnn_loss: 0.17411032\n",
      "step: [109/553] time: 1.0844s, d_loss: 0.60807204, g_loss: 2.27100754, rnn_loss: 0.09864566\n",
      "step: [164/553] time: 1.0872s, d_loss: 0.20641220, g_loss: 5.51505232, rnn_loss: 0.21951120\n",
      "step: [219/553] time: 1.1060s, d_loss: 0.10449993, g_loss: 3.81174254, rnn_loss: 0.11908714\n",
      "step: [274/553] time: 1.0553s, d_loss: 0.05835919, g_loss: 5.11588144, rnn_loss: 0.15057799\n",
      "step: [329/553] time: 1.0680s, d_loss: 0.43675667, g_loss: 2.72581649, rnn_loss: 0.07667476\n",
      "step: [384/553] time: 1.1549s, d_loss: 0.40548256, g_loss: 2.98674726, rnn_loss: 0.09941232\n",
      "step: [439/553] time: 1.1181s, d_loss: 0.15763138, g_loss: 4.71497726, rnn_loss: 0.12011021\n",
      "step: [494/553] time: 1.1091s, d_loss: 0.20146169, g_loss: 3.75764680, rnn_loss: 0.17652097\n",
      "step: [549/553] time: 1.0685s, d_loss: 0.29760218, g_loss: 2.66024280, rnn_loss: 0.18370192\n",
      " ** Epoch 59 took 605.564289s\n",
      "step: [54/553] time: 1.1033s, d_loss: 0.02180395, g_loss: 4.64127159, rnn_loss: 0.14794829\n",
      "step: [109/553] time: 1.1125s, d_loss: 0.06238200, g_loss: 5.31946611, rnn_loss: 0.09284481\n",
      "step: [164/553] time: 1.0754s, d_loss: 0.07706268, g_loss: 5.28715563, rnn_loss: 0.19629130\n",
      "step: [219/553] time: 1.0308s, d_loss: 0.27417415, g_loss: 3.56337547, rnn_loss: 0.11296716\n",
      "step: [274/553] time: 1.0453s, d_loss: 0.27660438, g_loss: 3.37992358, rnn_loss: 0.14259203\n",
      "step: [329/553] time: 1.0802s, d_loss: 0.07263251, g_loss: 5.71923971, rnn_loss: 0.11073044\n",
      "step: [384/553] time: 1.1927s, d_loss: 0.05048402, g_loss: 4.24097347, rnn_loss: 0.19331396\n",
      "step: [439/553] time: 1.1769s, d_loss: 0.27070227, g_loss: 1.98026490, rnn_loss: 0.07452914\n",
      "step: [494/553] time: 1.0792s, d_loss: 0.09612669, g_loss: 4.30680847, rnn_loss: 0.13304409\n",
      "step: [549/553] time: 1.0934s, d_loss: 0.22162844, g_loss: 1.89828897, rnn_loss: 0.16934174\n",
      " ** Epoch 60 took 606.821047s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "step: [54/553] time: 1.0910s, d_loss: 0.37004545, g_loss: 3.94411182, rnn_loss: 0.10996418\n",
      "step: [109/553] time: 1.0680s, d_loss: 0.16109541, g_loss: 4.53008080, rnn_loss: 0.11949990\n",
      "step: [164/553] time: 1.0997s, d_loss: 0.08741775, g_loss: 3.68439150, rnn_loss: 0.12644751\n",
      "step: [219/553] time: 1.0569s, d_loss: 0.08993179, g_loss: 1.53553867, rnn_loss: 0.10580830\n",
      "step: [274/553] time: 1.0199s, d_loss: 0.35632491, g_loss: 6.68388176, rnn_loss: 0.03617696\n",
      "step: [329/553] time: 1.1301s, d_loss: 0.65437758, g_loss: 5.12814808, rnn_loss: 0.24935469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [384/553] time: 1.1210s, d_loss: 0.12887579, g_loss: 9.22751427, rnn_loss: 0.14420411\n",
      "step: [439/553] time: 1.1267s, d_loss: 0.14085704, g_loss: 3.97485375, rnn_loss: 0.04304415\n",
      "step: [494/553] time: 1.1230s, d_loss: 0.08559012, g_loss: 4.90691662, rnn_loss: 0.04822606\n",
      "step: [549/553] time: 1.0572s, d_loss: 0.17557904, g_loss: 4.27266407, rnn_loss: 0.10463867\n",
      " ** Epoch 61 took 613.942306s\n",
      "step: [54/553] time: 1.1384s, d_loss: 0.50990605, g_loss: 3.25266552, rnn_loss: 0.10464712\n",
      "step: [109/553] time: 1.1119s, d_loss: 0.12600224, g_loss: 4.75193882, rnn_loss: 0.16195667\n",
      "step: [164/553] time: 1.0879s, d_loss: 0.29363936, g_loss: 2.97237062, rnn_loss: 0.08551756\n",
      "step: [219/553] time: 1.0846s, d_loss: 0.22568159, g_loss: 2.53418732, rnn_loss: 0.11687734\n",
      "step: [274/553] time: 1.0767s, d_loss: 0.32009849, g_loss: 5.75840044, rnn_loss: 0.14245069\n",
      "step: [329/553] time: 1.0987s, d_loss: 0.05218803, g_loss: 4.77447510, rnn_loss: 0.07700042\n",
      "step: [384/553] time: 1.1387s, d_loss: 0.03741790, g_loss: 3.94046783, rnn_loss: 0.05501381\n",
      "step: [439/553] time: 1.1626s, d_loss: 0.60007179, g_loss: 5.34663200, rnn_loss: 0.18327534\n",
      "step: [494/553] time: 1.2637s, d_loss: 0.28238091, g_loss: 6.70882797, rnn_loss: 0.13882837\n",
      "step: [549/553] time: 1.1213s, d_loss: 0.17185412, g_loss: 3.49904871, rnn_loss: 0.16819386\n",
      " ** Epoch 62 took 618.898539s\n",
      "step: [54/553] time: 1.1406s, d_loss: 0.68877983, g_loss: 3.48971486, rnn_loss: 0.17675513\n",
      "step: [109/553] time: 1.1514s, d_loss: 0.42376804, g_loss: 5.35847187, rnn_loss: 0.12356655\n",
      "step: [164/553] time: 1.1654s, d_loss: 0.73481667, g_loss: 11.51832581, rnn_loss: 0.13153937\n",
      "step: [219/553] time: 1.1374s, d_loss: 0.06765223, g_loss: 5.49306822, rnn_loss: 0.10048909\n",
      "step: [274/553] time: 1.0802s, d_loss: 0.19288373, g_loss: 2.94240284, rnn_loss: 0.13554299\n",
      "step: [329/553] time: 1.1330s, d_loss: 0.58921826, g_loss: 2.99591875, rnn_loss: 0.16651270\n",
      "step: [384/553] time: 1.1789s, d_loss: 1.09861636, g_loss: 0.22220352, rnn_loss: 0.16216105\n",
      "step: [439/553] time: 1.1608s, d_loss: 0.36430007, g_loss: 6.25562716, rnn_loss: 0.16349855\n",
      "step: [494/553] time: 1.1010s, d_loss: 0.77065969, g_loss: 2.61061168, rnn_loss: 0.05325441\n",
      "step: [549/553] time: 1.2606s, d_loss: 0.06761312, g_loss: 4.89210224, rnn_loss: 0.13407159\n",
      " ** Epoch 63 took 620.502831s\n",
      "step: [54/553] time: 1.1370s, d_loss: 0.03669585, g_loss: 4.70387077, rnn_loss: 0.12893754\n",
      "step: [109/553] time: 1.0201s, d_loss: 0.08730035, g_loss: 3.52299380, rnn_loss: 0.03402570\n",
      "step: [164/553] time: 1.0317s, d_loss: 0.05656964, g_loss: 5.80672646, rnn_loss: 0.20416456\n",
      "step: [219/553] time: 1.1118s, d_loss: 0.01594719, g_loss: 10.73777008, rnn_loss: 0.03991114\n",
      "step: [274/553] time: 1.1718s, d_loss: 1.10644054, g_loss: 6.43841076, rnn_loss: 0.10096480\n",
      "step: [329/553] time: 1.1280s, d_loss: 0.08586790, g_loss: 4.09653759, rnn_loss: 0.14451925\n",
      "step: [384/553] time: 1.2326s, d_loss: 0.37485552, g_loss: 3.21100569, rnn_loss: 0.15262432\n",
      "step: [439/553] time: 1.1621s, d_loss: 0.05497154, g_loss: 6.13447285, rnn_loss: 0.13408150\n",
      "step: [494/553] time: 1.0752s, d_loss: 1.40629590, g_loss: 3.18479848, rnn_loss: 0.11650792\n",
      "step: [549/553] time: 1.1242s, d_loss: 0.80118054, g_loss: 4.40132809, rnn_loss: 0.08340181\n",
      " ** Epoch 64 took 620.248857s\n",
      "step: [54/553] time: 1.0782s, d_loss: 0.07610262, g_loss: 3.92656183, rnn_loss: 0.13762847\n",
      "step: [109/553] time: 1.1164s, d_loss: 2.07015896, g_loss: 5.72862244, rnn_loss: 0.25458694\n",
      "step: [164/553] time: 1.1229s, d_loss: 0.18260506, g_loss: 6.56175232, rnn_loss: 0.08909070\n",
      "step: [219/553] time: 1.1186s, d_loss: 0.41291857, g_loss: 3.70357466, rnn_loss: 0.19468117\n",
      "step: [274/553] time: 1.1060s, d_loss: 0.06090706, g_loss: 6.08081913, rnn_loss: 0.12761569\n",
      "step: [329/553] time: 1.1762s, d_loss: 0.50396055, g_loss: 6.18568277, rnn_loss: 0.21577987\n",
      "step: [384/553] time: 1.0588s, d_loss: 0.18847185, g_loss: 4.17011356, rnn_loss: 0.11314061\n",
      "step: [439/553] time: 1.1538s, d_loss: 0.18266019, g_loss: 2.17253923, rnn_loss: 0.06765219\n",
      "step: [494/553] time: 1.0914s, d_loss: 0.07308888, g_loss: 8.65474510, rnn_loss: 0.12413199\n",
      "step: [549/553] time: 1.0573s, d_loss: 0.10240909, g_loss: 6.63163710, rnn_loss: 0.08451203\n",
      " ** Epoch 65 took 609.755132s\n",
      "step: [54/553] time: 1.0712s, d_loss: 0.24083166, g_loss: 2.99528289, rnn_loss: 0.17639738\n",
      "step: [109/553] time: 1.0910s, d_loss: 0.62140644, g_loss: 3.93661261, rnn_loss: 0.12504482\n",
      "step: [164/553] time: 1.0980s, d_loss: 0.05676793, g_loss: 3.89157104, rnn_loss: 0.10254434\n",
      "step: [219/553] time: 1.1236s, d_loss: 0.32183850, g_loss: 2.91772890, rnn_loss: 0.10654393\n",
      "step: [274/553] time: 1.1058s, d_loss: 0.07571337, g_loss: 5.43464947, rnn_loss: 0.11583022\n",
      "step: [329/553] time: 1.1376s, d_loss: 0.13929828, g_loss: 2.39454961, rnn_loss: 0.19382514\n",
      "step: [384/553] time: 1.0604s, d_loss: 0.48840675, g_loss: 6.91786385, rnn_loss: 0.06682210\n",
      "step: [439/553] time: 1.0251s, d_loss: 0.07824603, g_loss: 6.44365311, rnn_loss: 0.13081011\n",
      "step: [494/553] time: 1.0777s, d_loss: 0.70053977, g_loss: 4.10330105, rnn_loss: 0.19784462\n",
      "step: [549/553] time: 1.0275s, d_loss: 0.56150007, g_loss: 9.10308838, rnn_loss: 0.09489375\n",
      " ** Epoch 66 took 607.610761s\n",
      "step: [54/553] time: 1.1068s, d_loss: 0.42792779, g_loss: 5.60294390, rnn_loss: 0.13530380\n",
      "step: [109/553] time: 1.1292s, d_loss: 0.12702008, g_loss: 3.40039635, rnn_loss: 0.08563951\n",
      "step: [164/553] time: 1.1091s, d_loss: 0.21217243, g_loss: 6.39184332, rnn_loss: 0.18069197\n",
      "step: [219/553] time: 1.1352s, d_loss: 0.12320289, g_loss: 4.07201338, rnn_loss: 0.10740319\n",
      "step: [274/553] time: 1.1264s, d_loss: 0.12388907, g_loss: 3.81487083, rnn_loss: 0.04093163\n",
      "step: [329/553] time: 1.0603s, d_loss: 0.14698955, g_loss: 3.79449034, rnn_loss: 0.09208083\n",
      "step: [384/553] time: 1.2071s, d_loss: 0.03779379, g_loss: 3.67279911, rnn_loss: 0.13971846\n",
      "step: [439/553] time: 1.1474s, d_loss: 0.15242702, g_loss: 3.64239001, rnn_loss: 0.12010172\n",
      "step: [494/553] time: 1.1239s, d_loss: 0.08470522, g_loss: 3.24342251, rnn_loss: 0.05831384\n",
      "step: [549/553] time: 1.1076s, d_loss: 0.34530324, g_loss: 10.68234253, rnn_loss: 0.13582349\n",
      " ** Epoch 67 took 611.218874s\n",
      "step: [54/553] time: 1.0983s, d_loss: 0.41805080, g_loss: 5.01832819, rnn_loss: 0.07643211\n",
      "step: [109/553] time: 1.2070s, d_loss: 0.11721789, g_loss: 4.22571278, rnn_loss: 0.10052633\n",
      "step: [164/553] time: 1.1199s, d_loss: 0.20326179, g_loss: 4.39323854, rnn_loss: 0.09479439\n",
      "step: [219/553] time: 1.1247s, d_loss: 0.03099785, g_loss: 4.29386139, rnn_loss: 0.06776699\n",
      "step: [274/553] time: 1.1200s, d_loss: 1.20834076, g_loss: 6.56240273, rnn_loss: 0.11926382\n",
      "step: [329/553] time: 1.1100s, d_loss: 0.13525854, g_loss: 4.45160627, rnn_loss: 0.11185320\n",
      "step: [384/553] time: 1.0310s, d_loss: 0.04554930, g_loss: 6.55258751, rnn_loss: 0.14194690\n",
      "step: [439/553] time: 1.0542s, d_loss: 0.02474543, g_loss: 9.03263569, rnn_loss: 0.11156705\n",
      "step: [494/553] time: 1.0425s, d_loss: 0.06184774, g_loss: 4.30543041, rnn_loss: 0.11666213\n",
      "step: [549/553] time: 1.1217s, d_loss: 0.05316450, g_loss: 4.64515495, rnn_loss: 0.06344752\n",
      " ** Epoch 68 took 608.443944s\n",
      "step: [54/553] time: 1.0020s, d_loss: 0.12119626, g_loss: 2.59264565, rnn_loss: 0.11532110\n",
      "step: [109/553] time: 1.1461s, d_loss: 0.41081771, g_loss: 6.47950220, rnn_loss: 0.12254968\n",
      "step: [164/553] time: 1.1674s, d_loss: 0.21446709, g_loss: 2.47676206, rnn_loss: 0.16654018\n",
      "step: [219/553] time: 1.1077s, d_loss: 0.11898376, g_loss: 7.47462749, rnn_loss: 0.07973880\n",
      "step: [274/553] time: 1.1226s, d_loss: 0.76285768, g_loss: 0.73147821, rnn_loss: 0.07069605\n",
      "step: [329/553] time: 1.0486s, d_loss: 1.20343280, g_loss: 0.93785137, rnn_loss: 0.16443746\n",
      "step: [384/553] time: 1.0939s, d_loss: 2.66861916, g_loss: 0.01624339, rnn_loss: 0.13027819\n",
      "step: [439/553] time: 1.1585s, d_loss: 0.04406975, g_loss: 5.33065414, rnn_loss: 0.09694145\n",
      "step: [494/553] time: 1.0949s, d_loss: 0.07454976, g_loss: 4.65470171, rnn_loss: 0.10752881\n",
      "step: [549/553] time: 1.0984s, d_loss: 0.23659247, g_loss: 3.14404035, rnn_loss: 0.05940481\n",
      " ** Epoch 69 took 612.719178s\n",
      "step: [54/553] time: 1.0920s, d_loss: 0.58377850, g_loss: 3.78815079, rnn_loss: 0.09662552\n",
      "step: [109/553] time: 1.1254s, d_loss: 0.04197095, g_loss: 4.47430515, rnn_loss: 0.07363485\n",
      "step: [164/553] time: 1.1073s, d_loss: 0.87308532, g_loss: 4.00562477, rnn_loss: 0.11532871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [219/553] time: 1.0363s, d_loss: 0.35391682, g_loss: 8.67548561, rnn_loss: 0.12321776\n",
      "step: [274/553] time: 1.1053s, d_loss: 0.30954057, g_loss: 4.11697006, rnn_loss: 0.22572039\n",
      "step: [329/553] time: 1.0623s, d_loss: 0.18921337, g_loss: 5.48306847, rnn_loss: 0.05057829\n",
      "step: [384/553] time: 1.0861s, d_loss: 0.79551917, g_loss: 1.44367707, rnn_loss: 0.19589119\n",
      "step: [439/553] time: 1.0659s, d_loss: 0.03164611, g_loss: 9.48096085, rnn_loss: 0.14052048\n",
      "step: [494/553] time: 1.1653s, d_loss: 0.18663324, g_loss: 3.78264546, rnn_loss: 0.06226755\n",
      "step: [549/553] time: 1.1451s, d_loss: 1.53490341, g_loss: 6.16805840, rnn_loss: 0.15233725\n",
      " ** Epoch 70 took 606.718659s\n",
      "step: [54/553] time: 1.0784s, d_loss: 0.08043879, g_loss: 5.60106277, rnn_loss: 0.04939846\n",
      "step: [109/553] time: 1.1557s, d_loss: 0.38688889, g_loss: 5.16584015, rnn_loss: 0.17420584\n",
      "step: [164/553] time: 1.0973s, d_loss: 0.14847413, g_loss: 2.93566942, rnn_loss: 0.18805940\n",
      "step: [219/553] time: 1.1023s, d_loss: 0.44590604, g_loss: 5.60227489, rnn_loss: 0.11378577\n",
      "step: [274/553] time: 1.1093s, d_loss: 1.01873016, g_loss: 1.07756758, rnn_loss: 0.10753059\n",
      "step: [329/553] time: 1.0872s, d_loss: 0.15190411, g_loss: 8.88572788, rnn_loss: 0.09358265\n",
      "step: [384/553] time: 1.0755s, d_loss: 3.03667593, g_loss: 5.71698809, rnn_loss: 0.11348949\n",
      "step: [439/553] time: 1.0662s, d_loss: 0.11874685, g_loss: 2.22241807, rnn_loss: 0.04507221\n",
      "step: [494/553] time: 1.0874s, d_loss: 0.41706353, g_loss: 3.89020896, rnn_loss: 0.24710175\n",
      "step: [549/553] time: 1.0629s, d_loss: 0.01435053, g_loss: 5.79037094, rnn_loss: 0.11365321\n",
      " ** Epoch 71 took 608.223952s\n",
      "step: [54/553] time: 1.0740s, d_loss: 0.04500230, g_loss: 3.32047796, rnn_loss: 0.03629839\n",
      "step: [109/553] time: 1.1610s, d_loss: 0.02472625, g_loss: 8.56275940, rnn_loss: 0.03966301\n",
      "step: [164/553] time: 1.1392s, d_loss: 0.44746733, g_loss: 5.59802437, rnn_loss: 0.14131862\n",
      "step: [219/553] time: 1.1256s, d_loss: 0.26195940, g_loss: 5.15434837, rnn_loss: 0.14250170\n",
      "step: [274/553] time: 1.0856s, d_loss: 0.04059796, g_loss: 5.46270180, rnn_loss: 0.11786475\n",
      "step: [329/553] time: 1.0526s, d_loss: 0.29014549, g_loss: 3.69198227, rnn_loss: 0.08628510\n",
      "step: [384/553] time: 1.0440s, d_loss: 0.39897054, g_loss: 8.64358711, rnn_loss: 0.16453220\n",
      "step: [439/553] time: 1.1751s, d_loss: 0.06282432, g_loss: 5.38465452, rnn_loss: 0.08506556\n",
      "step: [494/553] time: 1.0379s, d_loss: 0.46324819, g_loss: 5.72859097, rnn_loss: 0.14499962\n",
      "step: [549/553] time: 1.1110s, d_loss: 0.28997666, g_loss: 5.62806797, rnn_loss: 0.13197814\n",
      " ** Epoch 72 took 605.362781s\n",
      "step: [54/553] time: 1.0745s, d_loss: 2.53521013, g_loss: 8.36256790, rnn_loss: 0.09690762\n",
      "step: [109/553] time: 1.1549s, d_loss: 0.11129408, g_loss: 3.37519312, rnn_loss: 0.17093927\n",
      "step: [164/553] time: 1.0701s, d_loss: 2.73050714, g_loss: 1.21110570, rnn_loss: 0.17645407\n",
      "step: [219/553] time: 1.0968s, d_loss: 3.76470017, g_loss: 0.70688438, rnn_loss: 0.08340048\n",
      "step: [274/553] time: 1.1106s, d_loss: 0.17960976, g_loss: 3.85302234, rnn_loss: 0.15582886\n",
      "step: [329/553] time: 1.1200s, d_loss: 0.29502183, g_loss: 3.47179317, rnn_loss: 0.07370096\n",
      "step: [384/553] time: 1.1020s, d_loss: 0.12141636, g_loss: 3.82192588, rnn_loss: 0.06995446\n",
      "step: [439/553] time: 1.0899s, d_loss: 3.89071488, g_loss: 0.70058727, rnn_loss: 0.04281340\n",
      "step: [494/553] time: 1.0381s, d_loss: 0.17215931, g_loss: 4.72535610, rnn_loss: 0.11298998\n",
      "step: [549/553] time: 1.1669s, d_loss: 0.07647872, g_loss: 6.60620308, rnn_loss: 0.22113788\n",
      " ** Epoch 73 took 605.456977s\n",
      "step: [54/553] time: 1.0626s, d_loss: 0.02259069, g_loss: 6.90944672, rnn_loss: 0.15396714\n",
      "step: [109/553] time: 1.0754s, d_loss: 1.16915917, g_loss: 1.95278704, rnn_loss: 0.14631686\n",
      "step: [164/553] time: 1.0889s, d_loss: 0.17807324, g_loss: 3.35444117, rnn_loss: 0.14287780\n",
      "step: [219/553] time: 1.1453s, d_loss: 0.58357775, g_loss: 1.16800773, rnn_loss: 0.08878006\n",
      "step: [274/553] time: 1.0715s, d_loss: 0.03439207, g_loss: 5.29594326, rnn_loss: 0.09491196\n",
      "step: [329/553] time: 1.1279s, d_loss: 0.26550072, g_loss: 3.93266058, rnn_loss: 0.13881277\n",
      "step: [384/553] time: 1.0852s, d_loss: 0.59463638, g_loss: 3.92068624, rnn_loss: 0.14475556\n",
      "step: [439/553] time: 1.0588s, d_loss: 0.22598755, g_loss: 10.97600555, rnn_loss: 0.10588652\n",
      "step: [494/553] time: 1.0703s, d_loss: 0.19235961, g_loss: 2.49644113, rnn_loss: 0.10346004\n",
      "step: [549/553] time: 1.0013s, d_loss: 0.22759549, g_loss: 4.52495575, rnn_loss: 0.15311126\n",
      " ** Epoch 74 took 602.595974s\n",
      "step: [54/553] time: 1.0474s, d_loss: 0.02933186, g_loss: 5.70012569, rnn_loss: 0.16276762\n",
      "step: [109/553] time: 1.1178s, d_loss: 0.01682388, g_loss: 8.14477634, rnn_loss: 0.12579256\n",
      "step: [164/553] time: 1.1416s, d_loss: 0.36618498, g_loss: 8.84334183, rnn_loss: 0.12397786\n",
      "step: [219/553] time: 1.0364s, d_loss: 0.73702335, g_loss: 6.10431862, rnn_loss: 0.11876394\n",
      "step: [274/553] time: 1.0842s, d_loss: 1.71979487, g_loss: 11.95746994, rnn_loss: 0.08611974\n",
      "step: [329/553] time: 1.0542s, d_loss: 0.08391720, g_loss: 4.10483932, rnn_loss: 0.08614727\n",
      "step: [384/553] time: 1.0408s, d_loss: 0.91017908, g_loss: 5.54340553, rnn_loss: 0.05707669\n",
      "step: [439/553] time: 1.1010s, d_loss: 0.09545451, g_loss: 5.91819477, rnn_loss: 0.14556341\n",
      "step: [494/553] time: 1.1165s, d_loss: 0.46255571, g_loss: 5.85013676, rnn_loss: 0.11549100\n",
      "step: [549/553] time: 1.1145s, d_loss: 0.17458332, g_loss: 3.87486792, rnn_loss: 0.05409888\n",
      " ** Epoch 75 took 605.439845s\n",
      "step: [54/553] time: 1.0826s, d_loss: 0.06724609, g_loss: 4.20653868, rnn_loss: 0.11224575\n",
      "step: [109/553] time: 1.0857s, d_loss: 0.00773228, g_loss: 5.41701460, rnn_loss: 0.10305888\n",
      "step: [164/553] time: 1.0745s, d_loss: 0.26114973, g_loss: 8.92551327, rnn_loss: 0.05743571\n",
      "step: [219/553] time: 1.1090s, d_loss: 0.12220276, g_loss: 4.30202532, rnn_loss: 0.13918242\n",
      "step: [274/553] time: 1.0540s, d_loss: 0.18711396, g_loss: 3.81192589, rnn_loss: 0.09071410\n",
      "step: [329/553] time: 1.0910s, d_loss: 0.39993966, g_loss: 5.33632040, rnn_loss: 0.14296576\n",
      "step: [384/553] time: 1.0673s, d_loss: 0.03979205, g_loss: 7.89554691, rnn_loss: 0.14569250\n",
      "step: [439/553] time: 0.9947s, d_loss: 0.41931346, g_loss: 2.68981075, rnn_loss: 0.13864678\n",
      "step: [494/553] time: 1.0866s, d_loss: 0.02508116, g_loss: 6.03493500, rnn_loss: 0.09260157\n",
      "step: [549/553] time: 1.0398s, d_loss: 0.26948944, g_loss: 5.74979734, rnn_loss: 0.09938167\n",
      " ** Epoch 76 took 605.458821s\n",
      "step: [54/553] time: 1.0896s, d_loss: 0.19694826, g_loss: 7.58069754, rnn_loss: 0.07443010\n",
      "step: [109/553] time: 1.1183s, d_loss: 0.04220489, g_loss: 5.16370487, rnn_loss: 0.13818941\n",
      "step: [164/553] time: 1.1641s, d_loss: 0.01939604, g_loss: 4.96170092, rnn_loss: 0.01972508\n",
      "step: [219/553] time: 1.1293s, d_loss: 1.81801224, g_loss: 8.01820374, rnn_loss: 0.15810157\n",
      "step: [274/553] time: 1.1118s, d_loss: 0.01668788, g_loss: 5.31295490, rnn_loss: 0.01700692\n",
      "step: [329/553] time: 1.0467s, d_loss: 0.78336632, g_loss: 8.30904579, rnn_loss: 0.06318297\n",
      "step: [384/553] time: 1.1054s, d_loss: 0.06859027, g_loss: 4.66386414, rnn_loss: 0.12395037\n",
      "step: [439/553] time: 1.1181s, d_loss: 0.09086809, g_loss: 3.54188180, rnn_loss: 0.12607262\n",
      "step: [494/553] time: 1.0137s, d_loss: 0.10300035, g_loss: 4.24852180, rnn_loss: 0.13127661\n",
      "step: [549/553] time: 1.1058s, d_loss: 0.11811935, g_loss: 2.84830785, rnn_loss: 0.03260499\n",
      " ** Epoch 77 took 599.569172s\n",
      "step: [54/553] time: 1.1105s, d_loss: 1.48668551, g_loss: 4.27827311, rnn_loss: 0.09788279\n",
      "step: [109/553] time: 1.1287s, d_loss: 0.00834132, g_loss: 6.78239250, rnn_loss: 0.14107308\n",
      "step: [164/553] time: 1.1342s, d_loss: 0.15898475, g_loss: 5.14066792, rnn_loss: 0.08261883\n",
      "step: [219/553] time: 1.0441s, d_loss: 0.08924656, g_loss: 5.56946135, rnn_loss: 0.11169403\n",
      "step: [274/553] time: 1.1744s, d_loss: 2.23648047, g_loss: 1.08148265, rnn_loss: 0.06256689\n",
      "step: [329/553] time: 1.0928s, d_loss: 0.22530937, g_loss: 3.09937143, rnn_loss: 0.23821497\n",
      "step: [384/553] time: 1.1388s, d_loss: 0.32639024, g_loss: 5.68289089, rnn_loss: 0.06278168\n",
      "step: [439/553] time: 1.0951s, d_loss: 0.56903440, g_loss: 5.25485134, rnn_loss: 0.07973424\n",
      "step: [494/553] time: 1.1766s, d_loss: 0.03189795, g_loss: 4.53576469, rnn_loss: 0.13538529\n",
      "step: [549/553] time: 1.0836s, d_loss: 0.16414440, g_loss: 4.61691761, rnn_loss: 0.11882313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** Epoch 78 took 603.795231s\n",
      "step: [54/553] time: 1.0961s, d_loss: 0.02776862, g_loss: 4.52806187, rnn_loss: 0.06675075\n",
      "step: [109/553] time: 1.1004s, d_loss: 0.04729906, g_loss: 4.59502792, rnn_loss: 0.03766588\n",
      "step: [164/553] time: 1.0338s, d_loss: 0.21768245, g_loss: 4.93410826, rnn_loss: 0.15894610\n",
      "step: [219/553] time: 1.1098s, d_loss: 1.52419519, g_loss: 0.12348305, rnn_loss: 0.14648047\n",
      "step: [274/553] time: 1.0837s, d_loss: 0.16750506, g_loss: 9.52077961, rnn_loss: 0.06385315\n",
      "step: [329/553] time: 1.1859s, d_loss: 0.02729553, g_loss: 6.61132145, rnn_loss: 0.10553037\n",
      "step: [384/553] time: 1.0277s, d_loss: 0.18684706, g_loss: 4.34644938, rnn_loss: 0.24784532\n",
      "step: [439/553] time: 1.1583s, d_loss: 0.19538146, g_loss: 2.93559861, rnn_loss: 0.09688410\n",
      "step: [494/553] time: 0.9841s, d_loss: 0.16673419, g_loss: 5.62372303, rnn_loss: 0.12362865\n",
      "step: [549/553] time: 1.1125s, d_loss: 0.16693145, g_loss: 10.02689171, rnn_loss: 0.11736253\n",
      " ** Epoch 79 took 601.014220s\n",
      " ** new learning rate: 0.000100\n",
      "step: [54/553] time: 1.0691s, d_loss: 0.08633232, g_loss: 2.70214462, rnn_loss: 0.10614379\n",
      "step: [109/553] time: 1.0679s, d_loss: 0.54136884, g_loss: 4.22854567, rnn_loss: 0.12892205\n",
      "step: [164/553] time: 1.0812s, d_loss: 0.11862476, g_loss: 2.77846050, rnn_loss: 0.17132518\n",
      "step: [219/553] time: 1.0955s, d_loss: 0.03360716, g_loss: 4.13371944, rnn_loss: 0.10884057\n",
      "step: [274/553] time: 1.0392s, d_loss: 1.41836691, g_loss: 3.80987835, rnn_loss: 0.13071144\n",
      "step: [329/553] time: 1.0149s, d_loss: 0.12121700, g_loss: 5.22629356, rnn_loss: 0.14582264\n",
      "step: [384/553] time: 1.0722s, d_loss: 0.12181339, g_loss: 3.36407638, rnn_loss: 0.10113260\n",
      "step: [439/553] time: 1.0272s, d_loss: 1.20068371, g_loss: 4.01163530, rnn_loss: 0.21312222\n",
      "step: [494/553] time: 1.1027s, d_loss: 2.78855634, g_loss: 1.51679897, rnn_loss: 0.14371765\n",
      "step: [549/553] time: 1.0821s, d_loss: 0.02612458, g_loss: 3.72001863, rnn_loss: 0.02458088\n",
      " ** Epoch 80 took 603.129414s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "step: [54/553] time: 1.1115s, d_loss: 0.08375267, g_loss: 2.87878895, rnn_loss: 0.11592057\n",
      "step: [109/553] time: 1.2649s, d_loss: 0.33753681, g_loss: 2.64371347, rnn_loss: 0.08657406\n",
      "step: [164/553] time: 1.0366s, d_loss: 0.04449222, g_loss: 7.33911896, rnn_loss: 0.19884856\n",
      "step: [219/553] time: 1.0181s, d_loss: 0.80356753, g_loss: 2.84847212, rnn_loss: 0.13495910\n",
      "step: [274/553] time: 1.1190s, d_loss: 0.26398462, g_loss: 2.11252117, rnn_loss: 0.07939057\n",
      "step: [329/553] time: 1.1389s, d_loss: 0.50108159, g_loss: 2.21043062, rnn_loss: 0.07043228\n",
      "step: [384/553] time: 1.1413s, d_loss: 0.37872228, g_loss: 3.69006658, rnn_loss: 0.12783974\n",
      "step: [439/553] time: 1.1022s, d_loss: 0.12858286, g_loss: 7.21828079, rnn_loss: 0.10597762\n",
      "step: [494/553] time: 1.0918s, d_loss: 0.06695742, g_loss: 4.01147461, rnn_loss: 0.11657659\n",
      "step: [549/553] time: 1.0874s, d_loss: 0.65033996, g_loss: 2.61202741, rnn_loss: 0.14702997\n",
      " ** Epoch 81 took 607.524481s\n",
      "step: [54/553] time: 1.0313s, d_loss: 0.01948345, g_loss: 4.46507549, rnn_loss: 0.13829243\n",
      "step: [109/553] time: 1.0982s, d_loss: 0.32791194, g_loss: 4.23513126, rnn_loss: 0.07705490\n",
      "step: [164/553] time: 1.0157s, d_loss: 0.01711455, g_loss: 8.41892147, rnn_loss: 0.12258583\n",
      "step: [219/553] time: 1.0552s, d_loss: 0.02649530, g_loss: 3.92896223, rnn_loss: 0.11053430\n",
      "step: [274/553] time: 1.1005s, d_loss: 0.01533861, g_loss: 5.70039749, rnn_loss: 0.10169217\n",
      "step: [329/553] time: 1.0705s, d_loss: 0.38464481, g_loss: 7.90161133, rnn_loss: 0.19637884\n",
      "step: [384/553] time: 1.1050s, d_loss: 0.10836487, g_loss: 4.56866646, rnn_loss: 0.06998526\n",
      "step: [439/553] time: 1.0926s, d_loss: 0.02018338, g_loss: 6.66589928, rnn_loss: 0.07903805\n",
      "step: [494/553] time: 1.1245s, d_loss: 0.04969530, g_loss: 3.26338053, rnn_loss: 0.12846960\n",
      "step: [549/553] time: 1.0656s, d_loss: 0.06430637, g_loss: 3.45290470, rnn_loss: 0.10024537\n",
      " ** Epoch 82 took 610.601431s\n",
      "step: [54/553] time: 1.0993s, d_loss: 0.07956064, g_loss: 6.11214352, rnn_loss: 0.06783999\n",
      "step: [109/553] time: 1.0730s, d_loss: 0.01196735, g_loss: 5.51316643, rnn_loss: 0.06383641\n",
      "step: [164/553] time: 1.0632s, d_loss: 0.92596900, g_loss: 5.14809799, rnn_loss: 0.03543098\n",
      "step: [219/553] time: 1.1034s, d_loss: 0.48414600, g_loss: 2.85132766, rnn_loss: 0.16381626\n",
      "step: [274/553] time: 1.1343s, d_loss: 1.35029459, g_loss: 5.32821846, rnn_loss: 0.10006315\n",
      "step: [329/553] time: 1.0974s, d_loss: 0.36453685, g_loss: 3.07559514, rnn_loss: 0.08360958\n",
      "step: [384/553] time: 1.0961s, d_loss: 0.01204497, g_loss: 9.79463196, rnn_loss: 0.16297990\n",
      "step: [439/553] time: 1.0766s, d_loss: 0.16137153, g_loss: 1.76500869, rnn_loss: 0.15049249\n",
      "step: [494/553] time: 1.1602s, d_loss: 0.10756121, g_loss: 3.07220840, rnn_loss: 0.09456167\n",
      "step: [549/553] time: 1.0651s, d_loss: 0.01758615, g_loss: 5.11690426, rnn_loss: 0.12039666\n",
      " ** Epoch 83 took 611.312559s\n",
      "step: [54/553] time: 1.1720s, d_loss: 0.22245076, g_loss: 5.05688906, rnn_loss: 0.11508511\n",
      "step: [109/553] time: 1.0578s, d_loss: 0.09804709, g_loss: 3.30478096, rnn_loss: 0.05291728\n",
      "step: [164/553] time: 1.0884s, d_loss: 0.02711404, g_loss: 4.52822590, rnn_loss: 0.11043532\n",
      "step: [219/553] time: 1.0913s, d_loss: 0.03057366, g_loss: 4.26570272, rnn_loss: 0.14222854\n",
      "step: [274/553] time: 1.1018s, d_loss: 0.17500547, g_loss: 3.52296400, rnn_loss: 0.06047793\n",
      "step: [329/553] time: 1.0733s, d_loss: 0.46476975, g_loss: 4.12476254, rnn_loss: 0.19186005\n",
      "step: [384/553] time: 1.0057s, d_loss: 0.22640170, g_loss: 3.57414389, rnn_loss: 0.16523118\n",
      "step: [439/553] time: 1.1472s, d_loss: 0.01023235, g_loss: 5.68821287, rnn_loss: 0.06638220\n",
      "step: [494/553] time: 1.1125s, d_loss: 0.08876906, g_loss: 2.59590316, rnn_loss: 0.02396446\n",
      "step: [549/553] time: 1.0912s, d_loss: 0.00489370, g_loss: 6.31102371, rnn_loss: 0.08795340\n",
      " ** Epoch 84 took 608.323102s\n",
      "step: [54/553] time: 1.0763s, d_loss: 0.19013894, g_loss: 9.43790054, rnn_loss: 0.17334390\n",
      "step: [109/553] time: 1.1134s, d_loss: 0.11379011, g_loss: 5.02897549, rnn_loss: 0.12819454\n",
      "step: [164/553] time: 1.0454s, d_loss: 0.02424049, g_loss: 8.82259750, rnn_loss: 0.06788777\n",
      "step: [219/553] time: 1.1021s, d_loss: 0.03160483, g_loss: 4.16069317, rnn_loss: 0.15630141\n",
      "step: [274/553] time: 1.1146s, d_loss: 1.06573486, g_loss: 0.78480434, rnn_loss: 0.11595189\n",
      "step: [329/553] time: 1.1221s, d_loss: 0.25335020, g_loss: 5.04984951, rnn_loss: 0.10704036\n",
      "step: [384/553] time: 1.0890s, d_loss: 0.00787309, g_loss: 6.98497820, rnn_loss: 0.08919179\n",
      "step: [439/553] time: 1.0660s, d_loss: 0.06523929, g_loss: 3.92967367, rnn_loss: 0.07517736\n",
      "step: [494/553] time: 1.1590s, d_loss: 0.12045322, g_loss: 3.22408342, rnn_loss: 0.13808322\n",
      "step: [549/553] time: 1.0835s, d_loss: 0.37789220, g_loss: 3.66226053, rnn_loss: 0.11059174\n",
      " ** Epoch 85 took 608.339177s\n",
      "step: [54/553] time: 1.1822s, d_loss: 0.00712247, g_loss: 5.30292320, rnn_loss: 0.03149195\n",
      "step: [109/553] time: 1.1383s, d_loss: 0.06382501, g_loss: 3.46651125, rnn_loss: 0.06203339\n",
      "step: [164/553] time: 1.0954s, d_loss: 0.02190956, g_loss: 6.91063404, rnn_loss: 0.07567223\n",
      "step: [219/553] time: 1.0777s, d_loss: 0.01858655, g_loss: 6.59987450, rnn_loss: 0.13399190\n",
      "step: [274/553] time: 1.0601s, d_loss: 0.00731494, g_loss: 5.48784065, rnn_loss: 0.04464462\n",
      "step: [329/553] time: 1.1549s, d_loss: 0.21405080, g_loss: 2.93504667, rnn_loss: 0.05534248\n",
      "step: [384/553] time: 1.1662s, d_loss: 0.05585796, g_loss: 8.61437607, rnn_loss: 0.10874129\n",
      "step: [439/553] time: 1.1975s, d_loss: 0.70905638, g_loss: 6.02462435, rnn_loss: 0.29557633\n",
      "step: [494/553] time: 1.1077s, d_loss: 0.10379319, g_loss: 2.10589123, rnn_loss: 0.07709919\n",
      "step: [549/553] time: 1.0776s, d_loss: 0.23012398, g_loss: 4.34042978, rnn_loss: 0.05082272\n",
      " ** Epoch 86 took 614.084663s\n",
      "step: [54/553] time: 1.0814s, d_loss: 0.04638348, g_loss: 4.84229946, rnn_loss: 0.12119269\n",
      "step: [109/553] time: 1.1107s, d_loss: 0.40722302, g_loss: 4.52557564, rnn_loss: 0.12435018\n",
      "step: [164/553] time: 1.0789s, d_loss: 0.18118061, g_loss: 4.03967190, rnn_loss: 0.09766650\n",
      "step: [219/553] time: 1.0837s, d_loss: 0.17742980, g_loss: 3.09365845, rnn_loss: 0.16322762\n",
      "step: [274/553] time: 1.1081s, d_loss: 0.05206690, g_loss: 4.00272465, rnn_loss: 0.14197168\n",
      "step: [329/553] time: 1.1013s, d_loss: 0.09061877, g_loss: 3.54894114, rnn_loss: 0.05890702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [384/553] time: 1.0587s, d_loss: 0.00509893, g_loss: 6.91237068, rnn_loss: 0.08184418\n",
      "step: [439/553] time: 1.0932s, d_loss: 0.05897102, g_loss: 4.45598221, rnn_loss: 0.24328756\n",
      "step: [494/553] time: 1.0729s, d_loss: 0.21522698, g_loss: 5.78236294, rnn_loss: 0.06866859\n",
      "step: [549/553] time: 1.1550s, d_loss: 0.02195061, g_loss: 5.73575687, rnn_loss: 0.06985673\n",
      " ** Epoch 87 took 608.344044s\n",
      "step: [54/553] time: 1.0151s, d_loss: 0.05601602, g_loss: 3.97740984, rnn_loss: 0.17791638\n",
      "step: [109/553] time: 1.1137s, d_loss: 0.03513929, g_loss: 5.07405376, rnn_loss: 0.13645625\n",
      "step: [164/553] time: 1.1206s, d_loss: 0.07348637, g_loss: 7.95953560, rnn_loss: 0.12105651\n",
      "step: [219/553] time: 1.0827s, d_loss: 0.04065099, g_loss: 2.67323232, rnn_loss: 0.12760487\n",
      "step: [274/553] time: 1.0609s, d_loss: 0.99633902, g_loss: 3.86695123, rnn_loss: 0.09250172\n",
      "step: [329/553] time: 1.0530s, d_loss: 0.08814814, g_loss: 5.41026258, rnn_loss: 0.08854595\n",
      "step: [384/553] time: 1.1226s, d_loss: 0.09345616, g_loss: 3.87613821, rnn_loss: 0.10203973\n",
      "step: [439/553] time: 1.0735s, d_loss: 1.28005946, g_loss: 1.65051150, rnn_loss: 0.10506895\n",
      "step: [494/553] time: 1.1282s, d_loss: 0.08324743, g_loss: 7.52170849, rnn_loss: 0.03748203\n",
      "step: [549/553] time: 1.1254s, d_loss: 0.13843912, g_loss: 4.65392017, rnn_loss: 0.10290992\n",
      " ** Epoch 88 took 608.816767s\n",
      "step: [54/553] time: 1.0933s, d_loss: 0.14492455, g_loss: 3.16410303, rnn_loss: 0.05681271\n",
      "step: [109/553] time: 1.0642s, d_loss: 0.29472205, g_loss: 4.35788059, rnn_loss: 0.01825449\n",
      "step: [164/553] time: 1.1812s, d_loss: 0.26053083, g_loss: 4.62056684, rnn_loss: 0.04519385\n",
      "step: [219/553] time: 1.1496s, d_loss: 0.51469839, g_loss: 4.33776188, rnn_loss: 0.10001896\n",
      "step: [274/553] time: 1.0906s, d_loss: 0.08724556, g_loss: 4.46447992, rnn_loss: 0.06625079\n",
      "step: [329/553] time: 1.1032s, d_loss: 0.03527347, g_loss: 6.60313177, rnn_loss: 0.06312133\n",
      "step: [384/553] time: 1.1382s, d_loss: 0.03544716, g_loss: 7.98368645, rnn_loss: 0.03716014\n",
      "step: [439/553] time: 1.1121s, d_loss: 0.11117409, g_loss: 2.91522527, rnn_loss: 0.06849837\n",
      "step: [494/553] time: 1.1223s, d_loss: 0.12425235, g_loss: 3.69361353, rnn_loss: 0.08156736\n",
      "step: [549/553] time: 1.1251s, d_loss: 0.02365280, g_loss: 5.37243557, rnn_loss: 0.11010808\n",
      " ** Epoch 89 took 613.771372s\n",
      "step: [54/553] time: 1.1483s, d_loss: 0.03040381, g_loss: 3.43556404, rnn_loss: 0.21271715\n",
      "step: [109/553] time: 1.0927s, d_loss: 0.02897918, g_loss: 5.38580704, rnn_loss: 0.14029448\n",
      "step: [164/553] time: 1.1055s, d_loss: 0.11637205, g_loss: 4.62487030, rnn_loss: 0.08430912\n",
      "step: [219/553] time: 1.0805s, d_loss: 1.06049085, g_loss: 5.74693584, rnn_loss: 0.13831386\n",
      "step: [274/553] time: 1.0728s, d_loss: 0.66136998, g_loss: 4.45813894, rnn_loss: 0.09426193\n",
      "step: [329/553] time: 1.1174s, d_loss: 0.61449057, g_loss: 4.79637766, rnn_loss: 0.10931603\n",
      "step: [384/553] time: 1.1284s, d_loss: 0.03415502, g_loss: 4.61685753, rnn_loss: 0.09822695\n",
      "step: [439/553] time: 1.1508s, d_loss: 0.20812508, g_loss: 2.68284798, rnn_loss: 0.13785300\n",
      "step: [494/553] time: 1.0912s, d_loss: 0.02982241, g_loss: 4.05327940, rnn_loss: 0.05511975\n",
      "step: [549/553] time: 1.1234s, d_loss: 0.04762733, g_loss: 7.51995373, rnn_loss: 0.21706186\n",
      " ** Epoch 90 took 611.452316s\n",
      "step: [54/553] time: 1.0106s, d_loss: 0.09804957, g_loss: 3.51121235, rnn_loss: 0.10216516\n",
      "step: [109/553] time: 1.1289s, d_loss: 0.16767301, g_loss: 3.04164815, rnn_loss: 0.19198069\n",
      "step: [164/553] time: 1.2047s, d_loss: 0.74972475, g_loss: 3.37997627, rnn_loss: 0.09354620\n",
      "step: [219/553] time: 1.0766s, d_loss: 0.25680631, g_loss: 3.17016983, rnn_loss: 0.10792462\n",
      "step: [274/553] time: 1.0622s, d_loss: 0.34759268, g_loss: 2.14314890, rnn_loss: 0.15259261\n",
      "step: [329/553] time: 1.0891s, d_loss: 0.13074259, g_loss: 5.36829281, rnn_loss: 0.13409850\n",
      "step: [384/553] time: 1.1142s, d_loss: 0.03979422, g_loss: 4.05075550, rnn_loss: 0.04697815\n",
      "step: [439/553] time: 1.0606s, d_loss: 0.19870900, g_loss: 1.53362715, rnn_loss: 0.17418435\n",
      "step: [494/553] time: 1.0902s, d_loss: 0.03470930, g_loss: 2.92309737, rnn_loss: 0.04619790\n",
      "step: [549/553] time: 1.0634s, d_loss: 1.20403373, g_loss: 1.07395196, rnn_loss: 0.09469556\n",
      " ** Epoch 91 took 607.630984s\n",
      "step: [54/553] time: 1.1090s, d_loss: 0.11731005, g_loss: 3.69796944, rnn_loss: 0.16328096\n",
      "step: [109/553] time: 1.0881s, d_loss: 0.01714950, g_loss: 5.07754230, rnn_loss: 0.10604614\n",
      "step: [164/553] time: 1.0731s, d_loss: 0.03874987, g_loss: 5.40050125, rnn_loss: 0.09889370\n",
      "step: [219/553] time: 1.1299s, d_loss: 0.02207982, g_loss: 4.82084942, rnn_loss: 0.14045659\n",
      "step: [274/553] time: 1.1331s, d_loss: 0.16446558, g_loss: 4.29173088, rnn_loss: 0.12052584\n",
      "step: [329/553] time: 1.0591s, d_loss: 0.18313858, g_loss: 3.33029032, rnn_loss: 0.07620329\n",
      "step: [384/553] time: 1.0998s, d_loss: 0.10240163, g_loss: 2.96645665, rnn_loss: 0.16495647\n",
      "step: [439/553] time: 1.0908s, d_loss: 0.17167264, g_loss: 3.88112688, rnn_loss: 0.12551701\n",
      "step: [494/553] time: 1.0811s, d_loss: 0.53994906, g_loss: 4.97887039, rnn_loss: 0.08424579\n",
      "step: [549/553] time: 1.0697s, d_loss: 0.22236857, g_loss: 4.38589525, rnn_loss: 0.13454528\n",
      " ** Epoch 92 took 606.984206s\n",
      "step: [54/553] time: 1.1002s, d_loss: 0.89464617, g_loss: 1.97722137, rnn_loss: 0.06553826\n",
      "step: [109/553] time: 1.1227s, d_loss: 0.11856040, g_loss: 3.21274281, rnn_loss: 0.09823794\n",
      "step: [164/553] time: 1.0904s, d_loss: 0.02444666, g_loss: 6.72331476, rnn_loss: 0.14914827\n",
      "step: [219/553] time: 1.0977s, d_loss: 0.03562273, g_loss: 3.81454706, rnn_loss: 0.05905080\n",
      "step: [274/553] time: 1.0658s, d_loss: 0.12689501, g_loss: 4.12007093, rnn_loss: 0.18709314\n",
      "step: [329/553] time: 1.1011s, d_loss: 0.05029143, g_loss: 6.76703501, rnn_loss: 0.10693473\n",
      "step: [384/553] time: 1.1267s, d_loss: 0.04413082, g_loss: 3.84125042, rnn_loss: 0.08154330\n",
      "step: [439/553] time: 1.1346s, d_loss: 0.35719696, g_loss: 2.39302540, rnn_loss: 0.08296490\n",
      "step: [494/553] time: 1.1355s, d_loss: 0.40365666, g_loss: 4.80328131, rnn_loss: 0.13255586\n",
      "step: [549/553] time: 1.0822s, d_loss: 0.18049751, g_loss: 3.69606304, rnn_loss: 0.07766624\n",
      " ** Epoch 93 took 605.559298s\n",
      "step: [54/553] time: 1.0063s, d_loss: 0.00379902, g_loss: 7.33940029, rnn_loss: 0.08837613\n",
      "step: [109/553] time: 1.0896s, d_loss: 0.09583093, g_loss: 5.62363005, rnn_loss: 0.11861919\n",
      "step: [164/553] time: 1.1282s, d_loss: 0.12466270, g_loss: 3.92976594, rnn_loss: 0.06683867\n",
      "step: [219/553] time: 1.1194s, d_loss: 0.03033531, g_loss: 9.22081184, rnn_loss: 0.07082583\n",
      "step: [274/553] time: 1.1224s, d_loss: 0.69956273, g_loss: 7.77622318, rnn_loss: 0.02505678\n",
      "step: [329/553] time: 1.1750s, d_loss: 0.16930746, g_loss: 12.62767982, rnn_loss: 0.16789673\n",
      "step: [384/553] time: 1.0235s, d_loss: 0.02390612, g_loss: 4.15977764, rnn_loss: 0.03133061\n",
      "step: [439/553] time: 1.1118s, d_loss: 0.02541852, g_loss: 6.60783148, rnn_loss: 0.04775188\n",
      "step: [494/553] time: 1.1553s, d_loss: 0.05301929, g_loss: 4.97056532, rnn_loss: 0.12515721\n",
      "step: [549/553] time: 1.0599s, d_loss: 0.04641378, g_loss: 5.14881897, rnn_loss: 0.06262162\n",
      " ** Epoch 94 took 609.136160s\n",
      "step: [54/553] time: 1.1020s, d_loss: 0.05648910, g_loss: 5.58539867, rnn_loss: 0.09322107\n",
      "step: [109/553] time: 1.1522s, d_loss: 0.00561256, g_loss: 8.32796288, rnn_loss: 0.13979404\n",
      "step: [164/553] time: 1.1147s, d_loss: 0.22124885, g_loss: 4.22823238, rnn_loss: 0.16155048\n",
      "step: [219/553] time: 1.0512s, d_loss: 0.09731022, g_loss: 8.61104298, rnn_loss: 0.15676421\n",
      "step: [274/553] time: 1.1618s, d_loss: 1.59897614, g_loss: 0.71018243, rnn_loss: 0.13180360\n",
      "step: [329/553] time: 1.0885s, d_loss: 0.03002730, g_loss: 12.68618011, rnn_loss: 0.06806469\n",
      "step: [384/553] time: 1.1577s, d_loss: 0.02399388, g_loss: 7.65827751, rnn_loss: 0.17322251\n",
      "step: [439/553] time: 1.0903s, d_loss: 0.00678648, g_loss: 8.69975090, rnn_loss: 0.09803022\n",
      "step: [494/553] time: 1.0172s, d_loss: 0.26350707, g_loss: 5.27664375, rnn_loss: 0.05199639\n",
      "step: [549/553] time: 1.1626s, d_loss: 0.00869207, g_loss: 5.00878048, rnn_loss: 0.10705185\n",
      " ** Epoch 95 took 606.202677s\n",
      "step: [54/553] time: 1.0367s, d_loss: 0.91015750, g_loss: 5.33448267, rnn_loss: 0.10425626\n",
      "step: [109/553] time: 1.0242s, d_loss: 0.15794398, g_loss: 5.61333561, rnn_loss: 0.15742753\n",
      "step: [164/553] time: 1.0896s, d_loss: 0.02251854, g_loss: 3.93641853, rnn_loss: 0.04185078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [219/553] time: 1.1249s, d_loss: 0.50285649, g_loss: 7.69290638, rnn_loss: 0.06055969\n",
      "step: [274/553] time: 1.0945s, d_loss: 0.04007732, g_loss: 3.69050050, rnn_loss: 0.14482872\n",
      "step: [329/553] time: 1.1393s, d_loss: 0.04886438, g_loss: 4.37130499, rnn_loss: 0.10121408\n",
      "step: [384/553] time: 1.1807s, d_loss: 1.20846558, g_loss: 1.23762453, rnn_loss: 0.13331589\n",
      "step: [439/553] time: 1.0650s, d_loss: 0.11469346, g_loss: 3.60234642, rnn_loss: 0.12697160\n",
      "step: [494/553] time: 1.0767s, d_loss: 0.00491094, g_loss: 6.19402361, rnn_loss: 0.03186202\n",
      "step: [549/553] time: 1.1126s, d_loss: 0.01497525, g_loss: 5.91199732, rnn_loss: 0.11475118\n",
      " ** Epoch 96 took 602.425176s\n",
      "step: [54/553] time: 1.0721s, d_loss: 0.20289254, g_loss: 3.14801693, rnn_loss: 0.07008798\n",
      "step: [109/553] time: 1.1426s, d_loss: 0.03195674, g_loss: 5.36317635, rnn_loss: 0.14668928\n",
      "step: [164/553] time: 1.1059s, d_loss: 0.01125731, g_loss: 5.94313002, rnn_loss: 0.21073838\n",
      "step: [219/553] time: 1.0517s, d_loss: 0.01747210, g_loss: 7.49639177, rnn_loss: 0.05358113\n",
      "step: [274/553] time: 1.0596s, d_loss: 0.09468417, g_loss: 7.59829044, rnn_loss: 0.25796056\n",
      "step: [329/553] time: 1.0852s, d_loss: 0.41934991, g_loss: 7.65724182, rnn_loss: 0.10794836\n",
      "step: [384/553] time: 1.0640s, d_loss: 0.27837145, g_loss: 5.18913364, rnn_loss: 0.09509854\n",
      "step: [439/553] time: 1.1365s, d_loss: 0.17878225, g_loss: 3.40745306, rnn_loss: 0.04699273\n",
      "step: [494/553] time: 1.1270s, d_loss: 0.49276218, g_loss: 0.80720162, rnn_loss: 0.12046304\n",
      "step: [549/553] time: 1.0631s, d_loss: 0.07256263, g_loss: 2.52429247, rnn_loss: 0.10187700\n",
      " ** Epoch 97 took 600.517857s\n",
      "step: [54/553] time: 1.1441s, d_loss: 0.00458293, g_loss: 8.06045914, rnn_loss: 0.06884320\n",
      "step: [109/553] time: 1.0877s, d_loss: 0.02161531, g_loss: 3.97105837, rnn_loss: 0.01291917\n",
      "step: [164/553] time: 1.0816s, d_loss: 0.11706357, g_loss: 7.05299377, rnn_loss: 0.09602802\n",
      "step: [219/553] time: 1.0633s, d_loss: 0.01546660, g_loss: 5.98562956, rnn_loss: 0.07642425\n",
      "step: [274/553] time: 1.1406s, d_loss: 0.04989279, g_loss: 4.86697865, rnn_loss: 0.06365483\n",
      "step: [329/553] time: 1.1715s, d_loss: 0.01683040, g_loss: 3.14384174, rnn_loss: 0.05345915\n",
      "step: [384/553] time: 1.1680s, d_loss: 0.13314351, g_loss: 3.75390077, rnn_loss: 0.15382542\n",
      "step: [439/553] time: 1.0733s, d_loss: 0.14133219, g_loss: 6.74004936, rnn_loss: 0.09482305\n",
      "step: [494/553] time: 1.1155s, d_loss: 0.00766875, g_loss: 6.66823244, rnn_loss: 0.14099455\n",
      "step: [549/553] time: 1.1438s, d_loss: 0.00574015, g_loss: 7.77987194, rnn_loss: 0.01900777\n",
      " ** Epoch 98 took 608.541769s\n",
      "step: [54/553] time: 1.0061s, d_loss: 0.43633741, g_loss: 4.69285965, rnn_loss: 0.07428332\n",
      "step: [109/553] time: 1.1150s, d_loss: 0.06589189, g_loss: 4.08038521, rnn_loss: 0.08214277\n",
      "step: [164/553] time: 1.1178s, d_loss: 0.08778422, g_loss: 3.01413345, rnn_loss: 0.17639764\n",
      "step: [219/553] time: 1.1267s, d_loss: 0.04353857, g_loss: 3.44998121, rnn_loss: 0.09773080\n",
      "step: [274/553] time: 1.1814s, d_loss: 0.97871923, g_loss: 2.77850151, rnn_loss: 0.08512671\n",
      "step: [329/553] time: 1.0549s, d_loss: 0.12630022, g_loss: 4.97409630, rnn_loss: 0.06932340\n",
      "step: [384/553] time: 1.0403s, d_loss: 0.07662065, g_loss: 3.36728191, rnn_loss: 0.16999656\n",
      "step: [439/553] time: 1.1202s, d_loss: 0.11275961, g_loss: 3.86693954, rnn_loss: 0.13650575\n",
      "step: [494/553] time: 1.0696s, d_loss: 0.00633703, g_loss: 4.81658840, rnn_loss: 0.06962311\n",
      "step: [549/553] time: 1.0257s, d_loss: 0.07320546, g_loss: 4.19966269, rnn_loss: 0.08000392\n",
      " ** Epoch 99 took 606.185389s\n",
      "step: [54/553] time: 1.1245s, d_loss: 0.09371778, g_loss: 7.41136742, rnn_loss: 0.04865348\n",
      "step: [109/553] time: 1.0462s, d_loss: 0.01630311, g_loss: 3.91348076, rnn_loss: 0.03059101\n",
      "step: [164/553] time: 1.0553s, d_loss: 0.03486906, g_loss: 4.01620865, rnn_loss: 0.05462390\n",
      "step: [219/553] time: 1.0250s, d_loss: 0.02357299, g_loss: 5.53001308, rnn_loss: 0.15347789\n",
      "step: [274/553] time: 1.0861s, d_loss: 0.10292140, g_loss: 3.08836246, rnn_loss: 0.16657604\n",
      "step: [329/553] time: 1.1204s, d_loss: 0.05869380, g_loss: 4.32325029, rnn_loss: 0.14560173\n",
      "step: [384/553] time: 1.1232s, d_loss: 0.01179881, g_loss: 4.16686106, rnn_loss: 0.06462093\n",
      "step: [439/553] time: 1.0711s, d_loss: 0.14837645, g_loss: 4.07530308, rnn_loss: 0.12700714\n",
      "step: [494/553] time: 1.1091s, d_loss: 0.69304037, g_loss: 1.95986652, rnn_loss: 0.11385580\n",
      "step: [549/553] time: 1.0641s, d_loss: 0.05568137, g_loss: 5.48863316, rnn_loss: 0.08154105\n",
      " ** Epoch 100 took 611.377320s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "step: [54/553] time: 1.0668s, d_loss: 0.17354479, g_loss: 5.44561386, rnn_loss: 0.14423969\n",
      "step: [109/553] time: 1.0586s, d_loss: 0.04806682, g_loss: 5.15043926, rnn_loss: 0.06174579\n",
      "step: [164/553] time: 1.1037s, d_loss: 0.04359505, g_loss: 5.58761406, rnn_loss: 0.14789437\n",
      "step: [219/553] time: 1.0923s, d_loss: 0.07811765, g_loss: 6.76737499, rnn_loss: 0.09539240\n",
      "step: [274/553] time: 1.0713s, d_loss: 2.64841318, g_loss: 0.32394734, rnn_loss: 0.15680903\n",
      "step: [329/553] time: 1.0857s, d_loss: 0.36497155, g_loss: 3.65582776, rnn_loss: 0.13697802\n",
      "step: [384/553] time: 0.9944s, d_loss: 0.38151652, g_loss: 4.86877871, rnn_loss: 0.14130560\n",
      "step: [439/553] time: 1.1582s, d_loss: 0.01020905, g_loss: 4.70611668, rnn_loss: 0.07783340\n",
      "step: [494/553] time: 1.0968s, d_loss: 0.00456451, g_loss: 8.57799530, rnn_loss: 0.02612111\n",
      "step: [549/553] time: 1.0793s, d_loss: 0.13665855, g_loss: 4.19631624, rnn_loss: 0.09730107\n",
      " ** Epoch 101 took 604.199996s\n",
      "step: [54/553] time: 1.0373s, d_loss: 2.99825311, g_loss: 4.84017897, rnn_loss: 0.06103418\n",
      "step: [109/553] time: 1.0979s, d_loss: 0.47483864, g_loss: 6.32197857, rnn_loss: 0.15916044\n",
      "step: [164/553] time: 1.1050s, d_loss: 0.73247427, g_loss: 5.38777351, rnn_loss: 0.11200614\n",
      "step: [219/553] time: 1.1161s, d_loss: 0.12295918, g_loss: 5.48299456, rnn_loss: 0.01684077\n",
      "step: [274/553] time: 1.1597s, d_loss: 0.05485052, g_loss: 4.82134914, rnn_loss: 0.14881986\n",
      "step: [329/553] time: 1.0918s, d_loss: 0.09082781, g_loss: 3.55928230, rnn_loss: 0.10521135\n",
      "step: [384/553] time: 1.0958s, d_loss: 0.54840398, g_loss: 5.85381413, rnn_loss: 0.08122189\n",
      "step: [439/553] time: 1.0880s, d_loss: 0.11033989, g_loss: 2.95842361, rnn_loss: 0.10070626\n",
      "step: [494/553] time: 1.1139s, d_loss: 0.39094165, g_loss: 2.22319031, rnn_loss: 0.18340477\n",
      "step: [549/553] time: 1.0437s, d_loss: 0.00571052, g_loss: 6.59012938, rnn_loss: 0.05965967\n",
      " ** Epoch 102 took 606.027296s\n",
      "step: [54/553] time: 1.0728s, d_loss: 0.15213202, g_loss: 4.52936172, rnn_loss: 0.11904852\n",
      "step: [109/553] time: 1.1181s, d_loss: 0.05281363, g_loss: 4.95927715, rnn_loss: 0.04095627\n",
      "step: [164/553] time: 1.1996s, d_loss: 0.38536602, g_loss: 4.53991985, rnn_loss: 0.07747330\n",
      "step: [219/553] time: 1.1457s, d_loss: 0.30605808, g_loss: 3.78624368, rnn_loss: 0.13378263\n",
      "step: [274/553] time: 1.0777s, d_loss: 1.26155424, g_loss: 4.28876400, rnn_loss: 0.03120418\n",
      "step: [329/553] time: 1.0974s, d_loss: 0.80341220, g_loss: 6.39782238, rnn_loss: 0.12022645\n",
      "step: [384/553] time: 1.0785s, d_loss: 0.26216310, g_loss: 2.75164509, rnn_loss: 0.10054187\n",
      "step: [439/553] time: 1.1250s, d_loss: 0.05598206, g_loss: 3.98895478, rnn_loss: 0.05810668\n",
      "step: [494/553] time: 1.1206s, d_loss: 0.01905245, g_loss: 6.52436447, rnn_loss: 0.08115894\n",
      "step: [549/553] time: 1.1790s, d_loss: 0.07726371, g_loss: 3.34627867, rnn_loss: 0.08702630\n",
      " ** Epoch 103 took 609.716592s\n",
      "step: [54/553] time: 1.1890s, d_loss: 0.02888267, g_loss: 4.01446819, rnn_loss: 0.05653028\n",
      "step: [109/553] time: 1.1053s, d_loss: 0.05106035, g_loss: 3.47943258, rnn_loss: 0.05876417\n",
      "step: [164/553] time: 1.1400s, d_loss: 0.64556187, g_loss: 7.41654205, rnn_loss: 0.14277852\n",
      "step: [219/553] time: 1.1285s, d_loss: 0.02277844, g_loss: 6.59096193, rnn_loss: 0.01954420\n",
      "step: [274/553] time: 1.1434s, d_loss: 0.50421011, g_loss: 3.69167042, rnn_loss: 0.07263231\n",
      "step: [329/553] time: 1.0550s, d_loss: 0.35002625, g_loss: 3.62439537, rnn_loss: 0.07355946\n",
      "step: [384/553] time: 1.1091s, d_loss: 0.09737714, g_loss: 4.83946323, rnn_loss: 0.11922047\n",
      "step: [439/553] time: 1.1469s, d_loss: 0.08646592, g_loss: 6.43809795, rnn_loss: 0.06415662\n",
      "step: [494/553] time: 1.1794s, d_loss: 0.10136129, g_loss: 4.63845015, rnn_loss: 0.13521895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [549/553] time: 1.0972s, d_loss: 0.00514068, g_loss: 6.14648724, rnn_loss: 0.04402585\n",
      " ** Epoch 104 took 615.479682s\n",
      "step: [54/553] time: 1.1684s, d_loss: 0.25047293, g_loss: 3.33241081, rnn_loss: 0.15517293\n",
      "step: [109/553] time: 1.0680s, d_loss: 0.08894019, g_loss: 6.48262453, rnn_loss: 0.16307811\n",
      "step: [164/553] time: 1.0726s, d_loss: 0.02085728, g_loss: 5.78406191, rnn_loss: 0.07132156\n",
      "step: [219/553] time: 1.0870s, d_loss: 0.47591916, g_loss: 6.17015314, rnn_loss: 0.11928892\n",
      "step: [274/553] time: 1.1302s, d_loss: 0.48210678, g_loss: 2.57144165, rnn_loss: 0.09625901\n",
      "step: [329/553] time: 1.1167s, d_loss: 1.02762961, g_loss: 5.22513723, rnn_loss: 0.12988979\n",
      "step: [384/553] time: 1.1277s, d_loss: 0.00948985, g_loss: 5.56094933, rnn_loss: 0.09206101\n",
      "step: [439/553] time: 1.0726s, d_loss: 0.04513664, g_loss: 6.80781841, rnn_loss: 0.07792510\n",
      "step: [494/553] time: 1.1121s, d_loss: 0.30272216, g_loss: 4.99048805, rnn_loss: 0.09897691\n",
      "step: [549/553] time: 1.1460s, d_loss: 0.21670121, g_loss: 4.13290691, rnn_loss: 0.06263042\n",
      " ** Epoch 105 took 619.460596s\n",
      "step: [54/553] time: 1.1118s, d_loss: 0.10772932, g_loss: 3.96707702, rnn_loss: 0.02244676\n",
      "step: [109/553] time: 1.0652s, d_loss: 0.00994649, g_loss: 4.11747122, rnn_loss: 0.05134098\n",
      "step: [164/553] time: 1.1323s, d_loss: 0.03146392, g_loss: 5.76527500, rnn_loss: 0.08640078\n",
      "step: [219/553] time: 1.0290s, d_loss: 0.20260993, g_loss: 3.54882479, rnn_loss: 0.12536812\n",
      "step: [274/553] time: 1.0684s, d_loss: 0.11527076, g_loss: 4.03246450, rnn_loss: 0.09178236\n",
      "step: [329/553] time: 1.1476s, d_loss: 0.07510663, g_loss: 3.92429423, rnn_loss: 0.11301151\n",
      "step: [384/553] time: 1.1350s, d_loss: 1.14041793, g_loss: 5.21745682, rnn_loss: 0.05549099\n",
      "step: [439/553] time: 1.1725s, d_loss: 0.24508978, g_loss: 13.69105530, rnn_loss: 0.20573856\n",
      "step: [494/553] time: 1.1433s, d_loss: 0.03658008, g_loss: 3.47269750, rnn_loss: 0.13851902\n",
      "step: [549/553] time: 1.0400s, d_loss: 0.21475968, g_loss: 8.18760681, rnn_loss: 0.11199510\n",
      " ** Epoch 106 took 619.424054s\n",
      "step: [54/553] time: 1.1136s, d_loss: 0.00411303, g_loss: 6.61725426, rnn_loss: 0.09038359\n",
      "step: [109/553] time: 1.0732s, d_loss: 0.05123986, g_loss: 3.86566520, rnn_loss: 0.08629743\n",
      "step: [164/553] time: 1.3031s, d_loss: 0.01063482, g_loss: 6.55981350, rnn_loss: 0.09845200\n",
      "step: [219/553] time: 1.1047s, d_loss: 0.39041051, g_loss: 5.06748581, rnn_loss: 0.17109805\n",
      "step: [274/553] time: 1.1560s, d_loss: 0.06969909, g_loss: 4.45450401, rnn_loss: 0.08959305\n",
      "step: [329/553] time: 1.1909s, d_loss: 0.07266331, g_loss: 3.61809921, rnn_loss: 0.12643817\n",
      "step: [384/553] time: 1.0986s, d_loss: 0.02730183, g_loss: 3.59155798, rnn_loss: 0.11236110\n",
      "step: [439/553] time: 1.1400s, d_loss: 0.00673927, g_loss: 6.80196714, rnn_loss: 0.09202994\n",
      "step: [494/553] time: 1.1664s, d_loss: 0.00665576, g_loss: 11.74734879, rnn_loss: 0.01570804\n",
      "step: [549/553] time: 1.0492s, d_loss: 0.04890200, g_loss: 5.57427168, rnn_loss: 0.07433865\n",
      " ** Epoch 107 took 620.351872s\n",
      "step: [54/553] time: 1.0760s, d_loss: 0.01877509, g_loss: 4.44791985, rnn_loss: 0.09358922\n",
      "step: [109/553] time: 1.1713s, d_loss: 0.07484601, g_loss: 3.84086466, rnn_loss: 0.06235214\n",
      "step: [164/553] time: 1.0952s, d_loss: 0.16954653, g_loss: 8.21366978, rnn_loss: 0.09748928\n",
      "step: [219/553] time: 1.2089s, d_loss: 0.04436675, g_loss: 3.87608004, rnn_loss: 0.12431304\n",
      "step: [274/553] time: 1.1436s, d_loss: 0.02605793, g_loss: 7.15552759, rnn_loss: 0.14334719\n",
      "step: [329/553] time: 1.1110s, d_loss: 0.00448156, g_loss: 6.24865818, rnn_loss: 0.07173824\n",
      "step: [384/553] time: 1.1492s, d_loss: 0.03730501, g_loss: 7.94130373, rnn_loss: 0.03309711\n",
      "step: [439/553] time: 1.1701s, d_loss: 0.00335312, g_loss: 7.77663803, rnn_loss: 0.13395840\n",
      "step: [494/553] time: 1.1481s, d_loss: 0.43717417, g_loss: 4.97990131, rnn_loss: 0.08197239\n",
      "step: [549/553] time: 1.1282s, d_loss: 0.04603744, g_loss: 4.08273220, rnn_loss: 0.05695278\n",
      " ** Epoch 108 took 624.026758s\n",
      "step: [54/553] time: 1.1164s, d_loss: 0.00694050, g_loss: 5.86828327, rnn_loss: 0.12806039\n",
      "step: [109/553] time: 1.1168s, d_loss: 0.00697890, g_loss: 5.80874443, rnn_loss: 0.04241947\n",
      "step: [164/553] time: 1.1239s, d_loss: 0.09631354, g_loss: 3.80417585, rnn_loss: 0.06361751\n",
      "step: [219/553] time: 1.1084s, d_loss: 0.09166011, g_loss: 3.66864252, rnn_loss: 0.07467980\n",
      "step: [274/553] time: 1.1386s, d_loss: 0.82995003, g_loss: 5.84871483, rnn_loss: 0.10770874\n",
      "step: [329/553] time: 1.1143s, d_loss: 0.02237543, g_loss: 5.40841866, rnn_loss: 0.11032982\n",
      "step: [384/553] time: 1.0847s, d_loss: 0.08310912, g_loss: 2.96460342, rnn_loss: 0.06041281\n",
      "step: [439/553] time: 1.1652s, d_loss: 0.03803888, g_loss: 5.65400124, rnn_loss: 0.08493671\n",
      "step: [494/553] time: 1.1543s, d_loss: 0.07112671, g_loss: 4.37559271, rnn_loss: 0.13924542\n",
      "step: [549/553] time: 1.0851s, d_loss: 0.85169476, g_loss: 1.48460853, rnn_loss: 0.04222727\n",
      " ** Epoch 109 took 623.662608s\n",
      "step: [54/553] time: 1.1589s, d_loss: 0.71502167, g_loss: 2.83503151, rnn_loss: 0.12101185\n",
      "step: [109/553] time: 1.2009s, d_loss: 0.18903373, g_loss: 7.29852247, rnn_loss: 0.10583007\n",
      "step: [164/553] time: 1.1092s, d_loss: 0.43176475, g_loss: 2.09809160, rnn_loss: 0.11700188\n",
      "step: [219/553] time: 1.1122s, d_loss: 0.07677957, g_loss: 3.98129106, rnn_loss: 0.08974051\n",
      "step: [274/553] time: 1.0829s, d_loss: 0.01480993, g_loss: 6.41161394, rnn_loss: 0.07111168\n",
      "step: [329/553] time: 1.1111s, d_loss: 0.02409633, g_loss: 4.63614559, rnn_loss: 0.07241194\n",
      "step: [384/553] time: 1.0598s, d_loss: 0.61260438, g_loss: 4.96832275, rnn_loss: 0.07301680\n",
      "step: [439/553] time: 1.1242s, d_loss: 4.04562092, g_loss: 3.17976069, rnn_loss: 0.06982955\n",
      "step: [494/553] time: 1.0795s, d_loss: 0.25780398, g_loss: 3.97652984, rnn_loss: 0.05476454\n",
      "step: [549/553] time: 1.1581s, d_loss: 0.07682392, g_loss: 3.41579485, rnn_loss: 0.08895267\n",
      " ** Epoch 110 took 620.259557s\n",
      "step: [54/553] time: 1.1025s, d_loss: 0.09340622, g_loss: 4.08563471, rnn_loss: 0.11054105\n",
      "step: [109/553] time: 1.1438s, d_loss: 0.12239267, g_loss: 3.73017931, rnn_loss: 0.16808954\n",
      "step: [164/553] time: 1.0740s, d_loss: 0.47336975, g_loss: 3.21197844, rnn_loss: 0.12055099\n",
      "step: [219/553] time: 1.1086s, d_loss: 0.33304209, g_loss: 6.96659708, rnn_loss: 0.02614371\n",
      "step: [274/553] time: 1.0969s, d_loss: 0.07600376, g_loss: 2.70218134, rnn_loss: 0.03673369\n",
      "step: [329/553] time: 1.1143s, d_loss: 0.00461252, g_loss: 6.87374735, rnn_loss: 0.07323898\n",
      "step: [384/553] time: 1.1282s, d_loss: 0.10522847, g_loss: 3.32956076, rnn_loss: 0.06691741\n",
      "step: [439/553] time: 1.1334s, d_loss: 0.04092963, g_loss: 6.18016338, rnn_loss: 0.08811340\n",
      "step: [494/553] time: 1.1512s, d_loss: 0.00497314, g_loss: 4.72947884, rnn_loss: 0.07057992\n",
      "step: [549/553] time: 1.1425s, d_loss: 0.14132331, g_loss: 4.30705118, rnn_loss: 0.06955579\n",
      " ** Epoch 111 took 617.743930s\n",
      "step: [54/553] time: 1.1367s, d_loss: 0.02048182, g_loss: 6.55093575, rnn_loss: 0.11016890\n",
      "step: [109/553] time: 1.1758s, d_loss: 0.77838016, g_loss: 7.44941616, rnn_loss: 0.05623803\n",
      "step: [164/553] time: 1.1364s, d_loss: 0.15122639, g_loss: 3.69613361, rnn_loss: 0.08463448\n",
      "step: [219/553] time: 1.1610s, d_loss: 0.69147831, g_loss: 2.98813033, rnn_loss: 0.20258072\n",
      "step: [274/553] time: 1.1161s, d_loss: 0.09554036, g_loss: 3.67898870, rnn_loss: 0.15521559\n",
      "step: [329/553] time: 1.1363s, d_loss: 0.07166596, g_loss: 3.57579947, rnn_loss: 0.21196304\n",
      "step: [384/553] time: 1.1334s, d_loss: 0.02143645, g_loss: 3.58020258, rnn_loss: 0.06138314\n",
      "step: [439/553] time: 1.2393s, d_loss: 0.00993532, g_loss: 7.19237423, rnn_loss: 0.06458639\n",
      "step: [494/553] time: 1.0142s, d_loss: 0.71213305, g_loss: 4.18075705, rnn_loss: 0.12846692\n",
      "step: [549/553] time: 1.1232s, d_loss: 0.04383355, g_loss: 5.47740078, rnn_loss: 0.15593287\n",
      " ** Epoch 112 took 612.608574s\n",
      "step: [54/553] time: 1.0535s, d_loss: 0.05947121, g_loss: 4.00595665, rnn_loss: 0.08285285\n",
      "step: [109/553] time: 1.1105s, d_loss: 0.01020713, g_loss: 6.48373890, rnn_loss: 0.08437760\n",
      "step: [164/553] time: 1.0630s, d_loss: 0.00844622, g_loss: 7.12664700, rnn_loss: 0.11774651\n",
      "step: [219/553] time: 1.0564s, d_loss: 0.26777804, g_loss: 2.71688890, rnn_loss: 0.13582930\n",
      "step: [274/553] time: 1.1041s, d_loss: 0.01779881, g_loss: 5.08490181, rnn_loss: 0.10817885\n",
      "step: [329/553] time: 1.1124s, d_loss: 0.00543285, g_loss: 6.52461290, rnn_loss: 0.07257961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [384/553] time: 1.0254s, d_loss: 0.03152180, g_loss: 5.95677567, rnn_loss: 0.15430996\n",
      "step: [439/553] time: 1.0995s, d_loss: 0.03242642, g_loss: 4.03701067, rnn_loss: 0.07191584\n",
      "step: [494/553] time: 1.1099s, d_loss: 0.01674936, g_loss: 6.44470882, rnn_loss: 0.13397415\n",
      "step: [549/553] time: 1.0644s, d_loss: 0.40065217, g_loss: 3.29887581, rnn_loss: 0.09080791\n",
      " ** Epoch 113 took 608.424594s\n",
      "step: [54/553] time: 1.0993s, d_loss: 0.02183127, g_loss: 4.56968307, rnn_loss: 0.02180161\n",
      "step: [109/553] time: 1.1237s, d_loss: 0.04534716, g_loss: 4.54189920, rnn_loss: 0.13836327\n",
      "step: [164/553] time: 1.1142s, d_loss: 2.52015209, g_loss: 3.64686394, rnn_loss: 0.18123977\n",
      "step: [219/553] time: 1.1210s, d_loss: 0.00589263, g_loss: 4.80582428, rnn_loss: 0.10656945\n",
      "step: [274/553] time: 1.1745s, d_loss: 0.01834426, g_loss: 4.50578880, rnn_loss: 0.11826214\n",
      "step: [329/553] time: 1.0442s, d_loss: 0.01694335, g_loss: 5.02903652, rnn_loss: 0.11831091\n",
      "step: [384/553] time: 1.1528s, d_loss: 0.77335531, g_loss: 5.31571674, rnn_loss: 0.05198039\n",
      "step: [439/553] time: 1.0727s, d_loss: 0.01799683, g_loss: 6.12613153, rnn_loss: 0.16282028\n",
      "step: [494/553] time: 1.1149s, d_loss: 0.01254628, g_loss: 10.08474350, rnn_loss: 0.06169490\n",
      "step: [549/553] time: 1.0552s, d_loss: 0.00960799, g_loss: 5.55676460, rnn_loss: 0.06079064\n",
      " ** Epoch 114 took 611.266210s\n",
      "step: [54/553] time: 1.0750s, d_loss: 0.09035023, g_loss: 3.14728498, rnn_loss: 0.09517916\n",
      "step: [109/553] time: 1.1975s, d_loss: 0.05400652, g_loss: 3.05512500, rnn_loss: 0.15007922\n",
      "step: [164/553] time: 1.1123s, d_loss: 0.39154828, g_loss: 3.78585315, rnn_loss: 0.12774986\n",
      "step: [219/553] time: 1.0749s, d_loss: 0.02702844, g_loss: 5.17999172, rnn_loss: 0.09906602\n",
      "step: [274/553] time: 1.0527s, d_loss: 0.04333977, g_loss: 4.26697063, rnn_loss: 0.02409234\n",
      "step: [329/553] time: 1.0603s, d_loss: 0.09802749, g_loss: 3.28804159, rnn_loss: 0.12097752\n",
      "step: [384/553] time: 1.1092s, d_loss: 0.05283760, g_loss: 4.36613178, rnn_loss: 0.07699976\n",
      "step: [439/553] time: 1.1556s, d_loss: 0.02117030, g_loss: 8.26792717, rnn_loss: 0.12835394\n",
      "step: [494/553] time: 1.0558s, d_loss: 0.20369244, g_loss: 3.92510676, rnn_loss: 0.14025903\n",
      "step: [549/553] time: 1.1009s, d_loss: 0.03736568, g_loss: 3.40025520, rnn_loss: 0.21178488\n",
      " ** Epoch 115 took 611.657282s\n",
      "step: [54/553] time: 1.1785s, d_loss: 0.00769124, g_loss: 5.24775028, rnn_loss: 0.02803349\n",
      "step: [109/553] time: 1.1056s, d_loss: 0.13542329, g_loss: 3.95685554, rnn_loss: 0.09804033\n",
      "step: [164/553] time: 1.1008s, d_loss: 0.06558366, g_loss: 4.23301411, rnn_loss: 0.04746868\n",
      "step: [219/553] time: 1.0876s, d_loss: 0.26309651, g_loss: 4.85029793, rnn_loss: 0.16483375\n",
      "step: [274/553] time: 1.0817s, d_loss: 0.38637429, g_loss: 4.28929090, rnn_loss: 0.07801656\n",
      "step: [329/553] time: 1.0873s, d_loss: 0.01795531, g_loss: 4.82354927, rnn_loss: 0.08972157\n",
      "step: [384/553] time: 1.1075s, d_loss: 0.23999125, g_loss: 2.69193506, rnn_loss: 0.12671572\n",
      "step: [439/553] time: 1.0792s, d_loss: 0.11587349, g_loss: 3.84761596, rnn_loss: 0.12036676\n",
      "step: [494/553] time: 1.0839s, d_loss: 0.07320475, g_loss: 3.49169850, rnn_loss: 0.07101046\n",
      "step: [549/553] time: 1.1342s, d_loss: 0.54773557, g_loss: 4.54393768, rnn_loss: 0.11713271\n",
      " ** Epoch 116 took 611.345835s\n",
      "step: [54/553] time: 1.1512s, d_loss: 0.02289499, g_loss: 4.12038660, rnn_loss: 0.11860918\n",
      "step: [109/553] time: 1.1927s, d_loss: 0.04421556, g_loss: 5.60284948, rnn_loss: 0.03440873\n",
      "step: [164/553] time: 1.1459s, d_loss: 0.10629082, g_loss: 5.43042755, rnn_loss: 0.11446483\n",
      "step: [219/553] time: 1.1106s, d_loss: 0.23670267, g_loss: 9.19851112, rnn_loss: 0.08131119\n",
      "step: [274/553] time: 1.1283s, d_loss: 0.01683590, g_loss: 6.30802917, rnn_loss: 0.08111972\n",
      "step: [329/553] time: 1.1835s, d_loss: 0.01838845, g_loss: 5.25086403, rnn_loss: 0.09647188\n",
      "step: [384/553] time: 1.1151s, d_loss: 0.05060146, g_loss: 3.69664478, rnn_loss: 0.03937417\n",
      "step: [439/553] time: 1.0745s, d_loss: 0.18260331, g_loss: 4.45639801, rnn_loss: 0.11408085\n",
      "step: [494/553] time: 1.1767s, d_loss: 0.20760199, g_loss: 4.26021957, rnn_loss: 0.04647252\n",
      "step: [549/553] time: 1.0904s, d_loss: 0.56866682, g_loss: 10.01857090, rnn_loss: 0.04027201\n",
      " ** Epoch 117 took 612.314815s\n",
      "step: [54/553] time: 1.2005s, d_loss: 0.01706164, g_loss: 6.69625854, rnn_loss: 0.09953915\n",
      "step: [109/553] time: 1.2546s, d_loss: 0.02224654, g_loss: 4.80902290, rnn_loss: 0.15129425\n",
      "step: [164/553] time: 1.1214s, d_loss: 0.08117854, g_loss: 5.03824806, rnn_loss: 0.08035325\n",
      "step: [219/553] time: 1.2105s, d_loss: 0.07921330, g_loss: 2.40070200, rnn_loss: 0.07648853\n",
      "step: [274/553] time: 1.1056s, d_loss: 0.13707960, g_loss: 9.37143421, rnn_loss: 0.15576106\n",
      "step: [329/553] time: 1.0288s, d_loss: 0.53643620, g_loss: 4.80704737, rnn_loss: 0.23881736\n",
      "step: [384/553] time: 1.0869s, d_loss: 0.36779115, g_loss: 6.46436977, rnn_loss: 0.09397350\n",
      "step: [439/553] time: 1.1295s, d_loss: 0.07103875, g_loss: 6.37818766, rnn_loss: 0.04930539\n",
      "step: [494/553] time: 1.1261s, d_loss: 0.00803987, g_loss: 5.08155489, rnn_loss: 0.16383137\n",
      "step: [549/553] time: 1.0109s, d_loss: 0.01409440, g_loss: 5.51432514, rnn_loss: 0.03056513\n",
      " ** Epoch 118 took 610.285481s\n",
      "step: [54/553] time: 1.0735s, d_loss: 0.10152629, g_loss: 7.62934971, rnn_loss: 0.21306898\n",
      "step: [109/553] time: 1.0719s, d_loss: 0.15305641, g_loss: 4.00951290, rnn_loss: 0.19987908\n",
      "step: [164/553] time: 1.1416s, d_loss: 0.36966348, g_loss: 6.37312794, rnn_loss: 0.17814966\n",
      "step: [219/553] time: 1.1201s, d_loss: 0.10683420, g_loss: 4.66002941, rnn_loss: 0.08523241\n",
      "step: [274/553] time: 1.0525s, d_loss: 0.10371239, g_loss: 3.57682872, rnn_loss: 0.06102411\n",
      "step: [329/553] time: 1.0649s, d_loss: 0.00912371, g_loss: 5.56379032, rnn_loss: 0.12338272\n",
      "step: [384/553] time: 1.1138s, d_loss: 0.09141566, g_loss: 2.67465258, rnn_loss: 0.09079367\n",
      "step: [439/553] time: 1.1466s, d_loss: 0.01228978, g_loss: 6.68244028, rnn_loss: 0.15953740\n",
      "step: [494/553] time: 1.0458s, d_loss: 0.02521578, g_loss: 4.74807930, rnn_loss: 0.08893502\n",
      "step: [549/553] time: 1.0836s, d_loss: 0.23298796, g_loss: 3.90967035, rnn_loss: 0.10444895\n",
      " ** Epoch 119 took 611.388963s\n",
      "step: [54/553] time: 1.0914s, d_loss: 0.00760490, g_loss: 5.32686281, rnn_loss: 0.06746739\n",
      "step: [109/553] time: 1.1649s, d_loss: 0.02036029, g_loss: 5.09339142, rnn_loss: 0.14020027\n",
      "step: [164/553] time: 1.1111s, d_loss: 0.06795724, g_loss: 5.56545162, rnn_loss: 0.14662437\n",
      "step: [219/553] time: 1.2440s, d_loss: 0.00403953, g_loss: 5.49504423, rnn_loss: 0.12831315\n",
      "step: [274/553] time: 1.0395s, d_loss: 0.34277368, g_loss: 2.56685686, rnn_loss: 0.04865554\n",
      "step: [329/553] time: 1.0630s, d_loss: 0.00199420, g_loss: 7.48239708, rnn_loss: 0.12007874\n",
      "step: [384/553] time: 1.1149s, d_loss: 0.02948032, g_loss: 5.37984276, rnn_loss: 0.04388893\n",
      "step: [439/553] time: 1.0776s, d_loss: 0.30225018, g_loss: 6.67500305, rnn_loss: 0.11413327\n",
      "step: [494/553] time: 1.1520s, d_loss: 0.13108020, g_loss: 5.52592278, rnn_loss: 0.16663948\n",
      "step: [549/553] time: 1.0499s, d_loss: 0.03488532, g_loss: 3.74709225, rnn_loss: 0.11502443\n",
      " ** Epoch 120 took 617.731729s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "step: [54/553] time: 1.1215s, d_loss: 0.02510044, g_loss: 12.81337833, rnn_loss: 0.12287091\n",
      "step: [109/553] time: 1.1172s, d_loss: 0.19481295, g_loss: 2.67893863, rnn_loss: 0.28363973\n",
      "step: [164/553] time: 1.0583s, d_loss: 0.14303699, g_loss: 7.99363995, rnn_loss: 0.04479027\n",
      "step: [219/553] time: 1.0926s, d_loss: 0.03284952, g_loss: 4.29751968, rnn_loss: 0.08342603\n",
      "step: [274/553] time: 1.0988s, d_loss: 0.09068903, g_loss: 4.23778009, rnn_loss: 0.08192943\n",
      "step: [329/553] time: 1.1548s, d_loss: 0.25765151, g_loss: 4.16518068, rnn_loss: 0.13979748\n",
      "step: [384/553] time: 1.0886s, d_loss: 0.31196487, g_loss: 3.63495922, rnn_loss: 0.15240715\n",
      "step: [439/553] time: 1.1327s, d_loss: 0.18601491, g_loss: 6.40812206, rnn_loss: 0.08131661\n",
      "step: [494/553] time: 1.1509s, d_loss: 0.01949826, g_loss: 4.24218655, rnn_loss: 0.09805924\n",
      "step: [549/553] time: 1.1541s, d_loss: 0.17924939, g_loss: 2.84972906, rnn_loss: 0.10370038\n",
      " ** Epoch 121 took 617.212811s\n",
      "step: [54/553] time: 1.0999s, d_loss: 0.28156775, g_loss: 3.76157236, rnn_loss: 0.11862230\n",
      "step: [109/553] time: 1.1317s, d_loss: 0.00518023, g_loss: 8.64802361, rnn_loss: 0.05655567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [164/553] time: 1.0518s, d_loss: 0.03454088, g_loss: 7.97100544, rnn_loss: 0.09468859\n",
      "step: [219/553] time: 1.0872s, d_loss: 0.00243239, g_loss: 6.61120605, rnn_loss: 0.05067404\n",
      "step: [274/553] time: 1.0899s, d_loss: 0.10593595, g_loss: 3.50987864, rnn_loss: 0.07041869\n",
      "step: [329/553] time: 1.0506s, d_loss: 1.72448432, g_loss: 5.18311930, rnn_loss: 0.09210553\n",
      "step: [384/553] time: 1.0949s, d_loss: 0.07403724, g_loss: 4.60642624, rnn_loss: 0.15223311\n",
      "step: [439/553] time: 1.0708s, d_loss: 0.10425515, g_loss: 6.15948439, rnn_loss: 0.13751037\n",
      "step: [494/553] time: 1.1173s, d_loss: 0.16061281, g_loss: 9.25624561, rnn_loss: 0.09250811\n",
      "step: [549/553] time: 1.0626s, d_loss: 0.34692791, g_loss: 7.71992111, rnn_loss: 0.18587422\n",
      " ** Epoch 122 took 613.636101s\n",
      "step: [54/553] time: 1.0661s, d_loss: 0.52917069, g_loss: 3.18769741, rnn_loss: 0.09928373\n",
      "step: [109/553] time: 1.0665s, d_loss: 0.01585220, g_loss: 3.08872890, rnn_loss: 0.05719649\n",
      "step: [164/553] time: 1.1239s, d_loss: 0.04106286, g_loss: 3.29965305, rnn_loss: 0.08649702\n",
      "step: [219/553] time: 1.1549s, d_loss: 0.01545724, g_loss: 5.72895432, rnn_loss: 0.05289997\n",
      "step: [274/553] time: 1.0361s, d_loss: 0.02963576, g_loss: 5.05339193, rnn_loss: 0.05037497\n",
      "step: [329/553] time: 1.1113s, d_loss: 0.00891399, g_loss: 5.04596138, rnn_loss: 0.12401661\n",
      "step: [384/553] time: 1.0894s, d_loss: 0.00775108, g_loss: 6.55167627, rnn_loss: 0.06371621\n",
      "step: [439/553] time: 1.1244s, d_loss: 0.16785729, g_loss: 7.33818674, rnn_loss: 0.15582162\n",
      "step: [494/553] time: 1.0592s, d_loss: 0.46737343, g_loss: 6.68087959, rnn_loss: 0.07801504\n",
      "step: [549/553] time: 1.1160s, d_loss: 0.01236128, g_loss: 5.66828346, rnn_loss: 0.17971876\n",
      " ** Epoch 123 took 614.076343s\n",
      "step: [54/553] time: 1.1774s, d_loss: 0.26249373, g_loss: 3.79602337, rnn_loss: 0.20522982\n",
      "step: [109/553] time: 1.1588s, d_loss: 0.02526639, g_loss: 5.74283504, rnn_loss: 0.08358500\n",
      "step: [164/553] time: 1.0758s, d_loss: 0.05328748, g_loss: 3.88490558, rnn_loss: 0.12070142\n",
      "step: [219/553] time: 1.0863s, d_loss: 0.00337676, g_loss: 9.00899124, rnn_loss: 0.06249474\n",
      "step: [274/553] time: 1.1233s, d_loss: 0.18898296, g_loss: 4.41723633, rnn_loss: 0.08186807\n",
      "step: [329/553] time: 1.0803s, d_loss: 0.07201897, g_loss: 4.23820114, rnn_loss: 0.03918998\n",
      "step: [384/553] time: 1.1092s, d_loss: 0.03248674, g_loss: 8.64496231, rnn_loss: 0.08279832\n",
      "step: [439/553] time: 1.0193s, d_loss: 0.10148291, g_loss: 3.64469624, rnn_loss: 0.22009361\n",
      "step: [494/553] time: 1.1325s, d_loss: 0.09757941, g_loss: 8.09852219, rnn_loss: 0.06101853\n",
      "step: [549/553] time: 1.0967s, d_loss: 0.31157181, g_loss: 2.43606186, rnn_loss: 0.17364512\n",
      " ** Epoch 124 took 609.643011s\n",
      "step: [54/553] time: 1.0903s, d_loss: 0.05880802, g_loss: 3.46439695, rnn_loss: 0.03291395\n",
      "step: [109/553] time: 1.1089s, d_loss: 0.03485386, g_loss: 3.40710783, rnn_loss: 0.13641426\n",
      "step: [164/553] time: 1.1184s, d_loss: 0.03920590, g_loss: 6.74970531, rnn_loss: 0.14649612\n",
      "step: [219/553] time: 1.0664s, d_loss: 0.13354748, g_loss: 5.25691652, rnn_loss: 0.11383595\n",
      "step: [274/553] time: 1.1009s, d_loss: 0.05324271, g_loss: 3.62124157, rnn_loss: 0.06555317\n",
      "step: [329/553] time: 1.1873s, d_loss: 0.01520350, g_loss: 5.81846476, rnn_loss: 0.16684011\n",
      "step: [384/553] time: 1.1079s, d_loss: 0.03582610, g_loss: 5.78835011, rnn_loss: 0.10729634\n",
      "step: [439/553] time: 1.1423s, d_loss: 0.00418318, g_loss: 5.43063498, rnn_loss: 0.13584803\n",
      "step: [494/553] time: 1.1444s, d_loss: 0.17043941, g_loss: 4.97712135, rnn_loss: 0.05746093\n",
      "step: [549/553] time: 1.0673s, d_loss: 0.02927032, g_loss: 5.29081535, rnn_loss: 0.10077149\n",
      " ** Epoch 125 took 614.389445s\n",
      "step: [54/553] time: 1.1090s, d_loss: 0.04333335, g_loss: 12.65363693, rnn_loss: 0.06391594\n",
      "step: [109/553] time: 1.1205s, d_loss: 0.03604985, g_loss: 6.03417873, rnn_loss: 0.11306125\n",
      "step: [164/553] time: 1.1555s, d_loss: 0.19010696, g_loss: 4.22285366, rnn_loss: 0.10971685\n",
      "step: [219/553] time: 1.0968s, d_loss: 0.04469641, g_loss: 4.13300610, rnn_loss: 0.10926545\n",
      "step: [274/553] time: 1.1464s, d_loss: 0.01727837, g_loss: 4.37372923, rnn_loss: 0.09843022\n",
      "step: [329/553] time: 1.1009s, d_loss: 0.60529065, g_loss: 7.81565571, rnn_loss: 0.02681783\n",
      "step: [384/553] time: 1.1096s, d_loss: 0.23923045, g_loss: 4.92875528, rnn_loss: 0.07145716\n",
      "step: [439/553] time: 1.0723s, d_loss: 0.24596117, g_loss: 1.77335572, rnn_loss: 0.13077480\n",
      "step: [494/553] time: 1.1518s, d_loss: 0.05870219, g_loss: 3.34445000, rnn_loss: 0.10240717\n",
      "step: [549/553] time: 1.0787s, d_loss: 0.05951411, g_loss: 3.68160152, rnn_loss: 0.11269373\n",
      " ** Epoch 126 took 617.315714s\n",
      "step: [54/553] time: 1.1430s, d_loss: 0.09508824, g_loss: 3.79031467, rnn_loss: 0.08417107\n",
      "step: [109/553] time: 1.1095s, d_loss: 0.24923050, g_loss: 5.30511045, rnn_loss: 0.09344406\n",
      "step: [164/553] time: 1.0824s, d_loss: 0.05870034, g_loss: 5.87896061, rnn_loss: 0.06490715\n",
      "step: [219/553] time: 1.1208s, d_loss: 0.01152283, g_loss: 11.02745533, rnn_loss: 0.05288840\n",
      "step: [274/553] time: 1.1285s, d_loss: 0.05182500, g_loss: 4.08458328, rnn_loss: 0.07263511\n",
      "step: [329/553] time: 1.1150s, d_loss: 0.01306611, g_loss: 5.63829041, rnn_loss: 0.09752860\n",
      "step: [384/553] time: 1.1510s, d_loss: 0.07587405, g_loss: 3.81509066, rnn_loss: 0.07775997\n",
      "step: [439/553] time: 1.1373s, d_loss: 0.01950656, g_loss: 7.99135590, rnn_loss: 0.07840020\n",
      "step: [494/553] time: 1.1068s, d_loss: 0.01026096, g_loss: 9.37883186, rnn_loss: 0.04209169\n",
      "step: [549/553] time: 1.0882s, d_loss: 0.32631508, g_loss: 7.84672737, rnn_loss: 0.06252629\n",
      " ** Epoch 127 took 619.988424s\n",
      "step: [54/553] time: 1.0938s, d_loss: 0.05391308, g_loss: 4.46937370, rnn_loss: 0.10689983\n",
      "step: [109/553] time: 1.1030s, d_loss: 0.01765366, g_loss: 15.94540119, rnn_loss: 0.17826551\n",
      "step: [164/553] time: 1.1291s, d_loss: 0.17093681, g_loss: 3.11335135, rnn_loss: 0.05321959\n",
      "step: [219/553] time: 1.2704s, d_loss: 0.01891629, g_loss: 6.61422634, rnn_loss: 0.05569777\n",
      "step: [274/553] time: 1.1090s, d_loss: 0.05622258, g_loss: 3.97332120, rnn_loss: 0.10219376\n",
      "step: [329/553] time: 1.1945s, d_loss: 0.20295928, g_loss: 4.21843147, rnn_loss: 0.04589471\n",
      "step: [384/553] time: 1.1403s, d_loss: 0.29225889, g_loss: 4.18249178, rnn_loss: 0.07570130\n",
      "step: [439/553] time: 1.1088s, d_loss: 0.03452098, g_loss: 5.47314262, rnn_loss: 0.14514075\n",
      "step: [494/553] time: 1.1348s, d_loss: 0.00439078, g_loss: 8.22551155, rnn_loss: 0.10987963\n",
      "step: [549/553] time: 1.1396s, d_loss: 2.49386740, g_loss: 7.11840820, rnn_loss: 0.10221541\n",
      " ** Epoch 128 took 622.087107s\n",
      "step: [54/553] time: 1.1280s, d_loss: 0.03362779, g_loss: 4.16678667, rnn_loss: 0.10686582\n",
      "step: [109/553] time: 1.0874s, d_loss: 0.23549369, g_loss: 2.66752028, rnn_loss: 0.05683177\n",
      "step: [164/553] time: 1.1075s, d_loss: 0.04297360, g_loss: 2.12172318, rnn_loss: 0.10086924\n",
      "step: [219/553] time: 1.0957s, d_loss: 0.10337051, g_loss: 3.49040389, rnn_loss: 0.13822001\n",
      "step: [274/553] time: 1.1526s, d_loss: 0.01543965, g_loss: 9.56336308, rnn_loss: 0.04873858\n",
      "step: [329/553] time: 1.0399s, d_loss: 0.50744879, g_loss: 10.29005432, rnn_loss: 0.13348743\n",
      "step: [384/553] time: 1.1405s, d_loss: 0.13658467, g_loss: 4.00951862, rnn_loss: 0.10219545\n",
      "step: [439/553] time: 1.1184s, d_loss: 0.14562532, g_loss: 4.06632233, rnn_loss: 0.15471227\n",
      "step: [494/553] time: 1.1501s, d_loss: 0.00646155, g_loss: 7.71571636, rnn_loss: 0.10706523\n",
      "step: [549/553] time: 1.1913s, d_loss: 0.00185669, g_loss: 6.02237463, rnn_loss: 0.03661720\n",
      " ** Epoch 129 took 621.002869s\n",
      "step: [54/553] time: 1.1210s, d_loss: 0.01208925, g_loss: 4.84699917, rnn_loss: 0.06848503\n",
      "step: [109/553] time: 1.1507s, d_loss: 0.03335947, g_loss: 8.72800064, rnn_loss: 0.17335069\n",
      "step: [164/553] time: 1.1153s, d_loss: 0.03980116, g_loss: 6.83154869, rnn_loss: 0.21313792\n",
      "step: [219/553] time: 1.0724s, d_loss: 0.06865621, g_loss: 3.47291946, rnn_loss: 0.18026021\n",
      "step: [274/553] time: 1.1182s, d_loss: 0.03229371, g_loss: 4.45422077, rnn_loss: 0.08163197\n",
      "step: [329/553] time: 1.1072s, d_loss: 3.68794537, g_loss: 7.98375416, rnn_loss: 0.02963457\n",
      "step: [384/553] time: 1.1359s, d_loss: 0.02633102, g_loss: 10.03837204, rnn_loss: 0.02947385\n",
      "step: [439/553] time: 1.0774s, d_loss: 0.04647820, g_loss: 3.70853186, rnn_loss: 0.05698245\n",
      "step: [494/553] time: 1.1393s, d_loss: 0.21142122, g_loss: 3.39741135, rnn_loss: 0.16533504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [549/553] time: 1.0363s, d_loss: 0.02546614, g_loss: 4.24951315, rnn_loss: 0.06667876\n",
      " ** Epoch 130 took 622.639375s\n",
      "step: [54/553] time: 1.0944s, d_loss: 0.11362079, g_loss: 6.55506897, rnn_loss: 0.12646469\n",
      "step: [109/553] time: 1.1609s, d_loss: 0.31458378, g_loss: 7.09548378, rnn_loss: 0.13226137\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = Text2Img()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=10)\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "    load_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "    load(loader, sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print('no checkpoints find.')\n",
    "\n",
    "n_epoch = 300\n",
    "n_batch_epoch = int(n_images_train / batch_size)\n",
    "for epoch in range(n_epoch):\n",
    "    start_time = time.time()\n",
    "    if epoch !=0 and (epoch % decay_every == 0):\n",
    "        new_lr_decay = lr_decay ** (epoch // decay_every)\n",
    "        sess.run(tf.assign(model.lr_v, lr * new_lr_decay))\n",
    "        log = \" ** new learning rate: %f\" % (lr * new_lr_decay)\n",
    "        print(log)\n",
    "    elif epoch == 0:\n",
    "        log = \" ** init lr: %f  decay_every_epoch: %d, lr_decay: %f\" % (lr, decay_every, lr_decay)\n",
    "        print(log)\n",
    "    for step in range(n_batch_epoch):\n",
    "        step_time = time.time()\n",
    "        idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\n",
    "        b_real_caption = train_captions[idexs]\n",
    "        b_real_images = train_images[np.floor(np.asarray(idexs).astype('float') / n_captions_per_image).astype('int')]\n",
    "        idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\n",
    "        b_wrong_caption = train_captions[idexs]\n",
    "        idexs2 = get_random_int(min=0, max=n_images_train-1, number=batch_size)\n",
    "        b_wrong_images = train_images[idexs2]\n",
    "        b_z = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, z_dim)).astype(np.float32)\n",
    "        b_real_images = threading_data(b_real_images, prepro_img, mode='train')\n",
    "        b_wrong_images = threading_data(b_wrong_images, prepro_img, mode='train')\n",
    "        if epoch < 160:\n",
    "            errRNN, _ = sess.run([model.rnn_loss, model.rnn_optim], feed_dict={\n",
    "                                            model.t_real_image : b_real_images,\n",
    "                                            model.t_wrong_image : b_wrong_images,\n",
    "                                            model.t_real_caption : b_real_caption,\n",
    "                                            model.t_wrong_caption : b_wrong_caption})\n",
    "        else:\n",
    "            errRNN = 0   \n",
    "        errD, _ = sess.run([model.d_loss, model.d_optim], feed_dict={\n",
    "                            model.t_real_image : b_real_images,\n",
    "                            model.t_wrong_caption : b_wrong_caption,\n",
    "                            model.t_real_caption : b_real_caption,\n",
    "                            model.t_z : b_z})\n",
    "        errG, _ = sess.run([model.g_loss, model.g_optim], feed_dict={\n",
    "                            model.t_real_caption : b_real_caption,\n",
    "                            model.t_z : b_z})\n",
    "        if (step + 1) % (n_batch_epoch // 10) == 0:\n",
    "            print(\"step: [%d/%d] time: %4.4fs, d_loss: %.8f, g_loss: %.8f, rnn_loss: %.8f\" \\\n",
    "                                % (step, n_batch_epoch, time.time() - step_time, errD, errG, errRNN))\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(\" ** Epoch %d took %fs\" % (epoch, time.time()-start_time))\n",
    "        img_gen, rnn_out = sess.run([model.net_g.outputs, model.net_rnn.outputs], feed_dict={\n",
    "                                        model.t_real_caption : sample_sentence,\n",
    "                                        model.t_z : sample_seed})\n",
    "        save_images(img_gen, [ni, ni], 'train_samples_1217_b/train_{:02d}.png'.format(epoch))\n",
    "    if (epoch != 0) and (epoch % 20) == 0:\n",
    "        save(saver, sess, checkpoint_dir, epoch)\n",
    "        print(\"[*] Save checkpoints SUCCESS!\")\n",
    "checkpoint_path = os.path.join(cfg.CHECKPOINT_DIR, cfg.CHECKPOINT_NAME)\n",
    "saver.save(sess, checkpoint_path, global_step=epoch)\n",
    "print('The checkpoint has been created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_r_precision_data():\n",
    "    caption_ids = np.reshape(np.asarray(test_dataset.captions_ids), (-1, cfg.TEXT.WORDS_NUM))\n",
    "    captions_ids_wrong = np.reshape(test_dataset.random_wrong_captions(), (-1, cfg.WRONG_CAPTION, cfg.TEXT.WORDS_NUM))\n",
    "\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # load the trained checkpoint\n",
    "    checkpoint_dir = cfg.CHECKPOINT_DIR\n",
    "    if checkpoint_dir is not None:\n",
    "        loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "        ckpt_path = os.path.join(cfg.CHECKPOINT_DIR, CHECKPOINT_NAME)\n",
    "        loader.restore(sess, ckpt_path)\n",
    "        print(\"Restored model parameters from {}\".format(ckpt_path))\n",
    "    else:\n",
    "        print('no checkpoints find.')\n",
    "\n",
    "    n_caption_test = len(caption_ids)\n",
    "    num_batches = n_caption_test // cfg.BATCH_SIZE\n",
    "\n",
    "    true_cnn_features = np.zeros((num_batches, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "    true_rnn_features = np.zeros((num_batches, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "    wrong_rnn_features = np.zeros((num_batches, cfg.WRONG_CAPTION, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        test_cap = caption_ids[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "\n",
    "        z = np.random.normal(loc=0.0, scale=1.0, size=(cfg.BATCH_SIZE, cfg.GAN.Z_DIM)).astype(np.float32)\n",
    "        \n",
    "        rnn_features = sess.run(rnn_encoder.outputs, feed_dict={t_real_caption: test_cap})\n",
    "        gen = sess.run(generator.outputs, feed_dict={t_real_caption: test_cap, t_z: z})\n",
    "        cnn_features = sess.run(cnn_encoder.outputs, feed_dict={t_real_image: gen})\n",
    "\n",
    "        true_cnn_features[i] = cnn_features\n",
    "        true_rnn_features[i] = rnn_features\n",
    "\n",
    "        for per_wrong_caption in range(cfg.WRONG_CAPTION):\n",
    "            test_cap = captions_ids_wrong[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "            rnn_features = sess.run(rnn_encoder.outputs, feed_dict={t_real_caption: test_cap[:, per_wrong_caption]})\n",
    "            wrong_rnn_features[i, per_wrong_caption] = rnn_features\n",
    "    \n",
    "    # if exists, remove the existing file first\n",
    "    try:\n",
    "        os.remove(os.path.join(cfg.R_PRECISION_DIR, cfg.R_PRECISION_FILE))\n",
    "    except OSError:\n",
    "        pass\n",
    "    np.savez(os.path.join(cfg.R_PRECISION_DIR, cfg.R_PRECISION_FILE), true_cnn=true_cnn_features, true_rnn=true_rnn_features,\n",
    "             wrong_rnn=wrong_rnn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inception_score_data():\n",
    "    caption_ids = np.reshape(np.asarray(test_dataset.captions_ids),\n",
    "                             (-1, cfg.TEXT.CAPTIONS_PER_IMAGE, cfg.TEXT.WORDS_NUM))\n",
    "    \n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    checkpoint_dir = cfg.CHECKPOINT_DIR\n",
    "    if checkpoint_dir is not None:\n",
    "        loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "        ckpt_path = os.path.join(cfg.CHECKPOINT_DIR, cfg.CHECKPOINT_NAME)\n",
    "        loader.restore(sess, ckpt_path)\n",
    "        print(\"Restored model parameters from {}\".format(ckpt_path))\n",
    "    else:\n",
    "        print('no checkpoints find.')\n",
    "\n",
    "    n_caption_test = len(caption_ids)\n",
    "    num_batches = n_caption_test // cfg.BATCH_SIZE\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        for per_caption in range(cfg.TEXT.CAPTIONS_PER_IMAGE):\n",
    "            test_cap = caption_ids[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE, per_caption]\n",
    "            test_directory = test_dataset.filenames[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "\n",
    "            z = np.random.normal(loc=0.0, scale=1.0, size=(cfg.BATCH_SIZE, cfg.GAN.Z_DIM)).astype(np.float32)\n",
    "            gen = sess.run(generator.outputs, feed_dict={t_real_caption: test_cap, t_z: z})\n",
    "            \n",
    "            for j in range(cfg.BATCH_SIZE):\n",
    "                if not os.path.exists(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j].split('/')[0])):\n",
    "                    os.mkdir(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j].split('/')[0]))\n",
    "\n",
    "                scipy.misc.imsave(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j] + '_{}.png'.format(per_caption)), gen[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_r_precision_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_inception_score_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Measure Inception score and R-precision of given test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After set the config file as 'eval_birds.yml' and run the 'generate_inception_score_data()' and 'generate_r_precision_data()', the synthesized images based on given captions and set of image and caption features should be saved inside a 'evaluation' folder, specifically in 'evaluation/generated_images/..' and as 'evaluation/r_precision.npz' respectively.\n",
    "\n",
    "**Then, go to the 'evaluation' folder and run each 'inception_score.ipynb' and 'r_precision.ipynb' file in order to measure inception score and r-precision score.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
