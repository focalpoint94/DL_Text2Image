{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Final Proejct: Text to Image Synthesis (Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For understanding of this work, please carefully look at given PPT file.**\n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the training process **</font> so that TAs can grade both your code and results.  \n",
    "**The TA will set a config file as 'eval_birds.yml' when evaluating the code using 'hidden test dataset'. Thus, please make sure that your code can generate proper data to measure inception score and R-precision of 'hidden test dataset'.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load datasets\n",
    "The Birds dataset will be downloaded automatically if it is not located in the *data* directory. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os, nltk\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "import numpy as np\n",
    "import scipy\n",
    "from utils.data_utils import CUBDataset\n",
    "from utils.loss import cosine_similarity\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "\n",
    "#################################################\n",
    "# DO NOT CHANGE \n",
    "from utils.model_1215_a import CNN_ENCODER, RNN_ENCODER, GENERATOR, DISCRIMINATOR\n",
    "#################################################\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'BATCH_SIZE': 64,\n",
      " 'CHECKPOINT_DIR': './checkpoint',\n",
      " 'CHECKPOINT_NAME': 'model.ckpt',\n",
      " 'CNN': {'EMBEDDING_DIM': 0, 'H_DIM': 0},\n",
      " 'CONFIG_NAME': 'text-to-image',\n",
      " 'CUDA': False,\n",
      " 'DATASET_NAME': 'birds',\n",
      " 'DATA_DIR': 'data/birds',\n",
      " 'EMBEDDING_TYPE': 'cnn-rnn',\n",
      " 'GAN': {'B_ATTENTION': False,\n",
      "         'B_CONDITION': False,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 0,\n",
      "         'DF_DIM': 0,\n",
      "         'EMBEDDING_DIM': 0,\n",
      "         'GF_DIM': 0,\n",
      "         'R_NUM': 0,\n",
      "         'Z_DIM': 512},\n",
      " 'GPU_ID': '0',\n",
      " 'IMAGE_SIZE': 256,\n",
      " 'NUM_BATCH_FOR_TEST': 0,\n",
      " 'RANDOM_SEED': 0,\n",
      " 'RNN': {'EMBEDDING_DIM': 0,\n",
      "         'H_DIM': 0,\n",
      "         'TYPE': '',\n",
      "         'VOCAB_SIZE': 0,\n",
      "         'WORD_EMBEDDING_DIM': 0},\n",
      " 'R_PRECISION_DIR': './evaluation',\n",
      " 'R_PRECISION_FILE': 'r_precision.npz',\n",
      " 'R_PRECISION_FILE_HIDDEN': 'r_precision_hidden.npz',\n",
      " 'TEST': {'B_EXAMPLE': False,\n",
      "          'GENERATED_HIDDEN_TEST_IMAGES': './evaluation/generated_images_hidden',\n",
      "          'GENERATED_TEST_IMAGES': './evaluation/generated_images'},\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 128, 'WORDS_NUM': 20},\n",
      " 'TRAIN': {'CNN_ENCODER': '',\n",
      "           'COEFF': {'COLOR_LOSS': 0.0, 'KL': 0.0, 'UNCOND_LOSS': 0.0},\n",
      "           'DISCRIMINATOR': '',\n",
      "           'DISCRIMINATOR_LR': 0.0,\n",
      "           'FLAG': True,\n",
      "           'GENERATOR': '',\n",
      "           'GENERATOR_LR': 0.0,\n",
      "           'MAX_EPOCH': 600,\n",
      "           'RNN_ENCODER': '',\n",
      "           'SNAPSHOT_INTERVAL': 0},\n",
      " 'WORKERS': 4,\n",
      " 'WRONG_CAPTION': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/final-project-deep-learning-19-tf/miscc/config.py:121: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "# Set a config file as 'train_birds.yml' in training, as 'eval_birds.yml' for evaluation\n",
    "cfg_from_file('cfg/train_birds.yml') # eval_birds.yml\n",
    "\n",
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cfg.GPU_ID\n",
    "\n",
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "output_dir = 'sample/%s_%s_%s' % (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf\n",
      "\n",
      "self.data_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds\n",
      "\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011.tgz\n",
      "\n",
      "Dataset already exists\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011/images\n",
      "\n",
      "Load from:  data/birds/captions.pickle\n",
      "self.current_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf\n",
      "\n",
      "self.data_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds\n",
      "\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011.tgz\n",
      "\n",
      "Dataset already exists\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011/images\n",
      "\n",
      "Load from:  data/birds/captions.pickle\n",
      "\n",
      "train data directory:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/train\n",
      "test data directory:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/test\n",
      "\n",
      "# of train filenames:(8855,)\n",
      "# of test filenames:(2933,)\n",
      "\n",
      "example of filename of train image:002.Laysan_Albatross/Laysan_Albatross_0002_1027\n",
      "example of filename of valid image:001.Black_footed_Albatross/Black_Footed_Albatross_0046_18\n",
      "\n",
      "example of caption and its ids:\n",
      "['a', 'bird', 'with', 'a', 'very', 'long', 'wing', 'span', 'and', 'a', 'long', 'pointed', 'beak']\n",
      "[ 1  2  3  1  4  5  6  7  8  1  5  9 10  0  0  0  0  0  0  0]\n",
      "\n",
      "example of caption and its ids:\n",
      "['light', 'tan', 'colored', 'bird', 'with', 'a', 'white', 'head', 'and', 'an', 'orange', 'beak']\n",
      "[ 67 106  89   2   3   1  14  25   8  28  52  10   0   0   0   0   0   0\n",
      "   0   0]\n",
      "\n",
      "# of train captions:(88550,)\n",
      "# of test captions:(29330,)\n",
      "\n",
      "# of train caption ids:(88550, 20)\n",
      "# of test caption ids:(29330, 20)\n",
      "\n",
      "# of train images:(8855, 256, 256, 3)\n",
      "# of test images:(2933, 256, 256, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CUBDataset(cfg.DATA_DIR, split='train')\n",
    "test_dataset = CUBDataset(cfg.DATA_DIR, split='test')\n",
    "\n",
    "print(f'\\ntrain data directory:\\n{train_dataset.split_dir}')\n",
    "print(f'test data directory:\\n{test_dataset.split_dir}\\n')\n",
    "\n",
    "print(f'# of train filenames:{train_dataset.filenames.shape}')\n",
    "print(f'# of test filenames:{test_dataset.filenames.shape}\\n')\n",
    "\n",
    "print(f'example of filename of train image:{train_dataset.filenames[0]}')\n",
    "print(f'example of filename of valid image:{test_dataset.filenames[0]}\\n')\n",
    "\n",
    "print(f'example of caption and its ids:\\n{train_dataset.captions[0]}\\n{train_dataset.captions_ids[0]}\\n')\n",
    "print(f'example of caption and its ids:\\n{test_dataset.captions[0]}\\n{test_dataset.captions_ids[0]}\\n')\n",
    "\n",
    "print(f'# of train captions:{np.asarray(train_dataset.captions).shape}')\n",
    "print(f'# of test captions:{np.asarray(test_dataset.captions).shape}\\n')\n",
    "\n",
    "print(f'# of train caption ids:{np.asarray(train_dataset.captions_ids).shape}')\n",
    "print(f'# of test caption ids:{np.asarray(test_dataset.captions_ids).shape}\\n')\n",
    "\n",
    "print(f'# of train images:{train_dataset.images.shape}')\n",
    "print(f'# of test images:{test_dataset.images.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8855, 256, 256, 3)\n",
      "(2933, 256, 256, 3)\n",
      "(88550, 20)\n",
      "(29330, 20)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_dataset.images\n",
    "test_images = test_dataset.images\n",
    "train_captions = np.asarray(train_dataset.captions_ids)\n",
    "test_captions = np.asarray(test_dataset.captions_ids)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(train_captions.shape)\n",
    "print(test_captions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8855, 64, 64, 3)\n",
      "(2933, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "train_images_64 = []\n",
    "for train_image in train_images:\n",
    "    train_images_64.append(resize(train_image, (64, 64, 3)))\n",
    "train_images_64 = np.asarray(train_images_64)\n",
    "print(train_images_64.shape)\n",
    "assert train_images_64.shape[0] == train_images.shape[0]\n",
    "test_images_64 = []\n",
    "for test_image in test_images:\n",
    "    test_images_64.append(resize(test_image, (64, 64, 3)))\n",
    "test_images_64 = np.asarray(test_images_64)\n",
    "print(test_images_64.shape)\n",
    "assert test_images_64.shape[0] == test_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images_64\n",
    "test_images = test_images_64\n",
    "n_captions_train = len(train_captions)\n",
    "n_captions_per_image = 10\n",
    "n_images_train = len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import threading\n",
    "import scipy.ndimage as ndi\n",
    "from skimage import transform\n",
    "from skimage import exposure\n",
    "import skimage\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def sent2ID(sample_sentence):\n",
    "    caption = []\n",
    "    cap = sample_sentence\n",
    "    if len(cap) == 0:\n",
    "        exit()\n",
    "    cap = cap.replace(\"\\ufffd\\ufffd\", \" \")\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(cap.lower())\n",
    "    tokens_new = []\n",
    "    for t in tokens:\n",
    "        t = t.encode('ascii', 'ignore').decode('ascii')\n",
    "        if len(t) > 0:\n",
    "            tokens_new.append(t)\n",
    "    caption.append(tokens_new)\n",
    "    caption_new = []\n",
    "    t = caption[0]\n",
    "    rev = []\n",
    "    for w in t:\n",
    "        if w in train_dataset.wordtoix:\n",
    "            rev.append(train_dataset.wordtoix[w])\n",
    "    x, x_len = train_dataset.get_caption(rev)\n",
    "    caption_new.append(np.squeeze(x, axis=1))\n",
    "    return caption_new\n",
    "\n",
    "def ID2sent(sample_caption):\n",
    "    sentence = []\n",
    "    for ID in sample_caption:\n",
    "        if ID != train_dataset.ixtoword['<PAD>']:\n",
    "            sentence.append(train_dataset.ixtoword[ID])\n",
    "    return sentence\n",
    "\n",
    "def get_random_int(min=0, max=10, number=5):\n",
    "    return [random.randint(min,max) for p in range(0,number)]\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "    return img\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return scipy.misc.imsave(path, merge(images, size))\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(images, size, image_path)\n",
    "\n",
    "def threading_data(data=None, fn=None, **kwargs):\n",
    "    def apply_fn(results, i, data, kwargs):\n",
    "        results[i] = fn(data, **kwargs)\n",
    "    results = [None] * len(data)\n",
    "    threads = []\n",
    "    for i in range(len(data)):\n",
    "        t = threading.Thread(\n",
    "                        name='threading_and_return',\n",
    "                        target=apply_fn,\n",
    "                        args=(results, i, data[i], kwargs)\n",
    "                        )\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    return np.asarray(results)\n",
    "\n",
    "def apply_transform(x, transform_matrix, channel_index=2, fill_mode='nearest', cval=0., order=1):\n",
    "    x = np.rollaxis(x, channel_index, 0)\n",
    "    final_affine_matrix = transform_matrix[:2, :2]\n",
    "    final_offset = transform_matrix[:2, 2]\n",
    "    channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n",
    "                      final_offset, order=order, mode=fill_mode, cval=cval) for x_channel in x]\n",
    "    x = np.stack(channel_images, axis=0)\n",
    "    x = np.rollaxis(x, 0, channel_index + 1)\n",
    "    return x\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 + 0.5\n",
    "    o_y = float(y) / 2 + 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "def rotation(x, rg=20, is_random=False, row_index=0, col_index=1, channel_index=2,\n",
    "                    fill_mode='nearest', cval=0.):\n",
    "    if is_random:\n",
    "        theta = np.pi / 180 * np.random.uniform(-rg, rg)\n",
    "    else:\n",
    "        theta = np.pi / 180 * rg\n",
    "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                [np.sin(theta), np.cos(theta), 0],\n",
    "                                [0, 0, 1]])\n",
    "    h, w = x.shape[row_index], x.shape[col_index]\n",
    "    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\n",
    "    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n",
    "    return x\n",
    "\n",
    "def crop(x, wrg, hrg, is_random=False, row_index=0, col_index=1, channel_index=2):\n",
    "    h, w = x.shape[row_index], x.shape[col_index]\n",
    "    assert (h > hrg) and (w > wrg), \"The size of cropping should smaller than the original image\"\n",
    "    if is_random:\n",
    "        h_offset = int(np.random.uniform(0, h-hrg) - 1)\n",
    "        w_offset = int(np.random.uniform(0, w-wrg) - 1)\n",
    "        return x[h_offset: hrg + h_offset ,w_offset: wrg + w_offset]\n",
    "    else:\n",
    "        h_offset = int(np.floor((h - hrg)/ 2.))\n",
    "        w_offset = int(np.floor((w - wrg)/ 2.))\n",
    "        h_end = h_offset + hrg\n",
    "        w_end = w_offset + wrg\n",
    "        return x[h_offset: h_end, w_offset: w_end]\n",
    "\n",
    "def flip_axis(x, axis, is_random=False):\n",
    "    if is_random:\n",
    "        factor = np.random.uniform(-1, 1)\n",
    "        if factor > 0:\n",
    "            x = np.asarray(x).swapaxes(axis, 0)\n",
    "            x = x[::-1, ...]\n",
    "            x = x.swapaxes(0, axis)\n",
    "            return x\n",
    "        else:\n",
    "            return x\n",
    "    else:\n",
    "        x = np.asarray(x).swapaxes(axis, 0)\n",
    "        x = x[::-1, ...]\n",
    "        x = x.swapaxes(0, axis)\n",
    "        return x\n",
    "\n",
    "def imresize(x, size=[100, 100], interp='bilinear', mode=None):\n",
    "    if x.shape[-1] == 1:\n",
    "        x = scipy.misc.imresize(x[:, :, 0], size, interp=interp, mode=mode)\n",
    "        return x[:, :, np.newaxis]\n",
    "    elif x.shape[-1] == 3:\n",
    "        return scipy.misc.imresize(x, size, interp=interp, mode=mode)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported channel %d\" % x.shape[-1])\n",
    "\n",
    "def prepro_img(x, mode=None):\n",
    "    if mode=='train':\n",
    "        x = flip_axis(x, axis=1, is_random=True)\n",
    "        x = rotation(x, rg=16, is_random=True, fill_mode='nearest')\n",
    "        x = imresize(x, size=[64 + 15, 64 + 15], interp='bilinear', mode=None)\n",
    "        x = crop(x, wrg=64, hrg=64, is_random=True)\n",
    "        x = x / (255. / 2.)\n",
    "        x = x - 1.\n",
    "    return x\n",
    "\n",
    "def combine_and_save_image_sets(image_sets, directory):\n",
    "    for i in range(len(image_sets[0])):\n",
    "        combined_image = []\n",
    "        for set_no in range(len(image_sets)):\n",
    "            combined_image.append(image_sets[set_no][i])\n",
    "            combined_image.append(np.zeros((image_sets[set_no][i].shape[0], 5, 3)))\n",
    "        combined_image = np.concatenate(combined_image, axis = 1)\n",
    "        scipy.misc.imsave(os.path.join(directory, 'combined_{}.jpg'.format(i)), combined_image)\n",
    "\n",
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print('The checkpoint has been created.')\n",
    "\n",
    "def load(saver, sess, ckpt_path):\n",
    "    saver.restore(sess, ckpt_path)\n",
    "    print(\"Restored model parameters from {}\".format(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20)\n"
     ]
    }
   ],
   "source": [
    "train_samples_dir = 'train_samples_1215_a'\n",
    "if os.path.exists(train_samples_dir) == False:\n",
    "    os.makedirs(train_samples_dir)\n",
    "\n",
    "lr = 0.0002\n",
    "lr_decay = 0.5      \n",
    "decay_every = 200  \n",
    "beta1 = 0.5\n",
    "checkpoint_dir = './checkpoint_1215_a'\n",
    "z_dim = 512\n",
    "image_size = 64\n",
    "c_dim = 3\n",
    "batch_size = 64\n",
    "ni = int(np.ceil(np.sqrt(batch_size)))\n",
    "\n",
    "sample_size = batch_size\n",
    "sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, z_dim)).astype(np.float32)\n",
    "sample_sentence = [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni)\n",
    "for i, sent in enumerate(sample_sentence):\n",
    "    sample_sentence[i] = sent2ID(sent)\n",
    "sample_sentence = np.asarray(sample_sentence)\n",
    "sample_sentence = np.reshape(sample_sentence, (sample_size, 20))\n",
    "print(sample_sentence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Text2Img:\n",
    "    def __init__(self):\n",
    "        \"\"\" Information \"\"\"\n",
    "        self.lr = 0.0002\n",
    "        self.lr_decay = 0.5      \n",
    "        self.decay_every = 200  \n",
    "        self.beta1 = 0.5\n",
    "        self.z_dim = 512\n",
    "        self.image_size = 64\n",
    "        self.c_dim = 3\n",
    "        self.batch_size = 64\n",
    "        self.alpha = 0.2\n",
    "        \n",
    "        \"\"\" Place Holders \"\"\"\n",
    "        self.t_real_image = tf.placeholder('float32', [self.batch_size, self.image_size, image_size, 3], name = 'real_image')\n",
    "        self.t_wrong_image = tf.placeholder('float32', [self.batch_size ,self.image_size, image_size, 3], name = 'wrong_image')\n",
    "        self.t_real_caption = tf.placeholder(dtype=tf.int64, shape=[self.batch_size, None], name='real_caption_input')\n",
    "        self.t_wrong_caption = tf.placeholder(dtype=tf.int64, shape=[self.batch_size, None], name='wrong_caption_input')\n",
    "        self.t_z = tf.placeholder(tf.float32, [self.batch_size, self.z_dim], name='z_noise')\n",
    "        \n",
    "        \"\"\" Training Phase - CNN - RNN mapping \"\"\"\n",
    "        net_cnn = CNN_ENCODER(self.t_real_image, is_training=True, reuse=False)\n",
    "        x = net_cnn.outputs\n",
    "        v = RNN_ENCODER(self.t_real_caption, is_training=True, reuse=False).outputs\n",
    "        x_w = CNN_ENCODER(self.t_wrong_image, is_training=True, reuse=True).outputs\n",
    "        v_w = RNN_ENCODER(self.t_wrong_caption, is_training=True, reuse=True).outputs\n",
    "        self.rnn_loss = tf.reduce_mean(tf.maximum(0., self.alpha - cosine_similarity(x, v) + cosine_similarity(x, v_w))) + \\\n",
    "                    tf.reduce_mean(tf.maximum(0., self.alpha - cosine_similarity(x, v) + cosine_similarity(x_w, v)))\n",
    "        \n",
    "        \"\"\" Training Phase - GAN \"\"\"\n",
    "        self.net_rnn = RNN_ENCODER(self.t_real_caption, is_training=False, reuse=True)\n",
    "        net_fake_image = GENERATOR(self.t_z, self.net_rnn.outputs, is_training=True, reuse=False)\n",
    "        net_disc_fake = DISCRIMINATOR(net_fake_image.outputs, self.net_rnn.outputs, is_training=True, reuse=False)\n",
    "        disc_fake_logits = net_disc_fake.logits\n",
    "        net_disc_real = DISCRIMINATOR(self.t_real_image, self.net_rnn.outputs, is_training=True, reuse=True)\n",
    "        disc_real_logits = net_disc_real.logits\n",
    "        net_disc_mismatch = DISCRIMINATOR(self.t_real_image, RNN_ENCODER(self.t_wrong_caption, is_training=False, reuse=True).outputs,\n",
    "                                        is_training=True, reuse=True)\n",
    "        disc_mismatch_logits = net_disc_mismatch.logits\n",
    "        d_loss1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_real_logits,     labels=tf.ones_like(disc_real_logits),      name='d1'))\n",
    "        d_loss2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_mismatch_logits, labels=tf.zeros_like(disc_mismatch_logits), name='d2'))\n",
    "        d_loss3 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits,     labels=tf.zeros_like(disc_fake_logits),     name='d3'))\n",
    "        self.d_loss = d_loss1 + (d_loss2 + d_loss3) * 0.5\n",
    "        self.g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits, labels=tf.ones_like(disc_fake_logits), name='g'))\n",
    "        \n",
    "        \"\"\" Testing Phase \"\"\"\n",
    "        self.net_g = GENERATOR(self.t_z, RNN_ENCODER(self.t_real_caption, is_training=False, reuse=True).outputs,\n",
    "                            is_training=False, reuse=True)\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        rnn_vars = [var for var in tf.trainable_variables() if 'rnnencoder' in var.name]\n",
    "        cnn_vars = [var for var in tf.trainable_variables() if 'cnnencoder' in var.name]\n",
    "        d_vars = [var for var in tf.trainable_variables() if 'discriminator' in var.name]\n",
    "        g_vars = [var for var in tf.trainable_variables() if 'generator' in var.name]\n",
    "        update_ops_CNN = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'cnnencoder' in var.name]\n",
    "        update_ops_D = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'discriminator' in var.name]\n",
    "        update_ops_G = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'generator' in var.name]\n",
    "        with tf.variable_scope('learning_rate'):\n",
    "            self.lr_v = tf.Variable(self.lr, trainable=False)\n",
    "        with tf.control_dependencies(update_ops_CNN):\n",
    "            grads, _ = tf.clip_by_global_norm(tf.gradients(self.rnn_loss, rnn_vars + cnn_vars), 10)\n",
    "            optimizer = tf.train.AdamOptimizer(self.lr_v, beta1=self.beta1)\n",
    "            self.rnn_optim = optimizer.apply_gradients(zip(grads, rnn_vars + cnn_vars))\n",
    "        with tf.control_dependencies(update_ops_D):\n",
    "            self.d_optim = tf.train.AdamOptimizer(self.lr_v, beta1=self.beta1).minimize(self.d_loss, var_list=d_vars)\n",
    "        with tf.control_dependencies(update_ops_G):\n",
    "            self.g_optim = tf.train.AdamOptimizer(self.lr_v, beta1=self.beta1).minimize(self.g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no checkpoints find.\n",
      " ** init lr: 0.000200  decay_every_epoch: 200, lr_decay: 0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py:142: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/1000] time: 0.4526s, d_loss: 1.39677835, g_loss: 3.25727654, rnn_loss: 0.28294724\n",
      " ** Epoch 0 took 70.973406s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1000] time: 0.4483s, d_loss: 1.08312941, g_loss: 2.02957177, rnn_loss: 0.27835143\n",
      " ** Epoch 1 took 62.322615s\n",
      "Epoch: [2/1000] time: 0.4504s, d_loss: 1.34336734, g_loss: 1.85429072, rnn_loss: 0.22829971\n",
      " ** Epoch 2 took 62.223853s\n",
      "Epoch: [3/1000] time: 0.4546s, d_loss: 1.36559641, g_loss: 0.82441747, rnn_loss: 0.27085733\n",
      " ** Epoch 3 took 62.359390s\n",
      "Epoch: [4/1000] time: 0.4489s, d_loss: 1.65723884, g_loss: 2.21429324, rnn_loss: 0.22263236\n",
      " ** Epoch 4 took 62.305847s\n",
      "Epoch: [5/1000] time: 0.4511s, d_loss: 1.22167110, g_loss: 1.37054646, rnn_loss: 0.17334834\n",
      " ** Epoch 5 took 62.724688s\n",
      "Epoch: [6/1000] time: 0.4441s, d_loss: 1.39337754, g_loss: 0.97370875, rnn_loss: 0.22804393\n",
      " ** Epoch 6 took 62.049126s\n",
      "Epoch: [7/1000] time: 0.4447s, d_loss: 1.01644659, g_loss: 1.34860778, rnn_loss: 0.16401580\n",
      " ** Epoch 7 took 61.415032s\n",
      "Epoch: [8/1000] time: 0.4460s, d_loss: 1.08504283, g_loss: 2.37551737, rnn_loss: 0.23385154\n",
      " ** Epoch 8 took 61.242856s\n",
      "Epoch: [9/1000] time: 0.4406s, d_loss: 1.11465311, g_loss: 0.95019245, rnn_loss: 0.14657161\n",
      " ** Epoch 9 took 61.130302s\n",
      "Epoch: [10/1000] time: 0.4500s, d_loss: 1.12689281, g_loss: 1.42656922, rnn_loss: 0.20272079\n",
      " ** Epoch 10 took 61.763397s\n",
      "Epoch: [11/1000] time: 0.4473s, d_loss: 1.22201705, g_loss: 1.53170156, rnn_loss: 0.19223928\n",
      " ** Epoch 11 took 61.482069s\n",
      "Epoch: [12/1000] time: 0.4458s, d_loss: 1.13514209, g_loss: 1.08705354, rnn_loss: 0.17684171\n",
      " ** Epoch 12 took 61.120114s\n",
      "Epoch: [13/1000] time: 0.4437s, d_loss: 0.98256439, g_loss: 1.06419587, rnn_loss: 0.14559287\n",
      " ** Epoch 13 took 61.103219s\n",
      "Epoch: [14/1000] time: 0.4425s, d_loss: 0.97585434, g_loss: 1.19928443, rnn_loss: 0.15451711\n",
      " ** Epoch 14 took 61.060911s\n",
      "Epoch: [15/1000] time: 0.4429s, d_loss: 0.68829620, g_loss: 1.51854300, rnn_loss: 0.17395753\n",
      " ** Epoch 15 took 61.598283s\n",
      "Epoch: [16/1000] time: 0.4460s, d_loss: 0.83952749, g_loss: 2.07170773, rnn_loss: 0.20761487\n",
      " ** Epoch 16 took 61.567442s\n",
      "Epoch: [17/1000] time: 0.4474s, d_loss: 0.98165572, g_loss: 1.16846836, rnn_loss: 0.19096218\n",
      " ** Epoch 17 took 61.155388s\n",
      "Epoch: [18/1000] time: 0.4441s, d_loss: 1.64453757, g_loss: 0.42981878, rnn_loss: 0.19259232\n",
      " ** Epoch 18 took 61.133493s\n",
      "Epoch: [19/1000] time: 0.4405s, d_loss: 0.86282337, g_loss: 3.19984555, rnn_loss: 0.14376381\n",
      " ** Epoch 19 took 61.215120s\n",
      "Epoch: [20/1000] time: 0.4440s, d_loss: 0.93129319, g_loss: 1.19742727, rnn_loss: 0.15652803\n",
      " ** Epoch 20 took 61.872555s\n",
      "Epoch: [21/1000] time: 0.4434s, d_loss: 0.96310413, g_loss: 0.60267979, rnn_loss: 0.23496494\n",
      " ** Epoch 21 took 61.704264s\n",
      "Epoch: [22/1000] time: 0.4421s, d_loss: 1.00849116, g_loss: 0.90006131, rnn_loss: 0.18341871\n",
      " ** Epoch 22 took 61.377539s\n",
      "Epoch: [23/1000] time: 0.4429s, d_loss: 0.97703046, g_loss: 1.50611210, rnn_loss: 0.20135394\n",
      " ** Epoch 23 took 61.291625s\n",
      "Epoch: [24/1000] time: 0.4464s, d_loss: 0.84640962, g_loss: 1.01185226, rnn_loss: 0.15230212\n",
      " ** Epoch 24 took 61.068371s\n",
      "Epoch: [25/1000] time: 0.4471s, d_loss: 1.22320068, g_loss: 1.49399531, rnn_loss: 0.14281970\n",
      " ** Epoch 25 took 61.614738s\n",
      "Epoch: [26/1000] time: 0.4458s, d_loss: 1.08989978, g_loss: 0.76807368, rnn_loss: 0.15394787\n",
      " ** Epoch 26 took 61.503971s\n",
      "Epoch: [27/1000] time: 0.4463s, d_loss: 0.87648773, g_loss: 0.87570369, rnn_loss: 0.17606324\n",
      " ** Epoch 27 took 61.463405s\n",
      "Epoch: [28/1000] time: 0.4488s, d_loss: 1.07510638, g_loss: 0.59245086, rnn_loss: 0.16720098\n",
      " ** Epoch 28 took 61.379764s\n",
      "Epoch: [29/1000] time: 0.4461s, d_loss: 0.90020633, g_loss: 0.72421259, rnn_loss: 0.17509609\n",
      " ** Epoch 29 took 61.496624s\n",
      "Epoch: [30/1000] time: 0.4413s, d_loss: 1.05278420, g_loss: 0.42271721, rnn_loss: 0.19069144\n",
      " ** Epoch 30 took 61.922545s\n",
      "Epoch: [31/1000] time: 0.4459s, d_loss: 1.33828819, g_loss: 2.77122307, rnn_loss: 0.10785300\n",
      " ** Epoch 31 took 61.530653s\n",
      "Epoch: [32/1000] time: 0.4443s, d_loss: 0.70497149, g_loss: 1.66667426, rnn_loss: 0.11950122\n",
      " ** Epoch 32 took 61.493686s\n",
      "Epoch: [33/1000] time: 0.4428s, d_loss: 0.88748866, g_loss: 0.51410329, rnn_loss: 0.11218600\n",
      " ** Epoch 33 took 61.220758s\n",
      "Epoch: [34/1000] time: 0.4462s, d_loss: 0.52086329, g_loss: 1.68686414, rnn_loss: 0.12054386\n",
      " ** Epoch 34 took 61.511793s\n",
      "Epoch: [35/1000] time: 0.4452s, d_loss: 0.82905102, g_loss: 1.76858902, rnn_loss: 0.14549714\n",
      " ** Epoch 35 took 61.787168s\n",
      "Epoch: [36/1000] time: 0.4511s, d_loss: 0.69644344, g_loss: 0.75915158, rnn_loss: 0.22325942\n",
      " ** Epoch 36 took 61.758655s\n",
      "Epoch: [37/1000] time: 0.4469s, d_loss: 0.70161027, g_loss: 2.00145817, rnn_loss: 0.14078185\n",
      " ** Epoch 37 took 61.538736s\n",
      "Epoch: [38/1000] time: 0.4467s, d_loss: 0.78816551, g_loss: 2.21587420, rnn_loss: 0.14568797\n",
      " ** Epoch 38 took 61.188251s\n",
      "Epoch: [39/1000] time: 0.4416s, d_loss: 1.60713255, g_loss: 0.52824879, rnn_loss: 0.13264298\n",
      " ** Epoch 39 took 61.121192s\n",
      "Epoch: [40/1000] time: 0.4664s, d_loss: 0.57269287, g_loss: 1.22353530, rnn_loss: 0.13837345\n",
      " ** Epoch 40 took 61.587816s\n",
      "Epoch: [41/1000] time: 0.4431s, d_loss: 0.74214685, g_loss: 1.21998739, rnn_loss: 0.14395876\n",
      " ** Epoch 41 took 61.556682s\n",
      "Epoch: [42/1000] time: 0.4412s, d_loss: 0.71720988, g_loss: 0.79509723, rnn_loss: 0.13943426\n",
      " ** Epoch 42 took 60.985471s\n",
      "Epoch: [43/1000] time: 0.4450s, d_loss: 0.61349535, g_loss: 1.36936688, rnn_loss: 0.16239166\n",
      " ** Epoch 43 took 60.999881s\n",
      "Epoch: [44/1000] time: 0.4456s, d_loss: 0.55070519, g_loss: 1.65827322, rnn_loss: 0.13350520\n",
      " ** Epoch 44 took 60.971741s\n",
      "Epoch: [45/1000] time: 0.4654s, d_loss: 1.03731501, g_loss: 1.51990569, rnn_loss: 0.18424676\n",
      " ** Epoch 45 took 61.293789s\n",
      "Epoch: [46/1000] time: 0.4440s, d_loss: 0.78577703, g_loss: 2.49569035, rnn_loss: 0.10651278\n",
      " ** Epoch 46 took 61.786070s\n",
      "Epoch: [47/1000] time: 0.4472s, d_loss: 1.18451726, g_loss: 2.29541135, rnn_loss: 0.17910281\n",
      " ** Epoch 47 took 61.155314s\n",
      "Epoch: [48/1000] time: 0.4428s, d_loss: 0.65758944, g_loss: 1.49726009, rnn_loss: 0.14432584\n",
      " ** Epoch 48 took 61.321162s\n",
      "Epoch: [49/1000] time: 0.4475s, d_loss: 0.72036290, g_loss: 1.21970224, rnn_loss: 0.11906915\n",
      " ** Epoch 49 took 61.520217s\n",
      "Epoch: [50/1000] time: 0.4676s, d_loss: 0.62700272, g_loss: 1.42151928, rnn_loss: 0.15659750\n",
      " ** Epoch 50 took 61.507140s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [51/1000] time: 0.4443s, d_loss: 0.54909503, g_loss: 2.63167858, rnn_loss: 0.15827386\n",
      " ** Epoch 51 took 61.790272s\n",
      "Epoch: [52/1000] time: 0.4510s, d_loss: 1.23598301, g_loss: 0.32306647, rnn_loss: 0.13663614\n",
      " ** Epoch 52 took 61.359198s\n",
      "Epoch: [53/1000] time: 0.4461s, d_loss: 0.57462347, g_loss: 2.08920574, rnn_loss: 0.14484355\n",
      " ** Epoch 53 took 61.647146s\n",
      "Epoch: [54/1000] time: 0.4480s, d_loss: 0.86099315, g_loss: 0.81827623, rnn_loss: 0.13169277\n",
      " ** Epoch 54 took 61.588519s\n",
      "Epoch: [55/1000] time: 0.4733s, d_loss: 0.71069372, g_loss: 1.43199468, rnn_loss: 0.16166800\n",
      " ** Epoch 55 took 61.667544s\n",
      "Epoch: [56/1000] time: 0.4444s, d_loss: 0.79787332, g_loss: 1.27684641, rnn_loss: 0.12665358\n",
      " ** Epoch 56 took 62.367298s\n",
      "Epoch: [57/1000] time: 0.4427s, d_loss: 0.70550793, g_loss: 1.16839194, rnn_loss: 0.09976143\n",
      " ** Epoch 57 took 61.285596s\n",
      "Epoch: [58/1000] time: 0.4440s, d_loss: 0.56286520, g_loss: 2.08863378, rnn_loss: 0.13460146\n",
      " ** Epoch 58 took 61.217295s\n",
      "Epoch: [59/1000] time: 0.4492s, d_loss: 0.81807542, g_loss: 1.04680467, rnn_loss: 0.12740988\n",
      " ** Epoch 59 took 61.198529s\n",
      "Epoch: [60/1000] time: 0.4457s, d_loss: 0.72657621, g_loss: 0.73278219, rnn_loss: 0.12809956\n",
      " ** Epoch 60 took 61.248566s\n",
      "Epoch: [61/1000] time: 0.4412s, d_loss: 0.62847704, g_loss: 2.65564013, rnn_loss: 0.10458966\n",
      " ** Epoch 61 took 62.059592s\n",
      "Epoch: [62/1000] time: 0.4420s, d_loss: 0.42070270, g_loss: 2.04337287, rnn_loss: 0.11907345\n",
      " ** Epoch 62 took 61.194534s\n",
      "Epoch: [63/1000] time: 0.4430s, d_loss: 0.57625180, g_loss: 2.02313423, rnn_loss: 0.16631085\n",
      " ** Epoch 63 took 61.223179s\n",
      "Epoch: [64/1000] time: 0.4465s, d_loss: 0.55013883, g_loss: 1.24407673, rnn_loss: 0.08639465\n",
      " ** Epoch 64 took 61.416296s\n",
      "Epoch: [65/1000] time: 0.4426s, d_loss: 1.29154170, g_loss: 0.30070841, rnn_loss: 0.17519587\n",
      " ** Epoch 65 took 61.044813s\n",
      "Epoch: [66/1000] time: 0.4465s, d_loss: 0.33611861, g_loss: 1.75685763, rnn_loss: 0.13006416\n",
      " ** Epoch 66 took 61.949966s\n",
      "Epoch: [67/1000] time: 0.4424s, d_loss: 0.79521996, g_loss: 1.74438035, rnn_loss: 0.14998007\n",
      " ** Epoch 67 took 61.158108s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [68/1000] time: 0.4477s, d_loss: 0.57435745, g_loss: 1.41203547, rnn_loss: 0.11899552\n",
      " ** Epoch 68 took 61.307806s\n",
      "Epoch: [69/1000] time: 0.4488s, d_loss: 0.43365258, g_loss: 0.83381140, rnn_loss: 0.10913260\n",
      " ** Epoch 69 took 61.338626s\n",
      "Epoch: [70/1000] time: 0.4446s, d_loss: 0.36439633, g_loss: 3.25707245, rnn_loss: 0.16765557\n",
      " ** Epoch 70 took 61.409520s\n",
      "Epoch: [71/1000] time: 0.4385s, d_loss: 0.72157705, g_loss: 0.54475248, rnn_loss: 0.13295031\n",
      " ** Epoch 71 took 62.009081s\n",
      "Epoch: [72/1000] time: 0.4397s, d_loss: 1.06414485, g_loss: 2.86718917, rnn_loss: 0.12723973\n",
      " ** Epoch 72 took 61.140329s\n",
      "Epoch: [73/1000] time: 0.4367s, d_loss: 0.65720475, g_loss: 0.22930384, rnn_loss: 0.13412008\n",
      " ** Epoch 73 took 61.219543s\n",
      "Epoch: [74/1000] time: 0.4429s, d_loss: 1.04844832, g_loss: 1.85211611, rnn_loss: 0.11930907\n",
      " ** Epoch 74 took 61.316349s\n",
      "Epoch: [75/1000] time: 0.4402s, d_loss: 0.72206068, g_loss: 0.97092807, rnn_loss: 0.10329174\n",
      " ** Epoch 75 took 61.432708s\n",
      "Epoch: [76/1000] time: 0.4433s, d_loss: 0.79069352, g_loss: 3.39240193, rnn_loss: 0.12253124\n",
      " ** Epoch 76 took 62.114644s\n",
      "Epoch: [77/1000] time: 0.4433s, d_loss: 1.48795819, g_loss: 0.53302783, rnn_loss: 0.12012092\n",
      " ** Epoch 77 took 61.324944s\n",
      "Epoch: [78/1000] time: 0.4464s, d_loss: 0.27775082, g_loss: 1.96849632, rnn_loss: 0.06605666\n",
      " ** Epoch 78 took 61.466253s\n",
      "Epoch: [79/1000] time: 0.4479s, d_loss: 0.78494614, g_loss: 2.76192832, rnn_loss: 0.12651119\n",
      " ** Epoch 79 took 61.680328s\n",
      "Epoch: [80/1000] time: 0.4765s, d_loss: 0.87866974, g_loss: 2.70172405, rnn_loss: 0.11011934\n",
      " ** Epoch 80 took 61.765990s\n",
      "Epoch: [81/1000] time: 0.4475s, d_loss: 0.39387277, g_loss: 2.46903205, rnn_loss: 0.06659038\n",
      " ** Epoch 81 took 62.334336s\n",
      "Epoch: [82/1000] time: 0.4423s, d_loss: 0.36252946, g_loss: 1.37719393, rnn_loss: 0.09640873\n",
      " ** Epoch 82 took 61.428494s\n",
      "Epoch: [83/1000] time: 0.4445s, d_loss: 0.60249877, g_loss: 0.97343504, rnn_loss: 0.11121615\n",
      " ** Epoch 83 took 61.395842s\n",
      "Epoch: [84/1000] time: 0.4481s, d_loss: 0.44190228, g_loss: 2.22535324, rnn_loss: 0.10195865\n",
      " ** Epoch 84 took 61.558934s\n",
      "Epoch: [85/1000] time: 0.4662s, d_loss: 1.06081545, g_loss: 0.50816911, rnn_loss: 0.11106651\n",
      " ** Epoch 85 took 61.584066s\n",
      "Epoch: [86/1000] time: 0.4379s, d_loss: 0.71663266, g_loss: 1.16412342, rnn_loss: 0.10685588\n",
      " ** Epoch 86 took 61.902077s\n",
      "Epoch: [87/1000] time: 0.4449s, d_loss: 0.82586014, g_loss: 2.75089169, rnn_loss: 0.11232404\n",
      " ** Epoch 87 took 61.513050s\n",
      "Epoch: [88/1000] time: 0.4476s, d_loss: 0.39331222, g_loss: 3.58498955, rnn_loss: 0.11462662\n",
      " ** Epoch 88 took 61.367424s\n",
      "Epoch: [89/1000] time: 0.4432s, d_loss: 0.47099078, g_loss: 2.74245834, rnn_loss: 0.10440718\n",
      " ** Epoch 89 took 61.469093s\n",
      "Epoch: [90/1000] time: 0.4513s, d_loss: 0.44235340, g_loss: 3.93304801, rnn_loss: 0.12051685\n",
      " ** Epoch 90 took 61.576010s\n",
      "Epoch: [91/1000] time: 0.4479s, d_loss: 0.22044626, g_loss: 3.07728028, rnn_loss: 0.12157947\n",
      " ** Epoch 91 took 61.731078s\n",
      "Epoch: [92/1000] time: 0.4425s, d_loss: 0.49087331, g_loss: 4.91286469, rnn_loss: 0.08049195\n",
      " ** Epoch 92 took 61.215281s\n",
      "Epoch: [93/1000] time: 0.4488s, d_loss: 1.17701900, g_loss: 3.69191647, rnn_loss: 0.11327732\n",
      " ** Epoch 93 took 61.479022s\n",
      "Epoch: [94/1000] time: 0.4446s, d_loss: 0.82628250, g_loss: 3.44217849, rnn_loss: 0.09144158\n",
      " ** Epoch 94 took 61.467041s\n",
      "Epoch: [95/1000] time: 0.4482s, d_loss: 0.73786491, g_loss: 2.81168127, rnn_loss: 0.12587602\n",
      " ** Epoch 95 took 61.782095s\n",
      "Epoch: [96/1000] time: 0.4458s, d_loss: 1.92457569, g_loss: 1.71040678, rnn_loss: 0.14009747\n",
      " ** Epoch 96 took 61.547701s\n",
      "Epoch: [97/1000] time: 0.4416s, d_loss: 0.33073127, g_loss: 3.29173517, rnn_loss: 0.14896668\n",
      " ** Epoch 97 took 61.182376s\n",
      "Epoch: [98/1000] time: 0.4444s, d_loss: 0.50785834, g_loss: 2.41772246, rnn_loss: 0.10738978\n",
      " ** Epoch 98 took 61.381070s\n",
      "Epoch: [99/1000] time: 0.4493s, d_loss: 0.49767733, g_loss: 1.45193052, rnn_loss: 0.10946610\n",
      " ** Epoch 99 took 61.776848s\n",
      "Epoch: [100/1000] time: 0.4498s, d_loss: 0.54311264, g_loss: 1.64294338, rnn_loss: 0.12430063\n",
      " ** Epoch 100 took 62.312775s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [101/1000] time: 0.4500s, d_loss: 0.56125301, g_loss: 1.91930890, rnn_loss: 0.12535496\n",
      " ** Epoch 101 took 62.415208s\n",
      "Epoch: [102/1000] time: 0.4490s, d_loss: 0.57227075, g_loss: 3.82707310, rnn_loss: 0.07781062\n",
      " ** Epoch 102 took 62.081671s\n",
      "Epoch: [103/1000] time: 0.4479s, d_loss: 0.54788661, g_loss: 2.05289245, rnn_loss: 0.14479798\n",
      " ** Epoch 103 took 62.170111s\n",
      "Epoch: [104/1000] time: 0.4533s, d_loss: 0.47372890, g_loss: 2.22468257, rnn_loss: 0.12671337\n",
      " ** Epoch 104 took 62.109691s\n",
      "Epoch: [105/1000] time: 0.4495s, d_loss: 0.37861347, g_loss: 1.90289617, rnn_loss: 0.06679160\n",
      " ** Epoch 105 took 62.450404s\n",
      "Epoch: [106/1000] time: 0.4511s, d_loss: 0.53578633, g_loss: 2.75986099, rnn_loss: 0.09848066\n",
      " ** Epoch 106 took 62.606023s\n",
      "Epoch: [107/1000] time: 0.4466s, d_loss: 0.88097692, g_loss: 3.92506909, rnn_loss: 0.11660532\n",
      " ** Epoch 107 took 62.044255s\n",
      "Epoch: [108/1000] time: 0.4493s, d_loss: 0.46037391, g_loss: 1.04938781, rnn_loss: 0.09091007\n",
      " ** Epoch 108 took 61.814958s\n",
      "Epoch: [109/1000] time: 0.4500s, d_loss: 0.59068257, g_loss: 1.09996510, rnn_loss: 0.11071365\n",
      " ** Epoch 109 took 61.822238s\n",
      "Epoch: [110/1000] time: 0.4481s, d_loss: 1.35894310, g_loss: 5.08705521, rnn_loss: 0.08203633\n",
      " ** Epoch 110 took 62.083585s\n",
      "Epoch: [111/1000] time: 0.4502s, d_loss: 0.37610710, g_loss: 0.81948519, rnn_loss: 0.10625613\n",
      " ** Epoch 111 took 62.422008s\n",
      "Epoch: [112/1000] time: 0.4473s, d_loss: 0.62538773, g_loss: 2.71454525, rnn_loss: 0.08699495\n",
      " ** Epoch 112 took 61.718926s\n",
      "Epoch: [113/1000] time: 0.4437s, d_loss: 1.27000129, g_loss: 0.42129916, rnn_loss: 0.11998068\n",
      " ** Epoch 113 took 61.676059s\n",
      "Epoch: [114/1000] time: 0.4473s, d_loss: 0.35470852, g_loss: 1.48760462, rnn_loss: 0.09869187\n",
      " ** Epoch 114 took 61.519188s\n",
      "Epoch: [115/1000] time: 0.4431s, d_loss: 0.30554217, g_loss: 3.46718144, rnn_loss: 0.09221836\n",
      " ** Epoch 115 took 61.874385s\n",
      "Epoch: [116/1000] time: 0.4399s, d_loss: 0.41895813, g_loss: 1.76827598, rnn_loss: 0.08317058\n",
      " ** Epoch 116 took 62.149323s\n",
      "Epoch: [117/1000] time: 0.4455s, d_loss: 0.54556561, g_loss: 3.42912078, rnn_loss: 0.12502840\n",
      " ** Epoch 117 took 61.575982s\n",
      "Epoch: [118/1000] time: 0.4467s, d_loss: 0.29598582, g_loss: 1.35218525, rnn_loss: 0.12503108\n",
      " ** Epoch 118 took 61.643149s\n",
      "Epoch: [119/1000] time: 0.4438s, d_loss: 0.69476599, g_loss: 3.52559137, rnn_loss: 0.10629536\n",
      " ** Epoch 119 took 61.679041s\n",
      "Epoch: [120/1000] time: 0.4468s, d_loss: 0.52325445, g_loss: 1.69165015, rnn_loss: 0.11358865\n",
      " ** Epoch 120 took 61.869153s\n",
      "Epoch: [121/1000] time: 0.4494s, d_loss: 0.54189342, g_loss: 1.51466262, rnn_loss: 0.10928053\n",
      " ** Epoch 121 took 62.144059s\n",
      "Epoch: [122/1000] time: 0.4489s, d_loss: 0.43971407, g_loss: 1.55599248, rnn_loss: 0.13830858\n",
      " ** Epoch 122 took 61.668951s\n",
      "Epoch: [123/1000] time: 0.4485s, d_loss: 0.41518727, g_loss: 2.63839030, rnn_loss: 0.11953710\n",
      " ** Epoch 123 took 61.750815s\n",
      "Epoch: [124/1000] time: 0.4529s, d_loss: 0.26690623, g_loss: 2.53626037, rnn_loss: 0.07814401\n",
      " ** Epoch 124 took 61.665690s\n",
      "Epoch: [125/1000] time: 0.4468s, d_loss: 0.51175624, g_loss: 0.59758413, rnn_loss: 0.10566968\n",
      " ** Epoch 125 took 62.221947s\n",
      "Epoch: [126/1000] time: 0.4477s, d_loss: 0.18548770, g_loss: 3.12259889, rnn_loss: 0.09805049\n",
      " ** Epoch 126 took 62.323900s\n",
      "Epoch: [127/1000] time: 0.4468s, d_loss: 0.35767904, g_loss: 1.34024847, rnn_loss: 0.18490940\n",
      " ** Epoch 127 took 61.823049s\n",
      "Epoch: [128/1000] time: 0.4440s, d_loss: 0.34250301, g_loss: 2.21042681, rnn_loss: 0.09220365\n",
      " ** Epoch 128 took 61.628005s\n",
      "Epoch: [129/1000] time: 0.4456s, d_loss: 0.67923975, g_loss: 5.15930557, rnn_loss: 0.11572666\n",
      " ** Epoch 129 took 61.778736s\n",
      "Epoch: [130/1000] time: 0.4477s, d_loss: 0.62841165, g_loss: 2.50210476, rnn_loss: 0.09272961\n",
      " ** Epoch 130 took 62.946221s\n",
      "Epoch: [131/1000] time: 0.4509s, d_loss: 0.18618321, g_loss: 3.40619135, rnn_loss: 0.13056189\n",
      " ** Epoch 131 took 62.397115s\n",
      "Epoch: [132/1000] time: 0.4513s, d_loss: 0.26828837, g_loss: 2.42916346, rnn_loss: 0.12241901\n",
      " ** Epoch 132 took 61.605096s\n",
      "Epoch: [133/1000] time: 0.4470s, d_loss: 0.41185629, g_loss: 2.74530935, rnn_loss: 0.09350674\n",
      " ** Epoch 133 took 61.625171s\n",
      "Epoch: [134/1000] time: 0.4490s, d_loss: 0.35966972, g_loss: 1.30294681, rnn_loss: 0.10838030\n",
      " ** Epoch 134 took 61.774924s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [135/1000] time: 0.4455s, d_loss: 0.82348806, g_loss: 5.56333351, rnn_loss: 0.14405340\n",
      " ** Epoch 135 took 61.898005s\n",
      "Epoch: [136/1000] time: 0.4423s, d_loss: 0.31512851, g_loss: 2.63049364, rnn_loss: 0.07639179\n",
      " ** Epoch 136 took 61.942282s\n",
      "Epoch: [137/1000] time: 0.4457s, d_loss: 0.59404492, g_loss: 3.58719969, rnn_loss: 0.11104029\n",
      " ** Epoch 137 took 61.466860s\n",
      "Epoch: [138/1000] time: 0.4461s, d_loss: 0.40660211, g_loss: 3.83510685, rnn_loss: 0.13480872\n",
      " ** Epoch 138 took 61.892293s\n",
      "Epoch: [139/1000] time: 0.4455s, d_loss: 0.35278887, g_loss: 1.96575153, rnn_loss: 0.12190742\n",
      " ** Epoch 139 took 61.608941s\n",
      "Epoch: [140/1000] time: 0.4448s, d_loss: 0.80812228, g_loss: 3.07921481, rnn_loss: 0.12482641\n",
      " ** Epoch 140 took 61.838987s\n",
      "Epoch: [141/1000] time: 0.4462s, d_loss: 0.27204043, g_loss: 2.68164277, rnn_loss: 0.06444436\n",
      " ** Epoch 141 took 62.299920s\n",
      "Epoch: [142/1000] time: 0.4437s, d_loss: 0.21372288, g_loss: 4.26452017, rnn_loss: 0.08651169\n",
      " ** Epoch 142 took 61.595062s\n",
      "Epoch: [143/1000] time: 0.4457s, d_loss: 0.66624480, g_loss: 8.26306629, rnn_loss: 0.11747295\n",
      " ** Epoch 143 took 61.715694s\n",
      "Epoch: [144/1000] time: 0.4484s, d_loss: 0.24700405, g_loss: 2.20897079, rnn_loss: 0.11851022\n",
      " ** Epoch 144 took 61.583931s\n",
      "Epoch: [145/1000] time: 0.4497s, d_loss: 0.91097707, g_loss: 6.12995815, rnn_loss: 0.09067711\n",
      " ** Epoch 145 took 62.003179s\n",
      "Epoch: [146/1000] time: 0.4570s, d_loss: 0.27880439, g_loss: 1.91842508, rnn_loss: 0.07891237\n",
      " ** Epoch 146 took 62.882231s\n",
      "Epoch: [147/1000] time: 0.4468s, d_loss: 0.38127297, g_loss: 1.87806439, rnn_loss: 0.06417027\n",
      " ** Epoch 147 took 62.010575s\n",
      "Epoch: [148/1000] time: 0.4503s, d_loss: 0.29057294, g_loss: 2.61292958, rnn_loss: 0.09409515\n",
      " ** Epoch 148 took 61.914226s\n",
      "Epoch: [149/1000] time: 0.4611s, d_loss: 0.42246482, g_loss: 2.07569766, rnn_loss: 0.10030104\n",
      " ** Epoch 149 took 61.611401s\n",
      "Epoch: [150/1000] time: 0.4349s, d_loss: 0.39188743, g_loss: 1.89353955, rnn_loss: 0.15381366\n",
      " ** Epoch 150 took 60.748550s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [151/1000] time: 0.4464s, d_loss: 0.49874386, g_loss: 3.51579976, rnn_loss: 0.09687077\n",
      " ** Epoch 151 took 61.558681s\n",
      "Epoch: [152/1000] time: 0.4482s, d_loss: 0.39210135, g_loss: 2.24775171, rnn_loss: 0.09123196\n",
      " ** Epoch 152 took 62.120162s\n",
      "Epoch: [153/1000] time: 0.4479s, d_loss: 0.87695116, g_loss: 1.34575927, rnn_loss: 0.10053485\n",
      " ** Epoch 153 took 61.968805s\n",
      "Epoch: [154/1000] time: 0.4473s, d_loss: 0.24561602, g_loss: 3.97645330, rnn_loss: 0.11078525\n",
      " ** Epoch 154 took 62.079374s\n",
      "Epoch: [155/1000] time: 0.4494s, d_loss: 0.58147788, g_loss: 0.48689881, rnn_loss: 0.09355841\n",
      " ** Epoch 155 took 61.861507s\n",
      "Epoch: [156/1000] time: 0.4488s, d_loss: 0.29809257, g_loss: 2.49752760, rnn_loss: 0.13405962\n",
      " ** Epoch 156 took 62.320100s\n",
      "Epoch: [157/1000] time: 0.4476s, d_loss: 0.64125800, g_loss: 3.59282970, rnn_loss: 0.06948218\n",
      " ** Epoch 157 took 61.816901s\n",
      "Epoch: [158/1000] time: 0.4472s, d_loss: 0.38113725, g_loss: 3.44761634, rnn_loss: 0.14847675\n",
      " ** Epoch 158 took 61.931681s\n",
      "Epoch: [159/1000] time: 0.4464s, d_loss: 2.12765217, g_loss: 1.21863389, rnn_loss: 0.07623969\n",
      " ** Epoch 159 took 62.301851s\n",
      "Epoch: [160/1000] time: 0.4485s, d_loss: 0.57830918, g_loss: 2.15869951, rnn_loss: 0.12522148\n",
      " ** Epoch 160 took 61.825885s\n",
      "Epoch: [161/1000] time: 0.4350s, d_loss: 0.57279688, g_loss: 2.21293688, rnn_loss: 0.05919191\n",
      " ** Epoch 161 took 62.592835s\n",
      "Epoch: [162/1000] time: 0.4478s, d_loss: 0.25203878, g_loss: 2.94350433, rnn_loss: 0.10808224\n",
      " ** Epoch 162 took 61.410607s\n",
      "Epoch: [163/1000] time: 0.4439s, d_loss: 0.25540251, g_loss: 4.07166672, rnn_loss: 0.09197383\n",
      " ** Epoch 163 took 61.372165s\n",
      "Epoch: [164/1000] time: 0.4423s, d_loss: 0.25685370, g_loss: 2.43649769, rnn_loss: 0.08503357\n",
      " ** Epoch 164 took 61.866060s\n",
      "Epoch: [165/1000] time: 0.4540s, d_loss: 0.80434090, g_loss: 2.90046120, rnn_loss: 0.12066370\n",
      " ** Epoch 165 took 61.565029s\n",
      "Epoch: [166/1000] time: 0.4513s, d_loss: 0.25694293, g_loss: 2.49073839, rnn_loss: 0.15144838\n",
      " ** Epoch 166 took 62.749902s\n",
      "Epoch: [167/1000] time: 0.4487s, d_loss: 1.23838973, g_loss: 0.63485169, rnn_loss: 0.09237322\n",
      " ** Epoch 167 took 62.091839s\n",
      "Epoch: [168/1000] time: 0.4465s, d_loss: 0.77190816, g_loss: 7.19829798, rnn_loss: 0.07084655\n",
      " ** Epoch 168 took 61.695776s\n",
      "Epoch: [169/1000] time: 0.4449s, d_loss: 0.18599005, g_loss: 4.39829731, rnn_loss: 0.08760083\n",
      " ** Epoch 169 took 61.929949s\n",
      "Epoch: [170/1000] time: 0.4478s, d_loss: 0.31522879, g_loss: 4.62962246, rnn_loss: 0.07552378\n",
      " ** Epoch 170 took 61.400689s\n",
      "Epoch: [171/1000] time: 0.4424s, d_loss: 0.39631233, g_loss: 3.70208597, rnn_loss: 0.08651903\n",
      " ** Epoch 171 took 61.789767s\n",
      "Epoch: [172/1000] time: 0.4458s, d_loss: 0.66546917, g_loss: 2.60272837, rnn_loss: 0.09805831\n",
      " ** Epoch 172 took 61.374017s\n",
      "Epoch: [173/1000] time: 0.4420s, d_loss: 0.35214075, g_loss: 2.76331329, rnn_loss: 0.11156622\n",
      " ** Epoch 173 took 61.232564s\n",
      "Epoch: [174/1000] time: 0.4526s, d_loss: 0.12250969, g_loss: 3.08739996, rnn_loss: 0.07426846\n",
      " ** Epoch 174 took 61.674602s\n",
      "Epoch: [175/1000] time: 0.4457s, d_loss: 0.34044421, g_loss: 3.21963263, rnn_loss: 0.07289803\n",
      " ** Epoch 175 took 61.497928s\n",
      "Epoch: [176/1000] time: 0.4493s, d_loss: 0.34262022, g_loss: 1.50344539, rnn_loss: 0.10377017\n",
      " ** Epoch 176 took 62.474146s\n",
      "Epoch: [177/1000] time: 0.4539s, d_loss: 0.89438874, g_loss: 4.71978951, rnn_loss: 0.07011759\n",
      " ** Epoch 177 took 62.105219s\n",
      "Epoch: [178/1000] time: 0.4495s, d_loss: 0.50547922, g_loss: 1.88314402, rnn_loss: 0.05804724\n",
      " ** Epoch 178 took 62.015333s\n",
      "Epoch: [179/1000] time: 0.4423s, d_loss: 0.19602890, g_loss: 2.66401243, rnn_loss: 0.07238970\n",
      " ** Epoch 179 took 62.227843s\n",
      "Epoch: [180/1000] time: 0.4445s, d_loss: 0.26897103, g_loss: 2.71767378, rnn_loss: 0.08655082\n",
      " ** Epoch 180 took 61.397584s\n",
      "Epoch: [181/1000] time: 0.4507s, d_loss: 0.37743932, g_loss: 2.61781859, rnn_loss: 0.06872751\n",
      " ** Epoch 181 took 62.554644s\n",
      "Epoch: [182/1000] time: 0.4486s, d_loss: 0.26466897, g_loss: 3.10705352, rnn_loss: 0.07283992\n",
      " ** Epoch 182 took 61.937741s\n",
      "Epoch: [183/1000] time: 0.4439s, d_loss: 0.22128680, g_loss: 3.39817047, rnn_loss: 0.08464043\n",
      " ** Epoch 183 took 61.676094s\n",
      "Epoch: [184/1000] time: 0.4396s, d_loss: 0.30190662, g_loss: 3.30040789, rnn_loss: 0.08192981\n",
      " ** Epoch 184 took 61.819927s\n",
      "Epoch: [185/1000] time: 0.4426s, d_loss: 0.43254787, g_loss: 4.49039364, rnn_loss: 0.06726380\n",
      " ** Epoch 185 took 61.247235s\n",
      "Epoch: [186/1000] time: 0.4350s, d_loss: 0.56242853, g_loss: 2.37039471, rnn_loss: 0.08597700\n",
      " ** Epoch 186 took 61.478302s\n",
      "Epoch: [187/1000] time: 0.4395s, d_loss: 0.54930121, g_loss: 4.10908794, rnn_loss: 0.11261408\n",
      " ** Epoch 187 took 60.678904s\n",
      "Epoch: [188/1000] time: 0.4411s, d_loss: 0.72915125, g_loss: 3.46765208, rnn_loss: 0.12138885\n",
      " ** Epoch 188 took 60.592570s\n",
      "Epoch: [189/1000] time: 0.4393s, d_loss: 0.23059559, g_loss: 2.72219133, rnn_loss: 0.10615224\n",
      " ** Epoch 189 took 60.911150s\n",
      "Epoch: [190/1000] time: 0.4390s, d_loss: 0.62434036, g_loss: 5.47866440, rnn_loss: 0.06814403\n",
      " ** Epoch 190 took 60.658267s\n",
      "Epoch: [191/1000] time: 0.4402s, d_loss: 0.93138182, g_loss: 0.93130916, rnn_loss: 0.11366212\n",
      " ** Epoch 191 took 61.246619s\n",
      "Epoch: [192/1000] time: 0.4369s, d_loss: 0.21172290, g_loss: 3.01454782, rnn_loss: 0.11658555\n",
      " ** Epoch 192 took 60.586251s\n",
      "Epoch: [193/1000] time: 0.4341s, d_loss: 0.15057641, g_loss: 3.39518738, rnn_loss: 0.05842607\n",
      " ** Epoch 193 took 60.672384s\n",
      "Epoch: [194/1000] time: 0.4384s, d_loss: 0.98683345, g_loss: 0.44975537, rnn_loss: 0.19621739\n",
      " ** Epoch 194 took 61.023729s\n",
      "Epoch: [195/1000] time: 0.4434s, d_loss: 0.34505710, g_loss: 4.11580944, rnn_loss: 0.07449737\n",
      " ** Epoch 195 took 60.672401s\n",
      "Epoch: [196/1000] time: 0.4372s, d_loss: 0.29485098, g_loss: 3.53602862, rnn_loss: 0.06320831\n",
      " ** Epoch 196 took 61.188474s\n",
      "Epoch: [197/1000] time: 0.4400s, d_loss: 0.24584652, g_loss: 4.14807510, rnn_loss: 0.05970052\n",
      " ** Epoch 197 took 60.746608s\n",
      "Epoch: [198/1000] time: 0.4387s, d_loss: 0.46528497, g_loss: 4.25209332, rnn_loss: 0.07107011\n",
      " ** Epoch 198 took 60.826530s\n",
      "Epoch: [199/1000] time: 0.4438s, d_loss: 0.41310117, g_loss: 1.42957282, rnn_loss: 0.12232532\n",
      " ** Epoch 199 took 61.120385s\n",
      " ** new learning rate: 0.000100\n",
      "Epoch: [200/1000] time: 0.4413s, d_loss: 0.23757181, g_loss: 2.71698761, rnn_loss: 0.05876319\n",
      " ** Epoch 200 took 61.343241s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [201/1000] time: 0.4428s, d_loss: 0.20356029, g_loss: 1.44445634, rnn_loss: 0.10186975\n",
      " ** Epoch 201 took 61.337691s\n",
      "Epoch: [202/1000] time: 0.4427s, d_loss: 0.28181460, g_loss: 2.66722584, rnn_loss: 0.08691559\n",
      " ** Epoch 202 took 60.868838s\n",
      "Epoch: [203/1000] time: 0.4403s, d_loss: 0.31179506, g_loss: 1.86932135, rnn_loss: 0.06049445\n",
      " ** Epoch 203 took 60.949792s\n",
      "Epoch: [204/1000] time: 0.4407s, d_loss: 0.26664892, g_loss: 2.55959177, rnn_loss: 0.06957857\n",
      " ** Epoch 204 took 61.289769s\n",
      "Epoch: [205/1000] time: 0.4426s, d_loss: 0.22687076, g_loss: 2.31266308, rnn_loss: 0.07165289\n",
      " ** Epoch 205 took 61.053741s\n",
      "Epoch: [206/1000] time: 0.4481s, d_loss: 0.14329326, g_loss: 1.83651352, rnn_loss: 0.12971431\n",
      " ** Epoch 206 took 61.842380s\n",
      "Epoch: [207/1000] time: 0.4486s, d_loss: 0.20269768, g_loss: 2.39168310, rnn_loss: 0.07360142\n",
      " ** Epoch 207 took 61.509089s\n",
      "Epoch: [208/1000] time: 0.4464s, d_loss: 0.30105093, g_loss: 2.68645144, rnn_loss: 0.10119882\n",
      " ** Epoch 208 took 61.415101s\n",
      "Epoch: [209/1000] time: 0.4451s, d_loss: 0.16012543, g_loss: 2.10792208, rnn_loss: 0.06308195\n",
      " ** Epoch 209 took 61.736075s\n",
      "Epoch: [210/1000] time: 0.4426s, d_loss: 0.19614196, g_loss: 2.50077963, rnn_loss: 0.09589550\n",
      " ** Epoch 210 took 61.621514s\n",
      "Epoch: [211/1000] time: 0.4451s, d_loss: 0.20610744, g_loss: 2.50248623, rnn_loss: 0.10744600\n",
      " ** Epoch 211 took 62.108319s\n",
      "Epoch: [212/1000] time: 0.4451s, d_loss: 0.14358391, g_loss: 3.37429547, rnn_loss: 0.06697191\n",
      " ** Epoch 212 took 61.383540s\n",
      "Epoch: [213/1000] time: 0.4456s, d_loss: 0.20686054, g_loss: 2.22556734, rnn_loss: 0.06053215\n",
      " ** Epoch 213 took 61.295088s\n",
      "Epoch: [214/1000] time: 0.4432s, d_loss: 0.17011097, g_loss: 3.25710487, rnn_loss: 0.06668158\n",
      " ** Epoch 214 took 61.683619s\n",
      "Epoch: [215/1000] time: 0.4480s, d_loss: 0.14019397, g_loss: 3.71718311, rnn_loss: 0.05419230\n",
      " ** Epoch 215 took 61.406584s\n",
      "Epoch: [216/1000] time: 0.4468s, d_loss: 0.31184578, g_loss: 2.53237438, rnn_loss: 0.09184045\n",
      " ** Epoch 216 took 62.277600s\n",
      "Epoch: [217/1000] time: 0.4491s, d_loss: 0.15626445, g_loss: 3.46901083, rnn_loss: 0.06813526\n",
      " ** Epoch 217 took 61.694081s\n",
      "Epoch: [218/1000] time: 0.4430s, d_loss: 0.13846174, g_loss: 3.27834725, rnn_loss: 0.11423384\n",
      " ** Epoch 218 took 61.318473s\n",
      "Epoch: [219/1000] time: 0.4421s, d_loss: 0.12782466, g_loss: 3.02384734, rnn_loss: 0.11830154\n",
      " ** Epoch 219 took 61.607663s\n",
      "Epoch: [220/1000] time: 0.4458s, d_loss: 0.20792525, g_loss: 2.35347986, rnn_loss: 0.05971386\n",
      " ** Epoch 220 took 61.333558s\n",
      "Epoch: [221/1000] time: 0.4446s, d_loss: 0.37503597, g_loss: 2.39140368, rnn_loss: 0.04791201\n",
      " ** Epoch 221 took 62.057652s\n",
      "Epoch: [222/1000] time: 0.4457s, d_loss: 0.32690805, g_loss: 2.77282476, rnn_loss: 0.07526920\n",
      " ** Epoch 222 took 61.414731s\n",
      "Epoch: [223/1000] time: 0.4469s, d_loss: 0.11089671, g_loss: 3.05050755, rnn_loss: 0.07395295\n",
      " ** Epoch 223 took 61.363433s\n",
      "Epoch: [224/1000] time: 0.4474s, d_loss: 0.15701222, g_loss: 2.82820630, rnn_loss: 0.08447561\n",
      " ** Epoch 224 took 61.826082s\n",
      "Epoch: [225/1000] time: 0.4436s, d_loss: 0.27740273, g_loss: 2.27741909, rnn_loss: 0.09096651\n",
      " ** Epoch 225 took 61.496662s\n",
      "Epoch: [226/1000] time: 0.4441s, d_loss: 0.17895383, g_loss: 2.89180326, rnn_loss: 0.06979236\n",
      " ** Epoch 226 took 62.202022s\n",
      "Epoch: [227/1000] time: 0.4433s, d_loss: 0.06542090, g_loss: 2.07933116, rnn_loss: 0.05828916\n",
      " ** Epoch 227 took 61.537764s\n",
      "Epoch: [228/1000] time: 0.4463s, d_loss: 0.40453750, g_loss: 3.36006832, rnn_loss: 0.05199841\n",
      " ** Epoch 228 took 61.295358s\n",
      "Epoch: [229/1000] time: 0.4453s, d_loss: 0.78328955, g_loss: 0.53696787, rnn_loss: 0.06367922\n",
      " ** Epoch 229 took 61.451824s\n",
      "Epoch: [230/1000] time: 0.4485s, d_loss: 0.19689834, g_loss: 2.05719113, rnn_loss: 0.09319530\n",
      " ** Epoch 230 took 61.297493s\n",
      "Epoch: [231/1000] time: 0.4442s, d_loss: 0.23789345, g_loss: 3.03548861, rnn_loss: 0.08945695\n",
      " ** Epoch 231 took 62.164691s\n",
      "Epoch: [232/1000] time: 0.4428s, d_loss: 0.08110099, g_loss: 3.29307365, rnn_loss: 0.05854266\n",
      " ** Epoch 232 took 61.292147s\n",
      "Epoch: [233/1000] time: 0.4474s, d_loss: 0.14521739, g_loss: 3.14328671, rnn_loss: 0.08449067\n",
      " ** Epoch 233 took 61.144736s\n",
      "Epoch: [234/1000] time: 0.4423s, d_loss: 0.43546021, g_loss: 1.96250355, rnn_loss: 0.06583835\n",
      " ** Epoch 234 took 61.482471s\n",
      "Epoch: [235/1000] time: 0.4439s, d_loss: 0.13079026, g_loss: 2.88024569, rnn_loss: 0.10987420\n",
      " ** Epoch 235 took 61.158852s\n",
      "Epoch: [236/1000] time: 0.4713s, d_loss: 0.16565254, g_loss: 2.91692567, rnn_loss: 0.08243582\n",
      " ** Epoch 236 took 61.810773s\n",
      "Epoch: [237/1000] time: 0.4464s, d_loss: 0.06072391, g_loss: 3.41648960, rnn_loss: 0.05041783\n",
      " ** Epoch 237 took 61.201504s\n",
      "Epoch: [238/1000] time: 0.4447s, d_loss: 0.15532440, g_loss: 4.34551334, rnn_loss: 0.07533541\n",
      " ** Epoch 238 took 61.197883s\n",
      "Epoch: [239/1000] time: 0.4471s, d_loss: 0.03264380, g_loss: 6.23002338, rnn_loss: 0.07528742\n",
      " ** Epoch 239 took 61.489853s\n",
      "Epoch: [240/1000] time: 0.4435s, d_loss: 0.22293060, g_loss: 3.00753760, rnn_loss: 0.07447641\n",
      " ** Epoch 240 took 61.406783s\n",
      "Epoch: [241/1000] time: 0.4711s, d_loss: 0.12608579, g_loss: 2.65821958, rnn_loss: 0.09128426\n",
      " ** Epoch 241 took 61.698286s\n",
      "Epoch: [242/1000] time: 0.4406s, d_loss: 0.43375304, g_loss: 5.07619858, rnn_loss: 0.04647968\n",
      " ** Epoch 242 took 61.154656s\n",
      "Epoch: [243/1000] time: 0.4453s, d_loss: 0.61271852, g_loss: 3.21090031, rnn_loss: 0.04436618\n",
      " ** Epoch 243 took 61.008210s\n",
      "Epoch: [244/1000] time: 0.4383s, d_loss: 0.25623590, g_loss: 2.16154552, rnn_loss: 0.08889748\n",
      " ** Epoch 244 took 61.384740s\n",
      "Epoch: [245/1000] time: 0.4359s, d_loss: 0.17460558, g_loss: 3.33495593, rnn_loss: 0.07662861\n",
      " ** Epoch 245 took 60.921826s\n",
      "Epoch: [246/1000] time: 0.4652s, d_loss: 0.30041516, g_loss: 3.01118731, rnn_loss: 0.03437319\n",
      " ** Epoch 246 took 60.928210s\n",
      "Epoch: [247/1000] time: 0.4454s, d_loss: 0.16804206, g_loss: 2.12011266, rnn_loss: 0.08125658\n",
      " ** Epoch 247 took 61.339955s\n",
      "Epoch: [248/1000] time: 0.4331s, d_loss: 0.24695948, g_loss: 3.31264949, rnn_loss: 0.08926252\n",
      " ** Epoch 248 took 60.751029s\n",
      "Epoch: [249/1000] time: 0.4467s, d_loss: 0.93034405, g_loss: 0.71690452, rnn_loss: 0.06995523\n",
      " ** Epoch 249 took 61.467111s\n",
      "Epoch: [250/1000] time: 0.4385s, d_loss: 0.65237015, g_loss: 3.70135331, rnn_loss: 0.07954971\n",
      " ** Epoch 250 took 61.052661s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [251/1000] time: 0.4426s, d_loss: 0.37367636, g_loss: 3.92550611, rnn_loss: 0.05674549\n",
      " ** Epoch 251 took 60.942177s\n",
      "Epoch: [252/1000] time: 0.4402s, d_loss: 0.47876298, g_loss: 7.00372171, rnn_loss: 0.08337079\n",
      " ** Epoch 252 took 61.598266s\n",
      "Epoch: [253/1000] time: 0.4480s, d_loss: 0.16136032, g_loss: 3.76287365, rnn_loss: 0.07986202\n",
      " ** Epoch 253 took 60.953753s\n",
      "Epoch: [254/1000] time: 0.4416s, d_loss: 0.35909754, g_loss: 2.73498940, rnn_loss: 0.06689209\n",
      " ** Epoch 254 took 61.232872s\n",
      "Epoch: [255/1000] time: 0.4392s, d_loss: 0.19955130, g_loss: 4.11591959, rnn_loss: 0.06297221\n",
      " ** Epoch 255 took 61.009229s\n",
      "Epoch: [256/1000] time: 0.4428s, d_loss: 0.08272205, g_loss: 3.80451226, rnn_loss: 0.08313741\n",
      " ** Epoch 256 took 61.363329s\n",
      "Epoch: [257/1000] time: 0.4457s, d_loss: 0.12571885, g_loss: 3.80985951, rnn_loss: 0.06771244\n",
      " ** Epoch 257 took 61.889323s\n",
      "Epoch: [258/1000] time: 0.4741s, d_loss: 1.57222140, g_loss: 8.04111862, rnn_loss: 0.07013863\n",
      " ** Epoch 258 took 61.514256s\n",
      "Epoch: [259/1000] time: 0.4416s, d_loss: 0.30707109, g_loss: 4.94687271, rnn_loss: 0.07578003\n",
      " ** Epoch 259 took 61.389291s\n",
      "Epoch: [260/1000] time: 0.4387s, d_loss: 0.11879104, g_loss: 3.30536914, rnn_loss: 0.05805418\n",
      " ** Epoch 260 took 61.059784s\n",
      "Epoch: [261/1000] time: 0.4506s, d_loss: 0.16568129, g_loss: 3.01450777, rnn_loss: 0.08144944\n",
      " ** Epoch 261 took 61.407360s\n",
      "Epoch: [262/1000] time: 0.4422s, d_loss: 0.14519931, g_loss: 3.48044968, rnn_loss: 0.10305938\n",
      " ** Epoch 262 took 61.740353s\n",
      "Epoch: [263/1000] time: 0.4714s, d_loss: 0.18283087, g_loss: 4.26851130, rnn_loss: 0.08309394\n",
      " ** Epoch 263 took 61.327184s\n",
      "Epoch: [264/1000] time: 0.4427s, d_loss: 0.27357650, g_loss: 3.75679326, rnn_loss: 0.06666392\n",
      " ** Epoch 264 took 61.110050s\n",
      "Epoch: [265/1000] time: 0.4469s, d_loss: 0.17114495, g_loss: 3.06492162, rnn_loss: 0.09394230\n",
      " ** Epoch 265 took 61.155486s\n",
      "Epoch: [266/1000] time: 0.4423s, d_loss: 0.09951422, g_loss: 3.25221086, rnn_loss: 0.06706352\n",
      " ** Epoch 266 took 61.181606s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [267/1000] time: 0.4420s, d_loss: 0.23477641, g_loss: 3.05454922, rnn_loss: 0.09012578\n",
      " ** Epoch 267 took 61.657087s\n",
      "Epoch: [268/1000] time: 0.4426s, d_loss: 0.16186604, g_loss: 2.68859339, rnn_loss: 0.08733658\n",
      " ** Epoch 268 took 61.562716s\n",
      "Epoch: [269/1000] time: 0.4455s, d_loss: 0.23740953, g_loss: 2.86203480, rnn_loss: 0.08120967\n",
      " ** Epoch 269 took 61.186738s\n",
      "Epoch: [270/1000] time: 0.4492s, d_loss: 0.36440700, g_loss: 1.41070676, rnn_loss: 0.07211971\n",
      " ** Epoch 270 took 61.411415s\n",
      "Epoch: [271/1000] time: 0.4477s, d_loss: 0.08237178, g_loss: 4.20739460, rnn_loss: 0.08904888\n",
      " ** Epoch 271 took 61.274730s\n",
      "Epoch: [272/1000] time: 0.4423s, d_loss: 1.07236958, g_loss: 4.15467501, rnn_loss: 0.09542677\n",
      " ** Epoch 272 took 61.710705s\n",
      "Epoch: [273/1000] time: 0.4375s, d_loss: 0.12813896, g_loss: 4.14169264, rnn_loss: 0.10771483\n",
      " ** Epoch 273 took 61.404680s\n",
      "Epoch: [274/1000] time: 0.4443s, d_loss: 0.08710026, g_loss: 3.42265701, rnn_loss: 0.08133576\n",
      " ** Epoch 274 took 61.217034s\n",
      "Epoch: [275/1000] time: 0.4400s, d_loss: 0.32877639, g_loss: 2.32872295, rnn_loss: 0.09793091\n",
      " ** Epoch 275 took 61.391485s\n",
      "Epoch: [276/1000] time: 0.4470s, d_loss: 0.02366975, g_loss: 4.68412304, rnn_loss: 0.07421923\n",
      " ** Epoch 276 took 61.344632s\n",
      "Epoch: [277/1000] time: 0.4417s, d_loss: 0.11171021, g_loss: 2.76442003, rnn_loss: 0.05160103\n",
      " ** Epoch 277 took 61.777445s\n",
      "Epoch: [278/1000] time: 0.4426s, d_loss: 0.07837382, g_loss: 3.07962728, rnn_loss: 0.05471908\n",
      " ** Epoch 278 took 61.722996s\n",
      "Epoch: [279/1000] time: 0.4496s, d_loss: 0.05724791, g_loss: 4.33788824, rnn_loss: 0.07501744\n",
      " ** Epoch 279 took 61.235409s\n",
      "Epoch: [280/1000] time: 0.4445s, d_loss: 0.56474406, g_loss: 0.56411815, rnn_loss: 0.11723196\n",
      " ** Epoch 280 took 61.233045s\n",
      "Epoch: [281/1000] time: 0.4442s, d_loss: 0.19376752, g_loss: 2.83643842, rnn_loss: 0.08247313\n",
      " ** Epoch 281 took 61.068040s\n",
      "Epoch: [282/1000] time: 0.4441s, d_loss: 0.23115337, g_loss: 5.17242241, rnn_loss: 0.11764237\n",
      " ** Epoch 282 took 61.948295s\n",
      "Epoch: [283/1000] time: 0.4401s, d_loss: 0.15858826, g_loss: 3.74998808, rnn_loss: 0.06743371\n",
      " ** Epoch 283 took 61.291347s\n",
      "Epoch: [284/1000] time: 0.4507s, d_loss: 0.22165275, g_loss: 2.35203409, rnn_loss: 0.07973394\n",
      " ** Epoch 284 took 61.095277s\n",
      "Epoch: [285/1000] time: 0.4431s, d_loss: 0.09573133, g_loss: 3.80487919, rnn_loss: 0.06743452\n",
      " ** Epoch 285 took 61.311755s\n",
      "Epoch: [286/1000] time: 0.4417s, d_loss: 0.10744506, g_loss: 3.94763494, rnn_loss: 0.06531573\n",
      " ** Epoch 286 took 61.374985s\n",
      "Epoch: [287/1000] time: 0.4398s, d_loss: 0.29227516, g_loss: 3.88764715, rnn_loss: 0.07147772\n",
      " ** Epoch 287 took 61.819219s\n",
      "Epoch: [288/1000] time: 0.4418s, d_loss: 0.24101421, g_loss: 4.13150692, rnn_loss: 0.06641730\n",
      " ** Epoch 288 took 61.546028s\n",
      "Epoch: [289/1000] time: 0.4469s, d_loss: 0.18313292, g_loss: 1.94499815, rnn_loss: 0.07113186\n",
      " ** Epoch 289 took 61.483994s\n",
      "Epoch: [290/1000] time: 0.4479s, d_loss: 0.21468677, g_loss: 2.82807636, rnn_loss: 0.09191968\n",
      " ** Epoch 290 took 61.598011s\n",
      "Epoch: [291/1000] time: 0.4509s, d_loss: 0.47205105, g_loss: 1.17031097, rnn_loss: 0.05121826\n",
      " ** Epoch 291 took 61.799242s\n",
      "Epoch: [292/1000] time: 0.4454s, d_loss: 0.15540165, g_loss: 5.13658094, rnn_loss: 0.09262618\n",
      " ** Epoch 292 took 62.333426s\n",
      "Epoch: [293/1000] time: 0.4484s, d_loss: 0.27385497, g_loss: 2.10430765, rnn_loss: 0.07880105\n",
      " ** Epoch 293 took 61.815176s\n",
      "Epoch: [294/1000] time: 0.4506s, d_loss: 0.08840416, g_loss: 5.09829235, rnn_loss: 0.07590197\n",
      " ** Epoch 294 took 61.662011s\n",
      "Epoch: [295/1000] time: 0.4467s, d_loss: 0.30967149, g_loss: 4.80834389, rnn_loss: 0.06643882\n",
      " ** Epoch 295 took 61.462120s\n",
      "Epoch: [296/1000] time: 0.4412s, d_loss: 0.51659292, g_loss: 6.21069527, rnn_loss: 0.09866077\n",
      " ** Epoch 296 took 61.161363s\n",
      "Epoch: [297/1000] time: 0.4440s, d_loss: 0.09133887, g_loss: 4.08347845, rnn_loss: 0.08139259\n",
      " ** Epoch 297 took 61.627249s\n",
      "Epoch: [298/1000] time: 0.4411s, d_loss: 0.43846098, g_loss: 5.81032848, rnn_loss: 0.07718792\n",
      " ** Epoch 298 took 61.467548s\n",
      "Epoch: [299/1000] time: 0.4389s, d_loss: 0.12310594, g_loss: 3.28410840, rnn_loss: 0.05766445\n",
      " ** Epoch 299 took 61.022074s\n",
      "Epoch: [300/1000] time: 0.3719s, d_loss: 0.08850400, g_loss: 2.49761152, rnn_loss: 0.00000000\n",
      " ** Epoch 300 took 51.673645s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [301/1000] time: 0.3764s, d_loss: 0.04800493, g_loss: 4.26308250, rnn_loss: 0.00000000\n",
      " ** Epoch 301 took 51.645560s\n",
      "Epoch: [302/1000] time: 0.3978s, d_loss: 0.16214453, g_loss: 3.49120975, rnn_loss: 0.00000000\n",
      " ** Epoch 302 took 52.083793s\n",
      "Epoch: [303/1000] time: 0.3767s, d_loss: 0.06763542, g_loss: 5.24374199, rnn_loss: 0.00000000\n",
      " ** Epoch 303 took 51.791060s\n",
      "Epoch: [304/1000] time: 0.3756s, d_loss: 0.08703437, g_loss: 4.24111319, rnn_loss: 0.00000000\n",
      " ** Epoch 304 took 52.029726s\n",
      "Epoch: [305/1000] time: 0.3727s, d_loss: 0.13899654, g_loss: 3.44706583, rnn_loss: 0.00000000\n",
      " ** Epoch 305 took 51.750340s\n",
      "Epoch: [306/1000] time: 0.3744s, d_loss: 0.12341194, g_loss: 3.36491323, rnn_loss: 0.00000000\n",
      " ** Epoch 306 took 51.710784s\n",
      "Epoch: [307/1000] time: 0.3732s, d_loss: 0.06400303, g_loss: 3.65454245, rnn_loss: 0.00000000\n",
      " ** Epoch 307 took 51.673657s\n",
      "Epoch: [308/1000] time: 0.3985s, d_loss: 0.55055988, g_loss: 5.45106506, rnn_loss: 0.00000000\n",
      " ** Epoch 308 took 52.179808s\n",
      "Epoch: [309/1000] time: 0.3721s, d_loss: 0.10523689, g_loss: 3.91330194, rnn_loss: 0.00000000\n",
      " ** Epoch 309 took 51.696204s\n",
      "Epoch: [310/1000] time: 0.3747s, d_loss: 0.60916376, g_loss: 2.59693146, rnn_loss: 0.00000000\n",
      " ** Epoch 310 took 52.020268s\n",
      "Epoch: [311/1000] time: 0.3768s, d_loss: 0.07726301, g_loss: 3.58217859, rnn_loss: 0.00000000\n",
      " ** Epoch 311 took 51.686019s\n",
      "Epoch: [312/1000] time: 0.3721s, d_loss: 0.33508030, g_loss: 5.97488308, rnn_loss: 0.00000000\n",
      " ** Epoch 312 took 51.696826s\n",
      "Epoch: [313/1000] time: 0.3746s, d_loss: 0.06207608, g_loss: 4.13451910, rnn_loss: 0.00000000\n",
      " ** Epoch 313 took 51.628817s\n",
      "Epoch: [314/1000] time: 0.3991s, d_loss: 0.05956078, g_loss: 4.77497578, rnn_loss: 0.00000000\n",
      " ** Epoch 314 took 52.266540s\n",
      "Epoch: [315/1000] time: 0.3704s, d_loss: 0.07333670, g_loss: 5.07200241, rnn_loss: 0.00000000\n",
      " ** Epoch 315 took 51.782619s\n",
      "Epoch: [316/1000] time: 0.3734s, d_loss: 0.11477282, g_loss: 4.29497766, rnn_loss: 0.00000000\n",
      " ** Epoch 316 took 52.123172s\n",
      "Epoch: [317/1000] time: 0.3745s, d_loss: 0.06434385, g_loss: 3.03112626, rnn_loss: 0.00000000\n",
      " ** Epoch 317 took 51.795503s\n",
      "Epoch: [318/1000] time: 0.3749s, d_loss: 0.30438015, g_loss: 4.23848534, rnn_loss: 0.00000000\n",
      " ** Epoch 318 took 51.910793s\n",
      "Epoch: [319/1000] time: 0.3773s, d_loss: 0.08860435, g_loss: 4.22739315, rnn_loss: 0.00000000\n",
      " ** Epoch 319 took 52.104731s\n",
      "Epoch: [320/1000] time: 0.3776s, d_loss: 0.17650487, g_loss: 3.19002628, rnn_loss: 0.00000000\n",
      " ** Epoch 320 took 52.698642s\n",
      "Epoch: [321/1000] time: 0.3790s, d_loss: 0.08141404, g_loss: 3.70715380, rnn_loss: 0.00000000\n",
      " ** Epoch 321 took 52.396681s\n",
      "Epoch: [322/1000] time: 0.3815s, d_loss: 0.10447696, g_loss: 3.45817709, rnn_loss: 0.00000000\n",
      " ** Epoch 322 took 52.235458s\n",
      "Epoch: [323/1000] time: 0.3775s, d_loss: 0.06454508, g_loss: 3.25197363, rnn_loss: 0.00000000\n",
      " ** Epoch 323 took 52.477071s\n",
      "Epoch: [324/1000] time: 0.3779s, d_loss: 0.01811542, g_loss: 5.32880497, rnn_loss: 0.00000000\n",
      " ** Epoch 324 took 52.312543s\n",
      "Epoch: [325/1000] time: 0.3799s, d_loss: 0.02184227, g_loss: 4.67825603, rnn_loss: 0.00000000\n",
      " ** Epoch 325 took 52.209591s\n",
      "Epoch: [326/1000] time: 0.3792s, d_loss: 0.08665258, g_loss: 3.30041265, rnn_loss: 0.00000000\n",
      " ** Epoch 326 took 52.656405s\n",
      "Epoch: [327/1000] time: 0.3797s, d_loss: 0.10723340, g_loss: 2.97246122, rnn_loss: 0.00000000\n",
      " ** Epoch 327 took 52.589987s\n",
      "Epoch: [328/1000] time: 0.3776s, d_loss: 0.35723165, g_loss: 1.93112814, rnn_loss: 0.00000000\n",
      " ** Epoch 328 took 52.112980s\n",
      "Epoch: [329/1000] time: 0.3809s, d_loss: 0.69031745, g_loss: 8.73656750, rnn_loss: 0.00000000\n",
      " ** Epoch 329 took 52.155587s\n",
      "Epoch: [330/1000] time: 0.3796s, d_loss: 0.06768344, g_loss: 4.94050789, rnn_loss: 0.00000000\n",
      " ** Epoch 330 took 52.189072s\n",
      "Epoch: [331/1000] time: 0.3754s, d_loss: 0.08514598, g_loss: 3.74260211, rnn_loss: 0.00000000\n",
      " ** Epoch 331 took 52.253584s\n",
      "Epoch: [332/1000] time: 0.3770s, d_loss: 0.07768933, g_loss: 3.32876396, rnn_loss: 0.00000000\n",
      " ** Epoch 332 took 52.910040s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [333/1000] time: 0.3814s, d_loss: 0.13486296, g_loss: 4.46625614, rnn_loss: 0.00000000\n",
      " ** Epoch 333 took 52.518762s\n",
      "Epoch: [334/1000] time: 0.3760s, d_loss: 0.01855983, g_loss: 4.58971882, rnn_loss: 0.00000000\n",
      " ** Epoch 334 took 51.981394s\n",
      "Epoch: [335/1000] time: 0.3770s, d_loss: 0.04642688, g_loss: 3.96350312, rnn_loss: 0.00000000\n",
      " ** Epoch 335 took 52.190089s\n",
      "Epoch: [336/1000] time: 0.3699s, d_loss: 0.06923918, g_loss: 4.02246761, rnn_loss: 0.00000000\n",
      " ** Epoch 336 took 52.162308s\n",
      "Epoch: [337/1000] time: 0.3763s, d_loss: 0.05042071, g_loss: 4.43398571, rnn_loss: 0.00000000\n",
      " ** Epoch 337 took 51.625433s\n",
      "Epoch: [338/1000] time: 0.3735s, d_loss: 0.12528276, g_loss: 4.07130289, rnn_loss: 0.00000000\n",
      " ** Epoch 338 took 52.605779s\n",
      "Epoch: [339/1000] time: 0.3760s, d_loss: 0.12030324, g_loss: 3.92543316, rnn_loss: 0.00000000\n",
      " ** Epoch 339 took 52.375752s\n",
      "Epoch: [340/1000] time: 0.3764s, d_loss: 0.23278978, g_loss: 3.32425833, rnn_loss: 0.00000000\n",
      " ** Epoch 340 took 52.110970s\n",
      "Epoch: [341/1000] time: 0.3822s, d_loss: 0.01567367, g_loss: 6.20556355, rnn_loss: 0.00000000\n",
      " ** Epoch 341 took 52.215129s\n",
      "Epoch: [342/1000] time: 0.3741s, d_loss: 0.30943263, g_loss: 7.51503181, rnn_loss: 0.00000000\n",
      " ** Epoch 342 took 52.282139s\n",
      "Epoch: [343/1000] time: 0.3822s, d_loss: 0.12824054, g_loss: 2.76867175, rnn_loss: 0.00000000\n",
      " ** Epoch 343 took 52.445052s\n",
      "Epoch: [344/1000] time: 0.3782s, d_loss: 0.25640652, g_loss: 3.51299047, rnn_loss: 0.00000000\n",
      " ** Epoch 344 took 52.837822s\n",
      "Epoch: [345/1000] time: 0.3755s, d_loss: 0.16223454, g_loss: 3.55422521, rnn_loss: 0.00000000\n",
      " ** Epoch 345 took 52.522783s\n",
      "Epoch: [346/1000] time: 0.3802s, d_loss: 0.11096508, g_loss: 2.34513426, rnn_loss: 0.00000000\n",
      " ** Epoch 346 took 52.086159s\n",
      "Epoch: [347/1000] time: 0.3735s, d_loss: 0.26275662, g_loss: 3.82896829, rnn_loss: 0.00000000\n",
      " ** Epoch 347 took 52.071429s\n",
      "Epoch: [348/1000] time: 0.3795s, d_loss: 0.01798715, g_loss: 3.75333881, rnn_loss: 0.00000000\n",
      " ** Epoch 348 took 52.104702s\n",
      "Epoch: [349/1000] time: 0.3768s, d_loss: 0.20899372, g_loss: 2.84925556, rnn_loss: 0.00000000\n",
      " ** Epoch 349 took 52.169904s\n",
      "Epoch: [350/1000] time: 0.4021s, d_loss: 0.03840607, g_loss: 5.16480637, rnn_loss: 0.00000000\n",
      " ** Epoch 350 took 52.811711s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [351/1000] time: 0.3777s, d_loss: 0.07771232, g_loss: 4.17989779, rnn_loss: 0.00000000\n",
      " ** Epoch 351 took 52.137105s\n",
      "Epoch: [352/1000] time: 0.3730s, d_loss: 0.02656631, g_loss: 5.42972469, rnn_loss: 0.00000000\n",
      " ** Epoch 352 took 52.048257s\n",
      "Epoch: [353/1000] time: 0.3778s, d_loss: 0.07545061, g_loss: 4.75803375, rnn_loss: 0.00000000\n",
      " ** Epoch 353 took 52.140296s\n",
      "Epoch: [354/1000] time: 0.3769s, d_loss: 0.02787014, g_loss: 4.48772240, rnn_loss: 0.00000000\n",
      " ** Epoch 354 took 52.416849s\n",
      "Epoch: [355/1000] time: 0.3800s, d_loss: 0.01554025, g_loss: 3.57491803, rnn_loss: 0.00000000\n",
      " ** Epoch 355 took 52.508673s\n",
      "Epoch: [356/1000] time: 0.3788s, d_loss: 0.20968257, g_loss: 6.98256540, rnn_loss: 0.00000000\n",
      " ** Epoch 356 took 53.316254s\n",
      "Epoch: [357/1000] time: 0.3779s, d_loss: 0.03925193, g_loss: 5.57335806, rnn_loss: 0.00000000\n",
      " ** Epoch 357 took 52.322701s\n",
      "Epoch: [358/1000] time: 0.3815s, d_loss: 0.02587432, g_loss: 4.78107452, rnn_loss: 0.00000000\n",
      " ** Epoch 358 took 52.289446s\n",
      "Epoch: [359/1000] time: 0.3825s, d_loss: 0.01347942, g_loss: 9.49006081, rnn_loss: 0.00000000\n",
      " ** Epoch 359 took 52.345219s\n",
      "Epoch: [360/1000] time: 0.3756s, d_loss: 0.04117262, g_loss: 4.99607658, rnn_loss: 0.00000000\n",
      " ** Epoch 360 took 52.334573s\n",
      "Epoch: [361/1000] time: 0.3830s, d_loss: 1.56957376, g_loss: 11.77852726, rnn_loss: 0.00000000\n",
      " ** Epoch 361 took 52.325831s\n",
      "Epoch: [362/1000] time: 0.3781s, d_loss: 0.09349812, g_loss: 3.84074569, rnn_loss: 0.00000000\n",
      " ** Epoch 362 took 53.292029s\n",
      "Epoch: [363/1000] time: 0.3781s, d_loss: 0.05951239, g_loss: 4.61816454, rnn_loss: 0.00000000\n",
      " ** Epoch 363 took 52.338740s\n",
      "Epoch: [364/1000] time: 0.3813s, d_loss: 0.13889597, g_loss: 4.90098286, rnn_loss: 0.00000000\n",
      " ** Epoch 364 took 52.331308s\n",
      "Epoch: [365/1000] time: 0.3753s, d_loss: 0.04747977, g_loss: 5.37978077, rnn_loss: 0.00000000\n",
      " ** Epoch 365 took 52.215684s\n",
      "Epoch: [366/1000] time: 0.3736s, d_loss: 0.02725255, g_loss: 4.03741837, rnn_loss: 0.00000000\n",
      " ** Epoch 366 took 51.800225s\n",
      "Epoch: [367/1000] time: 0.3716s, d_loss: 0.07585151, g_loss: 4.68086529, rnn_loss: 0.00000000\n",
      " ** Epoch 367 took 51.724554s\n",
      "Epoch: [368/1000] time: 0.3702s, d_loss: 0.13091412, g_loss: 4.84054279, rnn_loss: 0.00000000\n",
      " ** Epoch 368 took 52.372547s\n",
      "Epoch: [369/1000] time: 0.3728s, d_loss: 0.07117566, g_loss: 3.88798738, rnn_loss: 0.00000000\n",
      " ** Epoch 369 took 51.879132s\n",
      "Epoch: [370/1000] time: 0.3851s, d_loss: 0.01433185, g_loss: 4.97105980, rnn_loss: 0.00000000\n",
      " ** Epoch 370 took 51.905825s\n",
      "Epoch: [371/1000] time: 0.3732s, d_loss: 0.04996982, g_loss: 4.20877361, rnn_loss: 0.00000000\n",
      " ** Epoch 371 took 52.033731s\n",
      "Epoch: [372/1000] time: 0.3778s, d_loss: 0.11141305, g_loss: 8.01306152, rnn_loss: 0.00000000\n",
      " ** Epoch 372 took 52.077464s\n",
      "Epoch: [373/1000] time: 0.3761s, d_loss: 0.49473247, g_loss: 9.68694687, rnn_loss: 0.00000000\n",
      " ** Epoch 373 took 52.252831s\n",
      "Epoch: [374/1000] time: 0.3762s, d_loss: 0.01489873, g_loss: 4.99330425, rnn_loss: 0.00000000\n",
      " ** Epoch 374 took 53.147597s\n",
      "Epoch: [375/1000] time: 0.3797s, d_loss: 0.01601397, g_loss: 5.29700041, rnn_loss: 0.00000000\n",
      " ** Epoch 375 took 52.266254s\n",
      "Epoch: [376/1000] time: 0.3746s, d_loss: 0.07734475, g_loss: 8.70850468, rnn_loss: 0.00000000\n",
      " ** Epoch 376 took 52.278458s\n",
      "Epoch: [377/1000] time: 0.3788s, d_loss: 0.02423996, g_loss: 4.61922693, rnn_loss: 0.00000000\n",
      " ** Epoch 377 took 52.185667s\n",
      "Epoch: [378/1000] time: 0.3786s, d_loss: 0.01512309, g_loss: 5.05529404, rnn_loss: 0.00000000\n",
      " ** Epoch 378 took 52.201111s\n",
      "Epoch: [379/1000] time: 0.3976s, d_loss: 0.04003263, g_loss: 4.69777679, rnn_loss: 0.00000000\n",
      " ** Epoch 379 took 52.360116s\n",
      "Epoch: [380/1000] time: 0.3791s, d_loss: 0.02560709, g_loss: 4.95703506, rnn_loss: 0.00000000\n",
      " ** Epoch 380 took 52.605400s\n",
      "Epoch: [381/1000] time: 0.3780s, d_loss: 0.04975208, g_loss: 4.52634239, rnn_loss: 0.00000000\n",
      " ** Epoch 381 took 52.099239s\n",
      "Epoch: [382/1000] time: 0.3755s, d_loss: 0.43629622, g_loss: 0.44596505, rnn_loss: 0.00000000\n",
      " ** Epoch 382 took 52.116740s\n",
      "Epoch: [383/1000] time: 0.3764s, d_loss: 0.01655308, g_loss: 4.95922947, rnn_loss: 0.00000000\n",
      " ** Epoch 383 took 51.826741s\n",
      "Epoch: [384/1000] time: 0.3792s, d_loss: 0.02820552, g_loss: 4.72052813, rnn_loss: 0.00000000\n",
      " ** Epoch 384 took 51.878060s\n",
      "Epoch: [385/1000] time: 0.4155s, d_loss: 0.00452138, g_loss: 7.67149496, rnn_loss: 0.00000000\n",
      " ** Epoch 385 took 52.510623s\n",
      "Epoch: [386/1000] time: 0.3759s, d_loss: 0.04074727, g_loss: 6.97172737, rnn_loss: 0.00000000\n",
      " ** Epoch 386 took 52.011771s\n",
      "Epoch: [387/1000] time: 0.3775s, d_loss: 0.32083702, g_loss: 8.98004341, rnn_loss: 0.00000000\n",
      " ** Epoch 387 took 51.843819s\n",
      "Epoch: [388/1000] time: 0.3737s, d_loss: 0.02124130, g_loss: 5.11199665, rnn_loss: 0.00000000\n",
      " ** Epoch 388 took 51.710652s\n",
      "Epoch: [389/1000] time: 0.3739s, d_loss: 0.04250524, g_loss: 4.82302952, rnn_loss: 0.00000000\n",
      " ** Epoch 389 took 51.886990s\n",
      "Epoch: [390/1000] time: 0.3842s, d_loss: 0.00555757, g_loss: 7.48160028, rnn_loss: 0.00000000\n",
      " ** Epoch 390 took 52.049938s\n",
      "Epoch: [391/1000] time: 0.4059s, d_loss: 0.02860542, g_loss: 12.85732651, rnn_loss: 0.00000000\n",
      " ** Epoch 391 took 52.776796s\n",
      "Epoch: [392/1000] time: 0.3775s, d_loss: 0.10047583, g_loss: 5.39482355, rnn_loss: 0.00000000\n",
      " ** Epoch 392 took 52.086026s\n",
      "Epoch: [393/1000] time: 0.3751s, d_loss: 0.18149014, g_loss: 5.06833553, rnn_loss: 0.00000000\n",
      " ** Epoch 393 took 52.001752s\n",
      "Epoch: [394/1000] time: 0.3740s, d_loss: 0.00946568, g_loss: 5.63084030, rnn_loss: 0.00000000\n",
      " ** Epoch 394 took 51.866698s\n",
      "Epoch: [395/1000] time: 0.3748s, d_loss: 0.02022311, g_loss: 4.85706758, rnn_loss: 0.00000000\n",
      " ** Epoch 395 took 51.998387s\n",
      "Epoch: [396/1000] time: 0.3782s, d_loss: 0.01920959, g_loss: 4.82748652, rnn_loss: 0.00000000\n",
      " ** Epoch 396 took 51.981499s\n",
      "Epoch: [397/1000] time: 0.3800s, d_loss: 0.02681450, g_loss: 5.61252165, rnn_loss: 0.00000000\n",
      " ** Epoch 397 took 52.972019s\n",
      "Epoch: [398/1000] time: 0.3761s, d_loss: 0.01725119, g_loss: 7.06264782, rnn_loss: 0.00000000\n",
      " ** Epoch 398 took 52.018667s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [399/1000] time: 0.3761s, d_loss: 0.26067021, g_loss: 2.92448235, rnn_loss: 0.00000000\n",
      " ** Epoch 399 took 51.856039s\n",
      " ** new learning rate: 0.000050\n",
      "Epoch: [400/1000] time: 0.3787s, d_loss: 0.01210347, g_loss: 5.44188404, rnn_loss: 0.00000000\n",
      " ** Epoch 400 took 52.491945s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [401/1000] time: 0.3842s, d_loss: 0.00938686, g_loss: 6.57713699, rnn_loss: 0.00000000\n",
      " ** Epoch 401 took 52.225013s\n",
      "Epoch: [402/1000] time: 0.3762s, d_loss: 0.02594681, g_loss: 4.57750082, rnn_loss: 0.00000000\n",
      " ** Epoch 402 took 52.184524s\n",
      "Epoch: [403/1000] time: 0.3770s, d_loss: 0.04175401, g_loss: 4.29874420, rnn_loss: 0.00000000\n",
      " ** Epoch 403 took 53.218473s\n",
      "Epoch: [404/1000] time: 0.3784s, d_loss: 0.02436842, g_loss: 4.51301193, rnn_loss: 0.00000000\n",
      " ** Epoch 404 took 52.300745s\n",
      "Epoch: [405/1000] time: 0.3768s, d_loss: 0.01791300, g_loss: 4.86187267, rnn_loss: 0.00000000\n",
      " ** Epoch 405 took 52.274415s\n",
      "Epoch: [406/1000] time: 0.3760s, d_loss: 0.03676178, g_loss: 4.60361671, rnn_loss: 0.00000000\n",
      " ** Epoch 406 took 52.010091s\n",
      "Epoch: [407/1000] time: 0.3782s, d_loss: 0.02753176, g_loss: 4.35901833, rnn_loss: 0.00000000\n",
      " ** Epoch 407 took 51.974765s\n",
      "Epoch: [408/1000] time: 0.3778s, d_loss: 0.04958054, g_loss: 6.57962465, rnn_loss: 0.00000000\n",
      " ** Epoch 408 took 52.257270s\n",
      "Epoch: [409/1000] time: 0.3776s, d_loss: 0.03547332, g_loss: 4.30738068, rnn_loss: 0.00000000\n",
      " ** Epoch 409 took 53.084661s\n",
      "Epoch: [410/1000] time: 0.3820s, d_loss: 0.00841656, g_loss: 6.24615479, rnn_loss: 0.00000000\n",
      " ** Epoch 410 took 52.171102s\n",
      "Epoch: [411/1000] time: 0.3801s, d_loss: 0.12765092, g_loss: 2.75797033, rnn_loss: 0.00000000\n",
      " ** Epoch 411 took 52.250843s\n",
      "Epoch: [412/1000] time: 0.3786s, d_loss: 0.10574549, g_loss: 3.23553562, rnn_loss: 0.00000000\n",
      " ** Epoch 412 took 52.446935s\n",
      "Epoch: [413/1000] time: 0.3818s, d_loss: 0.12432741, g_loss: 4.21919346, rnn_loss: 0.00000000\n",
      " ** Epoch 413 took 52.415167s\n",
      "Epoch: [414/1000] time: 0.3771s, d_loss: 0.00281503, g_loss: 5.71296501, rnn_loss: 0.00000000\n",
      " ** Epoch 414 took 52.357590s\n",
      "Epoch: [415/1000] time: 0.3787s, d_loss: 0.01199209, g_loss: 4.78428364, rnn_loss: 0.00000000\n",
      " ** Epoch 415 took 53.426798s\n",
      "Epoch: [416/1000] time: 0.3862s, d_loss: 0.00990281, g_loss: 5.69914293, rnn_loss: 0.00000000\n",
      " ** Epoch 416 took 52.402797s\n",
      "Epoch: [417/1000] time: 0.3832s, d_loss: 0.03893713, g_loss: 4.44824409, rnn_loss: 0.00000000\n",
      " ** Epoch 417 took 52.422411s\n",
      "Epoch: [418/1000] time: 0.3816s, d_loss: 0.06715293, g_loss: 6.75876999, rnn_loss: 0.00000000\n",
      " ** Epoch 418 took 52.420276s\n",
      "Epoch: [419/1000] time: 0.3772s, d_loss: 0.00623235, g_loss: 5.04575729, rnn_loss: 0.00000000\n",
      " ** Epoch 419 took 52.306293s\n",
      "Epoch: [420/1000] time: 0.3810s, d_loss: 0.11527141, g_loss: 4.90730238, rnn_loss: 0.00000000\n",
      " ** Epoch 420 took 52.576672s\n",
      "Epoch: [421/1000] time: 0.3779s, d_loss: 0.01390656, g_loss: 4.65384150, rnn_loss: 0.00000000\n",
      " ** Epoch 421 took 52.759498s\n",
      "Epoch: [422/1000] time: 0.3737s, d_loss: 0.17830962, g_loss: 5.94708729, rnn_loss: 0.00000000\n",
      " ** Epoch 422 took 51.904294s\n",
      "Epoch: [423/1000] time: 0.3767s, d_loss: 0.02817791, g_loss: 4.41642857, rnn_loss: 0.00000000\n",
      " ** Epoch 423 took 51.861669s\n",
      "Epoch: [424/1000] time: 0.3748s, d_loss: 0.01361095, g_loss: 4.56565666, rnn_loss: 0.00000000\n",
      " ** Epoch 424 took 51.829271s\n",
      "Epoch: [425/1000] time: 0.3751s, d_loss: 0.00961323, g_loss: 5.33337975, rnn_loss: 0.00000000\n",
      " ** Epoch 425 took 51.776158s\n",
      "Epoch: [426/1000] time: 0.3730s, d_loss: 0.00748255, g_loss: 5.27288818, rnn_loss: 0.00000000\n",
      " ** Epoch 426 took 52.180409s\n",
      "Epoch: [427/1000] time: 0.3741s, d_loss: 0.02508355, g_loss: 4.86338902, rnn_loss: 0.00000000\n",
      " ** Epoch 427 took 52.364837s\n",
      "Epoch: [428/1000] time: 0.3769s, d_loss: 0.00331502, g_loss: 7.60339928, rnn_loss: 0.00000000\n",
      " ** Epoch 428 took 51.826684s\n",
      "Epoch: [429/1000] time: 0.3795s, d_loss: 0.05303817, g_loss: 4.86071348, rnn_loss: 0.00000000\n",
      " ** Epoch 429 took 51.818907s\n",
      "Epoch: [430/1000] time: 0.3767s, d_loss: 0.01669927, g_loss: 4.62506771, rnn_loss: 0.00000000\n",
      " ** Epoch 430 took 51.805809s\n",
      "Epoch: [431/1000] time: 0.3717s, d_loss: 0.01282826, g_loss: 5.91691208, rnn_loss: 0.00000000\n",
      " ** Epoch 431 took 51.861773s\n",
      "Epoch: [432/1000] time: 0.3736s, d_loss: 0.00948389, g_loss: 6.27965355, rnn_loss: 0.00000000\n",
      " ** Epoch 432 took 52.065933s\n",
      "Epoch: [433/1000] time: 0.3736s, d_loss: 0.14268309, g_loss: 6.88984156, rnn_loss: 0.00000000\n",
      " ** Epoch 433 took 52.378981s\n",
      "Epoch: [434/1000] time: 0.3784s, d_loss: 0.05647069, g_loss: 4.16186905, rnn_loss: 0.00000000\n",
      " ** Epoch 434 took 51.799350s\n",
      "Epoch: [435/1000] time: 0.3773s, d_loss: 0.00386959, g_loss: 6.47605133, rnn_loss: 0.00000000\n",
      " ** Epoch 435 took 51.798950s\n",
      "Epoch: [436/1000] time: 0.3790s, d_loss: 0.02672331, g_loss: 6.37882423, rnn_loss: 0.00000000\n",
      " ** Epoch 436 took 52.310605s\n",
      "Epoch: [437/1000] time: 0.3746s, d_loss: 0.03048301, g_loss: 5.99670315, rnn_loss: 0.00000000\n",
      " ** Epoch 437 took 52.280479s\n",
      "Epoch: [438/1000] time: 0.3816s, d_loss: 0.11011369, g_loss: 3.55066347, rnn_loss: 0.00000000\n",
      " ** Epoch 438 took 52.864898s\n",
      "Epoch: [439/1000] time: 0.3779s, d_loss: 0.00391985, g_loss: 9.67097473, rnn_loss: 0.00000000\n",
      " ** Epoch 439 took 52.946543s\n",
      "Epoch: [440/1000] time: 0.3797s, d_loss: 0.00929903, g_loss: 4.99206066, rnn_loss: 0.00000000\n",
      " ** Epoch 440 took 52.327868s\n",
      "Epoch: [441/1000] time: 0.3821s, d_loss: 0.02202397, g_loss: 4.82944107, rnn_loss: 0.00000000\n",
      " ** Epoch 441 took 52.364305s\n",
      "Epoch: [442/1000] time: 0.3832s, d_loss: 0.03792023, g_loss: 4.17307043, rnn_loss: 0.00000000\n",
      " ** Epoch 442 took 52.508253s\n",
      "Epoch: [443/1000] time: 0.3791s, d_loss: 0.27657875, g_loss: 5.07079601, rnn_loss: 0.00000000\n",
      " ** Epoch 443 took 52.577631s\n",
      "Epoch: [444/1000] time: 0.3813s, d_loss: 0.00611302, g_loss: 7.63173199, rnn_loss: 0.00000000\n",
      " ** Epoch 444 took 52.886702s\n",
      "Epoch: [445/1000] time: 0.3766s, d_loss: 0.17979318, g_loss: 3.76290989, rnn_loss: 0.00000000\n",
      " ** Epoch 445 took 53.161806s\n",
      "Epoch: [446/1000] time: 0.3793s, d_loss: 0.01720842, g_loss: 7.52733660, rnn_loss: 0.00000000\n",
      " ** Epoch 446 took 52.462020s\n",
      "Epoch: [447/1000] time: 0.3787s, d_loss: 0.02901047, g_loss: 3.48930693, rnn_loss: 0.00000000\n",
      " ** Epoch 447 took 52.380481s\n",
      "Epoch: [448/1000] time: 0.3775s, d_loss: 0.02383808, g_loss: 4.39888191, rnn_loss: 0.00000000\n",
      " ** Epoch 448 took 52.311857s\n",
      "Epoch: [449/1000] time: 0.4053s, d_loss: 0.04094484, g_loss: 3.59181261, rnn_loss: 0.00000000\n",
      " ** Epoch 449 took 52.343212s\n",
      "Epoch: [450/1000] time: 0.3810s, d_loss: 0.12345013, g_loss: 4.40270710, rnn_loss: 0.00000000\n",
      " ** Epoch 450 took 52.515511s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [451/1000] time: 0.3739s, d_loss: 0.00900452, g_loss: 6.89321899, rnn_loss: 0.00000000\n",
      " ** Epoch 451 took 52.686261s\n",
      "Epoch: [452/1000] time: 0.3798s, d_loss: 0.30710322, g_loss: 8.31190777, rnn_loss: 0.00000000\n",
      " ** Epoch 452 took 52.085193s\n",
      "Epoch: [453/1000] time: 0.3837s, d_loss: 0.00781231, g_loss: 5.09503603, rnn_loss: 0.00000000\n",
      " ** Epoch 453 took 52.155010s\n",
      "Epoch: [454/1000] time: 0.3796s, d_loss: 0.07419720, g_loss: 4.87733078, rnn_loss: 0.00000000\n",
      " ** Epoch 454 took 52.092053s\n",
      "Epoch: [455/1000] time: 0.3789s, d_loss: 0.00800243, g_loss: 5.42973804, rnn_loss: 0.00000000\n",
      " ** Epoch 455 took 52.278852s\n",
      "Epoch: [456/1000] time: 0.4026s, d_loss: 0.06941319, g_loss: 5.06032562, rnn_loss: 0.00000000\n",
      " ** Epoch 456 took 52.243725s\n",
      "Epoch: [457/1000] time: 0.3769s, d_loss: 0.00138258, g_loss: 7.79277754, rnn_loss: 0.00000000\n",
      " ** Epoch 457 took 52.269015s\n",
      "Epoch: [458/1000] time: 0.3759s, d_loss: 0.03580912, g_loss: 5.48701954, rnn_loss: 0.00000000\n",
      " ** Epoch 458 took 51.940347s\n",
      "Epoch: [459/1000] time: 0.3763s, d_loss: 0.00676266, g_loss: 6.64485216, rnn_loss: 0.00000000\n",
      " ** Epoch 459 took 51.966978s\n",
      "Epoch: [460/1000] time: 0.3754s, d_loss: 0.02152485, g_loss: 10.46597576, rnn_loss: 0.00000000\n",
      " ** Epoch 460 took 51.906602s\n",
      "Epoch: [461/1000] time: 0.3744s, d_loss: 0.01344165, g_loss: 6.97588921, rnn_loss: 0.00000000\n",
      " ** Epoch 461 took 52.177377s\n",
      "Epoch: [462/1000] time: 0.4052s, d_loss: 0.01750772, g_loss: 4.78798294, rnn_loss: 0.00000000\n",
      " ** Epoch 462 took 52.494127s\n",
      "Epoch: [463/1000] time: 0.3795s, d_loss: 0.04431132, g_loss: 4.00564671, rnn_loss: 0.00000000\n",
      " ** Epoch 463 took 52.314287s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [464/1000] time: 0.3756s, d_loss: 0.03644995, g_loss: 6.32729292, rnn_loss: 0.00000000\n",
      " ** Epoch 464 took 52.063684s\n",
      "Epoch: [465/1000] time: 0.3743s, d_loss: 0.04405097, g_loss: 6.02743816, rnn_loss: 0.00000000\n",
      " ** Epoch 465 took 52.034441s\n",
      "Epoch: [466/1000] time: 0.3751s, d_loss: 0.07276414, g_loss: 3.67867112, rnn_loss: 0.00000000\n",
      " ** Epoch 466 took 52.022748s\n",
      "Epoch: [467/1000] time: 0.3796s, d_loss: 0.02548708, g_loss: 4.85992622, rnn_loss: 0.00000000\n",
      " ** Epoch 467 took 52.502822s\n",
      "Epoch: [468/1000] time: 0.3791s, d_loss: 0.06704424, g_loss: 4.85019779, rnn_loss: 0.00000000\n",
      " ** Epoch 468 took 52.721846s\n",
      "Epoch: [469/1000] time: 0.3833s, d_loss: 0.00483389, g_loss: 6.78397083, rnn_loss: 0.00000000\n",
      " ** Epoch 469 took 52.148387s\n",
      "Epoch: [470/1000] time: 0.3824s, d_loss: 0.04015246, g_loss: 3.82990909, rnn_loss: 0.00000000\n",
      " ** Epoch 470 took 52.389028s\n",
      "Epoch: [471/1000] time: 0.3796s, d_loss: 0.00693915, g_loss: 5.88411140, rnn_loss: 0.00000000\n",
      " ** Epoch 471 took 52.366512s\n",
      "Epoch: [472/1000] time: 0.3775s, d_loss: 0.03302680, g_loss: 5.36521053, rnn_loss: 0.00000000\n",
      " ** Epoch 472 took 52.228628s\n",
      "Epoch: [473/1000] time: 0.3828s, d_loss: 0.01281684, g_loss: 8.02764320, rnn_loss: 0.00000000\n",
      " ** Epoch 473 took 52.824137s\n",
      "Epoch: [474/1000] time: 0.3857s, d_loss: 0.00541856, g_loss: 7.29815674, rnn_loss: 0.00000000\n",
      " ** Epoch 474 took 53.171199s\n",
      "Epoch: [475/1000] time: 0.3776s, d_loss: 0.02910109, g_loss: 5.20772171, rnn_loss: 0.00000000\n",
      " ** Epoch 475 took 52.644228s\n",
      "Epoch: [476/1000] time: 0.3798s, d_loss: 0.36660317, g_loss: 6.10494137, rnn_loss: 0.00000000\n",
      " ** Epoch 476 took 52.483726s\n",
      "Epoch: [477/1000] time: 0.3783s, d_loss: 0.04395589, g_loss: 4.00016356, rnn_loss: 0.00000000\n",
      " ** Epoch 477 took 52.569940s\n",
      "Epoch: [478/1000] time: 0.3819s, d_loss: 0.01097670, g_loss: 4.12534285, rnn_loss: 0.00000000\n",
      " ** Epoch 478 took 52.287884s\n",
      "Epoch: [479/1000] time: 0.3806s, d_loss: 0.01205121, g_loss: 4.60675144, rnn_loss: 0.00000000\n",
      " ** Epoch 479 took 52.656942s\n",
      "Epoch: [480/1000] time: 0.3786s, d_loss: 0.08083961, g_loss: 4.30048275, rnn_loss: 0.00000000\n",
      " ** Epoch 480 took 53.088553s\n",
      "Epoch: [481/1000] time: 0.3827s, d_loss: 0.08685050, g_loss: 8.44704437, rnn_loss: 0.00000000\n",
      " ** Epoch 481 took 52.499907s\n",
      "Epoch: [482/1000] time: 0.3782s, d_loss: 0.08569028, g_loss: 5.33605003, rnn_loss: 0.00000000\n",
      " ** Epoch 482 took 52.527882s\n",
      "Epoch: [483/1000] time: 0.3728s, d_loss: 0.02486977, g_loss: 5.05982685, rnn_loss: 0.00000000\n",
      " ** Epoch 483 took 52.426349s\n",
      "Epoch: [484/1000] time: 0.3729s, d_loss: 0.01168622, g_loss: 10.44492912, rnn_loss: 0.00000000\n",
      " ** Epoch 484 took 52.549905s\n",
      "Epoch: [485/1000] time: 0.3756s, d_loss: 0.05147468, g_loss: 3.60954404, rnn_loss: 0.00000000\n",
      " ** Epoch 485 took 52.057685s\n",
      "Epoch: [486/1000] time: 0.3772s, d_loss: 1.11960316, g_loss: 12.13306618, rnn_loss: 0.00000000\n",
      " ** Epoch 486 took 52.648094s\n",
      "Epoch: [487/1000] time: 0.3798s, d_loss: 0.09868239, g_loss: 4.86177444, rnn_loss: 0.00000000\n",
      " ** Epoch 487 took 52.150854s\n",
      "Epoch: [488/1000] time: 0.3795s, d_loss: 0.28495252, g_loss: 6.55905676, rnn_loss: 0.00000000\n",
      " ** Epoch 488 took 51.973190s\n",
      "Epoch: [489/1000] time: 0.3762s, d_loss: 0.14595890, g_loss: 10.38830948, rnn_loss: 0.00000000\n",
      " ** Epoch 489 took 52.055908s\n",
      "Epoch: [490/1000] time: 0.3776s, d_loss: 0.04591184, g_loss: 6.74885321, rnn_loss: 0.00000000\n",
      " ** Epoch 490 took 52.367190s\n",
      "Epoch: [491/1000] time: 0.3732s, d_loss: 0.02808100, g_loss: 6.68649340, rnn_loss: 0.00000000\n",
      " ** Epoch 491 took 52.053716s\n",
      "Epoch: [492/1000] time: 0.3762s, d_loss: 0.19157550, g_loss: 9.01597023, rnn_loss: 0.00000000\n",
      " ** Epoch 492 took 52.727489s\n",
      "Epoch: [493/1000] time: 0.3796s, d_loss: 0.08107073, g_loss: 3.83875179, rnn_loss: 0.00000000\n",
      " ** Epoch 493 took 52.121352s\n",
      "Epoch: [494/1000] time: 0.3789s, d_loss: 0.06174489, g_loss: 4.70842934, rnn_loss: 0.00000000\n",
      " ** Epoch 494 took 52.143203s\n",
      "Epoch: [495/1000] time: 0.3812s, d_loss: 0.01613890, g_loss: 4.09317112, rnn_loss: 0.00000000\n",
      " ** Epoch 495 took 52.196733s\n",
      "Epoch: [496/1000] time: 0.3756s, d_loss: 0.01327182, g_loss: 4.58308792, rnn_loss: 0.00000000\n",
      " ** Epoch 496 took 52.508715s\n",
      "Epoch: [497/1000] time: 0.3793s, d_loss: 0.01486813, g_loss: 5.61563492, rnn_loss: 0.00000000\n",
      " ** Epoch 497 took 52.206047s\n",
      "Epoch: [498/1000] time: 0.3786s, d_loss: 0.06269071, g_loss: 4.73923969, rnn_loss: 0.00000000\n",
      " ** Epoch 498 took 52.772060s\n",
      "Epoch: [499/1000] time: 0.3760s, d_loss: 0.05158593, g_loss: 5.91694117, rnn_loss: 0.00000000\n",
      " ** Epoch 499 took 52.192867s\n",
      "Epoch: [500/1000] time: 0.3780s, d_loss: 0.53497797, g_loss: 0.70118439, rnn_loss: 0.00000000\n",
      " ** Epoch 500 took 52.164416s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [501/1000] time: 0.3745s, d_loss: 0.12687069, g_loss: 6.44337082, rnn_loss: 0.00000000\n",
      " ** Epoch 501 took 52.187697s\n",
      "Epoch: [502/1000] time: 0.3760s, d_loss: 0.00535899, g_loss: 7.61732435, rnn_loss: 0.00000000\n",
      " ** Epoch 502 took 52.536611s\n",
      "Epoch: [503/1000] time: 0.3807s, d_loss: 0.02401743, g_loss: 6.12875652, rnn_loss: 0.00000000\n",
      " ** Epoch 503 took 52.222275s\n",
      "Epoch: [504/1000] time: 0.3773s, d_loss: 0.02269882, g_loss: 4.88867092, rnn_loss: 0.00000000\n",
      " ** Epoch 504 took 52.949252s\n",
      "Epoch: [505/1000] time: 0.3804s, d_loss: 1.14717698, g_loss: 0.39562902, rnn_loss: 0.00000000\n",
      " ** Epoch 505 took 52.252622s\n",
      "Epoch: [506/1000] time: 0.3793s, d_loss: 0.03305052, g_loss: 6.78955603, rnn_loss: 0.00000000\n",
      " ** Epoch 506 took 52.149374s\n",
      "Epoch: [507/1000] time: 0.3777s, d_loss: 0.19276847, g_loss: 5.90438843, rnn_loss: 0.00000000\n",
      " ** Epoch 507 took 52.556785s\n",
      "Epoch: [508/1000] time: 0.3761s, d_loss: 0.06081241, g_loss: 4.13788605, rnn_loss: 0.00000000\n",
      " ** Epoch 508 took 52.787071s\n",
      "Epoch: [509/1000] time: 0.3801s, d_loss: 0.04090051, g_loss: 4.04889727, rnn_loss: 0.00000000\n",
      " ** Epoch 509 took 52.439739s\n",
      "Epoch: [510/1000] time: 0.3772s, d_loss: 0.03314249, g_loss: 5.08496094, rnn_loss: 0.00000000\n",
      " ** Epoch 510 took 53.094029s\n",
      "Epoch: [511/1000] time: 0.3832s, d_loss: 0.01361407, g_loss: 5.27506971, rnn_loss: 0.00000000\n",
      " ** Epoch 511 took 52.632166s\n",
      "Epoch: [512/1000] time: 0.3751s, d_loss: 0.02671821, g_loss: 5.00974035, rnn_loss: 0.00000000\n",
      " ** Epoch 512 took 52.434647s\n",
      "Epoch: [513/1000] time: 0.4051s, d_loss: 0.02625516, g_loss: 3.99114609, rnn_loss: 0.00000000\n",
      " ** Epoch 513 took 52.874096s\n",
      "Epoch: [514/1000] time: 0.3818s, d_loss: 0.07325701, g_loss: 5.21415806, rnn_loss: 0.00000000\n",
      " ** Epoch 514 took 52.452709s\n",
      "Epoch: [515/1000] time: 0.4053s, d_loss: 0.40369073, g_loss: 4.95204306, rnn_loss: 0.00000000\n",
      " ** Epoch 515 took 52.384005s\n",
      "Epoch: [516/1000] time: 0.3780s, d_loss: 0.06127739, g_loss: 4.79642868, rnn_loss: 0.00000000\n",
      " ** Epoch 516 took 53.007560s\n",
      "Epoch: [517/1000] time: 0.3761s, d_loss: 0.08874637, g_loss: 4.36779976, rnn_loss: 0.00000000\n",
      " ** Epoch 517 took 52.398855s\n",
      "Epoch: [518/1000] time: 0.3827s, d_loss: 0.04054421, g_loss: 6.83267975, rnn_loss: 0.00000000\n",
      " ** Epoch 518 took 52.467371s\n",
      "Epoch: [519/1000] time: 0.3797s, d_loss: 0.02889876, g_loss: 4.54450512, rnn_loss: 0.00000000\n",
      " ** Epoch 519 took 52.793087s\n",
      "Epoch: [520/1000] time: 0.3807s, d_loss: 0.04453660, g_loss: 4.05800438, rnn_loss: 0.00000000\n",
      " ** Epoch 520 took 52.501012s\n",
      "Epoch: [521/1000] time: 0.4057s, d_loss: 0.25173092, g_loss: 7.01102877, rnn_loss: 0.00000000\n",
      " ** Epoch 521 took 53.086670s\n",
      "Epoch: [522/1000] time: 0.3824s, d_loss: 0.03857863, g_loss: 4.32460976, rnn_loss: 0.00000000\n",
      " ** Epoch 522 took 52.771592s\n",
      "Epoch: [523/1000] time: 0.3761s, d_loss: 0.00159174, g_loss: 7.37689877, rnn_loss: 0.00000000\n",
      " ** Epoch 523 took 52.566035s\n",
      "Epoch: [524/1000] time: 0.3773s, d_loss: 0.01162257, g_loss: 5.38039684, rnn_loss: 0.00000000\n",
      " ** Epoch 524 took 52.586562s\n",
      "Epoch: [525/1000] time: 0.3796s, d_loss: 0.00940307, g_loss: 6.26755571, rnn_loss: 0.00000000\n",
      " ** Epoch 525 took 52.822426s\n",
      "Epoch: [526/1000] time: 0.3779s, d_loss: 0.07186961, g_loss: 4.78221083, rnn_loss: 0.00000000\n",
      " ** Epoch 526 took 52.674274s\n",
      "Epoch: [527/1000] time: 0.3813s, d_loss: 0.02202843, g_loss: 4.89179230, rnn_loss: 0.00000000\n",
      " ** Epoch 527 took 53.430840s\n",
      "Epoch: [528/1000] time: 0.3842s, d_loss: 0.05523888, g_loss: 6.20582581, rnn_loss: 0.00000000\n",
      " ** Epoch 528 took 52.727855s\n",
      "Epoch: [529/1000] time: 0.3804s, d_loss: 0.01172836, g_loss: 5.35062885, rnn_loss: 0.00000000\n",
      " ** Epoch 529 took 52.643648s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [530/1000] time: 0.3814s, d_loss: 0.01022718, g_loss: 5.21137142, rnn_loss: 0.00000000\n",
      " ** Epoch 530 took 52.543090s\n",
      "Epoch: [531/1000] time: 0.3765s, d_loss: 0.03206986, g_loss: 4.11842251, rnn_loss: 0.00000000\n",
      " ** Epoch 531 took 52.669337s\n",
      "Epoch: [532/1000] time: 0.3801s, d_loss: 0.00363065, g_loss: 6.58688545, rnn_loss: 0.00000000\n",
      " ** Epoch 532 took 52.430453s\n",
      "Epoch: [533/1000] time: 0.3805s, d_loss: 0.04057636, g_loss: 4.11376238, rnn_loss: 0.00000000\n",
      " ** Epoch 533 took 53.293386s\n",
      "Epoch: [534/1000] time: 0.3798s, d_loss: 0.06685898, g_loss: 3.11948967, rnn_loss: 0.00000000\n",
      " ** Epoch 534 took 52.428019s\n",
      "Epoch: [535/1000] time: 0.3836s, d_loss: 0.05296512, g_loss: 4.02168798, rnn_loss: 0.00000000\n",
      " ** Epoch 535 took 52.405428s\n",
      "Epoch: [536/1000] time: 0.3800s, d_loss: 0.12641668, g_loss: 4.83500671, rnn_loss: 0.00000000\n",
      " ** Epoch 536 took 52.642856s\n",
      "Epoch: [537/1000] time: 0.3814s, d_loss: 0.02969495, g_loss: 3.06520033, rnn_loss: 0.00000000\n",
      " ** Epoch 537 took 52.843877s\n",
      "Epoch: [538/1000] time: 0.3782s, d_loss: 0.10687065, g_loss: 3.14240718, rnn_loss: 0.00000000\n",
      " ** Epoch 538 took 52.330040s\n",
      "Epoch: [539/1000] time: 0.3831s, d_loss: 0.22068529, g_loss: 6.17100334, rnn_loss: 0.00000000\n",
      " ** Epoch 539 took 52.964959s\n",
      "Epoch: [540/1000] time: 0.3781s, d_loss: 0.00903516, g_loss: 5.41464424, rnn_loss: 0.00000000\n",
      " ** Epoch 540 took 52.205523s\n",
      "Epoch: [541/1000] time: 0.3863s, d_loss: 0.59546900, g_loss: 0.38750660, rnn_loss: 0.00000000\n",
      " ** Epoch 541 took 52.926416s\n",
      "Epoch: [542/1000] time: 0.3716s, d_loss: 0.08948360, g_loss: 3.62333632, rnn_loss: 0.00000000\n",
      " ** Epoch 542 took 53.044710s\n",
      "Epoch: [543/1000] time: 0.3818s, d_loss: 0.02379382, g_loss: 4.39437771, rnn_loss: 0.00000000\n",
      " ** Epoch 543 took 52.598800s\n",
      "Epoch: [544/1000] time: 0.3821s, d_loss: 0.06654990, g_loss: 5.19980526, rnn_loss: 0.00000000\n",
      " ** Epoch 544 took 52.958757s\n",
      "Epoch: [545/1000] time: 0.3805s, d_loss: 0.07199845, g_loss: 3.92658019, rnn_loss: 0.00000000\n",
      " ** Epoch 545 took 53.455801s\n",
      "Epoch: [546/1000] time: 0.3799s, d_loss: 0.09248666, g_loss: 3.89701748, rnn_loss: 0.00000000\n",
      " ** Epoch 546 took 52.993368s\n",
      "Epoch: [547/1000] time: 0.3927s, d_loss: 0.04705679, g_loss: 3.76143074, rnn_loss: 0.00000000\n",
      " ** Epoch 547 took 53.203495s\n",
      "Epoch: [548/1000] time: 0.3765s, d_loss: 0.02087846, g_loss: 5.47976446, rnn_loss: 0.00000000\n",
      " ** Epoch 548 took 53.257743s\n",
      "Epoch: [549/1000] time: 0.3810s, d_loss: 0.03328046, g_loss: 4.38759804, rnn_loss: 0.00000000\n",
      " ** Epoch 549 took 52.963218s\n",
      "Epoch: [550/1000] time: 0.3796s, d_loss: 0.16048549, g_loss: 3.06738138, rnn_loss: 0.00000000\n",
      " ** Epoch 550 took 52.918905s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [551/1000] time: 0.3793s, d_loss: 0.10323618, g_loss: 5.19937229, rnn_loss: 0.00000000\n",
      " ** Epoch 551 took 53.454669s\n",
      "Epoch: [552/1000] time: 0.3918s, d_loss: 0.00971539, g_loss: 5.42273855, rnn_loss: 0.00000000\n",
      " ** Epoch 552 took 52.941655s\n",
      "Epoch: [553/1000] time: 0.3814s, d_loss: 0.07188768, g_loss: 3.79020977, rnn_loss: 0.00000000\n",
      " ** Epoch 553 took 52.866934s\n",
      "Epoch: [554/1000] time: 0.3800s, d_loss: 0.06625657, g_loss: 4.24641275, rnn_loss: 0.00000000\n",
      " ** Epoch 554 took 53.084517s\n",
      "Epoch: [555/1000] time: 0.3821s, d_loss: 0.03843318, g_loss: 5.13803768, rnn_loss: 0.00000000\n",
      " ** Epoch 555 took 52.576387s\n",
      "Epoch: [556/1000] time: 0.3850s, d_loss: 0.10501413, g_loss: 3.56330991, rnn_loss: 0.00000000\n",
      " ** Epoch 556 took 52.707558s\n",
      "Epoch: [557/1000] time: 0.3800s, d_loss: 0.06939153, g_loss: 3.88354278, rnn_loss: 0.00000000\n",
      " ** Epoch 557 took 53.188085s\n",
      "Epoch: [558/1000] time: 0.3776s, d_loss: 0.06820814, g_loss: 8.21565056, rnn_loss: 0.00000000\n",
      " ** Epoch 558 took 52.658007s\n",
      "Epoch: [559/1000] time: 0.3849s, d_loss: 0.02786654, g_loss: 5.72936249, rnn_loss: 0.00000000\n",
      " ** Epoch 559 took 52.763044s\n",
      "Epoch: [560/1000] time: 0.3798s, d_loss: 0.06176385, g_loss: 4.15006447, rnn_loss: 0.00000000\n",
      " ** Epoch 560 took 53.105514s\n",
      "Epoch: [561/1000] time: 0.3803s, d_loss: 0.08226123, g_loss: 4.08124352, rnn_loss: 0.00000000\n",
      " ** Epoch 561 took 52.701030s\n",
      "Epoch: [562/1000] time: 0.4053s, d_loss: 0.03476428, g_loss: 4.87325096, rnn_loss: 0.00000000\n",
      " ** Epoch 562 took 53.057583s\n",
      "Epoch: [563/1000] time: 0.3801s, d_loss: 0.01047542, g_loss: 4.97199583, rnn_loss: 0.00000000\n",
      " ** Epoch 563 took 52.801174s\n",
      "Epoch: [564/1000] time: 0.3828s, d_loss: 0.00679534, g_loss: 6.99027777, rnn_loss: 0.00000000\n",
      " ** Epoch 564 took 52.708118s\n",
      "Epoch: [565/1000] time: 0.3791s, d_loss: 0.00672090, g_loss: 8.77618790, rnn_loss: 0.00000000\n",
      " ** Epoch 565 took 53.010716s\n",
      "Epoch: [566/1000] time: 0.3825s, d_loss: 0.00917152, g_loss: 6.39531088, rnn_loss: 0.00000000\n",
      " ** Epoch 566 took 52.627205s\n",
      "Epoch: [567/1000] time: 0.3804s, d_loss: 0.01836031, g_loss: 6.35048103, rnn_loss: 0.00000000\n",
      " ** Epoch 567 took 52.695796s\n",
      "Epoch: [568/1000] time: 0.3814s, d_loss: 0.26287338, g_loss: 7.22220516, rnn_loss: 0.00000000\n",
      " ** Epoch 568 took 53.299350s\n",
      "Epoch: [569/1000] time: 0.3762s, d_loss: 0.04733536, g_loss: 10.43686199, rnn_loss: 0.00000000\n",
      " ** Epoch 569 took 52.773419s\n",
      "Epoch: [570/1000] time: 0.3824s, d_loss: 0.06490102, g_loss: 4.28389835, rnn_loss: 0.00000000\n",
      " ** Epoch 570 took 52.646373s\n",
      "Epoch: [571/1000] time: 0.3847s, d_loss: 0.01920513, g_loss: 4.36948776, rnn_loss: 0.00000000\n",
      " ** Epoch 571 took 53.047510s\n",
      "Epoch: [572/1000] time: 0.3842s, d_loss: 0.22396335, g_loss: 5.08510876, rnn_loss: 0.00000000\n",
      " ** Epoch 572 took 52.735870s\n",
      "Epoch: [573/1000] time: 0.3837s, d_loss: 0.05447351, g_loss: 4.52825785, rnn_loss: 0.00000000\n",
      " ** Epoch 573 took 52.734657s\n",
      "Epoch: [574/1000] time: 0.3793s, d_loss: 0.00605993, g_loss: 7.85343170, rnn_loss: 0.00000000\n",
      " ** Epoch 574 took 53.330584s\n",
      "Epoch: [575/1000] time: 0.3841s, d_loss: 0.12031800, g_loss: 2.91498327, rnn_loss: 0.00000000\n",
      " ** Epoch 575 took 52.717759s\n",
      "Epoch: [576/1000] time: 0.3852s, d_loss: 0.03292195, g_loss: 4.76448774, rnn_loss: 0.00000000\n",
      " ** Epoch 576 took 52.734801s\n",
      "Epoch: [577/1000] time: 0.3796s, d_loss: 0.04977915, g_loss: 7.33775854, rnn_loss: 0.00000000\n",
      " ** Epoch 577 took 53.044809s\n",
      "Epoch: [578/1000] time: 0.3799s, d_loss: 0.02502324, g_loss: 4.65301418, rnn_loss: 0.00000000\n",
      " ** Epoch 578 took 52.722084s\n",
      "Epoch: [579/1000] time: 0.3875s, d_loss: 0.05114064, g_loss: 6.07074165, rnn_loss: 0.00000000\n",
      " ** Epoch 579 took 52.723923s\n",
      "Epoch: [580/1000] time: 0.3783s, d_loss: 0.00536709, g_loss: 5.74091721, rnn_loss: 0.00000000\n",
      " ** Epoch 580 took 53.237703s\n",
      "Epoch: [581/1000] time: 0.3830s, d_loss: 0.21027546, g_loss: 6.18039131, rnn_loss: 0.00000000\n",
      " ** Epoch 581 took 52.598691s\n",
      "Epoch: [582/1000] time: 0.3875s, d_loss: 0.03733942, g_loss: 4.99655724, rnn_loss: 0.00000000\n",
      " ** Epoch 582 took 52.099222s\n",
      "Epoch: [583/1000] time: 0.3757s, d_loss: 0.02220123, g_loss: 5.45513916, rnn_loss: 0.00000000\n",
      " ** Epoch 583 took 52.584054s\n",
      "Epoch: [584/1000] time: 0.3859s, d_loss: 0.07436061, g_loss: 5.42017746, rnn_loss: 0.00000000\n",
      " ** Epoch 584 took 52.696375s\n",
      "Epoch: [585/1000] time: 0.3921s, d_loss: 0.00621718, g_loss: 6.57966852, rnn_loss: 0.00000000\n",
      " ** Epoch 585 took 52.966123s\n",
      "Epoch: [586/1000] time: 0.3824s, d_loss: 0.01138216, g_loss: 5.95349884, rnn_loss: 0.00000000\n",
      " ** Epoch 586 took 53.404675s\n",
      "Epoch: [587/1000] time: 0.3888s, d_loss: 0.13166328, g_loss: 3.04951859, rnn_loss: 0.00000000\n",
      " ** Epoch 587 took 52.807002s\n",
      "Epoch: [588/1000] time: 0.3829s, d_loss: 0.00252070, g_loss: 8.56867123, rnn_loss: 0.00000000\n",
      " ** Epoch 588 took 53.786456s\n",
      "Epoch: [589/1000] time: 0.3885s, d_loss: 0.00932401, g_loss: 5.68013287, rnn_loss: 0.00000000\n",
      " ** Epoch 589 took 53.438995s\n",
      "Epoch: [590/1000] time: 0.3850s, d_loss: 0.21721363, g_loss: 4.08122778, rnn_loss: 0.00000000\n",
      " ** Epoch 590 took 53.409395s\n",
      "Epoch: [591/1000] time: 0.3821s, d_loss: 0.12955520, g_loss: 3.40089869, rnn_loss: 0.00000000\n",
      " ** Epoch 591 took 53.116202s\n",
      "Epoch: [592/1000] time: 0.3842s, d_loss: 0.02565849, g_loss: 5.07572365, rnn_loss: 0.00000000\n",
      " ** Epoch 592 took 53.455567s\n",
      "Epoch: [593/1000] time: 0.3840s, d_loss: 0.12916611, g_loss: 3.64892197, rnn_loss: 0.00000000\n",
      " ** Epoch 593 took 52.724066s\n",
      "Epoch: [594/1000] time: 0.3846s, d_loss: 0.05512193, g_loss: 4.57452583, rnn_loss: 0.00000000\n",
      " ** Epoch 594 took 53.319163s\n",
      "Epoch: [595/1000] time: 0.3894s, d_loss: 0.00893606, g_loss: 8.11973095, rnn_loss: 0.00000000\n",
      " ** Epoch 595 took 53.099804s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [596/1000] time: 0.3829s, d_loss: 0.02649551, g_loss: 5.67996407, rnn_loss: 0.00000000\n",
      " ** Epoch 596 took 53.450839s\n",
      "Epoch: [597/1000] time: 0.4067s, d_loss: 0.00289816, g_loss: 9.80435371, rnn_loss: 0.00000000\n",
      " ** Epoch 597 took 53.449812s\n",
      "Epoch: [598/1000] time: 0.3788s, d_loss: 0.06167121, g_loss: 2.86602068, rnn_loss: 0.00000000\n",
      " ** Epoch 598 took 53.305729s\n",
      "Epoch: [599/1000] time: 0.3785s, d_loss: 0.03551814, g_loss: 4.02850008, rnn_loss: 0.00000000\n",
      " ** Epoch 599 took 52.552694s\n",
      " ** new learning rate: 0.000025\n",
      "Epoch: [600/1000] time: 0.3801s, d_loss: 0.05294380, g_loss: 4.22082615, rnn_loss: 0.00000000\n",
      " ** Epoch 600 took 53.349433s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [601/1000] time: 0.3893s, d_loss: 0.01994598, g_loss: 4.28329897, rnn_loss: 0.00000000\n",
      " ** Epoch 601 took 52.854660s\n",
      "Epoch: [602/1000] time: 0.3841s, d_loss: 0.03840312, g_loss: 3.96128368, rnn_loss: 0.00000000\n",
      " ** Epoch 602 took 53.092351s\n",
      "Epoch: [603/1000] time: 0.3858s, d_loss: 0.00942251, g_loss: 7.15920067, rnn_loss: 0.00000000\n",
      " ** Epoch 603 took 53.646317s\n",
      "Epoch: [604/1000] time: 0.3814s, d_loss: 0.05004603, g_loss: 4.03305531, rnn_loss: 0.00000000\n",
      " ** Epoch 604 took 52.752180s\n",
      "Epoch: [605/1000] time: 0.3794s, d_loss: 0.02088143, g_loss: 6.96229362, rnn_loss: 0.00000000\n",
      " ** Epoch 605 took 52.590809s\n",
      "Epoch: [606/1000] time: 0.3842s, d_loss: 0.02726885, g_loss: 4.21160364, rnn_loss: 0.00000000\n",
      " ** Epoch 606 took 52.975363s\n",
      "Epoch: [607/1000] time: 0.3821s, d_loss: 0.00922176, g_loss: 6.23611450, rnn_loss: 0.00000000\n",
      " ** Epoch 607 took 52.652072s\n",
      "Epoch: [608/1000] time: 0.3824s, d_loss: 0.01103110, g_loss: 5.71458149, rnn_loss: 0.00000000\n",
      " ** Epoch 608 took 52.721952s\n",
      "Epoch: [609/1000] time: 0.3782s, d_loss: 0.01960767, g_loss: 4.50177193, rnn_loss: 0.00000000\n",
      " ** Epoch 609 took 53.311392s\n",
      "Epoch: [610/1000] time: 0.3912s, d_loss: 0.00885034, g_loss: 4.91314077, rnn_loss: 0.00000000\n",
      " ** Epoch 610 took 52.823375s\n",
      "Epoch: [611/1000] time: 0.3831s, d_loss: 0.00362576, g_loss: 5.69873381, rnn_loss: 0.00000000\n",
      " ** Epoch 611 took 53.105439s\n",
      "Epoch: [612/1000] time: 0.3842s, d_loss: 0.06038605, g_loss: 4.59128952, rnn_loss: 0.00000000\n",
      " ** Epoch 612 took 53.044135s\n",
      "Epoch: [613/1000] time: 0.3885s, d_loss: 0.01037782, g_loss: 6.39692545, rnn_loss: 0.00000000\n",
      " ** Epoch 613 took 53.123894s\n",
      "Epoch: [614/1000] time: 0.3885s, d_loss: 0.00945059, g_loss: 6.33821964, rnn_loss: 0.00000000\n",
      " ** Epoch 614 took 53.102300s\n",
      "Epoch: [615/1000] time: 0.3821s, d_loss: 0.06589282, g_loss: 5.62986374, rnn_loss: 0.00000000\n",
      " ** Epoch 615 took 53.592883s\n",
      "Epoch: [616/1000] time: 0.3918s, d_loss: 0.01243847, g_loss: 4.54413939, rnn_loss: 0.00000000\n",
      " ** Epoch 616 took 53.139648s\n",
      "Epoch: [617/1000] time: 0.3810s, d_loss: 0.01120276, g_loss: 5.51571321, rnn_loss: 0.00000000\n",
      " ** Epoch 617 took 53.428045s\n",
      "Epoch: [618/1000] time: 0.3921s, d_loss: 0.00783928, g_loss: 4.91449118, rnn_loss: 0.00000000\n",
      " ** Epoch 618 took 53.248013s\n",
      "Epoch: [619/1000] time: 0.3893s, d_loss: 0.00559573, g_loss: 6.09964085, rnn_loss: 0.00000000\n",
      " ** Epoch 619 took 53.635824s\n",
      "Epoch: [620/1000] time: 0.3876s, d_loss: 0.04344481, g_loss: 4.95877123, rnn_loss: 0.00000000\n",
      " ** Epoch 620 took 53.599567s\n",
      "Epoch: [621/1000] time: 0.3911s, d_loss: 0.05156960, g_loss: 9.57904243, rnn_loss: 0.00000000\n",
      " ** Epoch 621 took 54.226242s\n",
      "Epoch: [622/1000] time: 0.3836s, d_loss: 0.01676781, g_loss: 4.25759220, rnn_loss: 0.00000000\n",
      " ** Epoch 622 took 53.659717s\n",
      "Epoch: [623/1000] time: 0.3832s, d_loss: 0.00661922, g_loss: 4.10326767, rnn_loss: 0.00000000\n",
      " ** Epoch 623 took 53.668556s\n",
      "Epoch: [624/1000] time: 0.3827s, d_loss: 0.03798856, g_loss: 7.13980150, rnn_loss: 0.00000000\n",
      " ** Epoch 624 took 53.127467s\n",
      "Epoch: [625/1000] time: 0.3863s, d_loss: 0.00958218, g_loss: 5.48637486, rnn_loss: 0.00000000\n",
      " ** Epoch 625 took 53.002529s\n",
      "Epoch: [626/1000] time: 0.3846s, d_loss: 0.01065859, g_loss: 4.88876152, rnn_loss: 0.00000000\n",
      " ** Epoch 626 took 52.941449s\n",
      "Epoch: [627/1000] time: 0.3842s, d_loss: 0.01177127, g_loss: 5.56040668, rnn_loss: 0.00000000\n",
      " ** Epoch 627 took 53.373767s\n",
      "Epoch: [628/1000] time: 0.3990s, d_loss: 0.04728720, g_loss: 5.64793158, rnn_loss: 0.00000000\n",
      " ** Epoch 628 took 52.971428s\n",
      "Epoch: [629/1000] time: 0.3814s, d_loss: 0.04713876, g_loss: 7.48278618, rnn_loss: 0.00000000\n",
      " ** Epoch 629 took 52.875377s\n",
      "Epoch: [630/1000] time: 0.3814s, d_loss: 0.00327564, g_loss: 7.13847685, rnn_loss: 0.00000000\n",
      " ** Epoch 630 took 52.731420s\n",
      "Epoch: [631/1000] time: 0.3853s, d_loss: 0.13435239, g_loss: 3.18745637, rnn_loss: 0.00000000\n",
      " ** Epoch 631 took 53.013733s\n",
      "Epoch: [632/1000] time: 0.4099s, d_loss: 0.06383503, g_loss: 3.40645742, rnn_loss: 0.00000000\n",
      " ** Epoch 632 took 53.361962s\n",
      "Epoch: [633/1000] time: 0.3782s, d_loss: 0.02262196, g_loss: 4.49599457, rnn_loss: 0.00000000\n",
      " ** Epoch 633 took 53.176156s\n",
      "Epoch: [634/1000] time: 0.3834s, d_loss: 0.04617051, g_loss: 5.11243296, rnn_loss: 0.00000000\n",
      " ** Epoch 634 took 53.234987s\n",
      "Epoch: [635/1000] time: 0.3840s, d_loss: 0.03180330, g_loss: 4.21351290, rnn_loss: 0.00000000\n",
      " ** Epoch 635 took 52.943143s\n",
      "Epoch: [636/1000] time: 0.3867s, d_loss: 0.06235119, g_loss: 5.45973873, rnn_loss: 0.00000000\n",
      " ** Epoch 636 took 53.018595s\n",
      "Epoch: [637/1000] time: 0.3888s, d_loss: 0.21517399, g_loss: 2.70305252, rnn_loss: 0.00000000\n",
      " ** Epoch 637 took 53.021536s\n",
      "Epoch: [638/1000] time: 0.3815s, d_loss: 0.01699504, g_loss: 6.75329018, rnn_loss: 0.00000000\n",
      " ** Epoch 638 took 53.550872s\n",
      "Epoch: [639/1000] time: 0.3799s, d_loss: 0.00299922, g_loss: 6.38518238, rnn_loss: 0.00000000\n",
      " ** Epoch 639 took 52.916884s\n",
      "Epoch: [640/1000] time: 0.3826s, d_loss: 0.02794807, g_loss: 4.82102776, rnn_loss: 0.00000000\n",
      " ** Epoch 640 took 52.883296s\n",
      "Epoch: [641/1000] time: 0.3848s, d_loss: 0.00386683, g_loss: 7.31621647, rnn_loss: 0.00000000\n",
      " ** Epoch 641 took 52.937914s\n",
      "Epoch: [642/1000] time: 0.3887s, d_loss: 0.02138966, g_loss: 5.07867241, rnn_loss: 0.00000000\n",
      " ** Epoch 642 took 53.138999s\n",
      "Epoch: [643/1000] time: 0.3884s, d_loss: 0.00870356, g_loss: 5.89848804, rnn_loss: 0.00000000\n",
      " ** Epoch 643 took 53.393235s\n",
      "Epoch: [644/1000] time: 0.3840s, d_loss: 0.00793585, g_loss: 7.46358585, rnn_loss: 0.00000000\n",
      " ** Epoch 644 took 54.096600s\n",
      "Epoch: [645/1000] time: 0.3845s, d_loss: 0.02050662, g_loss: 4.54282808, rnn_loss: 0.00000000\n",
      " ** Epoch 645 took 53.678772s\n",
      "Epoch: [646/1000] time: 0.3875s, d_loss: 0.03163622, g_loss: 5.03491688, rnn_loss: 0.00000000\n",
      " ** Epoch 646 took 54.340663s\n",
      "Epoch: [647/1000] time: 0.3889s, d_loss: 0.00321209, g_loss: 6.51655388, rnn_loss: 0.00000000\n",
      " ** Epoch 647 took 53.487231s\n",
      "Epoch: [648/1000] time: 0.3818s, d_loss: 0.00470466, g_loss: 9.17005730, rnn_loss: 0.00000000\n",
      " ** Epoch 648 took 53.541885s\n",
      "Epoch: [649/1000] time: 0.3899s, d_loss: 0.03486181, g_loss: 4.07687712, rnn_loss: 0.00000000\n",
      " ** Epoch 649 took 53.238006s\n",
      "Epoch: [650/1000] time: 0.3917s, d_loss: 0.00583312, g_loss: 6.25159931, rnn_loss: 0.00000000\n",
      " ** Epoch 650 took 53.907667s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [651/1000] time: 0.3861s, d_loss: 0.06609680, g_loss: 5.04942417, rnn_loss: 0.00000000\n",
      " ** Epoch 651 took 53.746608s\n",
      "Epoch: [652/1000] time: 0.3924s, d_loss: 0.02538959, g_loss: 4.46175623, rnn_loss: 0.00000000\n",
      " ** Epoch 652 took 53.587383s\n",
      "Epoch: [653/1000] time: 0.3805s, d_loss: 0.00261291, g_loss: 6.98279762, rnn_loss: 0.00000000\n",
      " ** Epoch 653 took 53.331264s\n",
      "Epoch: [654/1000] time: 0.3884s, d_loss: 0.02891884, g_loss: 4.03070068, rnn_loss: 0.00000000\n",
      " ** Epoch 654 took 53.438159s\n",
      "Epoch: [655/1000] time: 0.3835s, d_loss: 0.03783420, g_loss: 4.13448143, rnn_loss: 0.00000000\n",
      " ** Epoch 655 took 53.456283s\n",
      "Epoch: [656/1000] time: 0.3850s, d_loss: 0.12590761, g_loss: 3.47737694, rnn_loss: 0.00000000\n",
      " ** Epoch 656 took 54.062533s\n",
      "Epoch: [657/1000] time: 0.3832s, d_loss: 0.01344697, g_loss: 3.68398142, rnn_loss: 0.00000000\n",
      " ** Epoch 657 took 53.541741s\n",
      "Epoch: [658/1000] time: 0.3843s, d_loss: 0.03110402, g_loss: 4.39026928, rnn_loss: 0.00000000\n",
      " ** Epoch 658 took 52.745959s\n",
      "Epoch: [659/1000] time: 0.3794s, d_loss: 0.00665038, g_loss: 7.68492126, rnn_loss: 0.00000000\n",
      " ** Epoch 659 took 52.832251s\n",
      "Epoch: [660/1000] time: 0.3805s, d_loss: 0.05263257, g_loss: 4.72319269, rnn_loss: 0.00000000\n",
      " ** Epoch 660 took 53.183956s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [661/1000] time: 0.4078s, d_loss: 0.00214471, g_loss: 9.45944977, rnn_loss: 0.00000000\n",
      " ** Epoch 661 took 53.563015s\n",
      "Epoch: [662/1000] time: 0.3850s, d_loss: 0.00138806, g_loss: 8.84240341, rnn_loss: 0.00000000\n",
      " ** Epoch 662 took 53.522699s\n",
      "Epoch: [663/1000] time: 0.3853s, d_loss: 0.03717446, g_loss: 4.10726500, rnn_loss: 0.00000000\n",
      " ** Epoch 663 took 53.430427s\n",
      "Epoch: [664/1000] time: 0.3757s, d_loss: 0.01496491, g_loss: 4.46892262, rnn_loss: 0.00000000\n",
      " ** Epoch 664 took 52.815218s\n",
      "Epoch: [665/1000] time: 0.3908s, d_loss: 0.00917734, g_loss: 6.07565308, rnn_loss: 0.00000000\n",
      " ** Epoch 665 took 53.360471s\n",
      "Epoch: [666/1000] time: 0.3927s, d_loss: 0.00341166, g_loss: 8.30986595, rnn_loss: 0.00000000\n",
      " ** Epoch 666 took 53.743068s\n",
      "Epoch: [667/1000] time: 0.3879s, d_loss: 0.13887776, g_loss: 3.93472195, rnn_loss: 0.00000000\n",
      " ** Epoch 667 took 54.144067s\n",
      "Epoch: [668/1000] time: 0.3917s, d_loss: 0.04819794, g_loss: 3.88288212, rnn_loss: 0.00000000\n",
      " ** Epoch 668 took 53.994199s\n",
      "Epoch: [669/1000] time: 0.3876s, d_loss: 0.00178832, g_loss: 7.20416641, rnn_loss: 0.00000000\n",
      " ** Epoch 669 took 53.719264s\n",
      "Epoch: [670/1000] time: 0.3919s, d_loss: 0.04296106, g_loss: 5.14183521, rnn_loss: 0.00000000\n",
      " ** Epoch 670 took 53.763573s\n",
      "Epoch: [671/1000] time: 0.3809s, d_loss: 0.02154963, g_loss: 5.12969971, rnn_loss: 0.00000000\n",
      " ** Epoch 671 took 53.659970s\n",
      "Epoch: [672/1000] time: 0.3900s, d_loss: 0.02774209, g_loss: 4.84745598, rnn_loss: 0.00000000\n",
      " ** Epoch 672 took 53.637534s\n",
      "Epoch: [673/1000] time: 0.3851s, d_loss: 0.00402496, g_loss: 5.58198357, rnn_loss: 0.00000000\n",
      " ** Epoch 673 took 54.116687s\n",
      "Epoch: [674/1000] time: 0.3849s, d_loss: 0.18999951, g_loss: 5.34143496, rnn_loss: 0.00000000\n",
      " ** Epoch 674 took 53.977266s\n",
      "Epoch: [675/1000] time: 0.3894s, d_loss: 0.04180812, g_loss: 4.49507093, rnn_loss: 0.00000000\n",
      " ** Epoch 675 took 53.628857s\n",
      "Epoch: [676/1000] time: 0.3854s, d_loss: 0.06703710, g_loss: 7.12481833, rnn_loss: 0.00000000\n",
      " ** Epoch 676 took 53.353115s\n",
      "Epoch: [677/1000] time: 0.3966s, d_loss: 0.02366755, g_loss: 4.40120697, rnn_loss: 0.00000000\n",
      " ** Epoch 677 took 53.012232s\n",
      "Epoch: [678/1000] time: 0.3871s, d_loss: 0.01498694, g_loss: 5.98295593, rnn_loss: 0.00000000\n",
      " ** Epoch 678 took 53.211443s\n",
      "Epoch: [679/1000] time: 0.3871s, d_loss: 0.01362042, g_loss: 4.72870255, rnn_loss: 0.00000000\n",
      " ** Epoch 679 took 54.126655s\n",
      "Epoch: [680/1000] time: 0.3897s, d_loss: 0.02791459, g_loss: 4.41755962, rnn_loss: 0.00000000\n",
      " ** Epoch 680 took 53.765129s\n",
      "Epoch: [681/1000] time: 0.3951s, d_loss: 0.01959061, g_loss: 4.46466732, rnn_loss: 0.00000000\n",
      " ** Epoch 681 took 53.575185s\n",
      "Epoch: [682/1000] time: 0.3869s, d_loss: 0.01283660, g_loss: 7.25893354, rnn_loss: 0.00000000\n",
      " ** Epoch 682 took 53.578261s\n",
      "Epoch: [683/1000] time: 0.3885s, d_loss: 0.02538737, g_loss: 4.07665968, rnn_loss: 0.00000000\n",
      " ** Epoch 683 took 53.601136s\n",
      "Epoch: [684/1000] time: 0.3929s, d_loss: 0.00374526, g_loss: 7.98277712, rnn_loss: 0.00000000\n",
      " ** Epoch 684 took 53.533398s\n",
      "Epoch: [685/1000] time: 0.4137s, d_loss: 0.00245599, g_loss: 6.82199621, rnn_loss: 0.00000000\n",
      " ** Epoch 685 took 54.481310s\n",
      "Epoch: [686/1000] time: 0.3878s, d_loss: 0.02909998, g_loss: 4.90290737, rnn_loss: 0.00000000\n",
      " ** Epoch 686 took 53.755181s\n",
      "Epoch: [687/1000] time: 0.3913s, d_loss: 0.18848939, g_loss: 4.78601980, rnn_loss: 0.00000000\n",
      " ** Epoch 687 took 53.654352s\n",
      "Epoch: [688/1000] time: 0.3889s, d_loss: 0.02445924, g_loss: 4.50310516, rnn_loss: 0.00000000\n",
      " ** Epoch 688 took 53.557346s\n",
      "Epoch: [689/1000] time: 0.3947s, d_loss: 0.01855335, g_loss: 5.32435417, rnn_loss: 0.00000000\n",
      " ** Epoch 689 took 53.725148s\n",
      "Epoch: [690/1000] time: 0.3844s, d_loss: 0.02196919, g_loss: 3.64581728, rnn_loss: 0.00000000\n",
      " ** Epoch 690 took 53.665981s\n",
      "Epoch: [691/1000] time: 0.3871s, d_loss: 0.00395365, g_loss: 5.73630810, rnn_loss: 0.00000000\n",
      " ** Epoch 691 took 53.761768s\n",
      "Epoch: [692/1000] time: 0.3853s, d_loss: 0.10081175, g_loss: 4.70215225, rnn_loss: 0.00000000\n",
      " ** Epoch 692 took 53.646631s\n",
      "Epoch: [693/1000] time: 0.3856s, d_loss: 0.08347269, g_loss: 3.00521946, rnn_loss: 0.00000000\n",
      " ** Epoch 693 took 53.654393s\n",
      "Epoch: [694/1000] time: 0.3921s, d_loss: 0.03721829, g_loss: 7.15509129, rnn_loss: 0.00000000\n",
      " ** Epoch 694 took 53.793762s\n",
      "Epoch: [695/1000] time: 0.3884s, d_loss: 0.01025491, g_loss: 5.00874662, rnn_loss: 0.00000000\n",
      " ** Epoch 695 took 53.746849s\n",
      "Epoch: [696/1000] time: 0.3923s, d_loss: 0.01191601, g_loss: 6.52419710, rnn_loss: 0.00000000\n",
      " ** Epoch 696 took 54.342954s\n",
      "Epoch: [697/1000] time: 0.3924s, d_loss: 0.01557094, g_loss: 5.13765812, rnn_loss: 0.00000000\n",
      " ** Epoch 697 took 53.969353s\n",
      "Epoch: [698/1000] time: 0.3921s, d_loss: 0.12807576, g_loss: 5.32481575, rnn_loss: 0.00000000\n",
      " ** Epoch 698 took 53.824842s\n",
      "Epoch: [699/1000] time: 0.3923s, d_loss: 0.27423704, g_loss: 4.95393658, rnn_loss: 0.00000000\n",
      " ** Epoch 699 took 53.787339s\n",
      "Epoch: [700/1000] time: 0.3859s, d_loss: 0.00951109, g_loss: 4.63957405, rnn_loss: 0.00000000\n",
      " ** Epoch 700 took 53.715140s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [701/1000] time: 0.3922s, d_loss: 0.00319003, g_loss: 10.68715286, rnn_loss: 0.00000000\n",
      " ** Epoch 701 took 53.736841s\n",
      "Epoch: [702/1000] time: 0.3912s, d_loss: 0.98489571, g_loss: 1.15810657, rnn_loss: 0.00000000\n",
      " ** Epoch 702 took 54.775540s\n",
      "Epoch: [703/1000] time: 0.3904s, d_loss: 0.00254934, g_loss: 6.99473000, rnn_loss: 0.00000000\n",
      " ** Epoch 703 took 53.900683s\n",
      "Epoch: [704/1000] time: 0.3875s, d_loss: 0.00298677, g_loss: 8.28154755, rnn_loss: 0.00000000\n",
      " ** Epoch 704 took 53.907825s\n",
      "Epoch: [705/1000] time: 0.3870s, d_loss: 0.01509141, g_loss: 6.03985977, rnn_loss: 0.00000000\n",
      " ** Epoch 705 took 53.910508s\n",
      "Epoch: [706/1000] time: 0.3893s, d_loss: 0.02414891, g_loss: 5.53415537, rnn_loss: 0.00000000\n",
      " ** Epoch 706 took 53.987022s\n",
      "Epoch: [707/1000] time: 0.4176s, d_loss: 0.13005035, g_loss: 3.68210435, rnn_loss: 0.00000000\n",
      " ** Epoch 707 took 53.902991s\n",
      "Epoch: [708/1000] time: 0.3926s, d_loss: 0.14835304, g_loss: 2.98703885, rnn_loss: 0.00000000\n",
      " ** Epoch 708 took 54.826255s\n",
      "Epoch: [709/1000] time: 0.3870s, d_loss: 0.00591557, g_loss: 5.81586409, rnn_loss: 0.00000000\n",
      " ** Epoch 709 took 53.935945s\n",
      "Epoch: [710/1000] time: 0.3897s, d_loss: 0.05682646, g_loss: 6.57111931, rnn_loss: 0.00000000\n",
      " ** Epoch 710 took 54.007308s\n",
      "Epoch: [711/1000] time: 0.3899s, d_loss: 0.02162767, g_loss: 6.06828594, rnn_loss: 0.00000000\n",
      " ** Epoch 711 took 53.901645s\n",
      "Epoch: [712/1000] time: 0.3901s, d_loss: 0.01548149, g_loss: 3.82968521, rnn_loss: 0.00000000\n",
      " ** Epoch 712 took 54.033494s\n",
      "Epoch: [713/1000] time: 0.3950s, d_loss: 0.03031537, g_loss: 4.68730974, rnn_loss: 0.00000000\n",
      " ** Epoch 713 took 54.516115s\n",
      "Epoch: [714/1000] time: 0.3867s, d_loss: 0.06441668, g_loss: 4.61423874, rnn_loss: 0.00000000\n",
      " ** Epoch 714 took 54.080194s\n",
      "Epoch: [715/1000] time: 0.3889s, d_loss: 0.03658950, g_loss: 7.60400629, rnn_loss: 0.00000000\n",
      " ** Epoch 715 took 53.532666s\n",
      "Epoch: [716/1000] time: 0.3855s, d_loss: 0.01393968, g_loss: 5.07051086, rnn_loss: 0.00000000\n",
      " ** Epoch 716 took 53.469182s\n",
      "Epoch: [717/1000] time: 0.3871s, d_loss: 0.00264999, g_loss: 6.86430073, rnn_loss: 0.00000000\n",
      " ** Epoch 717 took 53.251734s\n",
      "Epoch: [718/1000] time: 0.3890s, d_loss: 0.03176656, g_loss: 4.82236862, rnn_loss: 0.00000000\n",
      " ** Epoch 718 took 53.842156s\n",
      "Epoch: [719/1000] time: 0.4019s, d_loss: 0.04697213, g_loss: 3.71376753, rnn_loss: 0.00000000\n",
      " ** Epoch 719 took 54.564445s\n",
      "Epoch: [720/1000] time: 0.3904s, d_loss: 0.03381470, g_loss: 4.40168619, rnn_loss: 0.00000000\n",
      " ** Epoch 720 took 53.824916s\n",
      "Epoch: [721/1000] time: 0.3889s, d_loss: 0.02546987, g_loss: 4.55175972, rnn_loss: 0.00000000\n",
      " ** Epoch 721 took 53.975966s\n",
      "Epoch: [722/1000] time: 0.3928s, d_loss: 0.00188840, g_loss: 6.50184631, rnn_loss: 0.00000000\n",
      " ** Epoch 722 took 53.891796s\n",
      "Epoch: [723/1000] time: 0.3849s, d_loss: 0.02568068, g_loss: 5.56338024, rnn_loss: 0.00000000\n",
      " ** Epoch 723 took 53.463309s\n",
      "Epoch: [724/1000] time: 0.3814s, d_loss: 0.00154640, g_loss: 6.49497032, rnn_loss: 0.00000000\n",
      " ** Epoch 724 took 53.070068s\n",
      "Epoch: [725/1000] time: 0.3907s, d_loss: 0.02033283, g_loss: 4.58908224, rnn_loss: 0.00000000\n",
      " ** Epoch 725 took 53.945190s\n",
      "Epoch: [726/1000] time: 0.3889s, d_loss: 0.04110470, g_loss: 3.54864883, rnn_loss: 0.00000000\n",
      " ** Epoch 726 took 54.077906s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [727/1000] time: 0.3973s, d_loss: 0.07473493, g_loss: 5.97950840, rnn_loss: 0.00000000\n",
      " ** Epoch 727 took 54.119787s\n",
      "Epoch: [728/1000] time: 0.3896s, d_loss: 0.03140585, g_loss: 4.68763924, rnn_loss: 0.00000000\n",
      " ** Epoch 728 took 54.194714s\n",
      "Epoch: [729/1000] time: 0.3947s, d_loss: 0.00069258, g_loss: 11.97150803, rnn_loss: 0.00000000\n",
      " ** Epoch 729 took 54.220334s\n",
      "Epoch: [730/1000] time: 0.4176s, d_loss: 0.04136960, g_loss: 4.27302265, rnn_loss: 0.00000000\n",
      " ** Epoch 730 took 54.399343s\n",
      "Epoch: [731/1000] time: 0.3985s, d_loss: 0.03883731, g_loss: 3.87454748, rnn_loss: 0.00000000\n",
      " ** Epoch 731 took 54.891918s\n",
      "Epoch: [732/1000] time: 0.3891s, d_loss: 0.07054738, g_loss: 6.52570820, rnn_loss: 0.00000000\n",
      " ** Epoch 732 took 54.304127s\n",
      "Epoch: [733/1000] time: 0.3991s, d_loss: 0.00872412, g_loss: 5.67878580, rnn_loss: 0.00000000\n",
      " ** Epoch 733 took 54.126649s\n",
      "Epoch: [734/1000] time: 0.3945s, d_loss: 0.50476122, g_loss: 1.14347339, rnn_loss: 0.00000000\n",
      " ** Epoch 734 took 54.203458s\n",
      "Epoch: [735/1000] time: 0.3889s, d_loss: 0.00514348, g_loss: 7.65478945, rnn_loss: 0.00000000\n",
      " ** Epoch 735 took 54.125629s\n",
      "Epoch: [736/1000] time: 0.3915s, d_loss: 0.11092354, g_loss: 4.31813383, rnn_loss: 0.00000000\n",
      " ** Epoch 736 took 54.991582s\n",
      "Epoch: [737/1000] time: 0.3917s, d_loss: 0.00285919, g_loss: 7.57668066, rnn_loss: 0.00000000\n",
      " ** Epoch 737 took 54.299731s\n",
      "Epoch: [738/1000] time: 0.3908s, d_loss: 0.00272763, g_loss: 6.19676495, rnn_loss: 0.00000000\n",
      " ** Epoch 738 took 54.231388s\n",
      "Epoch: [739/1000] time: 0.3909s, d_loss: 0.00765875, g_loss: 4.41456509, rnn_loss: 0.00000000\n",
      " ** Epoch 739 took 54.192109s\n",
      "Epoch: [740/1000] time: 0.3913s, d_loss: 0.02023261, g_loss: 4.36140251, rnn_loss: 0.00000000\n",
      " ** Epoch 740 took 54.117118s\n",
      "Epoch: [741/1000] time: 0.3944s, d_loss: 0.01776338, g_loss: 4.59722185, rnn_loss: 0.00000000\n",
      " ** Epoch 741 took 53.972762s\n",
      "Epoch: [742/1000] time: 0.3897s, d_loss: 0.01682780, g_loss: 4.69563580, rnn_loss: 0.00000000\n",
      " ** Epoch 742 took 54.702676s\n",
      "Epoch: [743/1000] time: 0.3884s, d_loss: 0.00272438, g_loss: 6.56071806, rnn_loss: 0.00000000\n",
      " ** Epoch 743 took 53.839869s\n",
      "Epoch: [744/1000] time: 0.3973s, d_loss: 0.00526528, g_loss: 9.36071110, rnn_loss: 0.00000000\n",
      " ** Epoch 744 took 53.913133s\n",
      "Epoch: [745/1000] time: 0.3917s, d_loss: 0.01814394, g_loss: 4.45571899, rnn_loss: 0.00000000\n",
      " ** Epoch 745 took 53.954932s\n",
      "Epoch: [746/1000] time: 0.3950s, d_loss: 0.02622742, g_loss: 5.31961155, rnn_loss: 0.00000000\n",
      " ** Epoch 746 took 53.833595s\n",
      "Epoch: [747/1000] time: 0.4139s, d_loss: 0.01636944, g_loss: 4.94269466, rnn_loss: 0.00000000\n",
      " ** Epoch 747 took 53.932723s\n",
      "Epoch: [748/1000] time: 0.3959s, d_loss: 0.00775939, g_loss: 5.89415359, rnn_loss: 0.00000000\n",
      " ** Epoch 748 took 54.687638s\n",
      "Epoch: [749/1000] time: 0.3889s, d_loss: 0.00408656, g_loss: 6.80955696, rnn_loss: 0.00000000\n",
      " ** Epoch 749 took 54.105350s\n",
      "Epoch: [750/1000] time: 0.3959s, d_loss: 0.01469151, g_loss: 7.11446571, rnn_loss: 0.00000000\n",
      " ** Epoch 750 took 54.072330s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [751/1000] time: 0.3909s, d_loss: 0.03070848, g_loss: 4.21743011, rnn_loss: 0.00000000\n",
      " ** Epoch 751 took 53.891536s\n",
      "Epoch: [752/1000] time: 0.3920s, d_loss: 0.01467023, g_loss: 4.83071995, rnn_loss: 0.00000000\n",
      " ** Epoch 752 took 53.828824s\n",
      "Epoch: [753/1000] time: 0.3916s, d_loss: 0.03546934, g_loss: 4.63394451, rnn_loss: 0.00000000\n",
      " ** Epoch 753 took 54.787756s\n",
      "Epoch: [754/1000] time: 0.3901s, d_loss: 0.00739280, g_loss: 7.00406361, rnn_loss: 0.00000000\n",
      " ** Epoch 754 took 53.736471s\n",
      "Epoch: [755/1000] time: 0.3919s, d_loss: 0.00466945, g_loss: 5.74134636, rnn_loss: 0.00000000\n",
      " ** Epoch 755 took 54.002079s\n",
      "Epoch: [756/1000] time: 0.3820s, d_loss: 0.00315596, g_loss: 8.42926884, rnn_loss: 0.00000000\n",
      " ** Epoch 756 took 53.761264s\n",
      "Epoch: [757/1000] time: 0.3937s, d_loss: 0.00564924, g_loss: 5.55046844, rnn_loss: 0.00000000\n",
      " ** Epoch 757 took 53.607584s\n",
      "Epoch: [758/1000] time: 0.3891s, d_loss: 0.17777003, g_loss: 2.54332972, rnn_loss: 0.00000000\n",
      " ** Epoch 758 took 53.948137s\n",
      "Epoch: [759/1000] time: 0.3875s, d_loss: 0.00450859, g_loss: 5.31242132, rnn_loss: 0.00000000\n",
      " ** Epoch 759 took 54.876045s\n",
      "Epoch: [760/1000] time: 0.3855s, d_loss: 0.00300942, g_loss: 6.75732756, rnn_loss: 0.00000000\n",
      " ** Epoch 760 took 54.136072s\n",
      "Epoch: [761/1000] time: 0.3956s, d_loss: 0.09464220, g_loss: 1.98078072, rnn_loss: 0.00000000\n",
      " ** Epoch 761 took 54.150068s\n",
      "Epoch: [762/1000] time: 0.3957s, d_loss: 0.09453940, g_loss: 4.93082428, rnn_loss: 0.00000000\n",
      " ** Epoch 762 took 54.229607s\n",
      "Epoch: [763/1000] time: 0.3884s, d_loss: 0.02919253, g_loss: 4.90417099, rnn_loss: 0.00000000\n",
      " ** Epoch 763 took 54.105589s\n",
      "Epoch: [764/1000] time: 0.3925s, d_loss: 0.05574545, g_loss: 7.01454926, rnn_loss: 0.00000000\n",
      " ** Epoch 764 took 54.341282s\n",
      "Epoch: [765/1000] time: 0.3927s, d_loss: 0.00375312, g_loss: 5.85614491, rnn_loss: 0.00000000\n",
      " ** Epoch 765 took 54.544706s\n",
      "Epoch: [766/1000] time: 0.3950s, d_loss: 0.00847752, g_loss: 5.99842930, rnn_loss: 0.00000000\n",
      " ** Epoch 766 took 54.783832s\n",
      "Epoch: [767/1000] time: 0.6691s, d_loss: 0.02026743, g_loss: 6.13872337, rnn_loss: 0.00000000\n",
      " ** Epoch 767 took 54.550981s\n",
      "Epoch: [768/1000] time: 0.3908s, d_loss: 0.00405660, g_loss: 6.21178722, rnn_loss: 0.00000000\n",
      " ** Epoch 768 took 54.169240s\n",
      "Epoch: [769/1000] time: 0.3941s, d_loss: 0.02048061, g_loss: 4.36828709, rnn_loss: 0.00000000\n",
      " ** Epoch 769 took 54.134238s\n",
      "Epoch: [770/1000] time: 0.4151s, d_loss: 0.00688680, g_loss: 7.09904146, rnn_loss: 0.00000000\n",
      " ** Epoch 770 took 55.164115s\n",
      "Epoch: [771/1000] time: 0.3890s, d_loss: 0.00979317, g_loss: 7.43045282, rnn_loss: 0.00000000\n",
      " ** Epoch 771 took 54.167284s\n",
      "Epoch: [772/1000] time: 0.3949s, d_loss: 0.12566608, g_loss: 3.35605645, rnn_loss: 0.00000000\n",
      " ** Epoch 772 took 53.666036s\n",
      "Epoch: [773/1000] time: 0.3842s, d_loss: 0.01577424, g_loss: 6.00995731, rnn_loss: 0.00000000\n",
      " ** Epoch 773 took 53.590927s\n",
      "Epoch: [774/1000] time: 0.3940s, d_loss: 0.00459854, g_loss: 5.52276754, rnn_loss: 0.00000000\n",
      " ** Epoch 774 took 53.822562s\n",
      "Epoch: [775/1000] time: 0.3848s, d_loss: 0.02008145, g_loss: 7.82137680, rnn_loss: 0.00000000\n",
      " ** Epoch 775 took 53.988684s\n",
      "Epoch: [776/1000] time: 0.3906s, d_loss: 0.00077433, g_loss: 8.83537579, rnn_loss: 0.00000000\n",
      " ** Epoch 776 took 54.880092s\n",
      "Epoch: [777/1000] time: 0.3870s, d_loss: 0.02531002, g_loss: 4.16184092, rnn_loss: 0.00000000\n",
      " ** Epoch 777 took 54.128100s\n",
      "Epoch: [778/1000] time: 0.3928s, d_loss: 0.02240838, g_loss: 5.75365019, rnn_loss: 0.00000000\n",
      " ** Epoch 778 took 54.127090s\n",
      "Epoch: [779/1000] time: 0.3920s, d_loss: 0.03247106, g_loss: 4.97811747, rnn_loss: 0.00000000\n",
      " ** Epoch 779 took 54.204216s\n",
      "Epoch: [780/1000] time: 0.3880s, d_loss: 0.02790153, g_loss: 4.50863028, rnn_loss: 0.00000000\n",
      " ** Epoch 780 took 53.971257s\n",
      "Epoch: [781/1000] time: 0.3888s, d_loss: 0.16136444, g_loss: 8.18775558, rnn_loss: 0.00000000\n",
      " ** Epoch 781 took 54.061231s\n",
      "Epoch: [782/1000] time: 0.3910s, d_loss: 0.01194966, g_loss: 4.80954218, rnn_loss: 0.00000000\n",
      " ** Epoch 782 took 54.198238s\n",
      "Epoch: [783/1000] time: 0.3968s, d_loss: 0.02928257, g_loss: 4.23121262, rnn_loss: 0.00000000\n",
      " ** Epoch 783 took 54.037270s\n",
      "Epoch: [784/1000] time: 0.3888s, d_loss: 0.00783036, g_loss: 5.58127499, rnn_loss: 0.00000000\n",
      " ** Epoch 784 took 53.786812s\n",
      "Epoch: [785/1000] time: 0.3944s, d_loss: 0.40668821, g_loss: 4.28972912, rnn_loss: 0.00000000\n",
      " ** Epoch 785 took 53.765030s\n",
      "Epoch: [786/1000] time: 0.3871s, d_loss: 0.04579112, g_loss: 4.16380501, rnn_loss: 0.00000000\n",
      " ** Epoch 786 took 53.817713s\n",
      "Epoch: [787/1000] time: 0.3894s, d_loss: 0.04284633, g_loss: 4.13709211, rnn_loss: 0.00000000\n",
      " ** Epoch 787 took 54.166582s\n",
      "Epoch: [788/1000] time: 0.3934s, d_loss: 0.00774550, g_loss: 5.35874653, rnn_loss: 0.00000000\n",
      " ** Epoch 788 took 54.387378s\n",
      "Epoch: [789/1000] time: 0.3744s, d_loss: 0.00182003, g_loss: 7.27709675, rnn_loss: 0.00000000\n",
      " ** Epoch 789 took 53.824027s\n",
      "Epoch: [790/1000] time: 0.3999s, d_loss: 0.00616114, g_loss: 5.51555920, rnn_loss: 0.00000000\n",
      " ** Epoch 790 took 53.680209s\n",
      "Epoch: [791/1000] time: 0.3917s, d_loss: 0.00467192, g_loss: 7.55478477, rnn_loss: 0.00000000\n",
      " ** Epoch 791 took 54.131806s\n",
      "Epoch: [792/1000] time: 0.4203s, d_loss: 0.00861717, g_loss: 9.59203529, rnn_loss: 0.00000000\n",
      " ** Epoch 792 took 53.864764s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [793/1000] time: 0.3882s, d_loss: 0.00750701, g_loss: 6.54685545, rnn_loss: 0.00000000\n",
      " ** Epoch 793 took 54.966171s\n",
      "Epoch: [794/1000] time: 0.3952s, d_loss: 0.01478549, g_loss: 5.31592274, rnn_loss: 0.00000000\n",
      " ** Epoch 794 took 54.570474s\n",
      "Epoch: [795/1000] time: 0.3996s, d_loss: 0.00228576, g_loss: 9.25747967, rnn_loss: 0.00000000\n",
      " ** Epoch 795 took 54.496722s\n",
      "Epoch: [796/1000] time: 0.3947s, d_loss: 0.08866515, g_loss: 5.54889297, rnn_loss: 0.00000000\n",
      " ** Epoch 796 took 54.461194s\n",
      "Epoch: [797/1000] time: 0.3988s, d_loss: 0.01574985, g_loss: 6.81949139, rnn_loss: 0.00000000\n",
      " ** Epoch 797 took 54.526120s\n",
      "Epoch: [798/1000] time: 0.3963s, d_loss: 0.00373009, g_loss: 6.60390615, rnn_loss: 0.00000000\n",
      " ** Epoch 798 took 54.825537s\n",
      "Epoch: [799/1000] time: 0.3928s, d_loss: 0.01348102, g_loss: 6.43580675, rnn_loss: 0.00000000\n",
      " ** Epoch 799 took 55.224668s\n",
      " ** new learning rate: 0.000013\n",
      "Epoch: [800/1000] time: 0.4037s, d_loss: 0.29555830, g_loss: 2.98319912, rnn_loss: 0.00000000\n",
      " ** Epoch 800 took 55.119390s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [801/1000] time: 0.3907s, d_loss: 0.01163417, g_loss: 4.96980095, rnn_loss: 0.00000000\n",
      " ** Epoch 801 took 54.441565s\n",
      "Epoch: [802/1000] time: 0.3996s, d_loss: 0.01613042, g_loss: 5.37961197, rnn_loss: 0.00000000\n",
      " ** Epoch 802 took 54.509921s\n",
      "Epoch: [803/1000] time: 0.3925s, d_loss: 0.01327195, g_loss: 5.64796782, rnn_loss: 0.00000000\n",
      " ** Epoch 803 took 54.689482s\n",
      "Epoch: [804/1000] time: 0.3917s, d_loss: 0.00442112, g_loss: 6.47600412, rnn_loss: 0.00000000\n",
      " ** Epoch 804 took 55.417820s\n",
      "Epoch: [805/1000] time: 0.3946s, d_loss: 0.00993130, g_loss: 5.24686241, rnn_loss: 0.00000000\n",
      " ** Epoch 805 took 56.482152s\n",
      "Epoch: [806/1000] time: 0.3926s, d_loss: 0.00333887, g_loss: 5.97072983, rnn_loss: 0.00000000\n",
      " ** Epoch 806 took 55.015980s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d502ecd0839d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mb_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mb_real_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_real_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepro_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mb_wrong_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_wrong_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepro_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             errRNN, _ = sess.run([model.rnn_loss, model.rnn_optim], feed_dict={\n",
      "\u001b[0;32m<ipython-input-8-678ddc01aa9e>\u001b[0m in \u001b[0;36mthreading_data\u001b[0;34m(data, fn, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                         )\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mthreads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-19/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-19/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-19/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = Text2Img()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=10)\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "    load_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "    load(loader, sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print('no checkpoints find.')\n",
    "\n",
    "n_epoch = 1000\n",
    "n_batch_epoch = int(n_images_train / batch_size)\n",
    "for epoch in range(n_epoch):\n",
    "    start_time = time.time()\n",
    "    if epoch !=0 and (epoch % decay_every == 0):\n",
    "        new_lr_decay = lr_decay ** (epoch // decay_every)\n",
    "        sess.run(tf.assign(model.lr_v, lr * new_lr_decay))\n",
    "        log = \" ** new learning rate: %f\" % (lr * new_lr_decay)\n",
    "        print(log)\n",
    "    elif epoch == 0:\n",
    "        log = \" ** init lr: %f  decay_every_epoch: %d, lr_decay: %f\" % (lr, decay_every, lr_decay)\n",
    "        print(log)\n",
    "    for step in range(n_batch_epoch):\n",
    "        step_time = time.time()\n",
    "        idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\n",
    "        b_real_caption = train_captions[idexs]\n",
    "        b_real_images = train_images[np.floor(np.asarray(idexs).astype('float') / n_captions_per_image).astype('int')]\n",
    "        idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\n",
    "        b_wrong_caption = train_captions[idexs]\n",
    "        idexs2 = get_random_int(min=0, max=n_images_train-1, number=batch_size)\n",
    "        b_wrong_images = train_images[idexs2]\n",
    "        b_z = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, z_dim)).astype(np.float32)\n",
    "        b_real_images = threading_data(b_real_images, prepro_img, mode='train')\n",
    "        b_wrong_images = threading_data(b_wrong_images, prepro_img, mode='train')\n",
    "        if epoch < 300:\n",
    "            errRNN, _ = sess.run([model.rnn_loss, model.rnn_optim], feed_dict={\n",
    "                                            model.t_real_image : b_real_images,\n",
    "                                            model.t_wrong_image : b_wrong_images,\n",
    "                                            model.t_real_caption : b_real_caption,\n",
    "                                            model.t_wrong_caption : b_wrong_caption})\n",
    "        else:\n",
    "            errRNN = 0   \n",
    "        errD, _ = sess.run([model.d_loss, model.d_optim], feed_dict={\n",
    "                            model.t_real_image : b_real_images,\n",
    "                            model.t_wrong_caption : b_wrong_caption,\n",
    "                            model.t_real_caption : b_real_caption,\n",
    "                            model.t_z : b_z})\n",
    "        errG, _ = sess.run([model.g_loss, model.g_optim], feed_dict={\n",
    "                            model.t_real_caption : b_real_caption,\n",
    "                            model.t_z : b_z})\n",
    "    print(\"Epoch: [%d/%d] time: %4.4fs, d_loss: %.8f, g_loss: %.8f, rnn_loss: %.8f\" \\\n",
    "                        % (epoch, n_epoch, time.time() - step_time, errD, errG, errRNN))\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(\" ** Epoch %d took %fs\" % (epoch, time.time()-start_time))\n",
    "        img_gen, rnn_out = sess.run([model.net_g.outputs, model.net_rnn.outputs], feed_dict={\n",
    "                                        model.t_real_caption : sample_sentence,\n",
    "                                        model.t_z : sample_seed})\n",
    "        save_images(img_gen, [ni, ni], 'train_samples_1215_a/train_{:02d}.png'.format(epoch))\n",
    "    if (epoch != 0) and (epoch % 50) == 0:\n",
    "        save(saver, sess, checkpoint_dir, epoch)\n",
    "        print(\"[*] Save checkpoints SUCCESS!\")\n",
    "checkpoint_path = os.path.join(cfg.CHECKPOINT_DIR, cfg.CHECKPOINT_NAME)\n",
    "saver.save(sess, checkpoint_path, global_step=epoch)\n",
    "print('The checkpoint has been created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_r_precision_data():\n",
    "    caption_ids = np.reshape(np.asarray(test_dataset.captions_ids), (-1, cfg.TEXT.WORDS_NUM))\n",
    "    captions_ids_wrong = np.reshape(test_dataset.random_wrong_captions(), (-1, cfg.WRONG_CAPTION, cfg.TEXT.WORDS_NUM))\n",
    "\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # load the trained checkpoint\n",
    "    checkpoint_dir = cfg.CHECKPOINT_DIR\n",
    "    if checkpoint_dir is not None:\n",
    "        loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "        ckpt_path = os.path.join(cfg.CHECKPOINT_DIR, CHECKPOINT_NAME)\n",
    "        loader.restore(sess, ckpt_path)\n",
    "        print(\"Restored model parameters from {}\".format(ckpt_path))\n",
    "    else:\n",
    "        print('no checkpoints find.')\n",
    "\n",
    "    n_caption_test = len(caption_ids)\n",
    "    num_batches = n_caption_test // cfg.BATCH_SIZE\n",
    "\n",
    "    true_cnn_features = np.zeros((num_batches, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "    true_rnn_features = np.zeros((num_batches, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "    wrong_rnn_features = np.zeros((num_batches, cfg.WRONG_CAPTION, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        test_cap = caption_ids[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "\n",
    "        z = np.random.normal(loc=0.0, scale=1.0, size=(cfg.BATCH_SIZE, cfg.GAN.Z_DIM)).astype(np.float32)\n",
    "        \n",
    "        rnn_features = sess.run(rnn_encoder.outputs, feed_dict={t_real_caption: test_cap})\n",
    "        gen = sess.run(generator.outputs, feed_dict={t_real_caption: test_cap, t_z: z})\n",
    "        cnn_features = sess.run(cnn_encoder.outputs, feed_dict={t_real_image: gen})\n",
    "\n",
    "        true_cnn_features[i] = cnn_features\n",
    "        true_rnn_features[i] = rnn_features\n",
    "\n",
    "        for per_wrong_caption in range(cfg.WRONG_CAPTION):\n",
    "            test_cap = captions_ids_wrong[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "            rnn_features = sess.run(rnn_encoder.outputs, feed_dict={t_real_caption: test_cap[:, per_wrong_caption]})\n",
    "            wrong_rnn_features[i, per_wrong_caption] = rnn_features\n",
    "    \n",
    "    # if exists, remove the existing file first\n",
    "    try:\n",
    "        os.remove(os.path.join(cfg.R_PRECISION_DIR, cfg.R_PRECISION_FILE))\n",
    "    except OSError:\n",
    "        pass\n",
    "    np.savez(os.path.join(cfg.R_PRECISION_DIR, cfg.R_PRECISION_FILE), true_cnn=true_cnn_features, true_rnn=true_rnn_features,\n",
    "             wrong_rnn=wrong_rnn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inception_score_data():\n",
    "    caption_ids = np.reshape(np.asarray(test_dataset.captions_ids),\n",
    "                             (-1, cfg.TEXT.CAPTIONS_PER_IMAGE, cfg.TEXT.WORDS_NUM))\n",
    "    \n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    checkpoint_dir = cfg.CHECKPOINT_DIR\n",
    "    if checkpoint_dir is not None:\n",
    "        loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "        ckpt_path = os.path.join(cfg.CHECKPOINT_DIR, cfg.CHECKPOINT_NAME)\n",
    "        loader.restore(sess, ckpt_path)\n",
    "        print(\"Restored model parameters from {}\".format(ckpt_path))\n",
    "    else:\n",
    "        print('no checkpoints find.')\n",
    "\n",
    "    n_caption_test = len(caption_ids)\n",
    "    num_batches = n_caption_test // cfg.BATCH_SIZE\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        for per_caption in range(cfg.TEXT.CAPTIONS_PER_IMAGE):\n",
    "            test_cap = caption_ids[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE, per_caption]\n",
    "            test_directory = test_dataset.filenames[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "\n",
    "            z = np.random.normal(loc=0.0, scale=1.0, size=(cfg.BATCH_SIZE, cfg.GAN.Z_DIM)).astype(np.float32)\n",
    "            gen = sess.run(generator.outputs, feed_dict={t_real_caption: test_cap, t_z: z})\n",
    "            \n",
    "            for j in range(cfg.BATCH_SIZE):\n",
    "                if not os.path.exists(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j].split('/')[0])):\n",
    "                    os.mkdir(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j].split('/')[0]))\n",
    "\n",
    "                scipy.misc.imsave(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j] + '_{}.png'.format(per_caption)), gen[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_r_precision_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_inception_score_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Measure Inception score and R-precision of given test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After set the config file as 'eval_birds.yml' and run the 'generate_inception_score_data()' and 'generate_r_precision_data()', the synthesized images based on given captions and set of image and caption features should be saved inside a 'evaluation' folder, specifically in 'evaluation/generated_images/..' and as 'evaluation/r_precision.npz' respectively.\n",
    "\n",
    "**Then, go to the 'evaluation' folder and run each 'inception_score.ipynb' and 'r_precision.ipynb' file in order to measure inception score and r-precision score.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
