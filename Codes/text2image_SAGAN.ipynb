{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Final Proejct: Text to Image Synthesis (Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For understanding of this work, please carefully look at given PPT file.**\n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the training process **</font> so that TAs can grade both your code and results.  \n",
    "**The TA will set a config file as 'eval_birds.yml' when evaluating the code using 'hidden test dataset'. Thus, please make sure that your code can generate proper data to measure inception score and R-precision of 'hidden test dataset'.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load datasets\n",
    "The Birds dataset will be downloaded automatically if it is not located in the *data* directory. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os, nltk\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "import numpy as np\n",
    "import scipy\n",
    "from utils.data_utils import CUBDataset\n",
    "from utils.loss import cosine_similarity\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "\n",
    "#################################################\n",
    "# DO NOT CHANGE \n",
    "from utils.model_1215_a import CNN_ENCODER, RNN_ENCODER, GENERATOR, DISCRIMINATOR\n",
    "#################################################\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'BATCH_SIZE': 64,\n",
      " 'CHECKPOINT_DIR': './checkpoint',\n",
      " 'CHECKPOINT_NAME': 'model.ckpt',\n",
      " 'CNN': {'EMBEDDING_DIM': 0, 'H_DIM': 0},\n",
      " 'CONFIG_NAME': 'text-to-image',\n",
      " 'CUDA': False,\n",
      " 'DATASET_NAME': 'birds',\n",
      " 'DATA_DIR': 'data/birds',\n",
      " 'EMBEDDING_TYPE': 'cnn-rnn',\n",
      " 'GAN': {'B_ATTENTION': False,\n",
      "         'B_CONDITION': False,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 0,\n",
      "         'DF_DIM': 0,\n",
      "         'EMBEDDING_DIM': 0,\n",
      "         'GF_DIM': 0,\n",
      "         'R_NUM': 0,\n",
      "         'Z_DIM': 512},\n",
      " 'GPU_ID': '0',\n",
      " 'IMAGE_SIZE': 256,\n",
      " 'NUM_BATCH_FOR_TEST': 0,\n",
      " 'RANDOM_SEED': 0,\n",
      " 'RNN': {'EMBEDDING_DIM': 0,\n",
      "         'H_DIM': 0,\n",
      "         'TYPE': '',\n",
      "         'VOCAB_SIZE': 0,\n",
      "         'WORD_EMBEDDING_DIM': 0},\n",
      " 'R_PRECISION_DIR': './evaluation',\n",
      " 'R_PRECISION_FILE': 'r_precision.npz',\n",
      " 'R_PRECISION_FILE_HIDDEN': 'r_precision_hidden.npz',\n",
      " 'TEST': {'B_EXAMPLE': False,\n",
      "          'GENERATED_HIDDEN_TEST_IMAGES': './evaluation/generated_images_hidden',\n",
      "          'GENERATED_TEST_IMAGES': './evaluation/generated_images'},\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 128, 'WORDS_NUM': 20},\n",
      " 'TRAIN': {'CNN_ENCODER': '',\n",
      "           'COEFF': {'COLOR_LOSS': 0.0, 'KL': 0.0, 'UNCOND_LOSS': 0.0},\n",
      "           'DISCRIMINATOR': '',\n",
      "           'DISCRIMINATOR_LR': 0.0,\n",
      "           'FLAG': True,\n",
      "           'GENERATOR': '',\n",
      "           'GENERATOR_LR': 0.0,\n",
      "           'MAX_EPOCH': 600,\n",
      "           'RNN_ENCODER': '',\n",
      "           'SNAPSHOT_INTERVAL': 0},\n",
      " 'WORKERS': 4,\n",
      " 'WRONG_CAPTION': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/final-project-deep-learning-19-tf/miscc/config.py:121: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "# Set a config file as 'train_birds.yml' in training, as 'eval_birds.yml' for evaluation\n",
    "cfg_from_file('cfg/train_birds.yml') # eval_birds.yml\n",
    "\n",
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cfg.GPU_ID\n",
    "\n",
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "output_dir = 'sample/%s_%s_%s' % (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf\n",
      "\n",
      "self.data_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds\n",
      "\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011.tgz\n",
      "\n",
      "Dataset already exists\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011/images\n",
      "\n",
      "Load from:  data/birds/captions.pickle\n",
      "self.current_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf\n",
      "\n",
      "self.data_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds\n",
      "\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011.tgz\n",
      "\n",
      "Dataset already exists\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011/images\n",
      "\n",
      "Load from:  data/birds/captions.pickle\n",
      "\n",
      "train data directory:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/train\n",
      "test data directory:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/test\n",
      "\n",
      "# of train filenames:(8855,)\n",
      "# of test filenames:(2933,)\n",
      "\n",
      "example of filename of train image:002.Laysan_Albatross/Laysan_Albatross_0002_1027\n",
      "example of filename of valid image:001.Black_footed_Albatross/Black_Footed_Albatross_0046_18\n",
      "\n",
      "example of caption and its ids:\n",
      "['a', 'bird', 'with', 'a', 'very', 'long', 'wing', 'span', 'and', 'a', 'long', 'pointed', 'beak']\n",
      "[ 1  2  3  1  4  5  6  7  8  1  5  9 10  0  0  0  0  0  0  0]\n",
      "\n",
      "example of caption and its ids:\n",
      "['light', 'tan', 'colored', 'bird', 'with', 'a', 'white', 'head', 'and', 'an', 'orange', 'beak']\n",
      "[ 67 106  89   2   3   1  14  25   8  28  52  10   0   0   0   0   0   0\n",
      "   0   0]\n",
      "\n",
      "# of train captions:(88550,)\n",
      "# of test captions:(29330,)\n",
      "\n",
      "# of train caption ids:(88550, 20)\n",
      "# of test caption ids:(29330, 20)\n",
      "\n",
      "# of train images:(8855, 256, 256, 3)\n",
      "# of test images:(2933, 256, 256, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CUBDataset(cfg.DATA_DIR, split='train')\n",
    "test_dataset = CUBDataset(cfg.DATA_DIR, split='test')\n",
    "\n",
    "print(f'\\ntrain data directory:\\n{train_dataset.split_dir}')\n",
    "print(f'test data directory:\\n{test_dataset.split_dir}\\n')\n",
    "\n",
    "print(f'# of train filenames:{train_dataset.filenames.shape}')\n",
    "print(f'# of test filenames:{test_dataset.filenames.shape}\\n')\n",
    "\n",
    "print(f'example of filename of train image:{train_dataset.filenames[0]}')\n",
    "print(f'example of filename of valid image:{test_dataset.filenames[0]}\\n')\n",
    "\n",
    "print(f'example of caption and its ids:\\n{train_dataset.captions[0]}\\n{train_dataset.captions_ids[0]}\\n')\n",
    "print(f'example of caption and its ids:\\n{test_dataset.captions[0]}\\n{test_dataset.captions_ids[0]}\\n')\n",
    "\n",
    "print(f'# of train captions:{np.asarray(train_dataset.captions).shape}')\n",
    "print(f'# of test captions:{np.asarray(test_dataset.captions).shape}\\n')\n",
    "\n",
    "print(f'# of train caption ids:{np.asarray(train_dataset.captions_ids).shape}')\n",
    "print(f'# of test caption ids:{np.asarray(test_dataset.captions_ids).shape}\\n')\n",
    "\n",
    "print(f'# of train images:{train_dataset.images.shape}')\n",
    "print(f'# of test images:{test_dataset.images.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8855, 256, 256, 3)\n",
      "(2933, 256, 256, 3)\n",
      "(88550, 20)\n",
      "(29330, 20)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_dataset.images\n",
    "test_images = test_dataset.images\n",
    "train_captions = np.asarray(train_dataset.captions_ids)\n",
    "test_captions = np.asarray(test_dataset.captions_ids)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(train_captions.shape)\n",
    "print(test_captions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8855, 64, 64, 3)\n",
      "(2933, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "train_images_64 = []\n",
    "for train_image in train_images:\n",
    "    train_images_64.append(resize(train_image, (64, 64, 3)))\n",
    "train_images_64 = np.asarray(train_images_64)\n",
    "print(train_images_64.shape)\n",
    "assert train_images_64.shape[0] == train_images.shape[0]\n",
    "test_images_64 = []\n",
    "for test_image in test_images:\n",
    "    test_images_64.append(resize(test_image, (64, 64, 3)))\n",
    "test_images_64 = np.asarray(test_images_64)\n",
    "print(test_images_64.shape)\n",
    "assert test_images_64.shape[0] == test_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images_64\n",
    "test_images = test_images_64\n",
    "n_captions_train = len(train_captions)\n",
    "n_captions_per_image = 10\n",
    "n_images_train = len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import threading\n",
    "import scipy.ndimage as ndi\n",
    "from skimage import transform\n",
    "from skimage import exposure\n",
    "import skimage\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def sent2ID(sample_sentence):\n",
    "    caption = []\n",
    "    cap = sample_sentence\n",
    "    if len(cap) == 0:\n",
    "        exit()\n",
    "    cap = cap.replace(\"\\ufffd\\ufffd\", \" \")\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(cap.lower())\n",
    "    tokens_new = []\n",
    "    for t in tokens:\n",
    "        t = t.encode('ascii', 'ignore').decode('ascii')\n",
    "        if len(t) > 0:\n",
    "            tokens_new.append(t)\n",
    "    caption.append(tokens_new)\n",
    "    caption_new = []\n",
    "    t = caption[0]\n",
    "    rev = []\n",
    "    for w in t:\n",
    "        if w in train_dataset.wordtoix:\n",
    "            rev.append(train_dataset.wordtoix[w])\n",
    "    x, x_len = train_dataset.get_caption(rev)\n",
    "    caption_new.append(np.squeeze(x, axis=1))\n",
    "    return caption_new\n",
    "\n",
    "def ID2sent(sample_caption):\n",
    "    sentence = []\n",
    "    for ID in sample_caption:\n",
    "        if ID != train_dataset.ixtoword['<PAD>']:\n",
    "            sentence.append(train_dataset.ixtoword[ID])\n",
    "    return sentence\n",
    "\n",
    "def get_random_int(min=0, max=10, number=5):\n",
    "    return [random.randint(min,max) for p in range(0,number)]\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "    return img\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return scipy.misc.imsave(path, merge(images, size))\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(images, size, image_path)\n",
    "\n",
    "def threading_data(data=None, fn=None, **kwargs):\n",
    "    def apply_fn(results, i, data, kwargs):\n",
    "        results[i] = fn(data, **kwargs)\n",
    "    results = [None] * len(data)\n",
    "    threads = []\n",
    "    for i in range(len(data)):\n",
    "        t = threading.Thread(\n",
    "                        name='threading_and_return',\n",
    "                        target=apply_fn,\n",
    "                        args=(results, i, data[i], kwargs)\n",
    "                        )\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    return np.asarray(results)\n",
    "\n",
    "def apply_transform(x, transform_matrix, channel_index=2, fill_mode='nearest', cval=0., order=1):\n",
    "    x = np.rollaxis(x, channel_index, 0)\n",
    "    final_affine_matrix = transform_matrix[:2, :2]\n",
    "    final_offset = transform_matrix[:2, 2]\n",
    "    channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n",
    "                      final_offset, order=order, mode=fill_mode, cval=cval) for x_channel in x]\n",
    "    x = np.stack(channel_images, axis=0)\n",
    "    x = np.rollaxis(x, 0, channel_index + 1)\n",
    "    return x\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 + 0.5\n",
    "    o_y = float(y) / 2 + 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "def rotation(x, rg=20, is_random=False, row_index=0, col_index=1, channel_index=2,\n",
    "                    fill_mode='nearest', cval=0.):\n",
    "    if is_random:\n",
    "        theta = np.pi / 180 * np.random.uniform(-rg, rg)\n",
    "    else:\n",
    "        theta = np.pi / 180 * rg\n",
    "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                [np.sin(theta), np.cos(theta), 0],\n",
    "                                [0, 0, 1]])\n",
    "    h, w = x.shape[row_index], x.shape[col_index]\n",
    "    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\n",
    "    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n",
    "    return x\n",
    "\n",
    "def crop(x, wrg, hrg, is_random=False, row_index=0, col_index=1, channel_index=2):\n",
    "    h, w = x.shape[row_index], x.shape[col_index]\n",
    "    assert (h > hrg) and (w > wrg), \"The size of cropping should smaller than the original image\"\n",
    "    if is_random:\n",
    "        h_offset = int(np.random.uniform(0, h-hrg) - 1)\n",
    "        w_offset = int(np.random.uniform(0, w-wrg) - 1)\n",
    "        return x[h_offset: hrg + h_offset ,w_offset: wrg + w_offset]\n",
    "    else:\n",
    "        h_offset = int(np.floor((h - hrg)/ 2.))\n",
    "        w_offset = int(np.floor((w - wrg)/ 2.))\n",
    "        h_end = h_offset + hrg\n",
    "        w_end = w_offset + wrg\n",
    "        return x[h_offset: h_end, w_offset: w_end]\n",
    "\n",
    "def flip_axis(x, axis, is_random=False):\n",
    "    if is_random:\n",
    "        factor = np.random.uniform(-1, 1)\n",
    "        if factor > 0:\n",
    "            x = np.asarray(x).swapaxes(axis, 0)\n",
    "            x = x[::-1, ...]\n",
    "            x = x.swapaxes(0, axis)\n",
    "            return x\n",
    "        else:\n",
    "            return x\n",
    "    else:\n",
    "        x = np.asarray(x).swapaxes(axis, 0)\n",
    "        x = x[::-1, ...]\n",
    "        x = x.swapaxes(0, axis)\n",
    "        return x\n",
    "\n",
    "def imresize(x, size=[100, 100], interp='bilinear', mode=None):\n",
    "    if x.shape[-1] == 1:\n",
    "        x = scipy.misc.imresize(x[:, :, 0], size, interp=interp, mode=mode)\n",
    "        return x[:, :, np.newaxis]\n",
    "    elif x.shape[-1] == 3:\n",
    "        return scipy.misc.imresize(x, size, interp=interp, mode=mode)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported channel %d\" % x.shape[-1])\n",
    "\n",
    "def prepro_img(x, mode=None):\n",
    "    if mode=='train':\n",
    "        x = flip_axis(x, axis=1, is_random=True)\n",
    "        x = rotation(x, rg=16, is_random=True, fill_mode='nearest')\n",
    "        x = imresize(x, size=[64 + 15, 64 + 15], interp='bilinear', mode=None)\n",
    "        x = crop(x, wrg=64, hrg=64, is_random=True)\n",
    "        x = x / (255. / 2.)\n",
    "        x = x - 1.\n",
    "    return x\n",
    "\n",
    "def combine_and_save_image_sets(image_sets, directory):\n",
    "    for i in range(len(image_sets[0])):\n",
    "        combined_image = []\n",
    "        for set_no in range(len(image_sets)):\n",
    "            combined_image.append(image_sets[set_no][i])\n",
    "            combined_image.append(np.zeros((image_sets[set_no][i].shape[0], 5, 3)))\n",
    "        combined_image = np.concatenate(combined_image, axis = 1)\n",
    "        scipy.misc.imsave(os.path.join(directory, 'combined_{}.jpg'.format(i)), combined_image)\n",
    "\n",
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print('The checkpoint has been created.')\n",
    "\n",
    "def load(saver, sess, ckpt_path):\n",
    "    saver.restore(sess, ckpt_path)\n",
    "    print(\"Restored model parameters from {}\".format(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20)\n"
     ]
    }
   ],
   "source": [
    "train_samples_dir = 'train_samples_1215_b'\n",
    "if os.path.exists(train_samples_dir) == False:\n",
    "    os.makedirs(train_samples_dir)\n",
    "\n",
    "lr = 0.0002\n",
    "lr_decay = 0.5      \n",
    "decay_every = 200  \n",
    "beta1 = 0.5\n",
    "checkpoint_dir = './checkpoint_1215_b'\n",
    "z_dim = 512\n",
    "image_size = 64\n",
    "c_dim = 3\n",
    "batch_size = 64\n",
    "ni = int(np.ceil(np.sqrt(batch_size)))\n",
    "\n",
    "sample_size = batch_size\n",
    "sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, z_dim)).astype(np.float32)\n",
    "sample_sentence = [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni)\n",
    "for i, sent in enumerate(sample_sentence):\n",
    "    sample_sentence[i] = sent2ID(sent)\n",
    "sample_sentence = np.asarray(sample_sentence)\n",
    "sample_sentence = np.reshape(sample_sentence, (sample_size, 20))\n",
    "print(sample_sentence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Text2Img:\n",
    "    def __init__(self):\n",
    "        \"\"\" Information \"\"\"\n",
    "        self.lr = 0.0002\n",
    "        self.lr_decay = 0.5      \n",
    "        self.decay_every = 200  \n",
    "        self.beta1 = 0.5\n",
    "        self.z_dim = 512\n",
    "        self.image_size = 64\n",
    "        self.c_dim = 3\n",
    "        self.batch_size = 64\n",
    "        self.alpha = 0.2\n",
    "        \n",
    "        \"\"\" Place Holders \"\"\"\n",
    "        self.t_real_image = tf.placeholder('float32', [self.batch_size, self.image_size, image_size, 3], name = 'real_image')\n",
    "        self.t_wrong_image = tf.placeholder('float32', [self.batch_size ,self.image_size, image_size, 3], name = 'wrong_image')\n",
    "        self.t_real_caption = tf.placeholder(dtype=tf.int64, shape=[self.batch_size, None], name='real_caption_input')\n",
    "        self.t_wrong_caption = tf.placeholder(dtype=tf.int64, shape=[self.batch_size, None], name='wrong_caption_input')\n",
    "        self.t_z = tf.placeholder(tf.float32, [self.batch_size, self.z_dim], name='z_noise')\n",
    "        \n",
    "        \"\"\" Training Phase - CNN - RNN mapping \"\"\"\n",
    "        net_cnn = CNN_ENCODER(self.t_real_image, is_training=True, reuse=False)\n",
    "        x = net_cnn.outputs\n",
    "        v = RNN_ENCODER(self.t_real_caption, is_training=True, reuse=False).outputs\n",
    "        x_w = CNN_ENCODER(self.t_wrong_image, is_training=True, reuse=True).outputs\n",
    "        v_w = RNN_ENCODER(self.t_wrong_caption, is_training=True, reuse=True).outputs\n",
    "        self.rnn_loss = tf.reduce_mean(tf.maximum(0., self.alpha - cosine_similarity(x, v) + cosine_similarity(x, v_w))) + \\\n",
    "                    tf.reduce_mean(tf.maximum(0., self.alpha - cosine_similarity(x, v) + cosine_similarity(x_w, v)))\n",
    "        \n",
    "        \"\"\" Training Phase - GAN \"\"\"\n",
    "        self.net_rnn = RNN_ENCODER(self.t_real_caption, is_training=False, reuse=True)\n",
    "        net_fake_image = GENERATOR(self.t_z, self.net_rnn.outputs, is_training=True, reuse=False)\n",
    "        net_disc_fake = DISCRIMINATOR(net_fake_image.outputs, self.net_rnn.outputs, is_training=True, reuse=False)\n",
    "        disc_fake_logits = net_disc_fake.logits\n",
    "        net_disc_real = DISCRIMINATOR(self.t_real_image, self.net_rnn.outputs, is_training=True, reuse=True)\n",
    "        disc_real_logits = net_disc_real.logits\n",
    "        net_disc_mismatch = DISCRIMINATOR(self.t_real_image, RNN_ENCODER(self.t_wrong_caption, is_training=False, reuse=True).outputs,\n",
    "                                        is_training=True, reuse=True)\n",
    "        disc_mismatch_logits = net_disc_mismatch.logits\n",
    "        d_loss1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_real_logits,     labels=tf.ones_like(disc_real_logits),      name='d1'))\n",
    "        d_loss2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_mismatch_logits, labels=tf.zeros_like(disc_mismatch_logits), name='d2'))\n",
    "        d_loss3 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits,     labels=tf.zeros_like(disc_fake_logits),     name='d3'))\n",
    "        self.d_loss = d_loss1 + (d_loss2 + d_loss3) * 0.5\n",
    "        self.g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits, labels=tf.ones_like(disc_fake_logits), name='g'))\n",
    "        \n",
    "        \"\"\" Testing Phase \"\"\"\n",
    "        self.net_g = GENERATOR(self.t_z, RNN_ENCODER(self.t_real_caption, is_training=False, reuse=True).outputs,\n",
    "                            is_training=False, reuse=True)\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        rnn_vars = [var for var in tf.trainable_variables() if 'rnnencoder' in var.name]\n",
    "        cnn_vars = [var for var in tf.trainable_variables() if 'cnnencoder' in var.name]\n",
    "        d_vars = [var for var in tf.trainable_variables() if 'discriminator' in var.name]\n",
    "        g_vars = [var for var in tf.trainable_variables() if 'generator' in var.name]\n",
    "        update_ops_CNN = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'cnnencoder' in var.name]\n",
    "        update_ops_D = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'discriminator' in var.name]\n",
    "        update_ops_G = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'generator' in var.name]\n",
    "        with tf.variable_scope('learning_rate'):\n",
    "            self.lr_v = tf.Variable(self.lr, trainable=False)\n",
    "        with tf.control_dependencies(update_ops_CNN):\n",
    "            grads, _ = tf.clip_by_global_norm(tf.gradients(self.rnn_loss, rnn_vars + cnn_vars), 10)\n",
    "            optimizer = tf.train.AdamOptimizer(self.lr_v, beta1=self.beta1)\n",
    "            self.rnn_optim = optimizer.apply_gradients(zip(grads, rnn_vars + cnn_vars))\n",
    "        with tf.control_dependencies(update_ops_D):\n",
    "            self.d_optim = tf.train.AdamOptimizer(self.lr_v, beta1=self.beta1).minimize(self.d_loss, var_list=d_vars)\n",
    "        with tf.control_dependencies(update_ops_G):\n",
    "            self.g_optim = tf.train.AdamOptimizer(self.lr_v, beta1=self.beta1).minimize(self.g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no checkpoints find.\n",
      " ** init lr: 0.000200  decay_every_epoch: 200, lr_decay: 0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py:142: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/1000] time: 0.7290s, d_loss: 1.49649596, g_loss: 0.85392177, rnn_loss: 0.29632312\n",
      " ** Epoch 0 took 119.728280s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1000] time: 0.7312s, d_loss: 1.37754560, g_loss: 0.99413884, rnn_loss: 0.29497206\n",
      " ** Epoch 1 took 100.732207s\n",
      "Epoch: [2/1000] time: 0.7283s, d_loss: 1.37133169, g_loss: 0.84102124, rnn_loss: 0.31148279\n",
      " ** Epoch 2 took 100.582112s\n",
      "Epoch: [3/1000] time: 0.7309s, d_loss: 1.34644961, g_loss: 0.97726154, rnn_loss: 0.24170528\n",
      " ** Epoch 3 took 100.698752s\n",
      "Epoch: [4/1000] time: 0.7322s, d_loss: 1.34033656, g_loss: 0.88991940, rnn_loss: 0.26539040\n",
      " ** Epoch 4 took 100.877783s\n",
      "Epoch: [5/1000] time: 0.7242s, d_loss: 1.25726700, g_loss: 1.61848593, rnn_loss: 0.22631121\n",
      " ** Epoch 5 took 100.273991s\n",
      "Epoch: [6/1000] time: 0.7258s, d_loss: 1.28749657, g_loss: 1.62431848, rnn_loss: 0.24634567\n",
      " ** Epoch 6 took 100.194320s\n",
      "Epoch: [7/1000] time: 0.7244s, d_loss: 1.30340540, g_loss: 0.75689375, rnn_loss: 0.29054916\n",
      " ** Epoch 7 took 100.353995s\n",
      "Epoch: [8/1000] time: 0.7192s, d_loss: 1.26029658, g_loss: 0.69842845, rnn_loss: 0.26558471\n",
      " ** Epoch 8 took 99.971570s\n",
      "Epoch: [9/1000] time: 0.7262s, d_loss: 1.29514503, g_loss: 0.83146179, rnn_loss: 0.21426657\n",
      " ** Epoch 9 took 100.031638s\n",
      "Epoch: [10/1000] time: 0.7228s, d_loss: 1.37405765, g_loss: 0.56956995, rnn_loss: 0.19757617\n",
      " ** Epoch 10 took 100.215099s\n",
      "Epoch: [11/1000] time: 0.7233s, d_loss: 1.13240242, g_loss: 0.68191171, rnn_loss: 0.20666137\n",
      " ** Epoch 11 took 100.030071s\n",
      "Epoch: [12/1000] time: 0.7283s, d_loss: 1.16790581, g_loss: 0.99040699, rnn_loss: 0.13661832\n",
      " ** Epoch 12 took 100.267152s\n",
      "Epoch: [13/1000] time: 0.7365s, d_loss: 1.15901995, g_loss: 0.67588729, rnn_loss: 0.20898223\n",
      " ** Epoch 13 took 100.019697s\n",
      "Epoch: [14/1000] time: 0.7236s, d_loss: 1.03867340, g_loss: 0.70473069, rnn_loss: 0.21902302\n",
      " ** Epoch 14 took 99.983012s\n",
      "Epoch: [15/1000] time: 0.7243s, d_loss: 1.13150465, g_loss: 0.60638684, rnn_loss: 0.19256639\n",
      " ** Epoch 15 took 99.973062s\n",
      "Epoch: [16/1000] time: 0.7186s, d_loss: 1.06396377, g_loss: 0.52130926, rnn_loss: 0.17236392\n",
      " ** Epoch 16 took 99.853729s\n",
      "Epoch: [17/1000] time: 0.7219s, d_loss: 1.14791083, g_loss: 1.35263634, rnn_loss: 0.17918982\n",
      " ** Epoch 17 took 100.044155s\n",
      "Epoch: [18/1000] time: 0.7247s, d_loss: 1.15029943, g_loss: 0.72753960, rnn_loss: 0.23452541\n",
      " ** Epoch 18 took 100.064147s\n",
      "Epoch: [19/1000] time: 0.7237s, d_loss: 0.99051380, g_loss: 0.80881500, rnn_loss: 0.18877885\n",
      " ** Epoch 19 took 100.078934s\n",
      "Epoch: [20/1000] time: 0.7221s, d_loss: 1.04954052, g_loss: 1.02422667, rnn_loss: 0.14634982\n",
      " ** Epoch 20 took 100.154155s\n",
      "Epoch: [21/1000] time: 0.7257s, d_loss: 0.98391259, g_loss: 0.74761832, rnn_loss: 0.20759881\n",
      " ** Epoch 21 took 100.006611s\n",
      "Epoch: [22/1000] time: 0.7237s, d_loss: 1.14695072, g_loss: 0.72413135, rnn_loss: 0.20278971\n",
      " ** Epoch 22 took 99.946694s\n",
      "Epoch: [23/1000] time: 0.7225s, d_loss: 0.93193620, g_loss: 0.68546057, rnn_loss: 0.17282152\n",
      " ** Epoch 23 took 100.181605s\n",
      "Epoch: [24/1000] time: 0.7319s, d_loss: 1.17599547, g_loss: 0.45317042, rnn_loss: 0.15358013\n",
      " ** Epoch 24 took 99.968669s\n",
      "Epoch: [25/1000] time: 0.7280s, d_loss: 1.19830942, g_loss: 0.98555529, rnn_loss: 0.16158801\n",
      " ** Epoch 25 took 99.946932s\n",
      "Epoch: [26/1000] time: 0.7272s, d_loss: 0.92766291, g_loss: 1.47360790, rnn_loss: 0.20699149\n",
      " ** Epoch 26 took 100.194004s\n",
      "Epoch: [27/1000] time: 0.7508s, d_loss: 0.95264924, g_loss: 0.88994396, rnn_loss: 0.16991962\n",
      " ** Epoch 27 took 100.022732s\n",
      "Epoch: [28/1000] time: 0.7249s, d_loss: 1.14817667, g_loss: 0.82123435, rnn_loss: 0.19371313\n",
      " ** Epoch 28 took 100.013750s\n",
      "Epoch: [29/1000] time: 0.7255s, d_loss: 0.77920634, g_loss: 0.81621706, rnn_loss: 0.15399069\n",
      " ** Epoch 29 took 100.197439s\n",
      "Epoch: [30/1000] time: 0.7229s, d_loss: 1.00158155, g_loss: 0.63227224, rnn_loss: 0.14864150\n",
      " ** Epoch 30 took 100.001734s\n",
      "Epoch: [31/1000] time: 0.7194s, d_loss: 0.83781517, g_loss: 1.51336026, rnn_loss: 0.15147877\n",
      " ** Epoch 31 took 100.090227s\n",
      "Epoch: [32/1000] time: 0.7215s, d_loss: 1.24895060, g_loss: 0.41292048, rnn_loss: 0.20347695\n",
      " ** Epoch 32 took 100.235563s\n",
      "Epoch: [33/1000] time: 0.7207s, d_loss: 0.81886864, g_loss: 1.09667861, rnn_loss: 0.16496767\n",
      " ** Epoch 33 took 99.985816s\n",
      "Epoch: [34/1000] time: 0.7260s, d_loss: 1.51832998, g_loss: 0.25388408, rnn_loss: 0.24201277\n",
      " ** Epoch 34 took 100.174287s\n",
      "Epoch: [35/1000] time: 0.7278s, d_loss: 1.10467350, g_loss: 1.22065973, rnn_loss: 0.18287259\n",
      " ** Epoch 35 took 100.298675s\n",
      "Epoch: [36/1000] time: 0.7217s, d_loss: 0.93837202, g_loss: 0.74665219, rnn_loss: 0.17855272\n",
      " ** Epoch 36 took 100.018860s\n",
      "Epoch: [37/1000] time: 0.7229s, d_loss: 0.79474950, g_loss: 0.84892988, rnn_loss: 0.13372350\n",
      " ** Epoch 37 took 100.171715s\n",
      "Epoch: [38/1000] time: 0.7238s, d_loss: 0.76053196, g_loss: 1.05222297, rnn_loss: 0.16905054\n",
      " ** Epoch 38 took 100.254552s\n",
      "Epoch: [39/1000] time: 0.7368s, d_loss: 0.92005563, g_loss: 0.60151815, rnn_loss: 0.08660121\n",
      " ** Epoch 39 took 100.048267s\n",
      "Epoch: [40/1000] time: 0.7191s, d_loss: 0.82634127, g_loss: 0.73095381, rnn_loss: 0.17511845\n",
      " ** Epoch 40 took 100.045649s\n",
      "Epoch: [41/1000] time: 0.7241s, d_loss: 0.89728457, g_loss: 0.77185678, rnn_loss: 0.17943487\n",
      " ** Epoch 41 took 100.206585s\n",
      "Epoch: [42/1000] time: 0.7268s, d_loss: 0.66862130, g_loss: 1.08808398, rnn_loss: 0.13140529\n",
      " ** Epoch 42 took 99.996448s\n",
      "Epoch: [43/1000] time: 0.7193s, d_loss: 0.94797361, g_loss: 1.18209386, rnn_loss: 0.17414337\n",
      " ** Epoch 43 took 100.043541s\n",
      "Epoch: [44/1000] time: 0.7427s, d_loss: 0.78119564, g_loss: 1.92269289, rnn_loss: 0.17784533\n",
      " ** Epoch 44 took 100.171365s\n",
      "Epoch: [45/1000] time: 0.7206s, d_loss: 0.88227803, g_loss: 0.88745737, rnn_loss: 0.14726646\n",
      " ** Epoch 45 took 100.025204s\n",
      "Epoch: [46/1000] time: 0.7219s, d_loss: 0.95606005, g_loss: 0.98133326, rnn_loss: 0.13346343\n",
      " ** Epoch 46 took 100.099528s\n",
      "Epoch: [47/1000] time: 0.7382s, d_loss: 0.72344184, g_loss: 1.01542830, rnn_loss: 0.14759393\n",
      " ** Epoch 47 took 100.903948s\n",
      "Epoch: [48/1000] time: 0.7212s, d_loss: 0.92384666, g_loss: 1.01765060, rnn_loss: 0.10571910\n",
      " ** Epoch 48 took 100.277634s\n",
      "Epoch: [49/1000] time: 0.7244s, d_loss: 0.69472390, g_loss: 1.65624464, rnn_loss: 0.12875345\n",
      " ** Epoch 49 took 100.087541s\n",
      "Epoch: [50/1000] time: 0.7256s, d_loss: 1.08661294, g_loss: 1.17768192, rnn_loss: 0.17034863\n",
      " ** Epoch 50 took 99.996018s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [51/1000] time: 0.7254s, d_loss: 1.21603072, g_loss: 1.16015184, rnn_loss: 0.12565511\n",
      " ** Epoch 51 took 100.700891s\n",
      "Epoch: [52/1000] time: 0.7250s, d_loss: 0.80824828, g_loss: 1.47517514, rnn_loss: 0.18329401\n",
      " ** Epoch 52 took 100.279278s\n",
      "Epoch: [53/1000] time: 0.7399s, d_loss: 0.75037825, g_loss: 0.96935683, rnn_loss: 0.14029348\n",
      " ** Epoch 53 took 100.310498s\n",
      "Epoch: [54/1000] time: 0.7218s, d_loss: 0.87864512, g_loss: 0.73946398, rnn_loss: 0.16240117\n",
      " ** Epoch 54 took 100.227386s\n",
      "Epoch: [55/1000] time: 0.7265s, d_loss: 0.90743029, g_loss: 1.31545651, rnn_loss: 0.13306281\n",
      " ** Epoch 55 took 100.362183s\n",
      "Epoch: [56/1000] time: 0.7207s, d_loss: 1.03122389, g_loss: 1.49560893, rnn_loss: 0.14071214\n",
      " ** Epoch 56 took 100.012650s\n",
      "Epoch: [57/1000] time: 0.7266s, d_loss: 0.96445608, g_loss: 0.47421727, rnn_loss: 0.15196237\n",
      " ** Epoch 57 took 100.231709s\n",
      "Epoch: [58/1000] time: 0.7244s, d_loss: 0.68056631, g_loss: 1.79561460, rnn_loss: 0.18511187\n",
      " ** Epoch 58 took 100.102697s\n",
      "Epoch: [59/1000] time: 0.7249s, d_loss: 0.90688592, g_loss: 1.13705349, rnn_loss: 0.15833279\n",
      " ** Epoch 59 took 99.954908s\n",
      "Epoch: [60/1000] time: 0.7248s, d_loss: 0.79308450, g_loss: 1.06551528, rnn_loss: 0.13808593\n",
      " ** Epoch 60 took 100.253981s\n",
      "Epoch: [61/1000] time: 0.7258s, d_loss: 0.62970626, g_loss: 1.28255153, rnn_loss: 0.13027105\n",
      " ** Epoch 61 took 100.077795s\n",
      "Epoch: [62/1000] time: 0.7254s, d_loss: 0.76913184, g_loss: 0.73657250, rnn_loss: 0.22826433\n",
      " ** Epoch 62 took 100.195427s\n",
      "Epoch: [63/1000] time: 0.7259s, d_loss: 0.89535773, g_loss: 1.06082988, rnn_loss: 0.10568689\n",
      " ** Epoch 63 took 100.420792s\n",
      "Epoch: [64/1000] time: 0.7225s, d_loss: 0.74130815, g_loss: 1.03233266, rnn_loss: 0.13030025\n",
      " ** Epoch 64 took 100.244466s\n",
      "Epoch: [65/1000] time: 0.7238s, d_loss: 0.79611862, g_loss: 1.00742519, rnn_loss: 0.13994667\n",
      " ** Epoch 65 took 100.123652s\n",
      "Epoch: [66/1000] time: 0.7234s, d_loss: 1.49511075, g_loss: 0.21980533, rnn_loss: 0.12693211\n",
      " ** Epoch 66 took 100.390030s\n",
      "Epoch: [67/1000] time: 0.7246s, d_loss: 0.97612911, g_loss: 1.61225367, rnn_loss: 0.17185381\n",
      " ** Epoch 67 took 100.225654s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [68/1000] time: 0.7224s, d_loss: 0.69536513, g_loss: 2.25021648, rnn_loss: 0.12083762\n",
      " ** Epoch 68 took 100.070199s\n",
      "Epoch: [69/1000] time: 0.7244s, d_loss: 0.70287126, g_loss: 1.62849259, rnn_loss: 0.20237416\n",
      " ** Epoch 69 took 100.292163s\n",
      "Epoch: [70/1000] time: 0.7233s, d_loss: 0.83298361, g_loss: 2.69859219, rnn_loss: 0.16642335\n",
      " ** Epoch 70 took 100.236041s\n",
      "Epoch: [71/1000] time: 0.7331s, d_loss: 0.90104675, g_loss: 0.92706370, rnn_loss: 0.17245217\n",
      " ** Epoch 71 took 99.920842s\n",
      "Epoch: [72/1000] time: 0.7213s, d_loss: 0.86087036, g_loss: 0.90935361, rnn_loss: 0.18205656\n",
      " ** Epoch 72 took 100.186673s\n",
      "Epoch: [73/1000] time: 0.7254s, d_loss: 0.71827585, g_loss: 1.48651004, rnn_loss: 0.10914633\n",
      " ** Epoch 73 took 100.102146s\n",
      "Epoch: [74/1000] time: 0.7207s, d_loss: 1.01200438, g_loss: 0.47195983, rnn_loss: 0.12687314\n",
      " ** Epoch 74 took 100.030205s\n",
      "Epoch: [75/1000] time: 0.7194s, d_loss: 0.61856294, g_loss: 1.96362579, rnn_loss: 0.07783947\n",
      " ** Epoch 75 took 100.221638s\n",
      "Epoch: [76/1000] time: 0.7265s, d_loss: 0.75241786, g_loss: 2.25971508, rnn_loss: 0.15429623\n",
      " ** Epoch 76 took 100.884295s\n",
      "Epoch: [77/1000] time: 0.7208s, d_loss: 0.93449378, g_loss: 0.61181068, rnn_loss: 0.15155789\n",
      " ** Epoch 77 took 100.162145s\n",
      "Epoch: [78/1000] time: 0.7276s, d_loss: 0.84761751, g_loss: 1.01970172, rnn_loss: 0.17216930\n",
      " ** Epoch 78 took 100.510184s\n",
      "Epoch: [79/1000] time: 0.7400s, d_loss: 0.76287216, g_loss: 1.12233710, rnn_loss: 0.19184464\n",
      " ** Epoch 79 took 100.585250s\n",
      "Epoch: [80/1000] time: 0.7260s, d_loss: 1.04220974, g_loss: 1.40648341, rnn_loss: 0.12741856\n",
      " ** Epoch 80 took 101.158806s\n",
      "Epoch: [81/1000] time: 0.7218s, d_loss: 0.76930898, g_loss: 1.25695276, rnn_loss: 0.12822954\n",
      " ** Epoch 81 took 101.198626s\n",
      "Epoch: [82/1000] time: 0.7288s, d_loss: 0.56534863, g_loss: 2.33499217, rnn_loss: 0.12679926\n",
      " ** Epoch 82 took 101.292525s\n",
      "Epoch: [83/1000] time: 0.7330s, d_loss: 0.74880850, g_loss: 1.34460723, rnn_loss: 0.15227714\n",
      " ** Epoch 83 took 100.848859s\n",
      "Epoch: [84/1000] time: 0.7261s, d_loss: 0.67701131, g_loss: 1.05534053, rnn_loss: 0.14869601\n",
      " ** Epoch 84 took 100.904674s\n",
      "Epoch: [85/1000] time: 0.7450s, d_loss: 0.59183300, g_loss: 1.27109230, rnn_loss: 0.13665989\n",
      " ** Epoch 85 took 100.926391s\n",
      "Epoch: [86/1000] time: 0.7333s, d_loss: 0.74126709, g_loss: 0.78850079, rnn_loss: 0.09796602\n",
      " ** Epoch 86 took 101.792751s\n",
      "Epoch: [87/1000] time: 0.7340s, d_loss: 0.71746874, g_loss: 1.03633833, rnn_loss: 0.14660011\n",
      " ** Epoch 87 took 101.528383s\n",
      "Epoch: [88/1000] time: 0.7361s, d_loss: 0.72523129, g_loss: 0.99321121, rnn_loss: 0.10621178\n",
      " ** Epoch 88 took 101.050036s\n",
      "Epoch: [89/1000] time: 0.7327s, d_loss: 1.03733134, g_loss: 1.98109007, rnn_loss: 0.12868220\n",
      " ** Epoch 89 took 100.811680s\n",
      "Epoch: [90/1000] time: 0.7449s, d_loss: 0.71644866, g_loss: 1.53145444, rnn_loss: 0.14364222\n",
      " ** Epoch 90 took 100.838248s\n",
      "Epoch: [91/1000] time: 0.7340s, d_loss: 0.69196737, g_loss: 1.13011789, rnn_loss: 0.17001283\n",
      " ** Epoch 91 took 101.691992s\n",
      "Epoch: [92/1000] time: 0.7290s, d_loss: 0.69289488, g_loss: 1.06649661, rnn_loss: 0.11934951\n",
      " ** Epoch 92 took 100.843746s\n",
      "Epoch: [93/1000] time: 0.7345s, d_loss: 0.54213297, g_loss: 3.19404292, rnn_loss: 0.10275558\n",
      " ** Epoch 93 took 101.004060s\n",
      "Epoch: [94/1000] time: 0.7273s, d_loss: 0.88833088, g_loss: 0.68568778, rnn_loss: 0.14114371\n",
      " ** Epoch 94 took 101.043352s\n",
      "Epoch: [95/1000] time: 0.7319s, d_loss: 0.46199340, g_loss: 2.66991401, rnn_loss: 0.12587395\n",
      " ** Epoch 95 took 101.073860s\n",
      "Epoch: [96/1000] time: 0.7278s, d_loss: 1.04583097, g_loss: 1.95173526, rnn_loss: 0.12731288\n",
      " ** Epoch 96 took 101.183622s\n",
      "Epoch: [97/1000] time: 0.7332s, d_loss: 0.56766373, g_loss: 1.27458298, rnn_loss: 0.14742783\n",
      " ** Epoch 97 took 101.511235s\n",
      "Epoch: [98/1000] time: 0.7261s, d_loss: 0.52678651, g_loss: 1.71677971, rnn_loss: 0.13398576\n",
      " ** Epoch 98 took 100.479346s\n",
      "Epoch: [99/1000] time: 0.7228s, d_loss: 0.72305733, g_loss: 1.94575191, rnn_loss: 0.11777963\n",
      " ** Epoch 99 took 100.338695s\n",
      "Epoch: [100/1000] time: 0.7250s, d_loss: 1.29368579, g_loss: 2.45501637, rnn_loss: 0.13973166\n",
      " ** Epoch 100 took 100.602206s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [101/1000] time: 0.7238s, d_loss: 0.59929186, g_loss: 1.64382839, rnn_loss: 0.12750494\n",
      " ** Epoch 101 took 100.498935s\n",
      "Epoch: [102/1000] time: 0.7403s, d_loss: 0.90791374, g_loss: 0.64871866, rnn_loss: 0.20017000\n",
      " ** Epoch 102 took 100.440207s\n",
      "Epoch: [103/1000] time: 0.7322s, d_loss: 0.64966691, g_loss: 1.24113035, rnn_loss: 0.13956493\n",
      " ** Epoch 103 took 100.589001s\n",
      "Epoch: [104/1000] time: 0.7262s, d_loss: 0.68410051, g_loss: 2.10311556, rnn_loss: 0.08745217\n",
      " ** Epoch 104 took 100.615770s\n",
      "Epoch: [105/1000] time: 0.7256s, d_loss: 0.65909505, g_loss: 1.93702364, rnn_loss: 0.09283465\n",
      " ** Epoch 105 took 100.230999s\n",
      "Epoch: [106/1000] time: 0.7295s, d_loss: 0.80022413, g_loss: 1.79590476, rnn_loss: 0.13293083\n",
      " ** Epoch 106 took 100.511904s\n",
      "Epoch: [107/1000] time: 0.7262s, d_loss: 0.75870800, g_loss: 1.22028756, rnn_loss: 0.13185298\n",
      " ** Epoch 107 took 100.284375s\n",
      "Epoch: [108/1000] time: 0.7242s, d_loss: 0.45761952, g_loss: 2.15010476, rnn_loss: 0.16101384\n",
      " ** Epoch 108 took 100.325381s\n",
      "Epoch: [109/1000] time: 0.7254s, d_loss: 0.83171153, g_loss: 3.04175091, rnn_loss: 0.11793813\n",
      " ** Epoch 109 took 100.517087s\n",
      "Epoch: [110/1000] time: 0.7255s, d_loss: 0.74833059, g_loss: 1.01349020, rnn_loss: 0.12203164\n",
      " ** Epoch 110 took 100.218506s\n",
      "Epoch: [111/1000] time: 0.7329s, d_loss: 0.53558123, g_loss: 1.41875601, rnn_loss: 0.10039337\n",
      " ** Epoch 111 took 100.287577s\n",
      "Epoch: [112/1000] time: 0.7233s, d_loss: 0.61300075, g_loss: 1.75001156, rnn_loss: 0.13335985\n",
      " ** Epoch 112 took 100.533828s\n",
      "Epoch: [113/1000] time: 0.7258s, d_loss: 0.71154696, g_loss: 0.64366704, rnn_loss: 0.11215898\n",
      " ** Epoch 113 took 100.249960s\n",
      "Epoch: [114/1000] time: 0.7240s, d_loss: 0.80346394, g_loss: 1.07325935, rnn_loss: 0.12724268\n",
      " ** Epoch 114 took 100.200107s\n",
      "Epoch: [115/1000] time: 0.7310s, d_loss: 0.63852733, g_loss: 1.72058916, rnn_loss: 0.14456770\n",
      " ** Epoch 115 took 101.158702s\n",
      "Epoch: [116/1000] time: 0.7263s, d_loss: 0.53464961, g_loss: 2.18795156, rnn_loss: 0.12523276\n",
      " ** Epoch 116 took 100.250421s\n",
      "Epoch: [117/1000] time: 0.7266s, d_loss: 0.72090006, g_loss: 1.45805931, rnn_loss: 0.12772605\n",
      " ** Epoch 117 took 100.190669s\n",
      "Epoch: [118/1000] time: 0.7253s, d_loss: 0.60057253, g_loss: 3.21135473, rnn_loss: 0.11236089\n",
      " ** Epoch 118 took 100.542501s\n",
      "Epoch: [119/1000] time: 0.7301s, d_loss: 0.67433697, g_loss: 0.92923999, rnn_loss: 0.11851779\n",
      " ** Epoch 119 took 100.273259s\n",
      "Epoch: [120/1000] time: 0.7275s, d_loss: 0.56246173, g_loss: 1.02932167, rnn_loss: 0.14745668\n",
      " ** Epoch 120 took 100.102598s\n",
      "Epoch: [121/1000] time: 0.7270s, d_loss: 0.64664090, g_loss: 2.01680970, rnn_loss: 0.12297113\n",
      " ** Epoch 121 took 100.488711s\n",
      "Epoch: [122/1000] time: 0.7291s, d_loss: 0.54354191, g_loss: 1.89466786, rnn_loss: 0.07858542\n",
      " ** Epoch 122 took 100.467756s\n",
      "Epoch: [123/1000] time: 0.7258s, d_loss: 0.84395486, g_loss: 1.09096122, rnn_loss: 0.10575594\n",
      " ** Epoch 123 took 100.514713s\n",
      "Epoch: [124/1000] time: 0.7288s, d_loss: 0.52779323, g_loss: 2.70076895, rnn_loss: 0.14673144\n",
      " ** Epoch 124 took 100.389570s\n",
      "Epoch: [125/1000] time: 0.7289s, d_loss: 0.40487742, g_loss: 3.83874106, rnn_loss: 0.11991538\n",
      " ** Epoch 125 took 100.150066s\n",
      "Epoch: [126/1000] time: 0.9320s, d_loss: 0.72584558, g_loss: 1.27489829, rnn_loss: 0.08434255\n",
      " ** Epoch 126 took 101.502730s\n",
      "Epoch: [127/1000] time: 0.7307s, d_loss: 0.75684327, g_loss: 2.65246439, rnn_loss: 0.12549452\n",
      " ** Epoch 127 took 101.927637s\n",
      "Epoch: [128/1000] time: 0.7271s, d_loss: 0.62899971, g_loss: 1.67775226, rnn_loss: 0.11609926\n",
      " ** Epoch 128 took 100.263003s\n",
      "Epoch: [129/1000] time: 0.7293s, d_loss: 0.78152394, g_loss: 0.82505441, rnn_loss: 0.09957630\n",
      " ** Epoch 129 took 100.897768s\n",
      "Epoch: [130/1000] time: 0.7248s, d_loss: 0.45680934, g_loss: 1.69308472, rnn_loss: 0.12060831\n",
      " ** Epoch 130 took 100.607522s\n",
      "Epoch: [131/1000] time: 0.7383s, d_loss: 0.47206950, g_loss: 1.99673605, rnn_loss: 0.10344627\n",
      " ** Epoch 131 took 100.256320s\n",
      "Epoch: [132/1000] time: 0.7344s, d_loss: 0.32311440, g_loss: 1.99892116, rnn_loss: 0.09489644\n",
      " ** Epoch 132 took 100.959586s\n",
      "Epoch: [133/1000] time: 0.7250s, d_loss: 0.76184410, g_loss: 1.24153209, rnn_loss: 0.09654602\n",
      " ** Epoch 133 took 100.670516s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [134/1000] time: 0.7289s, d_loss: 0.36012375, g_loss: 3.12904978, rnn_loss: 0.05978405\n",
      " ** Epoch 134 took 100.392999s\n",
      "Epoch: [135/1000] time: 0.7275s, d_loss: 0.58893585, g_loss: 2.93194437, rnn_loss: 0.10933587\n",
      " ** Epoch 135 took 100.169287s\n",
      "Epoch: [136/1000] time: 0.7241s, d_loss: 0.61770403, g_loss: 3.50717759, rnn_loss: 0.09381709\n",
      " ** Epoch 136 took 100.427167s\n",
      "Epoch: [137/1000] time: 0.7255s, d_loss: 0.54991072, g_loss: 3.58596635, rnn_loss: 0.15599479\n",
      " ** Epoch 137 took 100.720543s\n",
      "Epoch: [138/1000] time: 0.7222s, d_loss: 0.62247247, g_loss: 2.80832767, rnn_loss: 0.06736452\n",
      " ** Epoch 138 took 100.077939s\n",
      "Epoch: [139/1000] time: 0.7421s, d_loss: 0.54062134, g_loss: 1.45620489, rnn_loss: 0.12845470\n",
      " ** Epoch 139 took 100.614348s\n",
      "Epoch: [140/1000] time: 0.7261s, d_loss: 1.75169694, g_loss: 0.46919703, rnn_loss: 0.11354178\n",
      " ** Epoch 140 took 100.671023s\n",
      "Epoch: [141/1000] time: 0.7290s, d_loss: 0.44249225, g_loss: 2.46707392, rnn_loss: 0.06774154\n",
      " ** Epoch 141 took 100.979275s\n",
      "Epoch: [142/1000] time: 0.7226s, d_loss: 0.63267660, g_loss: 0.77954757, rnn_loss: 0.11033073\n",
      " ** Epoch 142 took 100.381639s\n",
      "Epoch: [143/1000] time: 0.7241s, d_loss: 1.21363771, g_loss: 0.33911550, rnn_loss: 0.11044517\n",
      " ** Epoch 143 took 100.487503s\n",
      "Epoch: [144/1000] time: 0.7244s, d_loss: 1.01644850, g_loss: 0.22026417, rnn_loss: 0.10205527\n",
      " ** Epoch 144 took 100.236957s\n",
      "Epoch: [145/1000] time: 0.7263s, d_loss: 0.76319867, g_loss: 2.13797474, rnn_loss: 0.10841105\n",
      " ** Epoch 145 took 100.393570s\n",
      "Epoch: [146/1000] time: 0.7235s, d_loss: 0.84326082, g_loss: 3.14263105, rnn_loss: 0.10088900\n",
      " ** Epoch 146 took 100.548573s\n",
      "Epoch: [147/1000] time: 0.7239s, d_loss: 0.76532692, g_loss: 2.38782835, rnn_loss: 0.09758425\n",
      " ** Epoch 147 took 100.328194s\n",
      "Epoch: [148/1000] time: 0.7282s, d_loss: 0.59975010, g_loss: 1.82169223, rnn_loss: 0.11295789\n",
      " ** Epoch 148 took 100.390827s\n",
      "Epoch: [149/1000] time: 0.7288s, d_loss: 0.86981153, g_loss: 0.41220087, rnn_loss: 0.11166985\n",
      " ** Epoch 149 took 100.579957s\n",
      "Epoch: [150/1000] time: 0.7227s, d_loss: 0.94315928, g_loss: 1.43537092, rnn_loss: 0.09236529\n",
      " ** Epoch 150 took 100.221665s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [151/1000] time: 0.7264s, d_loss: 0.81980300, g_loss: 1.37132752, rnn_loss: 0.10847848\n",
      " ** Epoch 151 took 100.816532s\n",
      "Epoch: [152/1000] time: 0.7268s, d_loss: 0.52659607, g_loss: 3.14288616, rnn_loss: 0.05951723\n",
      " ** Epoch 152 took 100.627771s\n",
      "Epoch: [153/1000] time: 0.7302s, d_loss: 0.88392323, g_loss: 2.68317151, rnn_loss: 0.17920710\n",
      " ** Epoch 153 took 100.316606s\n",
      "Epoch: [154/1000] time: 0.7245s, d_loss: 0.59147298, g_loss: 1.84765720, rnn_loss: 0.08140095\n",
      " ** Epoch 154 took 100.610313s\n",
      "Epoch: [155/1000] time: 0.7280s, d_loss: 0.45497909, g_loss: 2.54223633, rnn_loss: 0.10913990\n",
      " ** Epoch 155 took 100.637279s\n",
      "Epoch: [156/1000] time: 0.7235s, d_loss: 0.44022959, g_loss: 2.02829313, rnn_loss: 0.10055684\n",
      " ** Epoch 156 took 100.409703s\n",
      "Epoch: [157/1000] time: 0.7285s, d_loss: 1.35153449, g_loss: 0.23618194, rnn_loss: 0.10468601\n",
      " ** Epoch 157 took 100.430271s\n",
      "Epoch: [158/1000] time: 0.7247s, d_loss: 0.27808729, g_loss: 2.52326536, rnn_loss: 0.13735580\n",
      " ** Epoch 158 took 100.560065s\n",
      "Epoch: [159/1000] time: 0.7218s, d_loss: 0.37178773, g_loss: 3.64582515, rnn_loss: 0.10143652\n",
      " ** Epoch 159 took 100.271188s\n",
      "Epoch: [160/1000] time: 0.7240s, d_loss: 1.52031767, g_loss: 1.55572319, rnn_loss: 0.08235104\n",
      " ** Epoch 160 took 100.261630s\n",
      "Epoch: [161/1000] time: 0.7290s, d_loss: 0.22285365, g_loss: 3.42712426, rnn_loss: 0.09635046\n",
      " ** Epoch 161 took 100.554044s\n",
      "Epoch: [162/1000] time: 0.7219s, d_loss: 0.40777034, g_loss: 2.40263271, rnn_loss: 0.12606698\n",
      " ** Epoch 162 took 100.343001s\n",
      "Epoch: [163/1000] time: 0.7254s, d_loss: 0.51460087, g_loss: 1.95329857, rnn_loss: 0.10200389\n",
      " ** Epoch 163 took 100.713300s\n",
      "Epoch: [164/1000] time: 0.7272s, d_loss: 0.42957303, g_loss: 2.90761065, rnn_loss: 0.10176374\n",
      " ** Epoch 164 took 101.220356s\n",
      "Epoch: [165/1000] time: 0.7298s, d_loss: 1.11209905, g_loss: 0.40400916, rnn_loss: 0.09300362\n",
      " ** Epoch 165 took 100.961171s\n",
      "Epoch: [166/1000] time: 0.7250s, d_loss: 0.40696889, g_loss: 2.49394846, rnn_loss: 0.08590059\n",
      " ** Epoch 166 took 100.495564s\n",
      "Epoch: [167/1000] time: 0.7256s, d_loss: 0.45752862, g_loss: 3.66533661, rnn_loss: 0.10472904\n",
      " ** Epoch 167 took 100.700738s\n",
      "Epoch: [168/1000] time: 0.7255s, d_loss: 0.58373624, g_loss: 1.88933694, rnn_loss: 0.11081715\n",
      " ** Epoch 168 took 100.392543s\n",
      "Epoch: [169/1000] time: 0.7276s, d_loss: 0.55449975, g_loss: 1.21102452, rnn_loss: 0.11252043\n",
      " ** Epoch 169 took 100.428825s\n",
      "Epoch: [170/1000] time: 0.7313s, d_loss: 0.48284459, g_loss: 1.23259962, rnn_loss: 0.10044269\n",
      " ** Epoch 170 took 100.545201s\n",
      "Epoch: [171/1000] time: 0.7251s, d_loss: 0.45653164, g_loss: 2.33163691, rnn_loss: 0.13114263\n",
      " ** Epoch 171 took 100.253576s\n",
      "Epoch: [172/1000] time: 0.7348s, d_loss: 0.41728002, g_loss: 2.89720273, rnn_loss: 0.13272017\n",
      " ** Epoch 172 took 100.435386s\n",
      "Epoch: [173/1000] time: 0.7307s, d_loss: 0.24360177, g_loss: 3.51890588, rnn_loss: 0.08515784\n",
      " ** Epoch 173 took 100.567933s\n",
      "Epoch: [174/1000] time: 0.7253s, d_loss: 0.49836856, g_loss: 1.67268586, rnn_loss: 0.07439479\n",
      " ** Epoch 174 took 100.300302s\n",
      "Epoch: [175/1000] time: 0.7352s, d_loss: 0.46468991, g_loss: 2.66427088, rnn_loss: 0.08690313\n",
      " ** Epoch 175 took 100.413338s\n",
      "Epoch: [176/1000] time: 0.7338s, d_loss: 0.17653991, g_loss: 2.85943007, rnn_loss: 0.12554681\n",
      " ** Epoch 176 took 101.516675s\n",
      "Epoch: [177/1000] time: 0.7435s, d_loss: 0.83643073, g_loss: 1.86408722, rnn_loss: 0.12230119\n",
      " ** Epoch 177 took 101.237979s\n",
      "Epoch: [178/1000] time: 0.7334s, d_loss: 0.85163599, g_loss: 1.18952167, rnn_loss: 0.13729149\n",
      " ** Epoch 178 took 101.720831s\n",
      "Epoch: [179/1000] time: 0.7267s, d_loss: 0.51601428, g_loss: 1.28089607, rnn_loss: 0.08717456\n",
      " ** Epoch 179 took 101.710502s\n",
      "Epoch: [180/1000] time: 0.7362s, d_loss: 0.31163079, g_loss: 3.07631421, rnn_loss: 0.15157914\n",
      " ** Epoch 180 took 100.680645s\n",
      "Epoch: [181/1000] time: 0.7292s, d_loss: 0.45621955, g_loss: 1.82828987, rnn_loss: 0.11357835\n",
      " ** Epoch 181 took 100.643050s\n",
      "Epoch: [182/1000] time: 0.7269s, d_loss: 0.52125227, g_loss: 2.34962940, rnn_loss: 0.12591034\n",
      " ** Epoch 182 took 100.642084s\n",
      "Epoch: [183/1000] time: 0.7312s, d_loss: 0.26562813, g_loss: 3.19047689, rnn_loss: 0.06131620\n",
      " ** Epoch 183 took 100.350683s\n",
      "Epoch: [184/1000] time: 0.7236s, d_loss: 0.60693645, g_loss: 2.91479301, rnn_loss: 0.15650511\n",
      " ** Epoch 184 took 100.323016s\n",
      "Epoch: [185/1000] time: 0.7395s, d_loss: 0.98760188, g_loss: 0.40993237, rnn_loss: 0.07730173\n",
      " ** Epoch 185 took 100.750059s\n",
      "Epoch: [186/1000] time: 0.7277s, d_loss: 0.69003755, g_loss: 1.18079829, rnn_loss: 0.07916994\n",
      " ** Epoch 186 took 100.409592s\n",
      "Epoch: [187/1000] time: 0.7254s, d_loss: 0.40445408, g_loss: 2.25680256, rnn_loss: 0.06929360\n",
      " ** Epoch 187 took 100.887690s\n",
      "Epoch: [188/1000] time: 0.7597s, d_loss: 0.67777699, g_loss: 4.40661287, rnn_loss: 0.11441839\n",
      " ** Epoch 188 took 100.810578s\n",
      "Epoch: [189/1000] time: 0.7412s, d_loss: 0.76652890, g_loss: 3.81512165, rnn_loss: 0.06374439\n",
      " ** Epoch 189 took 101.960966s\n",
      "Epoch: [190/1000] time: 0.7286s, d_loss: 0.64150441, g_loss: 3.82765460, rnn_loss: 0.09990948\n",
      " ** Epoch 190 took 100.723857s\n",
      "Epoch: [191/1000] time: 0.7251s, d_loss: 0.27769247, g_loss: 2.12526083, rnn_loss: 0.08851594\n",
      " ** Epoch 191 took 100.391177s\n",
      "Epoch: [192/1000] time: 0.7341s, d_loss: 0.47572657, g_loss: 1.54671824, rnn_loss: 0.11747988\n",
      " ** Epoch 192 took 100.690016s\n",
      "Epoch: [193/1000] time: 0.7347s, d_loss: 0.44453260, g_loss: 1.73513818, rnn_loss: 0.11785579\n",
      " ** Epoch 193 took 100.368820s\n",
      "Epoch: [194/1000] time: 0.7332s, d_loss: 0.42420352, g_loss: 2.52905512, rnn_loss: 0.11557100\n",
      " ** Epoch 194 took 100.136320s\n",
      "Epoch: [195/1000] time: 0.7225s, d_loss: 0.59875798, g_loss: 3.15931058, rnn_loss: 0.11910410\n",
      " ** Epoch 195 took 100.394616s\n",
      "Epoch: [196/1000] time: 0.7518s, d_loss: 0.34290123, g_loss: 2.82004881, rnn_loss: 0.08840790\n",
      " ** Epoch 196 took 100.314581s\n",
      "Epoch: [197/1000] time: 0.7308s, d_loss: 0.67728055, g_loss: 1.37867761, rnn_loss: 0.09282479\n",
      " ** Epoch 197 took 100.666410s\n",
      "Epoch: [198/1000] time: 0.7251s, d_loss: 0.68145239, g_loss: 3.23587370, rnn_loss: 0.13009140\n",
      " ** Epoch 198 took 100.561974s\n",
      "Epoch: [199/1000] time: 0.7296s, d_loss: 0.46035868, g_loss: 2.54072952, rnn_loss: 0.09791575\n",
      " ** Epoch 199 took 100.227617s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** new learning rate: 0.000100\n",
      "Epoch: [200/1000] time: 0.7350s, d_loss: 0.68554288, g_loss: 1.47026610, rnn_loss: 0.08299430\n",
      " ** Epoch 200 took 100.723303s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [201/1000] time: 0.7307s, d_loss: 0.39364752, g_loss: 1.86816347, rnn_loss: 0.12625578\n",
      " ** Epoch 201 took 101.385787s\n",
      "Epoch: [202/1000] time: 0.7348s, d_loss: 0.30989486, g_loss: 1.98233652, rnn_loss: 0.12357607\n",
      " ** Epoch 202 took 101.176440s\n",
      "Epoch: [203/1000] time: 0.7333s, d_loss: 0.36042565, g_loss: 1.52097631, rnn_loss: 0.11553637\n",
      " ** Epoch 203 took 101.005152s\n",
      "Epoch: [204/1000] time: 0.7321s, d_loss: 0.33497396, g_loss: 2.28640747, rnn_loss: 0.08232877\n",
      " ** Epoch 204 took 101.170265s\n",
      "Epoch: [205/1000] time: 0.7317s, d_loss: 0.40763026, g_loss: 1.29966164, rnn_loss: 0.09354288\n",
      " ** Epoch 205 took 101.019372s\n",
      "Epoch: [206/1000] time: 0.7290s, d_loss: 0.40399712, g_loss: 2.23905420, rnn_loss: 0.11000635\n",
      " ** Epoch 206 took 100.832890s\n",
      "Epoch: [207/1000] time: 0.7296s, d_loss: 0.33121872, g_loss: 1.71056056, rnn_loss: 0.11472412\n",
      " ** Epoch 207 took 101.266013s\n",
      "Epoch: [208/1000] time: 0.7316s, d_loss: 0.33718151, g_loss: 2.39906597, rnn_loss: 0.13158509\n",
      " ** Epoch 208 took 101.071446s\n",
      "Epoch: [209/1000] time: 0.7337s, d_loss: 0.37456146, g_loss: 1.87861097, rnn_loss: 0.06145211\n",
      " ** Epoch 209 took 100.968811s\n",
      "Epoch: [210/1000] time: 0.7253s, d_loss: 0.33121336, g_loss: 3.09030199, rnn_loss: 0.12308331\n",
      " ** Epoch 210 took 101.260662s\n",
      "Epoch: [211/1000] time: 0.7276s, d_loss: 0.53056502, g_loss: 2.24888039, rnn_loss: 0.09631670\n",
      " ** Epoch 211 took 101.142547s\n",
      "Epoch: [212/1000] time: 0.7288s, d_loss: 0.30906948, g_loss: 2.25071073, rnn_loss: 0.10013784\n",
      " ** Epoch 212 took 100.902195s\n",
      "Epoch: [213/1000] time: 0.7514s, d_loss: 0.19461915, g_loss: 2.49480343, rnn_loss: 0.11067925\n",
      " ** Epoch 213 took 101.144446s\n",
      "Epoch: [214/1000] time: 0.7289s, d_loss: 0.74738878, g_loss: 1.76155972, rnn_loss: 0.07269504\n",
      " ** Epoch 214 took 101.590751s\n",
      "Epoch: [215/1000] time: 0.7263s, d_loss: 0.49568254, g_loss: 1.77161181, rnn_loss: 0.09113750\n",
      " ** Epoch 215 took 100.293959s\n",
      "Epoch: [216/1000] time: 0.7259s, d_loss: 0.38932025, g_loss: 2.36240077, rnn_loss: 0.05362239\n",
      " ** Epoch 216 took 100.424337s\n",
      "Epoch: [217/1000] time: 0.7287s, d_loss: 0.11353063, g_loss: 3.75843525, rnn_loss: 0.08661646\n",
      " ** Epoch 217 took 100.376537s\n",
      "Epoch: [218/1000] time: 0.7299s, d_loss: 0.25450110, g_loss: 2.40986371, rnn_loss: 0.07936496\n",
      " ** Epoch 218 took 100.387079s\n",
      "Epoch: [219/1000] time: 0.7234s, d_loss: 0.92051595, g_loss: 0.77596867, rnn_loss: 0.07963054\n",
      " ** Epoch 219 took 100.732896s\n",
      "Epoch: [220/1000] time: 0.7242s, d_loss: 0.40092263, g_loss: 2.91161108, rnn_loss: 0.07678367\n",
      " ** Epoch 220 took 100.267614s\n",
      "Epoch: [221/1000] time: 0.7223s, d_loss: 0.39576930, g_loss: 2.24121213, rnn_loss: 0.08223549\n",
      " ** Epoch 221 took 100.097792s\n",
      "Epoch: [222/1000] time: 0.7277s, d_loss: 0.19099557, g_loss: 2.94786453, rnn_loss: 0.08350828\n",
      " ** Epoch 222 took 100.317856s\n",
      "Epoch: [223/1000] time: 0.7259s, d_loss: 0.36243415, g_loss: 1.81044841, rnn_loss: 0.10253338\n",
      " ** Epoch 223 took 100.418948s\n",
      "Epoch: [224/1000] time: 0.7275s, d_loss: 0.33924180, g_loss: 2.39844513, rnn_loss: 0.09877144\n",
      " ** Epoch 224 took 100.387725s\n",
      "Epoch: [225/1000] time: 0.7235s, d_loss: 0.56483513, g_loss: 3.09980202, rnn_loss: 0.09046617\n",
      " ** Epoch 225 took 100.718626s\n",
      "Epoch: [226/1000] time: 0.7420s, d_loss: 0.34549955, g_loss: 1.85582566, rnn_loss: 0.07189243\n",
      " ** Epoch 226 took 100.536698s\n",
      "Epoch: [227/1000] time: 0.7353s, d_loss: 0.34424853, g_loss: 1.84254146, rnn_loss: 0.07362966\n",
      " ** Epoch 227 took 100.366800s\n",
      "Epoch: [228/1000] time: 0.7284s, d_loss: 0.18109271, g_loss: 3.19319797, rnn_loss: 0.06942619\n",
      " ** Epoch 228 took 100.662776s\n",
      "Epoch: [229/1000] time: 0.7399s, d_loss: 0.92585301, g_loss: 1.48510504, rnn_loss: 0.07962140\n",
      " ** Epoch 229 took 100.182300s\n",
      "Epoch: [230/1000] time: 0.7274s, d_loss: 0.70554447, g_loss: 2.57278776, rnn_loss: 0.05250175\n",
      " ** Epoch 230 took 100.171060s\n",
      "Epoch: [231/1000] time: 0.7226s, d_loss: 0.86867708, g_loss: 0.97391945, rnn_loss: 0.07485185\n",
      " ** Epoch 231 took 100.462456s\n",
      "Epoch: [232/1000] time: 0.7254s, d_loss: 1.06197357, g_loss: 0.89055824, rnn_loss: 0.10472411\n",
      " ** Epoch 232 took 100.137159s\n",
      "Epoch: [233/1000] time: 0.7263s, d_loss: 0.20292559, g_loss: 2.02894878, rnn_loss: 0.08068721\n",
      " ** Epoch 233 took 100.190237s\n",
      "Epoch: [234/1000] time: 0.7309s, d_loss: 0.29889953, g_loss: 1.99631584, rnn_loss: 0.09638771\n",
      " ** Epoch 234 took 100.434292s\n",
      "Epoch: [235/1000] time: 0.7259s, d_loss: 0.30417550, g_loss: 2.16500068, rnn_loss: 0.11676322\n",
      " ** Epoch 235 took 100.248971s\n",
      "Epoch: [236/1000] time: 0.7286s, d_loss: 0.38218331, g_loss: 2.19661427, rnn_loss: 0.08398609\n",
      " ** Epoch 236 took 100.501526s\n",
      "Epoch: [237/1000] time: 0.7610s, d_loss: 0.28410462, g_loss: 2.34624386, rnn_loss: 0.05117511\n",
      " ** Epoch 237 took 100.959006s\n",
      "Epoch: [238/1000] time: 0.7342s, d_loss: 0.35299611, g_loss: 1.70352042, rnn_loss: 0.09899746\n",
      " ** Epoch 238 took 101.251409s\n",
      "Epoch: [239/1000] time: 0.7250s, d_loss: 0.52592129, g_loss: 2.59527445, rnn_loss: 0.12465338\n",
      " ** Epoch 239 took 100.428795s\n",
      "Epoch: [240/1000] time: 0.7299s, d_loss: 0.24268895, g_loss: 3.00771189, rnn_loss: 0.12086134\n",
      " ** Epoch 240 took 101.534046s\n",
      "Epoch: [241/1000] time: 0.7328s, d_loss: 0.63153344, g_loss: 1.25361884, rnn_loss: 0.06379893\n",
      " ** Epoch 241 took 101.266890s\n",
      "Epoch: [242/1000] time: 0.7312s, d_loss: 0.44378084, g_loss: 2.62745428, rnn_loss: 0.10416828\n",
      " ** Epoch 242 took 101.042400s\n",
      "Epoch: [243/1000] time: 0.7436s, d_loss: 0.77327597, g_loss: 3.92600870, rnn_loss: 0.11381575\n",
      " ** Epoch 243 took 101.056679s\n",
      "Epoch: [244/1000] time: 0.7340s, d_loss: 0.64937335, g_loss: 2.87339711, rnn_loss: 0.11126233\n",
      " ** Epoch 244 took 101.733746s\n",
      "Epoch: [245/1000] time: 0.7320s, d_loss: 0.15952630, g_loss: 2.30256534, rnn_loss: 0.08383520\n",
      " ** Epoch 245 took 101.250013s\n",
      "Epoch: [246/1000] time: 0.7285s, d_loss: 0.41012877, g_loss: 1.82547474, rnn_loss: 0.10018829\n",
      " ** Epoch 246 took 100.749853s\n",
      "Epoch: [247/1000] time: 0.7343s, d_loss: 0.35775495, g_loss: 2.10804653, rnn_loss: 0.07447416\n",
      " ** Epoch 247 took 101.999110s\n",
      "Epoch: [248/1000] time: 0.7524s, d_loss: 0.39621198, g_loss: 2.26841593, rnn_loss: 0.09297424\n",
      " ** Epoch 248 took 102.104023s\n",
      "Epoch: [249/1000] time: 0.7346s, d_loss: 0.37730575, g_loss: 3.04283953, rnn_loss: 0.08863404\n",
      " ** Epoch 249 took 101.593612s\n",
      "Epoch: [250/1000] time: 0.7315s, d_loss: 0.29535684, g_loss: 1.72071171, rnn_loss: 0.09467164\n",
      " ** Epoch 250 took 101.467856s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [251/1000] time: 0.7328s, d_loss: 0.34448025, g_loss: 2.94610357, rnn_loss: 0.08921398\n",
      " ** Epoch 251 took 101.169708s\n",
      "Epoch: [252/1000] time: 0.7563s, d_loss: 0.38927898, g_loss: 3.01061630, rnn_loss: 0.10856219\n",
      " ** Epoch 252 took 101.396892s\n",
      "Epoch: [253/1000] time: 0.7319s, d_loss: 0.48111796, g_loss: 2.34936595, rnn_loss: 0.06039239\n",
      " ** Epoch 253 took 101.359352s\n",
      "Epoch: [254/1000] time: 0.7364s, d_loss: 0.60823619, g_loss: 1.88617039, rnn_loss: 0.07592279\n",
      " ** Epoch 254 took 101.054065s\n",
      "Epoch: [255/1000] time: 0.7334s, d_loss: 0.67182875, g_loss: 1.78821611, rnn_loss: 0.04816528\n",
      " ** Epoch 255 took 101.360748s\n",
      "Epoch: [256/1000] time: 0.7310s, d_loss: 0.37174219, g_loss: 2.00051117, rnn_loss: 0.06806658\n",
      " ** Epoch 256 took 101.545759s\n",
      "Epoch: [257/1000] time: 0.7383s, d_loss: 0.22580737, g_loss: 2.80221081, rnn_loss: 0.08627982\n",
      " ** Epoch 257 took 101.704525s\n",
      "Epoch: [258/1000] time: 0.7347s, d_loss: 0.23805305, g_loss: 3.05655956, rnn_loss: 0.05896230\n",
      " ** Epoch 258 took 101.557531s\n",
      "Epoch: [259/1000] time: 0.7310s, d_loss: 0.32252651, g_loss: 2.48725510, rnn_loss: 0.08946635\n",
      " ** Epoch 259 took 101.537294s\n",
      "Epoch: [260/1000] time: 0.7289s, d_loss: 0.16580760, g_loss: 3.31295967, rnn_loss: 0.07578788\n",
      " ** Epoch 260 took 101.058263s\n",
      "Epoch: [261/1000] time: 0.7303s, d_loss: 0.29382765, g_loss: 1.88604760, rnn_loss: 0.08322532\n",
      " ** Epoch 261 took 102.053914s\n",
      "Epoch: [262/1000] time: 0.7382s, d_loss: 0.36476061, g_loss: 1.67999268, rnn_loss: 0.12178101\n",
      " ** Epoch 262 took 100.898272s\n",
      "Epoch: [263/1000] time: 0.7255s, d_loss: 0.67410988, g_loss: 1.24369764, rnn_loss: 0.10242854\n",
      " ** Epoch 263 took 100.508477s\n",
      "Epoch: [264/1000] time: 0.7311s, d_loss: 0.81170118, g_loss: 2.12692404, rnn_loss: 0.10773933\n",
      " ** Epoch 264 took 100.605246s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [265/1000] time: 0.7280s, d_loss: 0.29639593, g_loss: 1.97412479, rnn_loss: 0.08518781\n",
      " ** Epoch 265 took 100.986466s\n",
      "Epoch: [266/1000] time: 0.7285s, d_loss: 0.28512785, g_loss: 2.35233188, rnn_loss: 0.10793336\n",
      " ** Epoch 266 took 100.484382s\n",
      "Epoch: [267/1000] time: 0.7332s, d_loss: 0.52441961, g_loss: 1.35312891, rnn_loss: 0.07670699\n",
      " ** Epoch 267 took 100.426997s\n",
      "Epoch: [268/1000] time: 0.7294s, d_loss: 0.31828138, g_loss: 2.50327587, rnn_loss: 0.10760441\n",
      " ** Epoch 268 took 100.853459s\n",
      "Epoch: [269/1000] time: 0.7264s, d_loss: 0.26218948, g_loss: 2.77501059, rnn_loss: 0.05476382\n",
      " ** Epoch 269 took 100.642251s\n",
      "Epoch: [270/1000] time: 0.7239s, d_loss: 0.25869757, g_loss: 2.30982447, rnn_loss: 0.07530057\n",
      " ** Epoch 270 took 100.441041s\n",
      "Epoch: [271/1000] time: 0.7374s, d_loss: 0.34136382, g_loss: 1.86899471, rnn_loss: 0.05409866\n",
      " ** Epoch 271 took 100.711624s\n",
      "Epoch: [272/1000] time: 0.7244s, d_loss: 0.48648956, g_loss: 3.37645102, rnn_loss: 0.07512838\n",
      " ** Epoch 272 took 100.464275s\n",
      "Epoch: [273/1000] time: 0.7298s, d_loss: 0.90890384, g_loss: 1.95334363, rnn_loss: 0.07978296\n",
      " ** Epoch 273 took 100.503957s\n",
      "Epoch: [274/1000] time: 0.7384s, d_loss: 0.35597250, g_loss: 2.73815346, rnn_loss: 0.07423756\n",
      " ** Epoch 274 took 100.665262s\n",
      "Epoch: [275/1000] time: 0.7304s, d_loss: 0.13240144, g_loss: 2.93746448, rnn_loss: 0.10208909\n",
      " ** Epoch 275 took 100.642227s\n",
      "Epoch: [276/1000] time: 0.7261s, d_loss: 0.39374238, g_loss: 1.83398116, rnn_loss: 0.07948673\n",
      " ** Epoch 276 took 100.628916s\n",
      "Epoch: [277/1000] time: 0.7258s, d_loss: 0.16987109, g_loss: 3.46692872, rnn_loss: 0.08066716\n",
      " ** Epoch 277 took 101.146722s\n",
      "Epoch: [278/1000] time: 0.7502s, d_loss: 0.41317576, g_loss: 1.77715755, rnn_loss: 0.08256315\n",
      " ** Epoch 278 took 101.078191s\n",
      "Epoch: [279/1000] time: 0.7295s, d_loss: 0.27023169, g_loss: 3.12941647, rnn_loss: 0.09257562\n",
      " ** Epoch 279 took 102.496219s\n",
      "Epoch: [280/1000] time: 0.7263s, d_loss: 0.28685904, g_loss: 2.38347769, rnn_loss: 0.11177099\n",
      " ** Epoch 280 took 100.738988s\n",
      "Epoch: [281/1000] time: 0.7357s, d_loss: 0.58797991, g_loss: 1.91606474, rnn_loss: 0.07255928\n",
      " ** Epoch 281 took 101.188970s\n",
      "Epoch: [282/1000] time: 0.7323s, d_loss: 0.39929405, g_loss: 2.19181752, rnn_loss: 0.07866210\n",
      " ** Epoch 282 took 101.523723s\n",
      "Epoch: [283/1000] time: 0.7272s, d_loss: 0.49444711, g_loss: 2.41029978, rnn_loss: 0.07088567\n",
      " ** Epoch 283 took 101.411762s\n",
      "Epoch: [284/1000] time: 0.7316s, d_loss: 0.18010281, g_loss: 3.06018949, rnn_loss: 0.05244683\n",
      " ** Epoch 284 took 101.085900s\n",
      "Epoch: [285/1000] time: 0.7314s, d_loss: 0.41446927, g_loss: 2.34283209, rnn_loss: 0.03824563\n",
      " ** Epoch 285 took 100.745363s\n",
      "Epoch: [286/1000] time: 0.7220s, d_loss: 0.19951968, g_loss: 2.32060838, rnn_loss: 0.04895108\n",
      " ** Epoch 286 took 101.076927s\n",
      "Epoch: [287/1000] time: 0.7350s, d_loss: 0.29403770, g_loss: 2.51809192, rnn_loss: 0.09060507\n",
      " ** Epoch 287 took 100.471624s\n",
      "Epoch: [288/1000] time: 0.7345s, d_loss: 0.10760688, g_loss: 3.12654448, rnn_loss: 0.06313467\n",
      " ** Epoch 288 took 102.815106s\n",
      "Epoch: [289/1000] time: 0.7343s, d_loss: 0.11582771, g_loss: 3.47484446, rnn_loss: 0.07965646\n",
      " ** Epoch 289 took 101.792116s\n",
      "Epoch: [290/1000] time: 0.7419s, d_loss: 0.18655795, g_loss: 2.69006205, rnn_loss: 0.11223836\n",
      " ** Epoch 290 took 101.641139s\n",
      "Epoch: [291/1000] time: 0.7355s, d_loss: 0.41168052, g_loss: 1.86626196, rnn_loss: 0.06196449\n",
      " ** Epoch 291 took 102.012975s\n",
      "Epoch: [292/1000] time: 0.7539s, d_loss: 0.19131716, g_loss: 3.07769632, rnn_loss: 0.07994074\n",
      " ** Epoch 292 took 102.904936s\n",
      "Epoch: [293/1000] time: 0.7465s, d_loss: 0.40035167, g_loss: 3.04257774, rnn_loss: 0.12040450\n",
      " ** Epoch 293 took 103.210008s\n",
      "Epoch: [294/1000] time: 0.7451s, d_loss: 0.19506922, g_loss: 2.64046049, rnn_loss: 0.07330120\n",
      " ** Epoch 294 took 103.024514s\n",
      "Epoch: [295/1000] time: 0.7561s, d_loss: 0.16025937, g_loss: 3.62910271, rnn_loss: 0.09714466\n",
      " ** Epoch 295 took 103.086864s\n",
      "Epoch: [296/1000] time: 0.7448s, d_loss: 0.41706541, g_loss: 1.54902911, rnn_loss: 0.10593265\n",
      " ** Epoch 296 took 103.016368s\n",
      "Epoch: [297/1000] time: 0.7434s, d_loss: 0.59584576, g_loss: 4.60635853, rnn_loss: 0.10170031\n",
      " ** Epoch 297 took 103.021608s\n",
      "Epoch: [298/1000] time: 0.7318s, d_loss: 0.40780160, g_loss: 2.99759150, rnn_loss: 0.09974451\n",
      " ** Epoch 298 took 103.697761s\n",
      "Epoch: [299/1000] time: 0.7480s, d_loss: 0.48681533, g_loss: 1.49325073, rnn_loss: 0.06870916\n",
      " ** Epoch 299 took 101.958411s\n",
      "Epoch: [300/1000] time: 0.6876s, d_loss: 0.13356705, g_loss: 2.09401226, rnn_loss: 0.00000000\n",
      " ** Epoch 300 took 94.986714s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [301/1000] time: 0.6872s, d_loss: 0.33172566, g_loss: 2.29123712, rnn_loss: 0.00000000\n",
      " ** Epoch 301 took 95.163550s\n",
      "Epoch: [302/1000] time: 0.6835s, d_loss: 0.69840163, g_loss: 2.43882155, rnn_loss: 0.00000000\n",
      " ** Epoch 302 took 94.616325s\n",
      "Epoch: [303/1000] time: 0.6920s, d_loss: 0.21607149, g_loss: 2.17179108, rnn_loss: 0.00000000\n",
      " ** Epoch 303 took 95.459547s\n",
      "Epoch: [304/1000] time: 0.7075s, d_loss: 0.22335313, g_loss: 3.01714706, rnn_loss: 0.00000000\n",
      " ** Epoch 304 took 95.065858s\n",
      "Epoch: [305/1000] time: 0.6892s, d_loss: 0.33604634, g_loss: 2.58109188, rnn_loss: 0.00000000\n",
      " ** Epoch 305 took 95.194819s\n",
      "Epoch: [306/1000] time: 0.7077s, d_loss: 0.22862214, g_loss: 2.90383911, rnn_loss: 0.00000000\n",
      " ** Epoch 306 took 95.495958s\n",
      "Epoch: [307/1000] time: 0.7035s, d_loss: 0.35884595, g_loss: 3.50605297, rnn_loss: 0.00000000\n",
      " ** Epoch 307 took 95.114582s\n",
      "Epoch: [308/1000] time: 0.6947s, d_loss: 0.12788175, g_loss: 3.48592901, rnn_loss: 0.00000000\n",
      " ** Epoch 308 took 96.008220s\n",
      "Epoch: [309/1000] time: 0.6842s, d_loss: 0.36972946, g_loss: 3.77374887, rnn_loss: 0.00000000\n",
      " ** Epoch 309 took 94.937989s\n",
      "Epoch: [310/1000] time: 0.6880s, d_loss: 0.40858248, g_loss: 4.04159451, rnn_loss: 0.00000000\n",
      " ** Epoch 310 took 95.026339s\n",
      "Epoch: [311/1000] time: 0.6893s, d_loss: 0.56536663, g_loss: 3.89007902, rnn_loss: 0.00000000\n",
      " ** Epoch 311 took 95.919157s\n",
      "Epoch: [312/1000] time: 0.6872s, d_loss: 0.30968690, g_loss: 2.39260483, rnn_loss: 0.00000000\n",
      " ** Epoch 312 took 94.899962s\n",
      "Epoch: [313/1000] time: 0.6913s, d_loss: 0.40632153, g_loss: 2.81436300, rnn_loss: 0.00000000\n",
      " ** Epoch 313 took 95.455752s\n",
      "Epoch: [314/1000] time: 0.6996s, d_loss: 0.15050268, g_loss: 3.61620712, rnn_loss: 0.00000000\n",
      " ** Epoch 314 took 96.554980s\n",
      "Epoch: [315/1000] time: 0.6905s, d_loss: 0.42382267, g_loss: 1.89970112, rnn_loss: 0.00000000\n",
      " ** Epoch 315 took 95.825916s\n",
      "Epoch: [316/1000] time: 0.6901s, d_loss: 0.15522115, g_loss: 2.93879342, rnn_loss: 0.00000000\n",
      " ** Epoch 316 took 95.406994s\n",
      "Epoch: [317/1000] time: 0.7052s, d_loss: 0.18716261, g_loss: 2.80108094, rnn_loss: 0.00000000\n",
      " ** Epoch 317 took 95.207330s\n",
      "Epoch: [318/1000] time: 0.6905s, d_loss: 0.21477818, g_loss: 2.49716043, rnn_loss: 0.00000000\n",
      " ** Epoch 318 took 96.186111s\n",
      "Epoch: [319/1000] time: 0.6908s, d_loss: 0.52573431, g_loss: 1.25726795, rnn_loss: 0.00000000\n",
      " ** Epoch 319 took 95.589729s\n",
      "Epoch: [320/1000] time: 0.6913s, d_loss: 0.47907361, g_loss: 1.26219845, rnn_loss: 0.00000000\n",
      " ** Epoch 320 took 95.645051s\n",
      "Epoch: [321/1000] time: 0.6950s, d_loss: 0.15737572, g_loss: 2.57174349, rnn_loss: 0.00000000\n",
      " ** Epoch 321 took 95.686061s\n",
      "Epoch: [322/1000] time: 0.6889s, d_loss: 0.84792072, g_loss: 1.41693521, rnn_loss: 0.00000000\n",
      " ** Epoch 322 took 95.376786s\n",
      "Epoch: [323/1000] time: 0.6888s, d_loss: 0.30374381, g_loss: 3.63450241, rnn_loss: 0.00000000\n",
      " ** Epoch 323 took 95.262665s\n",
      "Epoch: [324/1000] time: 0.7012s, d_loss: 0.29203823, g_loss: 3.12464929, rnn_loss: 0.00000000\n",
      " ** Epoch 324 took 96.049522s\n",
      "Epoch: [325/1000] time: 0.6879s, d_loss: 0.29929909, g_loss: 1.82544971, rnn_loss: 0.00000000\n",
      " ** Epoch 325 took 95.559370s\n",
      "Epoch: [326/1000] time: 0.6906s, d_loss: 0.20580035, g_loss: 2.49275994, rnn_loss: 0.00000000\n",
      " ** Epoch 326 took 95.123371s\n",
      "Epoch: [327/1000] time: 0.6864s, d_loss: 0.45856017, g_loss: 3.20559502, rnn_loss: 0.00000000\n",
      " ** Epoch 327 took 95.268151s\n",
      "Epoch: [328/1000] time: 0.6909s, d_loss: 0.26013380, g_loss: 2.88063431, rnn_loss: 0.00000000\n",
      " ** Epoch 328 took 94.907333s\n",
      "Epoch: [329/1000] time: 0.7009s, d_loss: 0.45073113, g_loss: 1.91787457, rnn_loss: 0.00000000\n",
      " ** Epoch 329 took 95.867505s\n",
      "Epoch: [330/1000] time: 0.7288s, d_loss: 0.84213012, g_loss: 3.73625565, rnn_loss: 0.00000000\n",
      " ** Epoch 330 took 96.099188s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [331/1000] time: 0.6862s, d_loss: 0.53908539, g_loss: 1.73854375, rnn_loss: 0.00000000\n",
      " ** Epoch 331 took 95.554707s\n",
      "Epoch: [332/1000] time: 0.6895s, d_loss: 0.53178620, g_loss: 1.68420684, rnn_loss: 0.00000000\n",
      " ** Epoch 332 took 95.120155s\n",
      "Epoch: [333/1000] time: 0.6915s, d_loss: 0.33108112, g_loss: 3.20127678, rnn_loss: 0.00000000\n",
      " ** Epoch 333 took 94.955430s\n",
      "Epoch: [334/1000] time: 0.6891s, d_loss: 0.37862426, g_loss: 3.36491752, rnn_loss: 0.00000000\n",
      " ** Epoch 334 took 95.896468s\n",
      "Epoch: [335/1000] time: 0.6879s, d_loss: 0.35916191, g_loss: 1.13773608, rnn_loss: 0.00000000\n",
      " ** Epoch 335 took 95.161989s\n",
      "Epoch: [336/1000] time: 0.6932s, d_loss: 0.36986715, g_loss: 3.73849630, rnn_loss: 0.00000000\n",
      " ** Epoch 336 took 95.188981s\n",
      "Epoch: [337/1000] time: 0.6941s, d_loss: 0.32665598, g_loss: 2.00104594, rnn_loss: 0.00000000\n",
      " ** Epoch 337 took 95.673546s\n",
      "Epoch: [338/1000] time: 0.6939s, d_loss: 0.36614895, g_loss: 3.10471869, rnn_loss: 0.00000000\n",
      " ** Epoch 338 took 95.467385s\n",
      "Epoch: [339/1000] time: 0.6859s, d_loss: 0.42390755, g_loss: 2.52220416, rnn_loss: 0.00000000\n",
      " ** Epoch 339 took 95.267734s\n",
      "Epoch: [340/1000] time: 0.6921s, d_loss: 0.21486399, g_loss: 2.57942152, rnn_loss: 0.00000000\n",
      " ** Epoch 340 took 95.418011s\n",
      "Epoch: [341/1000] time: 0.6853s, d_loss: 0.17277476, g_loss: 3.32403803, rnn_loss: 0.00000000\n",
      " ** Epoch 341 took 96.123426s\n",
      "Epoch: [342/1000] time: 0.6927s, d_loss: 0.52317858, g_loss: 1.04220235, rnn_loss: 0.00000000\n",
      " ** Epoch 342 took 95.012185s\n",
      "Epoch: [343/1000] time: 0.7054s, d_loss: 0.23163135, g_loss: 2.91469383, rnn_loss: 0.00000000\n",
      " ** Epoch 343 took 95.513959s\n",
      "Epoch: [344/1000] time: 0.6895s, d_loss: 0.19675669, g_loss: 2.99732876, rnn_loss: 0.00000000\n",
      " ** Epoch 344 took 95.190393s\n",
      "Epoch: [345/1000] time: 0.6866s, d_loss: 0.45279056, g_loss: 3.52479053, rnn_loss: 0.00000000\n",
      " ** Epoch 345 took 95.211626s\n",
      "Epoch: [346/1000] time: 0.6840s, d_loss: 0.31050929, g_loss: 1.73653460, rnn_loss: 0.00000000\n",
      " ** Epoch 346 took 95.256103s\n",
      "Epoch: [347/1000] time: 0.6929s, d_loss: 0.26625469, g_loss: 1.98119318, rnn_loss: 0.00000000\n",
      " ** Epoch 347 took 95.286314s\n",
      "Epoch: [348/1000] time: 0.6863s, d_loss: 0.92731625, g_loss: 2.80291939, rnn_loss: 0.00000000\n",
      " ** Epoch 348 took 95.054407s\n",
      "Epoch: [349/1000] time: 0.6872s, d_loss: 0.37924778, g_loss: 3.13507771, rnn_loss: 0.00000000\n",
      " ** Epoch 349 took 95.155225s\n",
      "Epoch: [350/1000] time: 0.6863s, d_loss: 0.09448110, g_loss: 4.19944572, rnn_loss: 0.00000000\n",
      " ** Epoch 350 took 95.294958s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [351/1000] time: 0.6961s, d_loss: 0.37773517, g_loss: 1.97619176, rnn_loss: 0.00000000\n",
      " ** Epoch 351 took 95.278996s\n",
      "Epoch: [352/1000] time: 0.6869s, d_loss: 0.39674753, g_loss: 2.29844522, rnn_loss: 0.00000000\n",
      " ** Epoch 352 took 95.481712s\n",
      "Epoch: [353/1000] time: 0.7069s, d_loss: 0.32050559, g_loss: 2.63763475, rnn_loss: 0.00000000\n",
      " ** Epoch 353 took 95.861844s\n",
      "Epoch: [354/1000] time: 0.7046s, d_loss: 0.73628545, g_loss: 2.79188347, rnn_loss: 0.00000000\n",
      " ** Epoch 354 took 97.131904s\n",
      "Epoch: [355/1000] time: 0.7009s, d_loss: 0.07468140, g_loss: 4.30014610, rnn_loss: 0.00000000\n",
      " ** Epoch 355 took 97.040955s\n",
      "Epoch: [356/1000] time: 0.7063s, d_loss: 0.19037560, g_loss: 3.31645870, rnn_loss: 0.00000000\n",
      " ** Epoch 356 took 97.091501s\n",
      "Epoch: [357/1000] time: 0.7002s, d_loss: 0.15745397, g_loss: 2.57313299, rnn_loss: 0.00000000\n",
      " ** Epoch 357 took 96.838705s\n",
      "Epoch: [358/1000] time: 0.7070s, d_loss: 0.58828008, g_loss: 5.80321980, rnn_loss: 0.00000000\n",
      " ** Epoch 358 took 96.834792s\n",
      "Epoch: [359/1000] time: 0.7092s, d_loss: 0.13072385, g_loss: 3.21352243, rnn_loss: 0.00000000\n",
      " ** Epoch 359 took 97.588962s\n",
      "Epoch: [360/1000] time: 0.7049s, d_loss: 0.11765950, g_loss: 3.64639258, rnn_loss: 0.00000000\n",
      " ** Epoch 360 took 97.432764s\n",
      "Epoch: [361/1000] time: 0.7267s, d_loss: 0.46244767, g_loss: 4.70870304, rnn_loss: 0.00000000\n",
      " ** Epoch 361 took 97.636291s\n",
      "Epoch: [362/1000] time: 0.7240s, d_loss: 0.21214977, g_loss: 2.86076641, rnn_loss: 0.00000000\n",
      " ** Epoch 362 took 97.513229s\n",
      "Epoch: [363/1000] time: 0.6989s, d_loss: 0.16186865, g_loss: 3.12592506, rnn_loss: 0.00000000\n",
      " ** Epoch 363 took 97.448797s\n",
      "Epoch: [364/1000] time: 0.8972s, d_loss: 0.35108846, g_loss: 2.58132029, rnn_loss: 0.00000000\n",
      " ** Epoch 364 took 101.285754s\n",
      "Epoch: [365/1000] time: 0.6879s, d_loss: 0.28426456, g_loss: 3.09942150, rnn_loss: 0.00000000\n",
      " ** Epoch 365 took 100.992839s\n",
      "Epoch: [366/1000] time: 0.6888s, d_loss: 0.84010357, g_loss: 1.07904601, rnn_loss: 0.00000000\n",
      " ** Epoch 366 took 99.002829s\n",
      "Epoch: [367/1000] time: 0.6914s, d_loss: 0.18667236, g_loss: 3.54325247, rnn_loss: 0.00000000\n",
      " ** Epoch 367 took 98.441203s\n",
      "Epoch: [368/1000] time: 0.6855s, d_loss: 0.41434026, g_loss: 3.45626760, rnn_loss: 0.00000000\n",
      " ** Epoch 368 took 98.512010s\n",
      "Epoch: [369/1000] time: 0.6911s, d_loss: 0.25393057, g_loss: 2.46430874, rnn_loss: 0.00000000\n",
      " ** Epoch 369 took 95.274079s\n",
      "Epoch: [370/1000] time: 0.6870s, d_loss: 0.18586890, g_loss: 3.12084341, rnn_loss: 0.00000000\n",
      " ** Epoch 370 took 95.058442s\n",
      "Epoch: [371/1000] time: 0.6871s, d_loss: 0.27580222, g_loss: 3.37370443, rnn_loss: 0.00000000\n",
      " ** Epoch 371 took 98.696150s\n",
      "Epoch: [372/1000] time: 0.6899s, d_loss: 0.73627591, g_loss: 2.27422762, rnn_loss: 0.00000000\n",
      " ** Epoch 372 took 95.303047s\n",
      "Epoch: [373/1000] time: 0.6921s, d_loss: 0.64209759, g_loss: 1.02990258, rnn_loss: 0.00000000\n",
      " ** Epoch 373 took 95.092127s\n",
      "Epoch: [374/1000] time: 0.6887s, d_loss: 0.31235433, g_loss: 2.70368528, rnn_loss: 0.00000000\n",
      " ** Epoch 374 took 95.267455s\n",
      "Epoch: [375/1000] time: 0.6892s, d_loss: 0.17091359, g_loss: 2.55764055, rnn_loss: 0.00000000\n",
      " ** Epoch 375 took 95.435939s\n",
      "Epoch: [376/1000] time: 0.6957s, d_loss: 0.13121998, g_loss: 2.85833645, rnn_loss: 0.00000000\n",
      " ** Epoch 376 took 95.299012s\n",
      "Epoch: [377/1000] time: 0.8775s, d_loss: 0.25734878, g_loss: 2.35993767, rnn_loss: 0.00000000\n",
      " ** Epoch 377 took 97.173726s\n",
      "Epoch: [378/1000] time: 0.6963s, d_loss: 0.58194339, g_loss: 1.05399549, rnn_loss: 0.00000000\n",
      " ** Epoch 378 took 97.242105s\n",
      "Epoch: [379/1000] time: 0.6899s, d_loss: 0.14398791, g_loss: 3.41137743, rnn_loss: 0.00000000\n",
      " ** Epoch 379 took 95.338432s\n",
      "Epoch: [380/1000] time: 0.6893s, d_loss: 0.12947412, g_loss: 3.20329762, rnn_loss: 0.00000000\n",
      " ** Epoch 380 took 95.437996s\n",
      "Epoch: [381/1000] time: 0.6880s, d_loss: 0.18394357, g_loss: 1.86376572, rnn_loss: 0.00000000\n",
      " ** Epoch 381 took 95.190368s\n",
      "Epoch: [382/1000] time: 0.6907s, d_loss: 0.25851583, g_loss: 3.10524940, rnn_loss: 0.00000000\n",
      " ** Epoch 382 took 95.430286s\n",
      "Epoch: [383/1000] time: 0.6935s, d_loss: 0.33531696, g_loss: 2.37387753, rnn_loss: 0.00000000\n",
      " ** Epoch 383 took 95.038198s\n",
      "Epoch: [384/1000] time: 0.6867s, d_loss: 0.39595973, g_loss: 3.24702120, rnn_loss: 0.00000000\n",
      " ** Epoch 384 took 94.990143s\n",
      "Epoch: [385/1000] time: 0.6895s, d_loss: 0.11475606, g_loss: 3.08758736, rnn_loss: 0.00000000\n",
      " ** Epoch 385 took 95.200509s\n",
      "Epoch: [386/1000] time: 0.6907s, d_loss: 0.35628664, g_loss: 3.20826387, rnn_loss: 0.00000000\n",
      " ** Epoch 386 took 95.737831s\n",
      "Epoch: [387/1000] time: 0.6892s, d_loss: 0.36517346, g_loss: 2.54206967, rnn_loss: 0.00000000\n",
      " ** Epoch 387 took 95.205713s\n",
      "Epoch: [388/1000] time: 0.6881s, d_loss: 1.12664068, g_loss: 3.01304078, rnn_loss: 0.00000000\n",
      " ** Epoch 388 took 95.334337s\n",
      "Epoch: [389/1000] time: 0.6905s, d_loss: 0.10490568, g_loss: 3.84497595, rnn_loss: 0.00000000\n",
      " ** Epoch 389 took 99.931416s\n",
      "Epoch: [390/1000] time: 0.6849s, d_loss: 0.36906499, g_loss: 3.07324266, rnn_loss: 0.00000000\n",
      " ** Epoch 390 took 95.118715s\n",
      "Epoch: [391/1000] time: 0.6910s, d_loss: 0.22820362, g_loss: 2.43475103, rnn_loss: 0.00000000\n",
      " ** Epoch 391 took 95.269666s\n",
      "Epoch: [392/1000] time: 0.6878s, d_loss: 0.71083868, g_loss: 2.18867755, rnn_loss: 0.00000000\n",
      " ** Epoch 392 took 95.078274s\n",
      "Epoch: [393/1000] time: 0.6877s, d_loss: 0.74945575, g_loss: 4.07927561, rnn_loss: 0.00000000\n",
      " ** Epoch 393 took 95.274559s\n",
      "Epoch: [394/1000] time: 0.6846s, d_loss: 0.65646726, g_loss: 2.32295609, rnn_loss: 0.00000000\n",
      " ** Epoch 394 took 94.899680s\n",
      "Epoch: [395/1000] time: 0.6880s, d_loss: 0.45621651, g_loss: 2.29494667, rnn_loss: 0.00000000\n",
      " ** Epoch 395 took 95.068629s\n",
      "Epoch: [396/1000] time: 0.6863s, d_loss: 0.30881390, g_loss: 2.04613590, rnn_loss: 0.00000000\n",
      " ** Epoch 396 took 95.244567s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [397/1000] time: 0.6874s, d_loss: 1.46679902, g_loss: 2.57434082, rnn_loss: 0.00000000\n",
      " ** Epoch 397 took 94.937856s\n",
      "Epoch: [398/1000] time: 0.6954s, d_loss: 0.14283602, g_loss: 2.54510832, rnn_loss: 0.00000000\n",
      " ** Epoch 398 took 95.411429s\n",
      "Epoch: [399/1000] time: 0.7045s, d_loss: 0.20784599, g_loss: 2.93210149, rnn_loss: 0.00000000\n",
      " ** Epoch 399 took 96.000744s\n",
      " ** new learning rate: 0.000050\n",
      "Epoch: [400/1000] time: 0.6904s, d_loss: 0.36145061, g_loss: 2.37543273, rnn_loss: 0.00000000\n",
      " ** Epoch 400 took 95.635947s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [401/1000] time: 0.7024s, d_loss: 0.22304128, g_loss: 3.44137502, rnn_loss: 0.00000000\n",
      " ** Epoch 401 took 95.879329s\n",
      "Epoch: [402/1000] time: 0.6892s, d_loss: 0.27717543, g_loss: 2.44635940, rnn_loss: 0.00000000\n",
      " ** Epoch 402 took 96.081604s\n",
      "Epoch: [403/1000] time: 0.6897s, d_loss: 0.33901063, g_loss: 2.36472940, rnn_loss: 0.00000000\n",
      " ** Epoch 403 took 95.348230s\n",
      "Epoch: [404/1000] time: 0.6968s, d_loss: 0.55671984, g_loss: 1.85731745, rnn_loss: 0.00000000\n",
      " ** Epoch 404 took 95.477537s\n",
      "Epoch: [405/1000] time: 0.7002s, d_loss: 0.15336800, g_loss: 2.30773401, rnn_loss: 0.00000000\n",
      " ** Epoch 405 took 95.756703s\n",
      "Epoch: [406/1000] time: 0.6971s, d_loss: 0.27669871, g_loss: 2.27522874, rnn_loss: 0.00000000\n",
      " ** Epoch 406 took 96.012930s\n",
      "Epoch: [407/1000] time: 0.6899s, d_loss: 0.57401514, g_loss: 0.93391985, rnn_loss: 0.00000000\n",
      " ** Epoch 407 took 96.396180s\n",
      "Epoch: [408/1000] time: 0.6901s, d_loss: 0.23320509, g_loss: 2.15038800, rnn_loss: 0.00000000\n",
      " ** Epoch 408 took 95.482708s\n",
      "Epoch: [409/1000] time: 0.6972s, d_loss: 0.14279841, g_loss: 3.05379939, rnn_loss: 0.00000000\n",
      " ** Epoch 409 took 95.390245s\n",
      "Epoch: [410/1000] time: 0.6909s, d_loss: 0.07074326, g_loss: 3.78376174, rnn_loss: 0.00000000\n",
      " ** Epoch 410 took 95.188095s\n",
      "Epoch: [411/1000] time: 0.6902s, d_loss: 0.41583288, g_loss: 2.68388510, rnn_loss: 0.00000000\n",
      " ** Epoch 411 took 95.471387s\n",
      "Epoch: [412/1000] time: 0.6868s, d_loss: 0.30793461, g_loss: 3.22892618, rnn_loss: 0.00000000\n",
      " ** Epoch 412 took 95.317144s\n",
      "Epoch: [413/1000] time: 0.6903s, d_loss: 0.46593872, g_loss: 2.11666679, rnn_loss: 0.00000000\n",
      " ** Epoch 413 took 95.244123s\n",
      "Epoch: [414/1000] time: 0.6938s, d_loss: 0.35023904, g_loss: 1.88875031, rnn_loss: 0.00000000\n",
      " ** Epoch 414 took 95.412259s\n",
      "Epoch: [415/1000] time: 0.6900s, d_loss: 0.23191911, g_loss: 1.93347311, rnn_loss: 0.00000000\n",
      " ** Epoch 415 took 95.359056s\n",
      "Epoch: [416/1000] time: 0.6852s, d_loss: 0.30258223, g_loss: 2.65757489, rnn_loss: 0.00000000\n",
      " ** Epoch 416 took 95.054195s\n",
      "Epoch: [417/1000] time: 0.6868s, d_loss: 0.24598065, g_loss: 2.51152134, rnn_loss: 0.00000000\n",
      " ** Epoch 417 took 95.282338s\n",
      "Epoch: [418/1000] time: 0.6844s, d_loss: 0.37333781, g_loss: 2.03930140, rnn_loss: 0.00000000\n",
      " ** Epoch 418 took 94.988031s\n",
      "Epoch: [419/1000] time: 0.6847s, d_loss: 0.40130910, g_loss: 2.94465780, rnn_loss: 0.00000000\n",
      " ** Epoch 419 took 94.884939s\n",
      "Epoch: [420/1000] time: 0.6848s, d_loss: 0.08151035, g_loss: 2.87833691, rnn_loss: 0.00000000\n",
      " ** Epoch 420 took 95.123444s\n",
      "Epoch: [421/1000] time: 0.7000s, d_loss: 0.17111173, g_loss: 2.70345140, rnn_loss: 0.00000000\n",
      " ** Epoch 421 took 95.033755s\n",
      "Epoch: [422/1000] time: 0.6874s, d_loss: 0.71700734, g_loss: 1.92946339, rnn_loss: 0.00000000\n",
      " ** Epoch 422 took 95.084881s\n",
      "Epoch: [423/1000] time: 0.6907s, d_loss: 0.13618846, g_loss: 2.94143963, rnn_loss: 0.00000000\n",
      " ** Epoch 423 took 95.406713s\n",
      "Epoch: [424/1000] time: 0.6949s, d_loss: 0.41637659, g_loss: 2.23708034, rnn_loss: 0.00000000\n",
      " ** Epoch 424 took 96.112350s\n",
      "Epoch: [425/1000] time: 0.6950s, d_loss: 0.38325086, g_loss: 2.24056387, rnn_loss: 0.00000000\n",
      " ** Epoch 425 took 95.587592s\n",
      "Epoch: [426/1000] time: 0.6848s, d_loss: 0.29746494, g_loss: 2.92138481, rnn_loss: 0.00000000\n",
      " ** Epoch 426 took 95.134048s\n",
      "Epoch: [427/1000] time: 0.6851s, d_loss: 0.11036219, g_loss: 2.99108744, rnn_loss: 0.00000000\n",
      " ** Epoch 427 took 95.310419s\n",
      "Epoch: [428/1000] time: 0.6886s, d_loss: 0.40797246, g_loss: 2.28687549, rnn_loss: 0.00000000\n",
      " ** Epoch 428 took 95.111713s\n",
      "Epoch: [429/1000] time: 0.6988s, d_loss: 0.33603114, g_loss: 1.74847269, rnn_loss: 0.00000000\n",
      " ** Epoch 429 took 95.193929s\n",
      "Epoch: [430/1000] time: 0.6954s, d_loss: 0.29728186, g_loss: 2.11783409, rnn_loss: 0.00000000\n",
      " ** Epoch 430 took 95.773019s\n",
      "Epoch: [431/1000] time: 0.7035s, d_loss: 0.40368208, g_loss: 1.98870647, rnn_loss: 0.00000000\n",
      " ** Epoch 431 took 96.220008s\n",
      "Epoch: [432/1000] time: 0.6887s, d_loss: 0.33540800, g_loss: 2.51876068, rnn_loss: 0.00000000\n",
      " ** Epoch 432 took 95.141378s\n",
      "Epoch: [433/1000] time: 0.6918s, d_loss: 0.18179172, g_loss: 4.13560486, rnn_loss: 0.00000000\n",
      " ** Epoch 433 took 95.119092s\n",
      "Epoch: [434/1000] time: 0.6835s, d_loss: 0.10384863, g_loss: 3.25657082, rnn_loss: 0.00000000\n",
      " ** Epoch 434 took 94.987693s\n",
      "Epoch: [435/1000] time: 0.6885s, d_loss: 0.30223674, g_loss: 2.45282388, rnn_loss: 0.00000000\n",
      " ** Epoch 435 took 95.141568s\n",
      "Epoch: [436/1000] time: 0.7059s, d_loss: 0.35294211, g_loss: 3.91448402, rnn_loss: 0.00000000\n",
      " ** Epoch 436 took 95.772900s\n",
      "Epoch: [437/1000] time: 0.6989s, d_loss: 0.12575997, g_loss: 2.91458869, rnn_loss: 0.00000000\n",
      " ** Epoch 437 took 96.357521s\n",
      "Epoch: [438/1000] time: 0.6869s, d_loss: 0.22505702, g_loss: 1.92429435, rnn_loss: 0.00000000\n",
      " ** Epoch 438 took 95.479922s\n",
      "Epoch: [439/1000] time: 0.6851s, d_loss: 0.48214942, g_loss: 2.14550543, rnn_loss: 0.00000000\n",
      " ** Epoch 439 took 95.022310s\n",
      "Epoch: [440/1000] time: 0.6834s, d_loss: 0.19999802, g_loss: 2.23328829, rnn_loss: 0.00000000\n",
      " ** Epoch 440 took 95.172350s\n",
      "Epoch: [441/1000] time: 0.6856s, d_loss: 0.33393079, g_loss: 2.47234678, rnn_loss: 0.00000000\n",
      " ** Epoch 441 took 95.009592s\n",
      "Epoch: [442/1000] time: 0.6840s, d_loss: 1.29022110, g_loss: 0.71026355, rnn_loss: 0.00000000\n",
      " ** Epoch 442 took 95.087928s\n",
      "Epoch: [443/1000] time: 0.6933s, d_loss: 0.17395604, g_loss: 2.85289574, rnn_loss: 0.00000000\n",
      " ** Epoch 443 took 96.004822s\n",
      "Epoch: [444/1000] time: 0.6892s, d_loss: 0.08906443, g_loss: 3.51083803, rnn_loss: 0.00000000\n",
      " ** Epoch 444 took 95.349159s\n",
      "Epoch: [445/1000] time: 0.6857s, d_loss: 0.35163766, g_loss: 2.30678558, rnn_loss: 0.00000000\n",
      " ** Epoch 445 took 95.002954s\n",
      "Epoch: [446/1000] time: 0.6900s, d_loss: 0.26551551, g_loss: 2.65911341, rnn_loss: 0.00000000\n",
      " ** Epoch 446 took 95.208557s\n",
      "Epoch: [447/1000] time: 0.6890s, d_loss: 0.16300128, g_loss: 3.08974886, rnn_loss: 0.00000000\n",
      " ** Epoch 447 took 95.059993s\n",
      "Epoch: [448/1000] time: 0.6955s, d_loss: 0.23664552, g_loss: 2.76780605, rnn_loss: 0.00000000\n",
      " ** Epoch 448 took 95.252461s\n",
      "Epoch: [449/1000] time: 0.6861s, d_loss: 0.45563427, g_loss: 2.00550818, rnn_loss: 0.00000000\n",
      " ** Epoch 449 took 95.001353s\n",
      "Epoch: [450/1000] time: 0.6858s, d_loss: 0.06814601, g_loss: 3.82292724, rnn_loss: 0.00000000\n",
      " ** Epoch 450 took 95.248125s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [451/1000] time: 0.6849s, d_loss: 0.19752997, g_loss: 2.62640548, rnn_loss: 0.00000000\n",
      " ** Epoch 451 took 95.206208s\n",
      "Epoch: [452/1000] time: 0.6808s, d_loss: 0.09437673, g_loss: 2.83549619, rnn_loss: 0.00000000\n",
      " ** Epoch 452 took 94.535869s\n",
      "Epoch: [453/1000] time: 0.6864s, d_loss: 0.58029795, g_loss: 2.12546062, rnn_loss: 0.00000000\n",
      " ** Epoch 453 took 94.800656s\n",
      "Epoch: [454/1000] time: 0.6870s, d_loss: 0.25663230, g_loss: 2.33343220, rnn_loss: 0.00000000\n",
      " ** Epoch 454 took 94.495824s\n",
      "Epoch: [455/1000] time: 0.6883s, d_loss: 0.18473183, g_loss: 3.68875909, rnn_loss: 0.00000000\n",
      " ** Epoch 455 took 94.838034s\n",
      "Epoch: [456/1000] time: 0.6840s, d_loss: 0.14611495, g_loss: 2.02078938, rnn_loss: 0.00000000\n",
      " ** Epoch 456 took 94.853371s\n",
      "Epoch: [457/1000] time: 0.6887s, d_loss: 0.10123231, g_loss: 3.21682549, rnn_loss: 0.00000000\n",
      " ** Epoch 457 took 95.359040s\n",
      "Epoch: [458/1000] time: 0.6869s, d_loss: 0.25220695, g_loss: 2.12014961, rnn_loss: 0.00000000\n",
      " ** Epoch 458 took 95.024558s\n",
      "Epoch: [459/1000] time: 0.6885s, d_loss: 0.12630399, g_loss: 3.05555201, rnn_loss: 0.00000000\n",
      " ** Epoch 459 took 95.082100s\n",
      "Epoch: [460/1000] time: 0.6868s, d_loss: 0.10261896, g_loss: 2.66667485, rnn_loss: 0.00000000\n",
      " ** Epoch 460 took 95.171032s\n",
      "Epoch: [461/1000] time: 0.6951s, d_loss: 0.87537307, g_loss: 2.02703404, rnn_loss: 0.00000000\n",
      " ** Epoch 461 took 95.174879s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [462/1000] time: 0.6955s, d_loss: 0.31525826, g_loss: 2.95553112, rnn_loss: 0.00000000\n",
      " ** Epoch 462 took 95.556427s\n",
      "Epoch: [463/1000] time: 0.6997s, d_loss: 0.38235861, g_loss: 2.14511633, rnn_loss: 0.00000000\n",
      " ** Epoch 463 took 95.948259s\n",
      "Epoch: [464/1000] time: 0.6977s, d_loss: 0.34715939, g_loss: 2.15880227, rnn_loss: 0.00000000\n",
      " ** Epoch 464 took 95.950935s\n",
      "Epoch: [465/1000] time: 0.6897s, d_loss: 0.04915903, g_loss: 2.91892290, rnn_loss: 0.00000000\n",
      " ** Epoch 465 took 95.685373s\n",
      "Epoch: [466/1000] time: 0.6917s, d_loss: 0.22480787, g_loss: 2.23410296, rnn_loss: 0.00000000\n",
      " ** Epoch 466 took 95.589964s\n",
      "Epoch: [467/1000] time: 0.6861s, d_loss: 0.38242653, g_loss: 2.60787368, rnn_loss: 0.00000000\n",
      " ** Epoch 467 took 95.726803s\n",
      "Epoch: [468/1000] time: 0.6829s, d_loss: 0.59770286, g_loss: 1.89008713, rnn_loss: 0.00000000\n",
      " ** Epoch 468 took 95.000569s\n",
      "Epoch: [469/1000] time: 0.6920s, d_loss: 0.11035276, g_loss: 2.60275698, rnn_loss: 0.00000000\n",
      " ** Epoch 469 took 95.203493s\n",
      "Epoch: [470/1000] time: 0.6968s, d_loss: 0.14589958, g_loss: 2.77163815, rnn_loss: 0.00000000\n",
      " ** Epoch 470 took 95.012006s\n",
      "Epoch: [471/1000] time: 0.6981s, d_loss: 0.19634633, g_loss: 2.94031525, rnn_loss: 0.00000000\n",
      " ** Epoch 471 took 95.328057s\n",
      "Epoch: [472/1000] time: 0.6970s, d_loss: 0.17174461, g_loss: 2.99311209, rnn_loss: 0.00000000\n",
      " ** Epoch 472 took 95.826428s\n",
      "Epoch: [473/1000] time: 0.6977s, d_loss: 0.20107964, g_loss: 2.45028496, rnn_loss: 0.00000000\n",
      " ** Epoch 473 took 96.572861s\n",
      "Epoch: [474/1000] time: 0.6933s, d_loss: 0.51953024, g_loss: 2.02406836, rnn_loss: 0.00000000\n",
      " ** Epoch 474 took 96.248975s\n",
      "Epoch: [475/1000] time: 0.6978s, d_loss: 0.33524644, g_loss: 2.34638262, rnn_loss: 0.00000000\n",
      " ** Epoch 475 took 96.198997s\n",
      "Epoch: [476/1000] time: 0.6937s, d_loss: 0.29753631, g_loss: 2.25726914, rnn_loss: 0.00000000\n",
      " ** Epoch 476 took 97.295017s\n",
      "Epoch: [477/1000] time: 0.7000s, d_loss: 0.33280355, g_loss: 2.47838759, rnn_loss: 0.00000000\n",
      " ** Epoch 477 took 96.095267s\n",
      "Epoch: [478/1000] time: 0.7083s, d_loss: 0.25511336, g_loss: 3.71764278, rnn_loss: 0.00000000\n",
      " ** Epoch 478 took 95.956000s\n",
      "Epoch: [479/1000] time: 0.6930s, d_loss: 0.18301472, g_loss: 3.05226183, rnn_loss: 0.00000000\n",
      " ** Epoch 479 took 95.839858s\n",
      "Epoch: [480/1000] time: 0.6995s, d_loss: 0.32227772, g_loss: 2.63605690, rnn_loss: 0.00000000\n",
      " ** Epoch 480 took 96.654551s\n",
      "Epoch: [481/1000] time: 0.6999s, d_loss: 0.44644114, g_loss: 1.79452956, rnn_loss: 0.00000000\n",
      " ** Epoch 481 took 97.333776s\n",
      "Epoch: [482/1000] time: 0.7171s, d_loss: 0.34903958, g_loss: 3.21099591, rnn_loss: 0.00000000\n",
      " ** Epoch 482 took 97.541669s\n",
      "Epoch: [483/1000] time: 0.7205s, d_loss: 0.27963984, g_loss: 2.79444408, rnn_loss: 0.00000000\n",
      " ** Epoch 483 took 97.587587s\n",
      "Epoch: [484/1000] time: 0.6886s, d_loss: 0.15088955, g_loss: 2.61894608, rnn_loss: 0.00000000\n",
      " ** Epoch 484 took 96.520966s\n",
      "Epoch: [485/1000] time: 0.6903s, d_loss: 0.31491655, g_loss: 3.03932118, rnn_loss: 0.00000000\n",
      " ** Epoch 485 took 96.455542s\n",
      "Epoch: [486/1000] time: 0.6921s, d_loss: 0.09761200, g_loss: 3.29692936, rnn_loss: 0.00000000\n",
      " ** Epoch 486 took 95.849920s\n",
      "Epoch: [487/1000] time: 0.6971s, d_loss: 0.11610896, g_loss: 2.97546887, rnn_loss: 0.00000000\n",
      " ** Epoch 487 took 95.863380s\n",
      "Epoch: [488/1000] time: 0.6953s, d_loss: 0.29565543, g_loss: 2.29897523, rnn_loss: 0.00000000\n",
      " ** Epoch 488 took 96.263163s\n",
      "Epoch: [489/1000] time: 0.6912s, d_loss: 0.06116498, g_loss: 3.83972335, rnn_loss: 0.00000000\n",
      " ** Epoch 489 took 95.824746s\n",
      "Epoch: [490/1000] time: 0.6999s, d_loss: 0.61396086, g_loss: 1.53211081, rnn_loss: 0.00000000\n",
      " ** Epoch 490 took 95.679643s\n",
      "Epoch: [491/1000] time: 0.6912s, d_loss: 0.36613137, g_loss: 1.99310589, rnn_loss: 0.00000000\n",
      " ** Epoch 491 took 95.777523s\n",
      "Epoch: [492/1000] time: 0.6932s, d_loss: 0.68598789, g_loss: 1.79125881, rnn_loss: 0.00000000\n",
      " ** Epoch 492 took 95.562895s\n",
      "Epoch: [493/1000] time: 0.6917s, d_loss: 0.28593174, g_loss: 2.72002363, rnn_loss: 0.00000000\n",
      " ** Epoch 493 took 95.509495s\n",
      "Epoch: [494/1000] time: 0.7001s, d_loss: 0.15083399, g_loss: 3.07448292, rnn_loss: 0.00000000\n",
      " ** Epoch 494 took 95.175880s\n",
      "Epoch: [495/1000] time: 0.6881s, d_loss: 0.08905691, g_loss: 3.91098595, rnn_loss: 0.00000000\n",
      " ** Epoch 495 took 95.554657s\n",
      "Epoch: [496/1000] time: 0.6972s, d_loss: 0.50636846, g_loss: 2.58094907, rnn_loss: 0.00000000\n",
      " ** Epoch 496 took 95.173861s\n",
      "Epoch: [497/1000] time: 0.6872s, d_loss: 0.14578888, g_loss: 3.14119720, rnn_loss: 0.00000000\n",
      " ** Epoch 497 took 95.273915s\n",
      "Epoch: [498/1000] time: 0.6875s, d_loss: 0.64968574, g_loss: 1.59749007, rnn_loss: 0.00000000\n",
      " ** Epoch 498 took 95.994978s\n",
      "Epoch: [499/1000] time: 0.6938s, d_loss: 0.30516845, g_loss: 2.40083075, rnn_loss: 0.00000000\n",
      " ** Epoch 499 took 95.938531s\n",
      "Epoch: [500/1000] time: 0.6978s, d_loss: 0.54781717, g_loss: 1.81490636, rnn_loss: 0.00000000\n",
      " ** Epoch 500 took 95.996262s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [501/1000] time: 0.6939s, d_loss: 0.25026444, g_loss: 3.07658100, rnn_loss: 0.00000000\n",
      " ** Epoch 501 took 96.507466s\n",
      "Epoch: [502/1000] time: 0.6874s, d_loss: 0.22340669, g_loss: 4.42594337, rnn_loss: 0.00000000\n",
      " ** Epoch 502 took 96.021927s\n",
      "Epoch: [503/1000] time: 0.6919s, d_loss: 0.55087566, g_loss: 2.70480275, rnn_loss: 0.00000000\n",
      " ** Epoch 503 took 95.301655s\n",
      "Epoch: [504/1000] time: 0.6899s, d_loss: 0.06664057, g_loss: 4.59567404, rnn_loss: 0.00000000\n",
      " ** Epoch 504 took 95.457348s\n",
      "Epoch: [505/1000] time: 0.6890s, d_loss: 0.48657125, g_loss: 1.89898002, rnn_loss: 0.00000000\n",
      " ** Epoch 505 took 95.182536s\n",
      "Epoch: [506/1000] time: 0.6855s, d_loss: 0.84388846, g_loss: 2.39881563, rnn_loss: 0.00000000\n",
      " ** Epoch 506 took 95.233814s\n",
      "Epoch: [507/1000] time: 0.6921s, d_loss: 0.11655210, g_loss: 3.42088532, rnn_loss: 0.00000000\n",
      " ** Epoch 507 took 95.678032s\n",
      "Epoch: [508/1000] time: 0.6870s, d_loss: 0.66675776, g_loss: 2.88938928, rnn_loss: 0.00000000\n",
      " ** Epoch 508 took 95.040191s\n",
      "Epoch: [509/1000] time: 0.6860s, d_loss: 0.07494254, g_loss: 3.23987174, rnn_loss: 0.00000000\n",
      " ** Epoch 509 took 94.917215s\n",
      "Epoch: [510/1000] time: 0.6990s, d_loss: 0.11254796, g_loss: 4.94832706, rnn_loss: 0.00000000\n",
      " ** Epoch 510 took 95.080067s\n",
      "Epoch: [511/1000] time: 0.6830s, d_loss: 0.32467076, g_loss: 2.29771876, rnn_loss: 0.00000000\n",
      " ** Epoch 511 took 95.109662s\n",
      "Epoch: [512/1000] time: 0.6929s, d_loss: 0.15779233, g_loss: 2.77677774, rnn_loss: 0.00000000\n",
      " ** Epoch 512 took 94.832762s\n",
      "Epoch: [513/1000] time: 0.6844s, d_loss: 0.25643104, g_loss: 3.02446747, rnn_loss: 0.00000000\n",
      " ** Epoch 513 took 95.030984s\n",
      "Epoch: [514/1000] time: 0.6850s, d_loss: 0.19556689, g_loss: 2.76813841, rnn_loss: 0.00000000\n",
      " ** Epoch 514 took 95.151635s\n",
      "Epoch: [515/1000] time: 0.6891s, d_loss: 0.09750298, g_loss: 3.34788513, rnn_loss: 0.00000000\n",
      " ** Epoch 515 took 94.982322s\n",
      "Epoch: [516/1000] time: 0.6894s, d_loss: 0.20515472, g_loss: 2.74257898, rnn_loss: 0.00000000\n",
      " ** Epoch 516 took 95.654006s\n",
      "Epoch: [517/1000] time: 0.6876s, d_loss: 0.43252131, g_loss: 2.60315847, rnn_loss: 0.00000000\n",
      " ** Epoch 517 took 96.076843s\n",
      "Epoch: [518/1000] time: 0.6880s, d_loss: 0.16876134, g_loss: 2.69441748, rnn_loss: 0.00000000\n",
      " ** Epoch 518 took 95.225970s\n",
      "Epoch: [519/1000] time: 0.6855s, d_loss: 0.24926820, g_loss: 2.92956090, rnn_loss: 0.00000000\n",
      " ** Epoch 519 took 95.104779s\n",
      "Epoch: [520/1000] time: 0.6904s, d_loss: 0.27656537, g_loss: 2.59955406, rnn_loss: 0.00000000\n",
      " ** Epoch 520 took 95.379793s\n",
      "Epoch: [521/1000] time: 0.6859s, d_loss: 0.22591540, g_loss: 2.53953171, rnn_loss: 0.00000000\n",
      " ** Epoch 521 took 95.106795s\n",
      "Epoch: [522/1000] time: 0.6856s, d_loss: 0.13932648, g_loss: 2.99740052, rnn_loss: 0.00000000\n",
      " ** Epoch 522 took 95.032930s\n",
      "Epoch: [523/1000] time: 0.6859s, d_loss: 0.48173362, g_loss: 1.68933511, rnn_loss: 0.00000000\n",
      " ** Epoch 523 took 95.046374s\n",
      "Epoch: [524/1000] time: 0.6888s, d_loss: 0.11408420, g_loss: 3.07631111, rnn_loss: 0.00000000\n",
      " ** Epoch 524 took 95.240696s\n",
      "Epoch: [525/1000] time: 0.6845s, d_loss: 0.19894925, g_loss: 3.16648293, rnn_loss: 0.00000000\n",
      " ** Epoch 525 took 94.980984s\n",
      "Epoch: [526/1000] time: 0.6875s, d_loss: 0.33753520, g_loss: 1.85419607, rnn_loss: 0.00000000\n",
      " ** Epoch 526 took 95.079654s\n",
      "Epoch: [527/1000] time: 0.6864s, d_loss: 1.20775437, g_loss: 0.59776151, rnn_loss: 0.00000000\n",
      " ** Epoch 527 took 95.155999s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [528/1000] time: 0.6848s, d_loss: 0.82303190, g_loss: 2.06422400, rnn_loss: 0.00000000\n",
      " ** Epoch 528 took 94.902857s\n",
      "Epoch: [529/1000] time: 0.6843s, d_loss: 0.12057817, g_loss: 3.13660336, rnn_loss: 0.00000000\n",
      " ** Epoch 529 took 95.023198s\n",
      "Epoch: [530/1000] time: 0.6891s, d_loss: 0.15067495, g_loss: 2.21040916, rnn_loss: 0.00000000\n",
      " ** Epoch 530 took 95.104677s\n",
      "Epoch: [531/1000] time: 0.6909s, d_loss: 0.25549686, g_loss: 2.31875730, rnn_loss: 0.00000000\n",
      " ** Epoch 531 took 94.908033s\n",
      "Epoch: [532/1000] time: 0.6920s, d_loss: 0.05891945, g_loss: 3.06131959, rnn_loss: 0.00000000\n",
      " ** Epoch 532 took 94.926098s\n",
      "Epoch: [533/1000] time: 0.6890s, d_loss: 0.32792461, g_loss: 1.91638589, rnn_loss: 0.00000000\n",
      " ** Epoch 533 took 95.124152s\n",
      "Epoch: [534/1000] time: 0.6869s, d_loss: 0.17631978, g_loss: 4.46703720, rnn_loss: 0.00000000\n",
      " ** Epoch 534 took 94.832918s\n",
      "Epoch: [535/1000] time: 0.6950s, d_loss: 0.28695148, g_loss: 2.58179355, rnn_loss: 0.00000000\n",
      " ** Epoch 535 took 94.834571s\n",
      "Epoch: [536/1000] time: 0.6874s, d_loss: 0.16043115, g_loss: 2.61328459, rnn_loss: 0.00000000\n",
      " ** Epoch 536 took 94.967707s\n",
      "Epoch: [537/1000] time: 0.6891s, d_loss: 0.22928423, g_loss: 2.37596607, rnn_loss: 0.00000000\n",
      " ** Epoch 537 took 95.087240s\n",
      "Epoch: [538/1000] time: 0.6832s, d_loss: 0.21559785, g_loss: 3.52595663, rnn_loss: 0.00000000\n",
      " ** Epoch 538 took 94.770690s\n",
      "Epoch: [539/1000] time: 0.6865s, d_loss: 0.62867439, g_loss: 1.91667533, rnn_loss: 0.00000000\n",
      " ** Epoch 539 took 94.701292s\n",
      "Epoch: [540/1000] time: 0.6858s, d_loss: 0.33761054, g_loss: 2.42220807, rnn_loss: 0.00000000\n",
      " ** Epoch 540 took 95.007132s\n",
      "Epoch: [541/1000] time: 0.6879s, d_loss: 0.10621118, g_loss: 3.07510614, rnn_loss: 0.00000000\n",
      " ** Epoch 541 took 95.141930s\n",
      "Epoch: [542/1000] time: 0.6856s, d_loss: 0.21466418, g_loss: 2.41964483, rnn_loss: 0.00000000\n",
      " ** Epoch 542 took 94.953609s\n",
      "Epoch: [543/1000] time: 0.6871s, d_loss: 0.49808285, g_loss: 2.84105849, rnn_loss: 0.00000000\n",
      " ** Epoch 543 took 95.015006s\n",
      "Epoch: [544/1000] time: 0.6824s, d_loss: 0.19377683, g_loss: 3.66366148, rnn_loss: 0.00000000\n",
      " ** Epoch 544 took 94.730182s\n",
      "Epoch: [545/1000] time: 0.6839s, d_loss: 0.37135717, g_loss: 2.89806652, rnn_loss: 0.00000000\n",
      " ** Epoch 545 took 94.851048s\n",
      "Epoch: [546/1000] time: 0.6885s, d_loss: 0.12392835, g_loss: 3.23649311, rnn_loss: 0.00000000\n",
      " ** Epoch 546 took 95.000076s\n",
      "Epoch: [547/1000] time: 0.6906s, d_loss: 0.41500413, g_loss: 4.14809656, rnn_loss: 0.00000000\n",
      " ** Epoch 547 took 94.879191s\n",
      "Epoch: [548/1000] time: 0.6888s, d_loss: 0.04046217, g_loss: 5.15475464, rnn_loss: 0.00000000\n",
      " ** Epoch 548 took 94.960721s\n",
      "Epoch: [549/1000] time: 0.6851s, d_loss: 0.61699307, g_loss: 1.79034686, rnn_loss: 0.00000000\n",
      " ** Epoch 549 took 95.017599s\n",
      "Epoch: [550/1000] time: 0.6875s, d_loss: 0.20808649, g_loss: 2.35595560, rnn_loss: 0.00000000\n",
      " ** Epoch 550 took 95.189557s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [551/1000] time: 0.6923s, d_loss: 0.94826865, g_loss: 4.39854527, rnn_loss: 0.00000000\n",
      " ** Epoch 551 took 95.134164s\n",
      "Epoch: [552/1000] time: 0.6856s, d_loss: 0.21681643, g_loss: 2.83355856, rnn_loss: 0.00000000\n",
      " ** Epoch 552 took 94.996839s\n",
      "Epoch: [553/1000] time: 0.6905s, d_loss: 0.37082189, g_loss: 3.88546419, rnn_loss: 0.00000000\n",
      " ** Epoch 553 took 95.136291s\n",
      "Epoch: [554/1000] time: 0.6915s, d_loss: 0.07598475, g_loss: 3.73673582, rnn_loss: 0.00000000\n",
      " ** Epoch 554 took 96.055232s\n",
      "Epoch: [555/1000] time: 0.6887s, d_loss: 0.14719780, g_loss: 2.24142790, rnn_loss: 0.00000000\n",
      " ** Epoch 555 took 95.213376s\n",
      "Epoch: [556/1000] time: 0.6919s, d_loss: 0.10261236, g_loss: 3.03529072, rnn_loss: 0.00000000\n",
      " ** Epoch 556 took 95.997618s\n",
      "Epoch: [557/1000] time: 0.6961s, d_loss: 0.28144234, g_loss: 2.40827513, rnn_loss: 0.00000000\n",
      " ** Epoch 557 took 95.646045s\n",
      "Epoch: [558/1000] time: 0.6932s, d_loss: 0.17388597, g_loss: 2.99763417, rnn_loss: 0.00000000\n",
      " ** Epoch 558 took 95.979867s\n",
      "Epoch: [559/1000] time: 0.6928s, d_loss: 0.25279656, g_loss: 2.68475294, rnn_loss: 0.00000000\n",
      " ** Epoch 559 took 96.005561s\n",
      "Epoch: [560/1000] time: 0.6903s, d_loss: 0.12581933, g_loss: 4.05570841, rnn_loss: 0.00000000\n",
      " ** Epoch 560 took 95.692690s\n",
      "Epoch: [561/1000] time: 0.6984s, d_loss: 0.44223002, g_loss: 2.27344823, rnn_loss: 0.00000000\n",
      " ** Epoch 561 took 95.817296s\n",
      "Epoch: [562/1000] time: 0.6946s, d_loss: 0.31340468, g_loss: 2.54208732, rnn_loss: 0.00000000\n",
      " ** Epoch 562 took 95.918475s\n",
      "Epoch: [563/1000] time: 0.6901s, d_loss: 0.27481794, g_loss: 1.98804998, rnn_loss: 0.00000000\n",
      " ** Epoch 563 took 95.574083s\n",
      "Epoch: [564/1000] time: 0.6912s, d_loss: 0.23962526, g_loss: 2.68228030, rnn_loss: 0.00000000\n",
      " ** Epoch 564 took 95.614247s\n",
      "Epoch: [565/1000] time: 0.6893s, d_loss: 0.09754521, g_loss: 3.03329611, rnn_loss: 0.00000000\n",
      " ** Epoch 565 took 95.391404s\n",
      "Epoch: [566/1000] time: 0.6899s, d_loss: 0.08386416, g_loss: 2.70542049, rnn_loss: 0.00000000\n",
      " ** Epoch 566 took 95.697949s\n",
      "Epoch: [567/1000] time: 0.6955s, d_loss: 0.30031520, g_loss: 2.43986940, rnn_loss: 0.00000000\n",
      " ** Epoch 567 took 95.561534s\n",
      "Epoch: [568/1000] time: 0.6923s, d_loss: 0.33290344, g_loss: 2.42627215, rnn_loss: 0.00000000\n",
      " ** Epoch 568 took 95.434153s\n",
      "Epoch: [569/1000] time: 0.6932s, d_loss: 0.37635541, g_loss: 2.94152856, rnn_loss: 0.00000000\n",
      " ** Epoch 569 took 95.560030s\n",
      "Epoch: [570/1000] time: 0.6883s, d_loss: 0.12522385, g_loss: 3.45356274, rnn_loss: 0.00000000\n",
      " ** Epoch 570 took 95.268073s\n",
      "Epoch: [571/1000] time: 0.6973s, d_loss: 0.39498228, g_loss: 2.48873281, rnn_loss: 0.00000000\n",
      " ** Epoch 571 took 95.478086s\n",
      "Epoch: [572/1000] time: 0.6988s, d_loss: 0.13362393, g_loss: 2.92527962, rnn_loss: 0.00000000\n",
      " ** Epoch 572 took 95.635866s\n",
      "Epoch: [573/1000] time: 0.6878s, d_loss: 0.16673015, g_loss: 3.07419825, rnn_loss: 0.00000000\n",
      " ** Epoch 573 took 95.275486s\n",
      "Epoch: [574/1000] time: 0.6905s, d_loss: 0.13610673, g_loss: 3.10026979, rnn_loss: 0.00000000\n",
      " ** Epoch 574 took 95.290393s\n",
      "Epoch: [575/1000] time: 0.6860s, d_loss: 0.09132887, g_loss: 3.41128874, rnn_loss: 0.00000000\n",
      " ** Epoch 575 took 95.423632s\n",
      "Epoch: [576/1000] time: 0.6977s, d_loss: 0.21170820, g_loss: 2.42536688, rnn_loss: 0.00000000\n",
      " ** Epoch 576 took 95.240524s\n",
      "Epoch: [577/1000] time: 0.6907s, d_loss: 0.08166896, g_loss: 3.38545132, rnn_loss: 0.00000000\n",
      " ** Epoch 577 took 97.716451s\n",
      "Epoch: [578/1000] time: 0.7068s, d_loss: 0.27320313, g_loss: 2.84526372, rnn_loss: 0.00000000\n",
      " ** Epoch 578 took 95.272341s\n",
      "Epoch: [579/1000] time: 0.6877s, d_loss: 0.18745357, g_loss: 3.05915928, rnn_loss: 0.00000000\n",
      " ** Epoch 579 took 95.504401s\n",
      "Epoch: [580/1000] time: 0.6906s, d_loss: 0.45289522, g_loss: 3.31520176, rnn_loss: 0.00000000\n",
      " ** Epoch 580 took 95.416023s\n",
      "Epoch: [581/1000] time: 0.6953s, d_loss: 0.12177474, g_loss: 4.17567682, rnn_loss: 0.00000000\n",
      " ** Epoch 581 took 95.349415s\n",
      "Epoch: [582/1000] time: 0.6903s, d_loss: 0.65727532, g_loss: 1.67148697, rnn_loss: 0.00000000\n",
      " ** Epoch 582 took 95.527241s\n",
      "Epoch: [583/1000] time: 0.6870s, d_loss: 0.12506770, g_loss: 3.53346348, rnn_loss: 0.00000000\n",
      " ** Epoch 583 took 95.471180s\n",
      "Epoch: [584/1000] time: 0.6858s, d_loss: 0.22435255, g_loss: 2.51064014, rnn_loss: 0.00000000\n",
      " ** Epoch 584 took 95.335446s\n",
      "Epoch: [585/1000] time: 0.6931s, d_loss: 0.10806993, g_loss: 2.85452008, rnn_loss: 0.00000000\n",
      " ** Epoch 585 took 96.101424s\n",
      "Epoch: [586/1000] time: 0.6902s, d_loss: 0.58856541, g_loss: 1.47767079, rnn_loss: 0.00000000\n",
      " ** Epoch 586 took 95.658466s\n",
      "Epoch: [587/1000] time: 0.6889s, d_loss: 0.11306938, g_loss: 4.15064478, rnn_loss: 0.00000000\n",
      " ** Epoch 587 took 95.387567s\n",
      "Epoch: [588/1000] time: 0.6849s, d_loss: 0.57495123, g_loss: 3.68024111, rnn_loss: 0.00000000\n",
      " ** Epoch 588 took 95.314052s\n",
      "Epoch: [589/1000] time: 0.6934s, d_loss: 0.35798806, g_loss: 2.30400968, rnn_loss: 0.00000000\n",
      " ** Epoch 589 took 97.045734s\n",
      "Epoch: [590/1000] time: 0.6879s, d_loss: 0.60471380, g_loss: 3.44572878, rnn_loss: 0.00000000\n",
      " ** Epoch 590 took 94.952935s\n",
      "Epoch: [591/1000] time: 0.7048s, d_loss: 0.21898989, g_loss: 2.94592905, rnn_loss: 0.00000000\n",
      " ** Epoch 591 took 95.048042s\n",
      "Epoch: [592/1000] time: 0.6898s, d_loss: 0.08213236, g_loss: 5.25081825, rnn_loss: 0.00000000\n",
      " ** Epoch 592 took 95.982281s\n",
      "Epoch: [593/1000] time: 0.6878s, d_loss: 0.32395780, g_loss: 2.52105427, rnn_loss: 0.00000000\n",
      " ** Epoch 593 took 95.229887s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [594/1000] time: 0.6894s, d_loss: 0.24764132, g_loss: 2.98362255, rnn_loss: 0.00000000\n",
      " ** Epoch 594 took 95.033024s\n",
      "Epoch: [595/1000] time: 0.6875s, d_loss: 0.15852898, g_loss: 3.23102403, rnn_loss: 0.00000000\n",
      " ** Epoch 595 took 95.234772s\n",
      "Epoch: [596/1000] time: 0.6881s, d_loss: 0.11442304, g_loss: 3.04267430, rnn_loss: 0.00000000\n",
      " ** Epoch 596 took 95.114132s\n",
      "Epoch: [597/1000] time: 0.6847s, d_loss: 0.14859420, g_loss: 2.73307419, rnn_loss: 0.00000000\n",
      " ** Epoch 597 took 95.101358s\n",
      "Epoch: [598/1000] time: 0.6901s, d_loss: 0.46998674, g_loss: 3.11230278, rnn_loss: 0.00000000\n",
      " ** Epoch 598 took 95.311799s\n",
      "Epoch: [599/1000] time: 0.6858s, d_loss: 0.59509313, g_loss: 3.05604315, rnn_loss: 0.00000000\n",
      " ** Epoch 599 took 95.168427s\n",
      " ** new learning rate: 0.000025\n",
      "Epoch: [600/1000] time: 0.6948s, d_loss: 0.22222646, g_loss: 1.99030948, rnn_loss: 0.00000000\n",
      " ** Epoch 600 took 95.574857s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [601/1000] time: 0.6894s, d_loss: 0.05862116, g_loss: 3.88003635, rnn_loss: 0.00000000\n",
      " ** Epoch 601 took 95.998347s\n",
      "Epoch: [602/1000] time: 0.6938s, d_loss: 0.20874818, g_loss: 2.45855665, rnn_loss: 0.00000000\n",
      " ** Epoch 602 took 95.503737s\n",
      "Epoch: [603/1000] time: 0.6984s, d_loss: 0.19826785, g_loss: 2.15189505, rnn_loss: 0.00000000\n",
      " ** Epoch 603 took 95.694278s\n",
      "Epoch: [604/1000] time: 0.6988s, d_loss: 0.46900809, g_loss: 2.07506943, rnn_loss: 0.00000000\n",
      " ** Epoch 604 took 96.186410s\n",
      "Epoch: [605/1000] time: 0.7074s, d_loss: 0.29518610, g_loss: 2.33895111, rnn_loss: 0.00000000\n",
      " ** Epoch 605 took 96.199200s\n",
      "Epoch: [606/1000] time: 0.6920s, d_loss: 0.38623959, g_loss: 3.31706142, rnn_loss: 0.00000000\n",
      " ** Epoch 606 took 95.942181s\n",
      "Epoch: [607/1000] time: 0.7106s, d_loss: 0.64010620, g_loss: 2.40127468, rnn_loss: 0.00000000\n",
      " ** Epoch 607 took 96.158728s\n",
      "Epoch: [608/1000] time: 0.6913s, d_loss: 0.28701258, g_loss: 1.98545742, rnn_loss: 0.00000000\n",
      " ** Epoch 608 took 95.706926s\n",
      "Epoch: [609/1000] time: 0.6877s, d_loss: 0.29569697, g_loss: 2.23891878, rnn_loss: 0.00000000\n",
      " ** Epoch 609 took 95.697755s\n",
      "Epoch: [610/1000] time: 0.7042s, d_loss: 0.07746328, g_loss: 2.99720836, rnn_loss: 0.00000000\n",
      " ** Epoch 610 took 96.787145s\n",
      "Epoch: [611/1000] time: 0.7057s, d_loss: 0.69657564, g_loss: 1.78083110, rnn_loss: 0.00000000\n",
      " ** Epoch 611 took 97.761318s\n",
      "Epoch: [612/1000] time: 0.7114s, d_loss: 0.07436542, g_loss: 3.23754644, rnn_loss: 0.00000000\n",
      " ** Epoch 612 took 97.503432s\n",
      "Epoch: [613/1000] time: 0.7066s, d_loss: 0.10133830, g_loss: 2.50946140, rnn_loss: 0.00000000\n",
      " ** Epoch 613 took 97.581742s\n",
      "Epoch: [614/1000] time: 0.7116s, d_loss: 0.27465424, g_loss: 2.07457113, rnn_loss: 0.00000000\n",
      " ** Epoch 614 took 98.067896s\n",
      "Epoch: [615/1000] time: 0.7037s, d_loss: 0.35562733, g_loss: 2.64895964, rnn_loss: 0.00000000\n",
      " ** Epoch 615 took 97.880388s\n",
      "Epoch: [616/1000] time: 0.7115s, d_loss: 0.24869502, g_loss: 2.46416783, rnn_loss: 0.00000000\n",
      " ** Epoch 616 took 95.403649s\n",
      "Epoch: [617/1000] time: 0.6867s, d_loss: 0.20976475, g_loss: 3.10904837, rnn_loss: 0.00000000\n",
      " ** Epoch 617 took 95.327498s\n",
      "Epoch: [618/1000] time: 0.6882s, d_loss: 0.15287623, g_loss: 2.68449712, rnn_loss: 0.00000000\n",
      " ** Epoch 618 took 95.010434s\n",
      "Epoch: [619/1000] time: 0.6876s, d_loss: 0.15095666, g_loss: 2.38343930, rnn_loss: 0.00000000\n",
      " ** Epoch 619 took 94.946176s\n",
      "Epoch: [620/1000] time: 0.6918s, d_loss: 0.37757534, g_loss: 1.69359887, rnn_loss: 0.00000000\n",
      " ** Epoch 620 took 95.059067s\n",
      "Epoch: [621/1000] time: 0.6884s, d_loss: 0.12254252, g_loss: 2.44906402, rnn_loss: 0.00000000\n",
      " ** Epoch 621 took 94.956214s\n",
      "Epoch: [622/1000] time: 0.6863s, d_loss: 0.36607292, g_loss: 3.10845947, rnn_loss: 0.00000000\n",
      " ** Epoch 622 took 94.917359s\n",
      "Epoch: [623/1000] time: 0.6868s, d_loss: 0.06289695, g_loss: 3.30183744, rnn_loss: 0.00000000\n",
      " ** Epoch 623 took 94.993581s\n",
      "Epoch: [624/1000] time: 0.6936s, d_loss: 0.06793750, g_loss: 4.69048548, rnn_loss: 0.00000000\n",
      " ** Epoch 624 took 95.353016s\n",
      "Epoch: [625/1000] time: 0.6938s, d_loss: 0.40696973, g_loss: 3.22755361, rnn_loss: 0.00000000\n",
      " ** Epoch 625 took 95.029894s\n",
      "Epoch: [626/1000] time: 0.6878s, d_loss: 0.08661643, g_loss: 3.60829496, rnn_loss: 0.00000000\n",
      " ** Epoch 626 took 94.989275s\n",
      "Epoch: [627/1000] time: 0.6917s, d_loss: 0.05909304, g_loss: 3.35480428, rnn_loss: 0.00000000\n",
      " ** Epoch 627 took 95.530871s\n",
      "Epoch: [628/1000] time: 0.6837s, d_loss: 0.14640649, g_loss: 2.87526083, rnn_loss: 0.00000000\n",
      " ** Epoch 628 took 95.182833s\n",
      "Epoch: [629/1000] time: 0.6847s, d_loss: 0.06311583, g_loss: 4.97438288, rnn_loss: 0.00000000\n",
      " ** Epoch 629 took 95.108917s\n",
      "Epoch: [630/1000] time: 0.6861s, d_loss: 0.18892547, g_loss: 2.40657520, rnn_loss: 0.00000000\n",
      " ** Epoch 630 took 95.257074s\n",
      "Epoch: [631/1000] time: 0.6897s, d_loss: 0.55746824, g_loss: 1.76081824, rnn_loss: 0.00000000\n",
      " ** Epoch 631 took 95.144717s\n",
      "Epoch: [632/1000] time: 0.6916s, d_loss: 0.24643406, g_loss: 2.97838616, rnn_loss: 0.00000000\n",
      " ** Epoch 632 took 95.213188s\n",
      "Epoch: [633/1000] time: 0.6904s, d_loss: 0.21056622, g_loss: 2.28735352, rnn_loss: 0.00000000\n",
      " ** Epoch 633 took 95.371522s\n",
      "Epoch: [634/1000] time: 0.6906s, d_loss: 0.09540662, g_loss: 3.60608625, rnn_loss: 0.00000000\n",
      " ** Epoch 634 took 95.315225s\n",
      "Epoch: [635/1000] time: 0.6862s, d_loss: 0.13450536, g_loss: 2.42368078, rnn_loss: 0.00000000\n",
      " ** Epoch 635 took 94.965434s\n",
      "Epoch: [636/1000] time: 0.6881s, d_loss: 0.14052281, g_loss: 2.91467810, rnn_loss: 0.00000000\n",
      " ** Epoch 636 took 95.010020s\n",
      "Epoch: [637/1000] time: 0.6844s, d_loss: 0.13385412, g_loss: 2.87915897, rnn_loss: 0.00000000\n",
      " ** Epoch 637 took 95.528097s\n",
      "Epoch: [638/1000] time: 0.6970s, d_loss: 0.06983751, g_loss: 3.22068787, rnn_loss: 0.00000000\n",
      " ** Epoch 638 took 95.079297s\n",
      "Epoch: [639/1000] time: 0.6869s, d_loss: 0.06850746, g_loss: 3.31620836, rnn_loss: 0.00000000\n",
      " ** Epoch 639 took 94.999243s\n",
      "Epoch: [640/1000] time: 0.6993s, d_loss: 0.13665389, g_loss: 3.22354484, rnn_loss: 0.00000000\n",
      " ** Epoch 640 took 95.228446s\n",
      "Epoch: [641/1000] time: 0.6835s, d_loss: 0.38668010, g_loss: 2.17799592, rnn_loss: 0.00000000\n",
      " ** Epoch 641 took 95.138222s\n",
      "Epoch: [642/1000] time: 0.6926s, d_loss: 0.07834132, g_loss: 2.72022724, rnn_loss: 0.00000000\n",
      " ** Epoch 642 took 95.328486s\n",
      "Epoch: [643/1000] time: 0.6894s, d_loss: 0.31301275, g_loss: 2.13332868, rnn_loss: 0.00000000\n",
      " ** Epoch 643 took 95.625376s\n",
      "Epoch: [644/1000] time: 0.7112s, d_loss: 0.44025460, g_loss: 2.18337393, rnn_loss: 0.00000000\n",
      " ** Epoch 644 took 96.072818s\n",
      "Epoch: [645/1000] time: 0.7018s, d_loss: 0.34243250, g_loss: 2.71553421, rnn_loss: 0.00000000\n",
      " ** Epoch 645 took 95.517648s\n",
      "Epoch: [646/1000] time: 0.7040s, d_loss: 0.07119847, g_loss: 2.83568645, rnn_loss: 0.00000000\n",
      " ** Epoch 646 took 96.219616s\n",
      "Epoch: [647/1000] time: 0.6898s, d_loss: 0.16073470, g_loss: 3.13038445, rnn_loss: 0.00000000\n",
      " ** Epoch 647 took 95.646449s\n",
      "Epoch: [648/1000] time: 0.6915s, d_loss: 0.18949041, g_loss: 2.30208230, rnn_loss: 0.00000000\n",
      " ** Epoch 648 took 95.278438s\n",
      "Epoch: [649/1000] time: 0.6983s, d_loss: 0.28842282, g_loss: 2.56055188, rnn_loss: 0.00000000\n",
      " ** Epoch 649 took 95.157547s\n",
      "Epoch: [650/1000] time: 0.6891s, d_loss: 0.62924647, g_loss: 1.61136711, rnn_loss: 0.00000000\n",
      " ** Epoch 650 took 95.522133s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [651/1000] time: 0.6889s, d_loss: 0.06445061, g_loss: 3.79653978, rnn_loss: 0.00000000\n",
      " ** Epoch 651 took 95.337515s\n",
      "Epoch: [652/1000] time: 0.7028s, d_loss: 0.24407400, g_loss: 1.94837904, rnn_loss: 0.00000000\n",
      " ** Epoch 652 took 95.758634s\n",
      "Epoch: [653/1000] time: 0.6860s, d_loss: 0.09347127, g_loss: 2.52752447, rnn_loss: 0.00000000\n",
      " ** Epoch 653 took 95.398481s\n",
      "Epoch: [654/1000] time: 0.6909s, d_loss: 0.18827026, g_loss: 2.12990808, rnn_loss: 0.00000000\n",
      " ** Epoch 654 took 95.195871s\n",
      "Epoch: [655/1000] time: 0.6904s, d_loss: 0.08926850, g_loss: 2.65128613, rnn_loss: 0.00000000\n",
      " ** Epoch 655 took 95.383440s\n",
      "Epoch: [656/1000] time: 0.6892s, d_loss: 0.22794971, g_loss: 1.60598433, rnn_loss: 0.00000000\n",
      " ** Epoch 656 took 95.553467s\n",
      "Epoch: [657/1000] time: 0.6904s, d_loss: 0.34894800, g_loss: 2.23570037, rnn_loss: 0.00000000\n",
      " ** Epoch 657 took 95.306740s\n",
      "Epoch: [658/1000] time: 0.6971s, d_loss: 0.21023226, g_loss: 2.49203944, rnn_loss: 0.00000000\n",
      " ** Epoch 658 took 95.168067s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [659/1000] time: 0.6941s, d_loss: 0.13953911, g_loss: 3.90833902, rnn_loss: 0.00000000\n",
      " ** Epoch 659 took 95.582210s\n",
      "Epoch: [660/1000] time: 0.6973s, d_loss: 0.18873431, g_loss: 2.57450771, rnn_loss: 0.00000000\n",
      " ** Epoch 660 took 95.368997s\n",
      "Epoch: [661/1000] time: 0.6888s, d_loss: 0.10105397, g_loss: 2.24803925, rnn_loss: 0.00000000\n",
      " ** Epoch 661 took 95.263026s\n",
      "Epoch: [662/1000] time: 0.6888s, d_loss: 0.19642240, g_loss: 2.92910886, rnn_loss: 0.00000000\n",
      " ** Epoch 662 took 95.532489s\n",
      "Epoch: [663/1000] time: 0.6875s, d_loss: 0.19517994, g_loss: 2.43901944, rnn_loss: 0.00000000\n",
      " ** Epoch 663 took 95.384099s\n",
      "Epoch: [664/1000] time: 0.7041s, d_loss: 0.07068720, g_loss: 3.69943166, rnn_loss: 0.00000000\n",
      " ** Epoch 664 took 95.323778s\n",
      "Epoch: [665/1000] time: 0.7024s, d_loss: 0.19392033, g_loss: 2.55140924, rnn_loss: 0.00000000\n",
      " ** Epoch 665 took 95.235702s\n",
      "Epoch: [666/1000] time: 0.6892s, d_loss: 0.06540371, g_loss: 4.22521400, rnn_loss: 0.00000000\n",
      " ** Epoch 666 took 95.648153s\n",
      "Epoch: [667/1000] time: 0.6902s, d_loss: 0.47563457, g_loss: 1.96069551, rnn_loss: 0.00000000\n",
      " ** Epoch 667 took 95.357893s\n",
      "Epoch: [668/1000] time: 0.6875s, d_loss: 0.14350218, g_loss: 2.25922894, rnn_loss: 0.00000000\n",
      " ** Epoch 668 took 95.172232s\n",
      "Epoch: [669/1000] time: 0.6818s, d_loss: 0.15611611, g_loss: 3.08837509, rnn_loss: 0.00000000\n",
      " ** Epoch 669 took 95.521318s\n",
      "Epoch: [670/1000] time: 0.6866s, d_loss: 0.28190771, g_loss: 1.96308601, rnn_loss: 0.00000000\n",
      " ** Epoch 670 took 95.027957s\n",
      "Epoch: [671/1000] time: 0.6871s, d_loss: 0.28933167, g_loss: 2.27730942, rnn_loss: 0.00000000\n",
      " ** Epoch 671 took 95.049595s\n",
      "Epoch: [672/1000] time: 0.6844s, d_loss: 0.03800426, g_loss: 4.04986525, rnn_loss: 0.00000000\n",
      " ** Epoch 672 took 95.399009s\n",
      "Epoch: [673/1000] time: 0.6910s, d_loss: 0.09764425, g_loss: 3.04635954, rnn_loss: 0.00000000\n",
      " ** Epoch 673 took 95.137470s\n",
      "Epoch: [674/1000] time: 0.6859s, d_loss: 0.09031504, g_loss: 4.35617638, rnn_loss: 0.00000000\n",
      " ** Epoch 674 took 96.220592s\n",
      "Epoch: [675/1000] time: 0.6975s, d_loss: 0.17662054, g_loss: 1.90143645, rnn_loss: 0.00000000\n",
      " ** Epoch 675 took 95.904169s\n",
      "Epoch: [676/1000] time: 0.6916s, d_loss: 0.17717017, g_loss: 2.69986439, rnn_loss: 0.00000000\n",
      " ** Epoch 676 took 95.405555s\n",
      "Epoch: [677/1000] time: 0.6972s, d_loss: 0.17028999, g_loss: 2.35295296, rnn_loss: 0.00000000\n",
      " ** Epoch 677 took 95.437708s\n",
      "Epoch: [678/1000] time: 0.7423s, d_loss: 0.08965684, g_loss: 2.94733524, rnn_loss: 0.00000000\n",
      " ** Epoch 678 took 95.575924s\n",
      "Epoch: [679/1000] time: 0.6942s, d_loss: 0.41553321, g_loss: 1.66630173, rnn_loss: 0.00000000\n",
      " ** Epoch 679 took 96.149657s\n",
      "Epoch: [680/1000] time: 0.6944s, d_loss: 0.11461020, g_loss: 2.71819878, rnn_loss: 0.00000000\n",
      " ** Epoch 680 took 97.128258s\n",
      "Epoch: [681/1000] time: 0.6990s, d_loss: 0.24942826, g_loss: 4.35998297, rnn_loss: 0.00000000\n",
      " ** Epoch 681 took 96.230807s\n",
      "Epoch: [682/1000] time: 0.6950s, d_loss: 0.08717233, g_loss: 3.25294256, rnn_loss: 0.00000000\n",
      " ** Epoch 682 took 96.861042s\n",
      "Epoch: [683/1000] time: 0.6970s, d_loss: 0.07964245, g_loss: 2.93248606, rnn_loss: 0.00000000\n",
      " ** Epoch 683 took 96.192597s\n",
      "Epoch: [684/1000] time: 0.6941s, d_loss: 1.22142839, g_loss: 1.63727379, rnn_loss: 0.00000000\n",
      " ** Epoch 684 took 96.005655s\n",
      "Epoch: [685/1000] time: 0.6956s, d_loss: 0.26247898, g_loss: 2.31270695, rnn_loss: 0.00000000\n",
      " ** Epoch 685 took 96.392401s\n",
      "Epoch: [686/1000] time: 0.6934s, d_loss: 0.24728045, g_loss: 2.61983061, rnn_loss: 0.00000000\n",
      " ** Epoch 686 took 95.847852s\n",
      "Epoch: [687/1000] time: 0.6938s, d_loss: 0.10675443, g_loss: 2.69214916, rnn_loss: 0.00000000\n",
      " ** Epoch 687 took 95.468227s\n",
      "Epoch: [688/1000] time: 0.6960s, d_loss: 0.33752897, g_loss: 2.23005676, rnn_loss: 0.00000000\n",
      " ** Epoch 688 took 95.665595s\n",
      "Epoch: [689/1000] time: 0.6904s, d_loss: 0.46917430, g_loss: 2.97563314, rnn_loss: 0.00000000\n",
      " ** Epoch 689 took 95.348762s\n",
      "Epoch: [690/1000] time: 0.6881s, d_loss: 0.29558939, g_loss: 2.54563379, rnn_loss: 0.00000000\n",
      " ** Epoch 690 took 95.297356s\n",
      "Epoch: [691/1000] time: 0.6967s, d_loss: 0.08405423, g_loss: 3.68568754, rnn_loss: 0.00000000\n",
      " ** Epoch 691 took 95.805555s\n",
      "Epoch: [692/1000] time: 0.6895s, d_loss: 0.18920431, g_loss: 3.15555143, rnn_loss: 0.00000000\n",
      " ** Epoch 692 took 95.426944s\n",
      "Epoch: [693/1000] time: 0.7017s, d_loss: 0.15921116, g_loss: 2.98413062, rnn_loss: 0.00000000\n",
      " ** Epoch 693 took 95.528738s\n",
      "Epoch: [694/1000] time: 0.6885s, d_loss: 0.06648254, g_loss: 4.11500072, rnn_loss: 0.00000000\n",
      " ** Epoch 694 took 95.515853s\n",
      "Epoch: [695/1000] time: 0.6900s, d_loss: 0.66659069, g_loss: 2.08052087, rnn_loss: 0.00000000\n",
      " ** Epoch 695 took 95.798403s\n",
      "Epoch: [696/1000] time: 0.6935s, d_loss: 0.06547222, g_loss: 4.65803623, rnn_loss: 0.00000000\n",
      " ** Epoch 696 took 95.381662s\n",
      "Epoch: [697/1000] time: 0.6914s, d_loss: 0.23378220, g_loss: 2.14404678, rnn_loss: 0.00000000\n",
      " ** Epoch 697 took 95.716639s\n",
      "Epoch: [698/1000] time: 0.6974s, d_loss: 0.26932147, g_loss: 2.37929344, rnn_loss: 0.00000000\n",
      " ** Epoch 698 took 95.740034s\n",
      "Epoch: [699/1000] time: 0.6872s, d_loss: 0.05701813, g_loss: 3.15507603, rnn_loss: 0.00000000\n",
      " ** Epoch 699 took 95.492193s\n",
      "Epoch: [700/1000] time: 0.6929s, d_loss: 0.43925858, g_loss: 1.96694088, rnn_loss: 0.00000000\n",
      " ** Epoch 700 took 95.733647s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [701/1000] time: 0.6947s, d_loss: 0.14275071, g_loss: 2.78151035, rnn_loss: 0.00000000\n",
      " ** Epoch 701 took 96.458027s\n",
      "Epoch: [702/1000] time: 0.6931s, d_loss: 0.41553169, g_loss: 2.99040174, rnn_loss: 0.00000000\n",
      " ** Epoch 702 took 95.701447s\n",
      "Epoch: [703/1000] time: 0.6959s, d_loss: 0.13363920, g_loss: 3.96479893, rnn_loss: 0.00000000\n",
      " ** Epoch 703 took 96.033568s\n",
      "Epoch: [704/1000] time: 0.6896s, d_loss: 0.13242374, g_loss: 2.51422358, rnn_loss: 0.00000000\n",
      " ** Epoch 704 took 96.152345s\n",
      "Epoch: [705/1000] time: 0.6961s, d_loss: 0.38511759, g_loss: 1.88685083, rnn_loss: 0.00000000\n",
      " ** Epoch 705 took 95.773416s\n",
      "Epoch: [706/1000] time: 0.6988s, d_loss: 0.08144002, g_loss: 2.99236631, rnn_loss: 0.00000000\n",
      " ** Epoch 706 took 95.782325s\n",
      "Epoch: [707/1000] time: 0.6934s, d_loss: 0.12939066, g_loss: 5.09214973, rnn_loss: 0.00000000\n",
      " ** Epoch 707 took 96.153628s\n",
      "Epoch: [708/1000] time: 0.6872s, d_loss: 0.08840770, g_loss: 3.64292192, rnn_loss: 0.00000000\n",
      " ** Epoch 708 took 95.617104s\n",
      "Epoch: [709/1000] time: 0.6912s, d_loss: 0.11829270, g_loss: 3.11844015, rnn_loss: 0.00000000\n",
      " ** Epoch 709 took 95.531417s\n",
      "Epoch: [710/1000] time: 0.6881s, d_loss: 0.43901789, g_loss: 2.15263724, rnn_loss: 0.00000000\n",
      " ** Epoch 710 took 95.861948s\n",
      "Epoch: [711/1000] time: 0.6938s, d_loss: 0.12400802, g_loss: 3.04305291, rnn_loss: 0.00000000\n",
      " ** Epoch 711 took 96.006067s\n",
      "Epoch: [712/1000] time: 0.6932s, d_loss: 0.14557186, g_loss: 3.35394669, rnn_loss: 0.00000000\n",
      " ** Epoch 712 took 95.823066s\n",
      "Epoch: [713/1000] time: 0.6930s, d_loss: 0.11043516, g_loss: 3.07827854, rnn_loss: 0.00000000\n",
      " ** Epoch 713 took 95.973647s\n",
      "Epoch: [714/1000] time: 0.7046s, d_loss: 0.05566987, g_loss: 3.70488358, rnn_loss: 0.00000000\n",
      " ** Epoch 714 took 96.078044s\n",
      "Epoch: [715/1000] time: 0.6869s, d_loss: 0.08601485, g_loss: 4.36232424, rnn_loss: 0.00000000\n",
      " ** Epoch 715 took 95.792396s\n",
      "Epoch: [716/1000] time: 0.6926s, d_loss: 0.71237844, g_loss: 1.67995548, rnn_loss: 0.00000000\n",
      " ** Epoch 716 took 95.856296s\n",
      "Epoch: [717/1000] time: 0.6937s, d_loss: 0.08450171, g_loss: 2.83934069, rnn_loss: 0.00000000\n",
      " ** Epoch 717 took 95.896674s\n",
      "Epoch: [718/1000] time: 0.6890s, d_loss: 0.05720621, g_loss: 4.47816563, rnn_loss: 0.00000000\n",
      " ** Epoch 718 took 95.744074s\n",
      "Epoch: [719/1000] time: 0.6870s, d_loss: 0.29266620, g_loss: 2.63170409, rnn_loss: 0.00000000\n",
      " ** Epoch 719 took 95.733861s\n",
      "Epoch: [720/1000] time: 0.6913s, d_loss: 0.36520299, g_loss: 2.78495550, rnn_loss: 0.00000000\n",
      " ** Epoch 720 took 95.989125s\n",
      "Epoch: [721/1000] time: 0.6891s, d_loss: 0.13957104, g_loss: 2.56483412, rnn_loss: 0.00000000\n",
      " ** Epoch 721 took 95.755707s\n",
      "Epoch: [722/1000] time: 0.6983s, d_loss: 0.49384484, g_loss: 2.02641773, rnn_loss: 0.00000000\n",
      " ** Epoch 722 took 95.797294s\n",
      "Epoch: [723/1000] time: 0.7077s, d_loss: 0.32668287, g_loss: 1.33359313, rnn_loss: 0.00000000\n",
      " ** Epoch 723 took 96.169064s\n",
      "Epoch: [724/1000] time: 0.6927s, d_loss: 0.10242610, g_loss: 3.57287312, rnn_loss: 0.00000000\n",
      " ** Epoch 724 took 95.658915s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [725/1000] time: 0.6961s, d_loss: 0.16689377, g_loss: 3.06090021, rnn_loss: 0.00000000\n",
      " ** Epoch 725 took 95.664838s\n",
      "Epoch: [726/1000] time: 0.6914s, d_loss: 0.39242399, g_loss: 1.90669203, rnn_loss: 0.00000000\n",
      " ** Epoch 726 took 95.536027s\n",
      "Epoch: [727/1000] time: 0.6980s, d_loss: 0.23276754, g_loss: 2.74709105, rnn_loss: 0.00000000\n",
      " ** Epoch 727 took 95.718106s\n",
      "Epoch: [728/1000] time: 0.6866s, d_loss: 0.08670847, g_loss: 3.26392555, rnn_loss: 0.00000000\n",
      " ** Epoch 728 took 95.649178s\n",
      "Epoch: [729/1000] time: 0.6886s, d_loss: 0.09787811, g_loss: 3.02437210, rnn_loss: 0.00000000\n",
      " ** Epoch 729 took 95.847628s\n",
      "Epoch: [730/1000] time: 0.6913s, d_loss: 0.33168709, g_loss: 1.94058597, rnn_loss: 0.00000000\n",
      " ** Epoch 730 took 95.743218s\n",
      "Epoch: [731/1000] time: 0.6918s, d_loss: 0.10807772, g_loss: 2.82239294, rnn_loss: 0.00000000\n",
      " ** Epoch 731 took 95.511526s\n",
      "Epoch: [732/1000] time: 0.6958s, d_loss: 0.04971494, g_loss: 3.23304462, rnn_loss: 0.00000000\n",
      " ** Epoch 732 took 95.557106s\n",
      "Epoch: [733/1000] time: 0.6895s, d_loss: 0.26157433, g_loss: 2.52283931, rnn_loss: 0.00000000\n",
      " ** Epoch 733 took 95.787851s\n",
      "Epoch: [734/1000] time: 0.6955s, d_loss: 0.04117084, g_loss: 3.48045969, rnn_loss: 0.00000000\n",
      " ** Epoch 734 took 95.342601s\n",
      "Epoch: [735/1000] time: 0.6885s, d_loss: 0.13434425, g_loss: 3.00779486, rnn_loss: 0.00000000\n",
      " ** Epoch 735 took 95.503778s\n",
      "Epoch: [736/1000] time: 0.7053s, d_loss: 0.22631159, g_loss: 2.57668018, rnn_loss: 0.00000000\n",
      " ** Epoch 736 took 95.839741s\n",
      "Epoch: [737/1000] time: 0.6904s, d_loss: 0.09459172, g_loss: 2.69016790, rnn_loss: 0.00000000\n",
      " ** Epoch 737 took 95.603184s\n",
      "Epoch: [738/1000] time: 0.6861s, d_loss: 0.17472674, g_loss: 2.52933431, rnn_loss: 0.00000000\n",
      " ** Epoch 738 took 95.533757s\n",
      "Epoch: [739/1000] time: 0.6838s, d_loss: 0.62903118, g_loss: 1.86730039, rnn_loss: 0.00000000\n",
      " ** Epoch 739 took 95.486509s\n",
      "Epoch: [740/1000] time: 0.6936s, d_loss: 0.23483106, g_loss: 1.88062620, rnn_loss: 0.00000000\n",
      " ** Epoch 740 took 95.575081s\n",
      "Epoch: [741/1000] time: 0.6897s, d_loss: 0.04999307, g_loss: 3.70673203, rnn_loss: 0.00000000\n",
      " ** Epoch 741 took 95.435209s\n",
      "Epoch: [742/1000] time: 0.6958s, d_loss: 0.09712131, g_loss: 2.99461460, rnn_loss: 0.00000000\n",
      " ** Epoch 742 took 95.541169s\n",
      "Epoch: [743/1000] time: 0.6939s, d_loss: 0.13223130, g_loss: 2.70659542, rnn_loss: 0.00000000\n",
      " ** Epoch 743 took 95.717029s\n",
      "Epoch: [744/1000] time: 0.6894s, d_loss: 0.16220862, g_loss: 2.96468973, rnn_loss: 0.00000000\n",
      " ** Epoch 744 took 95.481416s\n",
      "Epoch: [745/1000] time: 0.6874s, d_loss: 0.14311235, g_loss: 3.40870738, rnn_loss: 0.00000000\n",
      " ** Epoch 745 took 95.455307s\n",
      "Epoch: [746/1000] time: 0.8330s, d_loss: 0.77601051, g_loss: 1.61648941, rnn_loss: 0.00000000\n",
      " ** Epoch 746 took 97.523680s\n",
      "Epoch: [747/1000] time: 0.6901s, d_loss: 0.07243063, g_loss: 3.41649055, rnn_loss: 0.00000000\n",
      " ** Epoch 747 took 98.189737s\n",
      "Epoch: [748/1000] time: 0.7035s, d_loss: 0.09781691, g_loss: 2.70166993, rnn_loss: 0.00000000\n",
      " ** Epoch 748 took 96.539666s\n",
      "Epoch: [749/1000] time: 0.6902s, d_loss: 0.06642764, g_loss: 3.19611025, rnn_loss: 0.00000000\n",
      " ** Epoch 749 took 96.588021s\n",
      "Epoch: [750/1000] time: 0.7050s, d_loss: 0.41754159, g_loss: 2.51280951, rnn_loss: 0.00000000\n",
      " ** Epoch 750 took 96.143833s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [751/1000] time: 0.7046s, d_loss: 0.13186896, g_loss: 2.98924708, rnn_loss: 0.00000000\n",
      " ** Epoch 751 took 97.128318s\n",
      "Epoch: [752/1000] time: 0.7102s, d_loss: 0.11217281, g_loss: 2.72315359, rnn_loss: 0.00000000\n",
      " ** Epoch 752 took 97.706816s\n",
      "Epoch: [753/1000] time: 0.7164s, d_loss: 0.10549080, g_loss: 3.28142929, rnn_loss: 0.00000000\n",
      " ** Epoch 753 took 96.725919s\n",
      "Epoch: [754/1000] time: 0.6891s, d_loss: 0.42244351, g_loss: 1.87943327, rnn_loss: 0.00000000\n",
      " ** Epoch 754 took 96.164219s\n",
      "Epoch: [755/1000] time: 0.7154s, d_loss: 0.14233272, g_loss: 3.57684231, rnn_loss: 0.00000000\n",
      " ** Epoch 755 took 96.817193s\n",
      "Epoch: [756/1000] time: 0.6973s, d_loss: 0.46719736, g_loss: 2.09982252, rnn_loss: 0.00000000\n",
      " ** Epoch 756 took 97.339618s\n",
      "Epoch: [757/1000] time: 0.6957s, d_loss: 0.13800034, g_loss: 3.23785591, rnn_loss: 0.00000000\n",
      " ** Epoch 757 took 97.255147s\n",
      "Epoch: [758/1000] time: 0.6955s, d_loss: 0.35763586, g_loss: 2.15779257, rnn_loss: 0.00000000\n",
      " ** Epoch 758 took 100.448825s\n",
      "Epoch: [759/1000] time: 0.6927s, d_loss: 0.12690578, g_loss: 2.33047152, rnn_loss: 0.00000000\n",
      " ** Epoch 759 took 96.170797s\n",
      "Epoch: [760/1000] time: 0.6945s, d_loss: 0.07834158, g_loss: 3.21782541, rnn_loss: 0.00000000\n",
      " ** Epoch 760 took 96.210576s\n",
      "Epoch: [761/1000] time: 0.7040s, d_loss: 0.14093810, g_loss: 2.61633396, rnn_loss: 0.00000000\n",
      " ** Epoch 761 took 95.933280s\n",
      "Epoch: [762/1000] time: 0.6905s, d_loss: 0.23554477, g_loss: 2.11822152, rnn_loss: 0.00000000\n",
      " ** Epoch 762 took 96.274055s\n",
      "Epoch: [763/1000] time: 0.6951s, d_loss: 0.09932511, g_loss: 3.02357793, rnn_loss: 0.00000000\n",
      " ** Epoch 763 took 96.013949s\n",
      "Epoch: [764/1000] time: 0.6941s, d_loss: 0.30697873, g_loss: 2.31389284, rnn_loss: 0.00000000\n",
      " ** Epoch 764 took 96.085740s\n",
      "Epoch: [765/1000] time: 0.7075s, d_loss: 0.15717848, g_loss: 2.44970632, rnn_loss: 0.00000000\n",
      " ** Epoch 765 took 96.615531s\n",
      "Epoch: [766/1000] time: 0.7135s, d_loss: 0.02517242, g_loss: 4.12981081, rnn_loss: 0.00000000\n",
      " ** Epoch 766 took 96.674306s\n",
      "Epoch: [767/1000] time: 0.7010s, d_loss: 0.28330785, g_loss: 2.04732370, rnn_loss: 0.00000000\n",
      " ** Epoch 767 took 96.309588s\n",
      "Epoch: [768/1000] time: 0.6927s, d_loss: 0.07823777, g_loss: 3.61029911, rnn_loss: 0.00000000\n",
      " ** Epoch 768 took 97.325017s\n",
      "Epoch: [769/1000] time: 0.6945s, d_loss: 0.30598348, g_loss: 1.96323740, rnn_loss: 0.00000000\n",
      " ** Epoch 769 took 97.105092s\n",
      "Epoch: [770/1000] time: 0.8507s, d_loss: 0.03635532, g_loss: 4.22696972, rnn_loss: 0.00000000\n",
      " ** Epoch 770 took 99.862007s\n",
      "Epoch: [771/1000] time: 0.6891s, d_loss: 0.18900333, g_loss: 3.57659268, rnn_loss: 0.00000000\n",
      " ** Epoch 771 took 96.430002s\n",
      "Epoch: [772/1000] time: 0.6891s, d_loss: 0.10266600, g_loss: 2.74243855, rnn_loss: 0.00000000\n",
      " ** Epoch 772 took 95.728666s\n",
      "Epoch: [773/1000] time: 0.6977s, d_loss: 0.16239215, g_loss: 2.62712216, rnn_loss: 0.00000000\n",
      " ** Epoch 773 took 96.278496s\n",
      "Epoch: [774/1000] time: 0.7017s, d_loss: 0.45679072, g_loss: 1.93769383, rnn_loss: 0.00000000\n",
      " ** Epoch 774 took 95.844823s\n",
      "Epoch: [775/1000] time: 0.6961s, d_loss: 0.15070781, g_loss: 2.76650119, rnn_loss: 0.00000000\n",
      " ** Epoch 775 took 96.186708s\n",
      "Epoch: [776/1000] time: 0.6913s, d_loss: 0.14674991, g_loss: 3.48624587, rnn_loss: 0.00000000\n",
      " ** Epoch 776 took 96.062495s\n",
      "Epoch: [777/1000] time: 0.6907s, d_loss: 0.21747208, g_loss: 2.50891781, rnn_loss: 0.00000000\n",
      " ** Epoch 777 took 95.700758s\n",
      "Epoch: [778/1000] time: 0.6949s, d_loss: 0.06996291, g_loss: 3.35154152, rnn_loss: 0.00000000\n",
      " ** Epoch 778 took 96.622066s\n",
      "Epoch: [779/1000] time: 0.6981s, d_loss: 0.26739168, g_loss: 2.56762314, rnn_loss: 0.00000000\n",
      " ** Epoch 779 took 96.113629s\n",
      "Epoch: [780/1000] time: 0.6907s, d_loss: 0.14259763, g_loss: 2.52248049, rnn_loss: 0.00000000\n",
      " ** Epoch 780 took 96.479748s\n",
      "Epoch: [781/1000] time: 0.6966s, d_loss: 0.26596779, g_loss: 2.50134635, rnn_loss: 0.00000000\n",
      " ** Epoch 781 took 96.296900s\n",
      "Epoch: [782/1000] time: 0.6890s, d_loss: 0.32383400, g_loss: 4.42512226, rnn_loss: 0.00000000\n",
      " ** Epoch 782 took 96.043609s\n",
      "Epoch: [783/1000] time: 0.6996s, d_loss: 0.37556624, g_loss: 2.47801495, rnn_loss: 0.00000000\n",
      " ** Epoch 783 took 96.541499s\n",
      "Epoch: [784/1000] time: 0.6940s, d_loss: 0.14731908, g_loss: 3.30676651, rnn_loss: 0.00000000\n",
      " ** Epoch 784 took 96.289759s\n",
      "Epoch: [785/1000] time: 0.7194s, d_loss: 0.17858055, g_loss: 2.65044260, rnn_loss: 0.00000000\n",
      " ** Epoch 785 took 96.378501s\n",
      "Epoch: [786/1000] time: 0.7035s, d_loss: 0.19451618, g_loss: 2.83443356, rnn_loss: 0.00000000\n",
      " ** Epoch 786 took 97.263052s\n",
      "Epoch: [787/1000] time: 0.7239s, d_loss: 0.15360969, g_loss: 2.54201961, rnn_loss: 0.00000000\n",
      " ** Epoch 787 took 97.197433s\n",
      "Epoch: [788/1000] time: 0.7005s, d_loss: 0.97599089, g_loss: 1.79991269, rnn_loss: 0.00000000\n",
      " ** Epoch 788 took 96.857500s\n",
      "Epoch: [789/1000] time: 0.6973s, d_loss: 0.06742198, g_loss: 2.95656872, rnn_loss: 0.00000000\n",
      " ** Epoch 789 took 97.615835s\n",
      "Epoch: [790/1000] time: 0.7004s, d_loss: 0.15198733, g_loss: 4.69797134, rnn_loss: 0.00000000\n",
      " ** Epoch 790 took 96.069792s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [791/1000] time: 0.6967s, d_loss: 0.63134098, g_loss: 1.88803327, rnn_loss: 0.00000000\n",
      " ** Epoch 791 took 96.662262s\n",
      "Epoch: [792/1000] time: 0.7149s, d_loss: 0.36472416, g_loss: 2.06318283, rnn_loss: 0.00000000\n",
      " ** Epoch 792 took 96.854851s\n",
      "Epoch: [793/1000] time: 0.6992s, d_loss: 0.06926033, g_loss: 3.54841757, rnn_loss: 0.00000000\n",
      " ** Epoch 793 took 97.104078s\n",
      "Epoch: [794/1000] time: 0.7028s, d_loss: 0.11836354, g_loss: 3.14610052, rnn_loss: 0.00000000\n",
      " ** Epoch 794 took 96.904320s\n",
      "Epoch: [795/1000] time: 0.6943s, d_loss: 0.09940353, g_loss: 3.20571733, rnn_loss: 0.00000000\n",
      " ** Epoch 795 took 96.550879s\n",
      "Epoch: [796/1000] time: 0.7004s, d_loss: 0.06352280, g_loss: 3.44907546, rnn_loss: 0.00000000\n",
      " ** Epoch 796 took 96.399016s\n",
      "Epoch: [797/1000] time: 0.6929s, d_loss: 0.15602207, g_loss: 2.46550894, rnn_loss: 0.00000000\n",
      " ** Epoch 797 took 96.473928s\n",
      "Epoch: [798/1000] time: 0.6885s, d_loss: 0.23965807, g_loss: 2.05443382, rnn_loss: 0.00000000\n",
      " ** Epoch 798 took 96.403267s\n",
      "Epoch: [799/1000] time: 0.6974s, d_loss: 0.10490458, g_loss: 2.94975042, rnn_loss: 0.00000000\n",
      " ** Epoch 799 took 97.030005s\n",
      " ** new learning rate: 0.000013\n",
      "Epoch: [800/1000] time: 0.6929s, d_loss: 0.04142990, g_loss: 3.23365664, rnn_loss: 0.00000000\n",
      " ** Epoch 800 took 97.053363s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [801/1000] time: 0.6942s, d_loss: 0.11785516, g_loss: 2.68344378, rnn_loss: 0.00000000\n",
      " ** Epoch 801 took 96.478750s\n",
      "Epoch: [802/1000] time: 0.6936s, d_loss: 0.23821448, g_loss: 1.91557407, rnn_loss: 0.00000000\n",
      " ** Epoch 802 took 96.202626s\n",
      "Epoch: [803/1000] time: 0.6982s, d_loss: 0.55402023, g_loss: 1.26720738, rnn_loss: 0.00000000\n",
      " ** Epoch 803 took 96.609755s\n",
      "Epoch: [804/1000] time: 0.6954s, d_loss: 0.09291885, g_loss: 5.14088726, rnn_loss: 0.00000000\n",
      " ** Epoch 804 took 96.375652s\n",
      "Epoch: [805/1000] time: 0.6973s, d_loss: 0.21685514, g_loss: 1.73509049, rnn_loss: 0.00000000\n",
      " ** Epoch 805 took 96.554887s\n",
      "Epoch: [806/1000] time: 0.6932s, d_loss: 0.09212288, g_loss: 2.54563141, rnn_loss: 0.00000000\n",
      " ** Epoch 806 took 96.361173s\n",
      "Epoch: [807/1000] time: 0.7030s, d_loss: 0.06611340, g_loss: 4.62698555, rnn_loss: 0.00000000\n",
      " ** Epoch 807 took 96.387453s\n",
      "Epoch: [808/1000] time: 0.6998s, d_loss: 0.19079345, g_loss: 2.47783089, rnn_loss: 0.00000000\n",
      " ** Epoch 808 took 96.638005s\n",
      "Epoch: [809/1000] time: 0.7003s, d_loss: 0.04889766, g_loss: 4.12436628, rnn_loss: 0.00000000\n",
      " ** Epoch 809 took 97.032935s\n",
      "Epoch: [810/1000] time: 0.7005s, d_loss: 0.11460441, g_loss: 3.26270723, rnn_loss: 0.00000000\n",
      " ** Epoch 810 took 97.586036s\n",
      "Epoch: [811/1000] time: 0.7036s, d_loss: 0.19407222, g_loss: 1.95590818, rnn_loss: 0.00000000\n",
      " ** Epoch 811 took 99.975629s\n",
      "Epoch: [812/1000] time: 0.7015s, d_loss: 0.09616764, g_loss: 3.64995766, rnn_loss: 0.00000000\n",
      " ** Epoch 812 took 96.839799s\n",
      "Epoch: [813/1000] time: 0.6960s, d_loss: 0.11952576, g_loss: 2.80554080, rnn_loss: 0.00000000\n",
      " ** Epoch 813 took 97.011288s\n",
      "Epoch: [814/1000] time: 0.6970s, d_loss: 0.09852611, g_loss: 2.66668129, rnn_loss: 0.00000000\n",
      " ** Epoch 814 took 96.659788s\n",
      "Epoch: [815/1000] time: 0.7001s, d_loss: 0.16605365, g_loss: 2.07219529, rnn_loss: 0.00000000\n",
      " ** Epoch 815 took 96.933631s\n",
      "Epoch: [816/1000] time: 0.6963s, d_loss: 0.14561005, g_loss: 3.18974090, rnn_loss: 0.00000000\n",
      " ** Epoch 816 took 97.027573s\n",
      "Epoch: [817/1000] time: 0.6968s, d_loss: 0.16161916, g_loss: 2.50351763, rnn_loss: 0.00000000\n",
      " ** Epoch 817 took 96.624670s\n",
      "Epoch: [818/1000] time: 0.6957s, d_loss: 0.15957609, g_loss: 4.47380829, rnn_loss: 0.00000000\n",
      " ** Epoch 818 took 96.389279s\n",
      "Epoch: [819/1000] time: 0.6991s, d_loss: 0.39567459, g_loss: 1.57034898, rnn_loss: 0.00000000\n",
      " ** Epoch 819 took 96.811359s\n",
      "Epoch: [820/1000] time: 0.6962s, d_loss: 0.08664311, g_loss: 3.71193123, rnn_loss: 0.00000000\n",
      " ** Epoch 820 took 96.363091s\n",
      "Epoch: [821/1000] time: 0.7070s, d_loss: 0.15539344, g_loss: 2.88518357, rnn_loss: 0.00000000\n",
      " ** Epoch 821 took 96.309232s\n",
      "Epoch: [822/1000] time: 0.7149s, d_loss: 0.11871246, g_loss: 2.39634705, rnn_loss: 0.00000000\n",
      " ** Epoch 822 took 96.816998s\n",
      "Epoch: [823/1000] time: 0.6982s, d_loss: 0.19680266, g_loss: 1.87206650, rnn_loss: 0.00000000\n",
      " ** Epoch 823 took 98.846486s\n",
      "Epoch: [824/1000] time: 0.6987s, d_loss: 0.14508718, g_loss: 2.68981004, rnn_loss: 0.00000000\n",
      " ** Epoch 824 took 96.441041s\n",
      "Epoch: [825/1000] time: 0.6999s, d_loss: 0.19437793, g_loss: 2.73623466, rnn_loss: 0.00000000\n",
      " ** Epoch 825 took 96.884371s\n",
      "Epoch: [826/1000] time: 0.7117s, d_loss: 0.11059566, g_loss: 2.67075038, rnn_loss: 0.00000000\n",
      " ** Epoch 826 took 96.878209s\n",
      "Epoch: [827/1000] time: 0.6961s, d_loss: 0.03923576, g_loss: 3.85368538, rnn_loss: 0.00000000\n",
      " ** Epoch 827 took 96.427660s\n",
      "Epoch: [828/1000] time: 0.7109s, d_loss: 0.06726509, g_loss: 3.19362640, rnn_loss: 0.00000000\n",
      " ** Epoch 828 took 96.453672s\n",
      "Epoch: [829/1000] time: 0.7143s, d_loss: 0.16387418, g_loss: 2.32387638, rnn_loss: 0.00000000\n",
      " ** Epoch 829 took 96.510849s\n",
      "Epoch: [830/1000] time: 0.6917s, d_loss: 0.26598904, g_loss: 1.99392533, rnn_loss: 0.00000000\n",
      " ** Epoch 830 took 96.559085s\n",
      "Epoch: [831/1000] time: 0.7022s, d_loss: 0.12979816, g_loss: 3.51007438, rnn_loss: 0.00000000\n",
      " ** Epoch 831 took 96.307854s\n",
      "Epoch: [832/1000] time: 0.6888s, d_loss: 0.14560027, g_loss: 2.61326504, rnn_loss: 0.00000000\n",
      " ** Epoch 832 took 96.546784s\n",
      "Epoch: [833/1000] time: 0.7022s, d_loss: 0.11330114, g_loss: 3.15369320, rnn_loss: 0.00000000\n",
      " ** Epoch 833 took 96.039840s\n",
      "Epoch: [834/1000] time: 0.6880s, d_loss: 0.07882255, g_loss: 2.78614140, rnn_loss: 0.00000000\n",
      " ** Epoch 834 took 96.369308s\n",
      "Epoch: [835/1000] time: 0.6929s, d_loss: 0.04950072, g_loss: 4.15562439, rnn_loss: 0.00000000\n",
      " ** Epoch 835 took 99.212649s\n",
      "Epoch: [836/1000] time: 0.6930s, d_loss: 0.05608561, g_loss: 3.02130580, rnn_loss: 0.00000000\n",
      " ** Epoch 836 took 96.304754s\n",
      "Epoch: [837/1000] time: 0.6901s, d_loss: 0.09948115, g_loss: 2.38707542, rnn_loss: 0.00000000\n",
      " ** Epoch 837 took 96.075714s\n",
      "Epoch: [838/1000] time: 0.7322s, d_loss: 0.18326622, g_loss: 1.98125780, rnn_loss: 0.00000000\n",
      " ** Epoch 838 took 96.665573s\n",
      "Epoch: [839/1000] time: 0.6954s, d_loss: 0.34873810, g_loss: 3.25479841, rnn_loss: 0.00000000\n",
      " ** Epoch 839 took 96.427022s\n",
      "Epoch: [840/1000] time: 0.7021s, d_loss: 0.10672092, g_loss: 2.39760494, rnn_loss: 0.00000000\n",
      " ** Epoch 840 took 96.964718s\n",
      "Epoch: [841/1000] time: 0.6984s, d_loss: 0.18699619, g_loss: 2.25068045, rnn_loss: 0.00000000\n",
      " ** Epoch 841 took 96.466080s\n",
      "Epoch: [842/1000] time: 0.6964s, d_loss: 0.12760603, g_loss: 2.40654850, rnn_loss: 0.00000000\n",
      " ** Epoch 842 took 97.265236s\n",
      "Epoch: [843/1000] time: 0.6907s, d_loss: 0.14092958, g_loss: 3.48618269, rnn_loss: 0.00000000\n",
      " ** Epoch 843 took 96.045991s\n",
      "Epoch: [844/1000] time: 0.6918s, d_loss: 0.08239055, g_loss: 2.91339445, rnn_loss: 0.00000000\n",
      " ** Epoch 844 took 96.480064s\n",
      "Epoch: [845/1000] time: 0.7011s, d_loss: 0.37009254, g_loss: 2.68123031, rnn_loss: 0.00000000\n",
      " ** Epoch 845 took 96.317243s\n",
      "Epoch: [846/1000] time: 0.6926s, d_loss: 0.14229654, g_loss: 2.41159916, rnn_loss: 0.00000000\n",
      " ** Epoch 846 took 96.572309s\n",
      "Epoch: [847/1000] time: 0.7009s, d_loss: 0.05072691, g_loss: 2.93978095, rnn_loss: 0.00000000\n",
      " ** Epoch 847 took 96.101599s\n",
      "Epoch: [848/1000] time: 0.6967s, d_loss: 0.29333901, g_loss: 1.75744164, rnn_loss: 0.00000000\n",
      " ** Epoch 848 took 96.943469s\n",
      "Epoch: [849/1000] time: 0.6953s, d_loss: 0.23166460, g_loss: 2.36702418, rnn_loss: 0.00000000\n",
      " ** Epoch 849 took 95.785686s\n",
      "Epoch: [850/1000] time: 0.6925s, d_loss: 0.21597090, g_loss: 2.69349527, rnn_loss: 0.00000000\n",
      " ** Epoch 850 took 96.195496s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [851/1000] time: 0.6906s, d_loss: 0.23229770, g_loss: 3.67850399, rnn_loss: 0.00000000\n",
      " ** Epoch 851 took 96.569603s\n",
      "Epoch: [852/1000] time: 0.6936s, d_loss: 0.09716971, g_loss: 2.56346822, rnn_loss: 0.00000000\n",
      " ** Epoch 852 took 96.065078s\n",
      "Epoch: [853/1000] time: 0.6969s, d_loss: 0.14954776, g_loss: 2.50124288, rnn_loss: 0.00000000\n",
      " ** Epoch 853 took 96.067044s\n",
      "Epoch: [854/1000] time: 0.7056s, d_loss: 0.31230763, g_loss: 2.02052116, rnn_loss: 0.00000000\n",
      " ** Epoch 854 took 97.385458s\n",
      "Epoch: [855/1000] time: 0.6914s, d_loss: 0.40634242, g_loss: 4.16139364, rnn_loss: 0.00000000\n",
      " ** Epoch 855 took 96.216397s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [856/1000] time: 0.7416s, d_loss: 0.07098988, g_loss: 2.28779411, rnn_loss: 0.00000000\n",
      " ** Epoch 856 took 96.784974s\n",
      "Epoch: [857/1000] time: 0.7092s, d_loss: 0.18112411, g_loss: 3.40401816, rnn_loss: 0.00000000\n",
      " ** Epoch 857 took 96.563474s\n",
      "Epoch: [858/1000] time: 0.6927s, d_loss: 0.48312911, g_loss: 2.27302480, rnn_loss: 0.00000000\n",
      " ** Epoch 858 took 96.553096s\n",
      "Epoch: [859/1000] time: 0.6975s, d_loss: 0.12883641, g_loss: 4.02741241, rnn_loss: 0.00000000\n",
      " ** Epoch 859 took 96.781672s\n",
      "Epoch: [860/1000] time: 0.6994s, d_loss: 0.31378710, g_loss: 1.87345243, rnn_loss: 0.00000000\n",
      " ** Epoch 860 took 96.970049s\n",
      "Epoch: [861/1000] time: 0.7161s, d_loss: 0.14540896, g_loss: 2.20583272, rnn_loss: 0.00000000\n",
      " ** Epoch 861 took 97.271165s\n",
      "Epoch: [862/1000] time: 0.7036s, d_loss: 0.25167438, g_loss: 3.27396965, rnn_loss: 0.00000000\n",
      " ** Epoch 862 took 96.426781s\n",
      "Epoch: [863/1000] time: 0.7253s, d_loss: 0.17770202, g_loss: 2.05113745, rnn_loss: 0.00000000\n",
      " ** Epoch 863 took 97.138194s\n",
      "Epoch: [864/1000] time: 0.6979s, d_loss: 0.35407805, g_loss: 1.84797072, rnn_loss: 0.00000000\n",
      " ** Epoch 864 took 97.409629s\n",
      "Epoch: [865/1000] time: 0.6983s, d_loss: 0.34044254, g_loss: 1.78291106, rnn_loss: 0.00000000\n",
      " ** Epoch 865 took 97.208902s\n",
      "Epoch: [866/1000] time: 0.6947s, d_loss: 0.04779953, g_loss: 4.60973358, rnn_loss: 0.00000000\n",
      " ** Epoch 866 took 96.713083s\n",
      "Epoch: [867/1000] time: 0.6896s, d_loss: 0.11284746, g_loss: 2.53295708, rnn_loss: 0.00000000\n",
      " ** Epoch 867 took 96.844884s\n",
      "Epoch: [868/1000] time: 0.7012s, d_loss: 0.26467961, g_loss: 2.25110650, rnn_loss: 0.00000000\n",
      " ** Epoch 868 took 96.762850s\n",
      "Epoch: [869/1000] time: 0.6892s, d_loss: 0.06588213, g_loss: 3.27985501, rnn_loss: 0.00000000\n",
      " ** Epoch 869 took 96.826554s\n",
      "Epoch: [870/1000] time: 0.7191s, d_loss: 0.52986306, g_loss: 1.58477354, rnn_loss: 0.00000000\n",
      " ** Epoch 870 took 97.084048s\n",
      "Epoch: [871/1000] time: 0.6986s, d_loss: 0.08921226, g_loss: 2.62857533, rnn_loss: 0.00000000\n",
      " ** Epoch 871 took 96.826914s\n",
      "Epoch: [872/1000] time: 0.6984s, d_loss: 0.13441496, g_loss: 2.29084134, rnn_loss: 0.00000000\n",
      " ** Epoch 872 took 96.765500s\n",
      "Epoch: [873/1000] time: 0.7117s, d_loss: 0.21668285, g_loss: 2.06889200, rnn_loss: 0.00000000\n",
      " ** Epoch 873 took 97.279508s\n",
      "Epoch: [874/1000] time: 0.7240s, d_loss: 0.02167695, g_loss: 3.99147153, rnn_loss: 0.00000000\n",
      " ** Epoch 874 took 96.790478s\n",
      "Epoch: [875/1000] time: 0.6973s, d_loss: 0.06016750, g_loss: 3.02654791, rnn_loss: 0.00000000\n",
      " ** Epoch 875 took 96.702206s\n",
      "Epoch: [876/1000] time: 0.6952s, d_loss: 0.42931354, g_loss: 1.80922508, rnn_loss: 0.00000000\n",
      " ** Epoch 876 took 98.355586s\n",
      "Epoch: [877/1000] time: 0.7058s, d_loss: 0.11268049, g_loss: 2.56667233, rnn_loss: 0.00000000\n",
      " ** Epoch 877 took 96.636118s\n",
      "Epoch: [878/1000] time: 0.7022s, d_loss: 0.32495034, g_loss: 2.01586342, rnn_loss: 0.00000000\n",
      " ** Epoch 878 took 96.526228s\n",
      "Epoch: [879/1000] time: 0.7063s, d_loss: 0.30428711, g_loss: 3.29023671, rnn_loss: 0.00000000\n",
      " ** Epoch 879 took 97.116675s\n",
      "Epoch: [880/1000] time: 0.7533s, d_loss: 0.06614041, g_loss: 2.73471403, rnn_loss: 0.00000000\n",
      " ** Epoch 880 took 98.032648s\n",
      "Epoch: [881/1000] time: 0.7572s, d_loss: 0.25325319, g_loss: 1.97461104, rnn_loss: 0.00000000\n",
      " ** Epoch 881 took 97.113379s\n",
      "Epoch: [882/1000] time: 0.6933s, d_loss: 0.27369374, g_loss: 1.92697167, rnn_loss: 0.00000000\n",
      " ** Epoch 882 took 97.387475s\n",
      "Epoch: [883/1000] time: 0.6938s, d_loss: 0.36176279, g_loss: 1.73196292, rnn_loss: 0.00000000\n",
      " ** Epoch 883 took 96.893113s\n",
      "Epoch: [884/1000] time: 0.7027s, d_loss: 0.10010956, g_loss: 2.79763222, rnn_loss: 0.00000000\n",
      " ** Epoch 884 took 97.437267s\n",
      "Epoch: [885/1000] time: 0.6933s, d_loss: 0.14188658, g_loss: 2.36591768, rnn_loss: 0.00000000\n",
      " ** Epoch 885 took 97.168981s\n",
      "Epoch: [886/1000] time: 0.6995s, d_loss: 0.18473192, g_loss: 1.66114926, rnn_loss: 0.00000000\n",
      " ** Epoch 886 took 97.690606s\n",
      "Epoch: [887/1000] time: 0.8297s, d_loss: 0.06687284, g_loss: 3.13842392, rnn_loss: 0.00000000\n",
      " ** Epoch 887 took 98.221812s\n",
      "Epoch: [888/1000] time: 0.7005s, d_loss: 0.29208043, g_loss: 1.66014874, rnn_loss: 0.00000000\n",
      " ** Epoch 888 took 98.844880s\n",
      "Epoch: [889/1000] time: 0.6956s, d_loss: 0.18409073, g_loss: 2.33654571, rnn_loss: 0.00000000\n",
      " ** Epoch 889 took 97.867102s\n",
      "Epoch: [890/1000] time: 0.6938s, d_loss: 0.15358996, g_loss: 3.33244419, rnn_loss: 0.00000000\n",
      " ** Epoch 890 took 97.995125s\n",
      "Epoch: [891/1000] time: 0.6900s, d_loss: 0.60414237, g_loss: 1.23544180, rnn_loss: 0.00000000\n",
      " ** Epoch 891 took 97.968074s\n",
      "Epoch: [892/1000] time: 0.7062s, d_loss: 0.30279192, g_loss: 1.96811187, rnn_loss: 0.00000000\n",
      " ** Epoch 892 took 97.447423s\n",
      "Epoch: [893/1000] time: 0.6907s, d_loss: 0.35531867, g_loss: 1.65218592, rnn_loss: 0.00000000\n",
      " ** Epoch 893 took 98.018580s\n",
      "Epoch: [894/1000] time: 0.7087s, d_loss: 0.45556372, g_loss: 1.46999383, rnn_loss: 0.00000000\n",
      " ** Epoch 894 took 96.719061s\n",
      "Epoch: [895/1000] time: 0.6991s, d_loss: 0.18964902, g_loss: 2.24931812, rnn_loss: 0.00000000\n",
      " ** Epoch 895 took 98.558376s\n",
      "Epoch: [896/1000] time: 0.7013s, d_loss: 0.45098689, g_loss: 1.41197157, rnn_loss: 0.00000000\n",
      " ** Epoch 896 took 98.365347s\n",
      "Epoch: [897/1000] time: 0.6928s, d_loss: 0.19358851, g_loss: 3.45621634, rnn_loss: 0.00000000\n",
      " ** Epoch 897 took 97.624586s\n",
      "Epoch: [898/1000] time: 0.6921s, d_loss: 0.12468828, g_loss: 2.30052352, rnn_loss: 0.00000000\n",
      " ** Epoch 898 took 97.709195s\n",
      "Epoch: [899/1000] time: 0.6944s, d_loss: 0.19870198, g_loss: 2.49253178, rnn_loss: 0.00000000\n",
      " ** Epoch 899 took 99.323903s\n",
      "Epoch: [900/1000] time: 0.6922s, d_loss: 0.15431428, g_loss: 2.43488765, rnn_loss: 0.00000000\n",
      " ** Epoch 900 took 98.077733s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [901/1000] time: 0.6946s, d_loss: 0.19688487, g_loss: 2.99600267, rnn_loss: 0.00000000\n",
      " ** Epoch 901 took 98.497022s\n",
      "Epoch: [902/1000] time: 0.7175s, d_loss: 0.21839218, g_loss: 4.62357950, rnn_loss: 0.00000000\n",
      " ** Epoch 902 took 97.698061s\n",
      "Epoch: [903/1000] time: 0.7077s, d_loss: 0.06692843, g_loss: 2.89400959, rnn_loss: 0.00000000\n",
      " ** Epoch 903 took 98.345945s\n",
      "Epoch: [904/1000] time: 0.6953s, d_loss: 0.29114491, g_loss: 2.24671960, rnn_loss: 0.00000000\n",
      " ** Epoch 904 took 97.672949s\n",
      "Epoch: [905/1000] time: 0.6934s, d_loss: 0.29872677, g_loss: 1.96757936, rnn_loss: 0.00000000\n",
      " ** Epoch 905 took 97.659335s\n",
      "Epoch: [906/1000] time: 0.6971s, d_loss: 0.09131673, g_loss: 3.32212114, rnn_loss: 0.00000000\n",
      " ** Epoch 906 took 99.045171s\n",
      "Epoch: [907/1000] time: 0.7895s, d_loss: 0.11039894, g_loss: 2.33401728, rnn_loss: 0.00000000\n",
      " ** Epoch 907 took 97.995408s\n",
      "Epoch: [908/1000] time: 0.7054s, d_loss: 0.07413999, g_loss: 3.28711891, rnn_loss: 0.00000000\n",
      " ** Epoch 908 took 99.488627s\n",
      "Epoch: [909/1000] time: 0.6937s, d_loss: 0.44289148, g_loss: 2.65878630, rnn_loss: 0.00000000\n",
      " ** Epoch 909 took 97.650326s\n",
      "Epoch: [910/1000] time: 0.7041s, d_loss: 0.54279500, g_loss: 2.45541286, rnn_loss: 0.00000000\n",
      " ** Epoch 910 took 98.532763s\n",
      "Epoch: [911/1000] time: 0.7037s, d_loss: 1.05703592, g_loss: 1.25001621, rnn_loss: 0.00000000\n",
      " ** Epoch 911 took 98.745957s\n",
      "Epoch: [912/1000] time: 0.7280s, d_loss: 0.03780389, g_loss: 3.75540948, rnn_loss: 0.00000000\n",
      " ** Epoch 912 took 100.981916s\n",
      "Epoch: [913/1000] time: 0.7066s, d_loss: 0.25050426, g_loss: 1.88534868, rnn_loss: 0.00000000\n",
      " ** Epoch 913 took 102.590077s\n",
      "Epoch: [914/1000] time: 0.6878s, d_loss: 0.08239910, g_loss: 3.62471390, rnn_loss: 0.00000000\n",
      " ** Epoch 914 took 98.400466s\n",
      "Epoch: [915/1000] time: 0.7226s, d_loss: 0.33790284, g_loss: 1.91944027, rnn_loss: 0.00000000\n",
      " ** Epoch 915 took 97.707223s\n",
      "Epoch: [916/1000] time: 0.7046s, d_loss: 0.47037590, g_loss: 1.77861810, rnn_loss: 0.00000000\n",
      " ** Epoch 916 took 98.279168s\n",
      "Epoch: [917/1000] time: 0.7763s, d_loss: 0.20833641, g_loss: 2.95206022, rnn_loss: 0.00000000\n",
      " ** Epoch 917 took 99.318674s\n",
      "Epoch: [918/1000] time: 0.7035s, d_loss: 0.31150252, g_loss: 2.03434563, rnn_loss: 0.00000000\n",
      " ** Epoch 918 took 98.264195s\n",
      "Epoch: [919/1000] time: 0.6964s, d_loss: 0.33541387, g_loss: 2.00321341, rnn_loss: 0.00000000\n",
      " ** Epoch 919 took 98.216220s\n",
      "Epoch: [920/1000] time: 0.7566s, d_loss: 0.07545508, g_loss: 3.60127544, rnn_loss: 0.00000000\n",
      " ** Epoch 920 took 97.827700s\n",
      "Epoch: [921/1000] time: 0.7119s, d_loss: 0.36236674, g_loss: 1.57160306, rnn_loss: 0.00000000\n",
      " ** Epoch 921 took 99.537994s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [922/1000] time: 0.7059s, d_loss: 0.18346640, g_loss: 2.01748419, rnn_loss: 0.00000000\n",
      " ** Epoch 922 took 98.365837s\n",
      "Epoch: [923/1000] time: 0.7236s, d_loss: 0.11494214, g_loss: 2.36484289, rnn_loss: 0.00000000\n",
      " ** Epoch 923 took 98.802034s\n",
      "Epoch: [924/1000] time: 0.7833s, d_loss: 0.08828337, g_loss: 2.99044895, rnn_loss: 0.00000000\n",
      " ** Epoch 924 took 100.994431s\n",
      "Epoch: [925/1000] time: 0.7046s, d_loss: 0.41015318, g_loss: 1.30677557, rnn_loss: 0.00000000\n",
      " ** Epoch 925 took 99.470583s\n",
      "Epoch: [926/1000] time: 0.7397s, d_loss: 0.09312907, g_loss: 2.79050827, rnn_loss: 0.00000000\n",
      " ** Epoch 926 took 98.483651s\n",
      "Epoch: [927/1000] time: 0.7225s, d_loss: 0.74359137, g_loss: 1.10862279, rnn_loss: 0.00000000\n",
      " ** Epoch 927 took 100.346544s\n",
      "Epoch: [928/1000] time: 0.7111s, d_loss: 0.05494282, g_loss: 3.30764866, rnn_loss: 0.00000000\n",
      " ** Epoch 928 took 98.765232s\n",
      "Epoch: [929/1000] time: 0.7288s, d_loss: 0.30083454, g_loss: 2.00351334, rnn_loss: 0.00000000\n",
      " ** Epoch 929 took 101.049555s\n",
      "Epoch: [930/1000] time: 0.7055s, d_loss: 0.17751160, g_loss: 2.04174042, rnn_loss: 0.00000000\n",
      " ** Epoch 930 took 99.776953s\n",
      "Epoch: [931/1000] time: 0.7029s, d_loss: 0.06767264, g_loss: 3.31516075, rnn_loss: 0.00000000\n",
      " ** Epoch 931 took 99.492707s\n",
      "Epoch: [932/1000] time: 0.7271s, d_loss: 0.44257471, g_loss: 5.21537971, rnn_loss: 0.00000000\n",
      " ** Epoch 932 took 100.319402s\n",
      "Epoch: [933/1000] time: 0.7369s, d_loss: 0.09048626, g_loss: 3.60213447, rnn_loss: 0.00000000\n",
      " ** Epoch 933 took 99.403484s\n",
      "Epoch: [934/1000] time: 0.7106s, d_loss: 0.36206096, g_loss: 1.32990289, rnn_loss: 0.00000000\n",
      " ** Epoch 934 took 98.668429s\n",
      "Epoch: [935/1000] time: 0.7427s, d_loss: 0.20117834, g_loss: 1.90906227, rnn_loss: 0.00000000\n",
      " ** Epoch 935 took 98.697927s\n",
      "Epoch: [936/1000] time: 0.8020s, d_loss: 0.68099421, g_loss: 2.40041065, rnn_loss: 0.00000000\n",
      " ** Epoch 936 took 100.022856s\n",
      "Epoch: [937/1000] time: 0.7089s, d_loss: 0.84803712, g_loss: 3.22621107, rnn_loss: 0.00000000\n",
      " ** Epoch 937 took 98.260545s\n",
      "Epoch: [938/1000] time: 0.7111s, d_loss: 0.12694432, g_loss: 2.48186827, rnn_loss: 0.00000000\n",
      " ** Epoch 938 took 101.883247s\n",
      "Epoch: [939/1000] time: 0.7149s, d_loss: 0.15806420, g_loss: 2.11574435, rnn_loss: 0.00000000\n",
      " ** Epoch 939 took 99.554633s\n",
      "Epoch: [940/1000] time: 0.6953s, d_loss: 0.06820381, g_loss: 2.85158348, rnn_loss: 0.00000000\n",
      " ** Epoch 940 took 99.982439s\n",
      "Epoch: [941/1000] time: 0.7531s, d_loss: 0.06370765, g_loss: 3.17539787, rnn_loss: 0.00000000\n",
      " ** Epoch 941 took 99.756653s\n",
      "Epoch: [942/1000] time: 0.6932s, d_loss: 0.07904811, g_loss: 3.00364780, rnn_loss: 0.00000000\n",
      " ** Epoch 942 took 99.091668s\n",
      "Epoch: [943/1000] time: 0.6901s, d_loss: 0.17098308, g_loss: 2.32373762, rnn_loss: 0.00000000\n",
      " ** Epoch 943 took 101.262685s\n",
      "Epoch: [944/1000] time: 0.7175s, d_loss: 0.06465292, g_loss: 3.35227990, rnn_loss: 0.00000000\n",
      " ** Epoch 944 took 99.293315s\n",
      "Epoch: [945/1000] time: 0.7506s, d_loss: 0.09491891, g_loss: 3.49327683, rnn_loss: 0.00000000\n",
      " ** Epoch 945 took 99.165782s\n",
      "Epoch: [946/1000] time: 0.6943s, d_loss: 0.32308578, g_loss: 2.00565434, rnn_loss: 0.00000000\n",
      " ** Epoch 946 took 100.731163s\n",
      "Epoch: [947/1000] time: 0.7671s, d_loss: 0.03957354, g_loss: 3.90911627, rnn_loss: 0.00000000\n",
      " ** Epoch 947 took 98.881496s\n",
      "Epoch: [948/1000] time: 0.7234s, d_loss: 0.14162692, g_loss: 2.61181068, rnn_loss: 0.00000000\n",
      " ** Epoch 948 took 99.063839s\n",
      "Epoch: [949/1000] time: 0.7117s, d_loss: 0.32889888, g_loss: 1.71722078, rnn_loss: 0.00000000\n",
      " ** Epoch 949 took 100.338218s\n",
      "Epoch: [950/1000] time: 0.7085s, d_loss: 0.28405252, g_loss: 1.53980207, rnn_loss: 0.00000000\n",
      " ** Epoch 950 took 100.678535s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [951/1000] time: 0.7003s, d_loss: 0.43023199, g_loss: 1.53454578, rnn_loss: 0.00000000\n",
      " ** Epoch 951 took 98.946523s\n",
      "Epoch: [952/1000] time: 0.7225s, d_loss: 0.28048223, g_loss: 3.18625593, rnn_loss: 0.00000000\n",
      " ** Epoch 952 took 100.738527s\n",
      "Epoch: [953/1000] time: 0.6981s, d_loss: 0.24012916, g_loss: 2.41036344, rnn_loss: 0.00000000\n",
      " ** Epoch 953 took 101.396945s\n",
      "Epoch: [954/1000] time: 0.7058s, d_loss: 0.53071421, g_loss: 3.29508638, rnn_loss: 0.00000000\n",
      " ** Epoch 954 took 101.228254s\n",
      "Epoch: [955/1000] time: 0.6927s, d_loss: 0.07148582, g_loss: 2.95855021, rnn_loss: 0.00000000\n",
      " ** Epoch 955 took 102.605080s\n",
      "Epoch: [956/1000] time: 0.8280s, d_loss: 0.27257591, g_loss: 2.03924584, rnn_loss: 0.00000000\n",
      " ** Epoch 956 took 101.907856s\n",
      "Epoch: [957/1000] time: 0.7184s, d_loss: 0.21444950, g_loss: 2.02345037, rnn_loss: 0.00000000\n",
      " ** Epoch 957 took 101.912599s\n",
      "Epoch: [958/1000] time: 0.8141s, d_loss: 0.07358211, g_loss: 3.96834278, rnn_loss: 0.00000000\n",
      " ** Epoch 958 took 102.075405s\n",
      "Epoch: [959/1000] time: 0.7014s, d_loss: 0.12430879, g_loss: 2.62260365, rnn_loss: 0.00000000\n",
      " ** Epoch 959 took 103.698779s\n",
      "Epoch: [960/1000] time: 0.7042s, d_loss: 0.17024845, g_loss: 2.29981613, rnn_loss: 0.00000000\n",
      " ** Epoch 960 took 102.721937s\n",
      "Epoch: [961/1000] time: 0.6972s, d_loss: 0.38046560, g_loss: 3.28355932, rnn_loss: 0.00000000\n",
      " ** Epoch 961 took 101.774212s\n",
      "Epoch: [962/1000] time: 0.7146s, d_loss: 0.17312773, g_loss: 3.12405396, rnn_loss: 0.00000000\n",
      " ** Epoch 962 took 102.383850s\n",
      "Epoch: [963/1000] time: 0.7419s, d_loss: 0.08677748, g_loss: 2.78795838, rnn_loss: 0.00000000\n",
      " ** Epoch 963 took 104.125200s\n",
      "Epoch: [964/1000] time: 0.7017s, d_loss: 0.08023347, g_loss: 3.34016705, rnn_loss: 0.00000000\n",
      " ** Epoch 964 took 98.983869s\n",
      "Epoch: [965/1000] time: 0.7926s, d_loss: 0.41689074, g_loss: 1.87119603, rnn_loss: 0.00000000\n",
      " ** Epoch 965 took 99.878147s\n",
      "Epoch: [966/1000] time: 0.7270s, d_loss: 0.17084783, g_loss: 3.05727243, rnn_loss: 0.00000000\n",
      " ** Epoch 966 took 101.778105s\n",
      "Epoch: [967/1000] time: 0.7664s, d_loss: 0.06367293, g_loss: 3.23781538, rnn_loss: 0.00000000\n",
      " ** Epoch 967 took 102.027749s\n",
      "Epoch: [968/1000] time: 0.7360s, d_loss: 0.05869122, g_loss: 3.08043671, rnn_loss: 0.00000000\n",
      " ** Epoch 968 took 99.842689s\n",
      "Epoch: [969/1000] time: 0.7403s, d_loss: 0.17545584, g_loss: 2.44334054, rnn_loss: 0.00000000\n",
      " ** Epoch 969 took 101.575709s\n",
      "Epoch: [970/1000] time: 0.7442s, d_loss: 0.06071632, g_loss: 3.31730962, rnn_loss: 0.00000000\n",
      " ** Epoch 970 took 105.085311s\n",
      "Epoch: [971/1000] time: 0.7870s, d_loss: 0.04468086, g_loss: 4.33362961, rnn_loss: 0.00000000\n",
      " ** Epoch 971 took 103.597112s\n",
      "Epoch: [972/1000] time: 0.7254s, d_loss: 0.23451561, g_loss: 2.52997875, rnn_loss: 0.00000000\n",
      " ** Epoch 972 took 103.156985s\n",
      "Epoch: [973/1000] time: 0.6983s, d_loss: 0.12139447, g_loss: 2.32588959, rnn_loss: 0.00000000\n",
      " ** Epoch 973 took 104.284100s\n",
      "Epoch: [974/1000] time: 0.7613s, d_loss: 0.26816759, g_loss: 3.36994624, rnn_loss: 0.00000000\n",
      " ** Epoch 974 took 101.301711s\n",
      "Epoch: [975/1000] time: 0.7252s, d_loss: 0.13003138, g_loss: 2.89434624, rnn_loss: 0.00000000\n",
      " ** Epoch 975 took 104.725654s\n",
      "Epoch: [976/1000] time: 0.7124s, d_loss: 0.20858479, g_loss: 1.90577531, rnn_loss: 0.00000000\n",
      " ** Epoch 976 took 105.975388s\n",
      "Epoch: [977/1000] time: 0.7057s, d_loss: 0.38305125, g_loss: 1.50652814, rnn_loss: 0.00000000\n",
      " ** Epoch 977 took 104.392064s\n",
      "Epoch: [978/1000] time: 0.7550s, d_loss: 0.37968394, g_loss: 5.33556080, rnn_loss: 0.00000000\n",
      " ** Epoch 978 took 103.969776s\n",
      "Epoch: [979/1000] time: 0.7596s, d_loss: 0.35359985, g_loss: 1.60210788, rnn_loss: 0.00000000\n",
      " ** Epoch 979 took 105.961341s\n",
      "Epoch: [980/1000] time: 0.7377s, d_loss: 0.07694145, g_loss: 3.39059067, rnn_loss: 0.00000000\n",
      " ** Epoch 980 took 106.189797s\n",
      "Epoch: [981/1000] time: 0.7141s, d_loss: 0.19153000, g_loss: 1.95476723, rnn_loss: 0.00000000\n",
      " ** Epoch 981 took 104.284690s\n",
      "Epoch: [982/1000] time: 0.7191s, d_loss: 0.13258442, g_loss: 3.81904650, rnn_loss: 0.00000000\n",
      " ** Epoch 982 took 103.562289s\n",
      "Epoch: [983/1000] time: 0.7085s, d_loss: 0.17554456, g_loss: 2.87147570, rnn_loss: 0.00000000\n",
      " ** Epoch 983 took 102.257905s\n",
      "Epoch: [984/1000] time: 0.7101s, d_loss: 0.10925190, g_loss: 2.46218586, rnn_loss: 0.00000000\n",
      " ** Epoch 984 took 104.404653s\n",
      "Epoch: [985/1000] time: 0.7109s, d_loss: 0.01551378, g_loss: 5.46411562, rnn_loss: 0.00000000\n",
      " ** Epoch 985 took 103.938991s\n",
      "Epoch: [986/1000] time: 0.8437s, d_loss: 0.07644585, g_loss: 3.10560703, rnn_loss: 0.00000000\n",
      " ** Epoch 986 took 104.270262s\n",
      "Epoch: [987/1000] time: 0.7646s, d_loss: 0.13411361, g_loss: 3.04824686, rnn_loss: 0.00000000\n",
      " ** Epoch 987 took 107.925735s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [988/1000] time: 0.7666s, d_loss: 0.12903501, g_loss: 3.81055117, rnn_loss: 0.00000000\n",
      " ** Epoch 988 took 105.175717s\n",
      "Epoch: [989/1000] time: 0.8286s, d_loss: 0.12241114, g_loss: 2.59005833, rnn_loss: 0.00000000\n",
      " ** Epoch 989 took 103.426058s\n",
      "Epoch: [990/1000] time: 0.7379s, d_loss: 0.10007529, g_loss: 3.16802025, rnn_loss: 0.00000000\n",
      " ** Epoch 990 took 102.740494s\n",
      "Epoch: [991/1000] time: 0.7894s, d_loss: 0.36774862, g_loss: 1.69402111, rnn_loss: 0.00000000\n",
      " ** Epoch 991 took 103.393481s\n",
      "Epoch: [992/1000] time: 0.7267s, d_loss: 0.04324257, g_loss: 3.33473778, rnn_loss: 0.00000000\n",
      " ** Epoch 992 took 107.472787s\n",
      "Epoch: [993/1000] time: 0.7482s, d_loss: 0.10786066, g_loss: 2.97771549, rnn_loss: 0.00000000\n",
      " ** Epoch 993 took 105.214008s\n",
      "Epoch: [994/1000] time: 0.7190s, d_loss: 0.21804029, g_loss: 2.33146906, rnn_loss: 0.00000000\n",
      " ** Epoch 994 took 104.281992s\n",
      "Epoch: [995/1000] time: 0.8388s, d_loss: 0.19595832, g_loss: 3.20138955, rnn_loss: 0.00000000\n",
      " ** Epoch 995 took 103.602194s\n",
      "Epoch: [996/1000] time: 0.7371s, d_loss: 0.05933649, g_loss: 3.25621176, rnn_loss: 0.00000000\n",
      " ** Epoch 996 took 105.357918s\n",
      "Epoch: [997/1000] time: 0.7444s, d_loss: 0.12505819, g_loss: 3.75582457, rnn_loss: 0.00000000\n",
      " ** Epoch 997 took 104.108902s\n",
      "Epoch: [998/1000] time: 0.7662s, d_loss: 0.06882038, g_loss: 2.89091349, rnn_loss: 0.00000000\n",
      " ** Epoch 998 took 103.418429s\n",
      "Epoch: [999/1000] time: 0.6941s, d_loss: 0.08040027, g_loss: 3.03093076, rnn_loss: 0.00000000\n",
      " ** Epoch 999 took 103.708229s\n",
      "The checkpoint has been created.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = Text2Img()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=10)\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "    load_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "    load(loader, sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print('no checkpoints find.')\n",
    "\n",
    "n_epoch = 1000\n",
    "n_batch_epoch = int(n_images_train / batch_size)\n",
    "for epoch in range(n_epoch):\n",
    "    start_time = time.time()\n",
    "    if epoch !=0 and (epoch % decay_every == 0):\n",
    "        new_lr_decay = lr_decay ** (epoch // decay_every)\n",
    "        sess.run(tf.assign(model.lr_v, lr * new_lr_decay))\n",
    "        log = \" ** new learning rate: %f\" % (lr * new_lr_decay)\n",
    "        print(log)\n",
    "    elif epoch == 0:\n",
    "        log = \" ** init lr: %f  decay_every_epoch: %d, lr_decay: %f\" % (lr, decay_every, lr_decay)\n",
    "        print(log)\n",
    "    for step in range(n_batch_epoch):\n",
    "        step_time = time.time()\n",
    "        idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\n",
    "        b_real_caption = train_captions[idexs]\n",
    "        b_real_images = train_images[np.floor(np.asarray(idexs).astype('float') / n_captions_per_image).astype('int')]\n",
    "        idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\n",
    "        b_wrong_caption = train_captions[idexs]\n",
    "        idexs2 = get_random_int(min=0, max=n_images_train-1, number=batch_size)\n",
    "        b_wrong_images = train_images[idexs2]\n",
    "        b_z = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, z_dim)).astype(np.float32)\n",
    "        b_real_images = threading_data(b_real_images, prepro_img, mode='train')\n",
    "        b_wrong_images = threading_data(b_wrong_images, prepro_img, mode='train')\n",
    "        if epoch < 300:\n",
    "            errRNN, _ = sess.run([model.rnn_loss, model.rnn_optim], feed_dict={\n",
    "                                            model.t_real_image : b_real_images,\n",
    "                                            model.t_wrong_image : b_wrong_images,\n",
    "                                            model.t_real_caption : b_real_caption,\n",
    "                                            model.t_wrong_caption : b_wrong_caption})\n",
    "        else:\n",
    "            errRNN = 0   \n",
    "        errD, _ = sess.run([model.d_loss, model.d_optim], feed_dict={\n",
    "                            model.t_real_image : b_real_images,\n",
    "                            model.t_wrong_caption : b_wrong_caption,\n",
    "                            model.t_real_caption : b_real_caption,\n",
    "                            model.t_z : b_z})\n",
    "        errG, _ = sess.run([model.g_loss, model.g_optim], feed_dict={\n",
    "                            model.t_real_caption : b_real_caption,\n",
    "                            model.t_z : b_z})\n",
    "    print(\"Epoch: [%d/%d] time: %4.4fs, d_loss: %.8f, g_loss: %.8f, rnn_loss: %.8f\" \\\n",
    "                        % (epoch, n_epoch, time.time() - step_time, errD, errG, errRNN))\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(\" ** Epoch %d took %fs\" % (epoch, time.time()-start_time))\n",
    "        img_gen, rnn_out = sess.run([model.net_g.outputs, model.net_rnn.outputs], feed_dict={\n",
    "                                        model.t_real_caption : sample_sentence,\n",
    "                                        model.t_z : sample_seed})\n",
    "        save_images(img_gen, [ni, ni], 'train_samples_1215_b/train_{:02d}.png'.format(epoch))\n",
    "    if (epoch != 0) and (epoch % 50) == 0:\n",
    "        save(saver, sess, checkpoint_dir, epoch)\n",
    "        print(\"[*] Save checkpoints SUCCESS!\")\n",
    "checkpoint_path = os.path.join(cfg.CHECKPOINT_DIR, cfg.CHECKPOINT_NAME)\n",
    "saver.save(sess, checkpoint_path, global_step=epoch)\n",
    "print('The checkpoint has been created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_r_precision_data():\n",
    "    caption_ids = np.reshape(np.asarray(test_dataset.captions_ids), (-1, cfg.TEXT.WORDS_NUM))\n",
    "    captions_ids_wrong = np.reshape(test_dataset.random_wrong_captions(), (-1, cfg.WRONG_CAPTION, cfg.TEXT.WORDS_NUM))\n",
    "\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # load the trained checkpoint\n",
    "    checkpoint_dir = cfg.CHECKPOINT_DIR\n",
    "    if checkpoint_dir is not None:\n",
    "        loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "        ckpt_path = os.path.join(cfg.CHECKPOINT_DIR, CHECKPOINT_NAME)\n",
    "        loader.restore(sess, ckpt_path)\n",
    "        print(\"Restored model parameters from {}\".format(ckpt_path))\n",
    "    else:\n",
    "        print('no checkpoints find.')\n",
    "\n",
    "    n_caption_test = len(caption_ids)\n",
    "    num_batches = n_caption_test // cfg.BATCH_SIZE\n",
    "\n",
    "    true_cnn_features = np.zeros((num_batches, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "    true_rnn_features = np.zeros((num_batches, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "    wrong_rnn_features = np.zeros((num_batches, cfg.WRONG_CAPTION, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        test_cap = caption_ids[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "\n",
    "        z = np.random.normal(loc=0.0, scale=1.0, size=(cfg.BATCH_SIZE, cfg.GAN.Z_DIM)).astype(np.float32)\n",
    "        \n",
    "        rnn_features = sess.run(rnn_encoder.outputs, feed_dict={t_real_caption: test_cap})\n",
    "        gen = sess.run(generator.outputs, feed_dict={t_real_caption: test_cap, t_z: z})\n",
    "        cnn_features = sess.run(cnn_encoder.outputs, feed_dict={t_real_image: gen})\n",
    "\n",
    "        true_cnn_features[i] = cnn_features\n",
    "        true_rnn_features[i] = rnn_features\n",
    "\n",
    "        for per_wrong_caption in range(cfg.WRONG_CAPTION):\n",
    "            test_cap = captions_ids_wrong[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "            rnn_features = sess.run(rnn_encoder.outputs, feed_dict={t_real_caption: test_cap[:, per_wrong_caption]})\n",
    "            wrong_rnn_features[i, per_wrong_caption] = rnn_features\n",
    "    \n",
    "    # if exists, remove the existing file first\n",
    "    try:\n",
    "        os.remove(os.path.join(cfg.R_PRECISION_DIR, cfg.R_PRECISION_FILE))\n",
    "    except OSError:\n",
    "        pass\n",
    "    np.savez(os.path.join(cfg.R_PRECISION_DIR, cfg.R_PRECISION_FILE), true_cnn=true_cnn_features, true_rnn=true_rnn_features,\n",
    "             wrong_rnn=wrong_rnn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inception_score_data():\n",
    "    caption_ids = np.reshape(np.asarray(test_dataset.captions_ids),\n",
    "                             (-1, cfg.TEXT.CAPTIONS_PER_IMAGE, cfg.TEXT.WORDS_NUM))\n",
    "    \n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    checkpoint_dir = cfg.CHECKPOINT_DIR\n",
    "    if checkpoint_dir is not None:\n",
    "        loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "        ckpt_path = os.path.join(cfg.CHECKPOINT_DIR, cfg.CHECKPOINT_NAME)\n",
    "        loader.restore(sess, ckpt_path)\n",
    "        print(\"Restored model parameters from {}\".format(ckpt_path))\n",
    "    else:\n",
    "        print('no checkpoints find.')\n",
    "\n",
    "    n_caption_test = len(caption_ids)\n",
    "    num_batches = n_caption_test // cfg.BATCH_SIZE\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        for per_caption in range(cfg.TEXT.CAPTIONS_PER_IMAGE):\n",
    "            test_cap = caption_ids[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE, per_caption]\n",
    "            test_directory = test_dataset.filenames[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "\n",
    "            z = np.random.normal(loc=0.0, scale=1.0, size=(cfg.BATCH_SIZE, cfg.GAN.Z_DIM)).astype(np.float32)\n",
    "            gen = sess.run(generator.outputs, feed_dict={t_real_caption: test_cap, t_z: z})\n",
    "            \n",
    "            for j in range(cfg.BATCH_SIZE):\n",
    "                if not os.path.exists(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j].split('/')[0])):\n",
    "                    os.mkdir(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j].split('/')[0]))\n",
    "\n",
    "                scipy.misc.imsave(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j] + '_{}.png'.format(per_caption)), gen[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_r_precision_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_inception_score_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Measure Inception score and R-precision of given test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After set the config file as 'eval_birds.yml' and run the 'generate_inception_score_data()' and 'generate_r_precision_data()', the synthesized images based on given captions and set of image and caption features should be saved inside a 'evaluation' folder, specifically in 'evaluation/generated_images/..' and as 'evaluation/r_precision.npz' respectively.\n",
    "\n",
    "**Then, go to the 'evaluation' folder and run each 'inception_score.ipynb' and 'r_precision.ipynb' file in order to measure inception score and r-precision score.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
