{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Final Proejct: Text to Image Synthesis (Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For understanding of this work, please carefully look at given PPT file.**\n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the training process **</font> so that TAs can grade both your code and results.  \n",
    "**The TA will set a config file as 'eval_birds.yml' when evaluating the code using 'hidden test dataset'. Thus, please make sure that your code can generate proper data to measure inception score and R-precision of 'hidden test dataset'.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load datasets\n",
    "The Birds dataset will be downloaded automatically if it is not located in the *data* directory. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os, nltk\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "import numpy as np\n",
    "import scipy\n",
    "from utils.data_utils import CUBDataset\n",
    "from utils.loss import cosine_similarity\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "\n",
    "#################################################\n",
    "# DO NOT CHANGE \n",
    "from utils.model import CNN_ENCODER, RNN_ENCODER, GENERATOR, DISCRIMINATOR\n",
    "#################################################\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'BATCH_SIZE': 64,\n",
      " 'CHECKPOINT_DIR': './checkpoint',\n",
      " 'CHECKPOINT_NAME': 'model.ckpt',\n",
      " 'CNN': {'EMBEDDING_DIM': 0, 'H_DIM': 0},\n",
      " 'CONFIG_NAME': 'text-to-image',\n",
      " 'CUDA': False,\n",
      " 'DATASET_NAME': 'birds',\n",
      " 'DATA_DIR': 'data/birds',\n",
      " 'EMBEDDING_TYPE': 'cnn-rnn',\n",
      " 'GAN': {'B_ATTENTION': False,\n",
      "         'B_CONDITION': False,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 0,\n",
      "         'DF_DIM': 0,\n",
      "         'EMBEDDING_DIM': 0,\n",
      "         'GF_DIM': 0,\n",
      "         'R_NUM': 0,\n",
      "         'Z_DIM': 512},\n",
      " 'GPU_ID': '0',\n",
      " 'IMAGE_SIZE': 256,\n",
      " 'NUM_BATCH_FOR_TEST': 0,\n",
      " 'RANDOM_SEED': 0,\n",
      " 'RNN': {'EMBEDDING_DIM': 0,\n",
      "         'H_DIM': 0,\n",
      "         'TYPE': '',\n",
      "         'VOCAB_SIZE': 0,\n",
      "         'WORD_EMBEDDING_DIM': 0},\n",
      " 'R_PRECISION_DIR': './evaluation',\n",
      " 'R_PRECISION_FILE': 'r_precision.npz',\n",
      " 'R_PRECISION_FILE_HIDDEN': 'r_precision_hidden.npz',\n",
      " 'TEST': {'B_EXAMPLE': False,\n",
      "          'GENERATED_HIDDEN_TEST_IMAGES': './evaluation/generated_images_hidden',\n",
      "          'GENERATED_TEST_IMAGES': './evaluation/generated_images'},\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 128, 'WORDS_NUM': 20},\n",
      " 'TRAIN': {'CNN_ENCODER': '',\n",
      "           'COEFF': {'COLOR_LOSS': 0.0, 'KL': 0.0, 'UNCOND_LOSS': 0.0},\n",
      "           'DISCRIMINATOR': '',\n",
      "           'DISCRIMINATOR_LR': 0.0,\n",
      "           'FLAG': True,\n",
      "           'GENERATOR': '',\n",
      "           'GENERATOR_LR': 0.0,\n",
      "           'MAX_EPOCH': 600,\n",
      "           'RNN_ENCODER': '',\n",
      "           'SNAPSHOT_INTERVAL': 0},\n",
      " 'WORKERS': 4,\n",
      " 'WRONG_CAPTION': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/final-project-deep-learning-19-tf/miscc/config.py:121: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "# Set a config file as 'train_birds.yml' in training, as 'eval_birds.yml' for evaluation\n",
    "cfg_from_file('cfg/train_birds.yml') # eval_birds.yml\n",
    "\n",
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cfg.GPU_ID\n",
    "\n",
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "output_dir = 'sample/%s_%s_%s' % (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf\n",
      "\n",
      "self.data_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds\n",
      "\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011.tgz\n",
      "\n",
      "Downloading: CUB-200-2011 (birds images) Bytes: 1150585339\n",
      "[======================================================================>   ***progress: 100.0% ]=======================>   ***progress: 38.6% ][=================================>   ***progress: 48.0% ][====================================>   ***progress: 52.6% ][=================================================>   ***progress: 71.1% ][========================================================>   ***progress: 81.4% ][==============================================================>   ***progress: 88.9% ][==================================================================>   ***progress: 94.3% ]\n",
      "unzipping /home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011.tgz\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011/images\n",
      "\n",
      "Save to:  data/birds/captions.pickle\n",
      "self.current_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf\n",
      "\n",
      "self.data_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds\n",
      "\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011.tgz\n",
      "\n",
      "Dataset already exists\n",
      "self.image_dir:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/CUB_200_2011/images\n",
      "\n",
      "Load from:  data/birds/captions.pickle\n",
      "\n",
      "train data directory:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/train\n",
      "test data directory:\n",
      "/home/chszerg/final-project-deep-learning-19-tf/data/birds/test\n",
      "\n",
      "# of train filenames:(8855,)\n",
      "# of test filenames:(2933,)\n",
      "\n",
      "example of filename of train image:002.Laysan_Albatross/Laysan_Albatross_0002_1027\n",
      "example of filename of valid image:001.Black_footed_Albatross/Black_Footed_Albatross_0046_18\n",
      "\n",
      "example of caption and its ids:\n",
      "['a', 'bird', 'with', 'a', 'very', 'long', 'wing', 'span', 'and', 'a', 'long', 'pointed', 'beak']\n",
      "[ 1  2  3  1  4  5  6  7  8  1  5  9 10  0  0  0  0  0  0  0]\n",
      "\n",
      "example of caption and its ids:\n",
      "['light', 'tan', 'colored', 'bird', 'with', 'a', 'white', 'head', 'and', 'an', 'orange', 'beak']\n",
      "[ 67 106  89   2   3   1  14  25   8  28  52  10   0   0   0   0   0   0\n",
      "   0   0]\n",
      "\n",
      "# of train captions:(88550,)\n",
      "# of test captions:(29330,)\n",
      "\n",
      "# of train caption ids:(88550, 20)\n",
      "# of test caption ids:(29330, 20)\n",
      "\n",
      "# of train images:(8855, 256, 256, 3)\n",
      "# of test images:(2933, 256, 256, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CUBDataset(cfg.DATA_DIR, split='train')\n",
    "test_dataset = CUBDataset(cfg.DATA_DIR, split='test')\n",
    "\n",
    "print(f'\\ntrain data directory:\\n{train_dataset.split_dir}')\n",
    "print(f'test data directory:\\n{test_dataset.split_dir}\\n')\n",
    "\n",
    "print(f'# of train filenames:{train_dataset.filenames.shape}')\n",
    "print(f'# of test filenames:{test_dataset.filenames.shape}\\n')\n",
    "\n",
    "print(f'example of filename of train image:{train_dataset.filenames[0]}')\n",
    "print(f'example of filename of valid image:{test_dataset.filenames[0]}\\n')\n",
    "\n",
    "print(f'example of caption and its ids:\\n{train_dataset.captions[0]}\\n{train_dataset.captions_ids[0]}\\n')\n",
    "print(f'example of caption and its ids:\\n{test_dataset.captions[0]}\\n{test_dataset.captions_ids[0]}\\n')\n",
    "\n",
    "print(f'# of train captions:{np.asarray(train_dataset.captions).shape}')\n",
    "print(f'# of test captions:{np.asarray(test_dataset.captions).shape}\\n')\n",
    "\n",
    "print(f'# of train caption ids:{np.asarray(train_dataset.captions_ids).shape}')\n",
    "print(f'# of test caption ids:{np.asarray(test_dataset.captions_ids).shape}\\n')\n",
    "\n",
    "print(f'# of train images:{train_dataset.images.shape}')\n",
    "print(f'# of test images:{test_dataset.images.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8855, 256, 256, 3)\n",
      "(2933, 256, 256, 3)\n",
      "(88550, 20)\n",
      "(29330, 20)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_dataset.images\n",
    "test_images = test_dataset.images\n",
    "train_captions = np.asarray(train_dataset.captions_ids)\n",
    "test_captions = np.asarray(test_dataset.captions_ids)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(train_captions.shape)\n",
    "print(test_captions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8855, 64, 64, 3)\n",
      "(2933, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "train_images_64 = []\n",
    "for train_image in train_images:\n",
    "    train_images_64.append(resize(train_image, (64, 64, 3)))\n",
    "train_images_64 = np.asarray(train_images_64)\n",
    "print(train_images_64.shape)\n",
    "assert train_images_64.shape[0] == train_images.shape[0]\n",
    "test_images_64 = []\n",
    "for test_image in test_images:\n",
    "    test_images_64.append(resize(test_image, (64, 64, 3)))\n",
    "test_images_64 = np.asarray(test_images_64)\n",
    "print(test_images_64.shape)\n",
    "assert test_images_64.shape[0] == test_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images_64\n",
    "test_images = test_images_64\n",
    "n_captions_train = len(train_captions)\n",
    "n_captions_per_image = 10\n",
    "n_images_train = len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import threading\n",
    "import scipy.ndimage as ndi\n",
    "from skimage import transform\n",
    "from skimage import exposure\n",
    "import skimage\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def sent2ID(sample_sentence):\n",
    "    caption = []\n",
    "    cap = sample_sentence\n",
    "    if len(cap) == 0:\n",
    "        exit()\n",
    "    cap = cap.replace(\"\\ufffd\\ufffd\", \" \")\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(cap.lower())\n",
    "    # print('tokens', tokens)\n",
    "    tokens_new = []\n",
    "    for t in tokens:\n",
    "        t = t.encode('ascii', 'ignore').decode('ascii')\n",
    "        if len(t) > 0:\n",
    "            tokens_new.append(t)\n",
    "    caption.append(tokens_new)\n",
    "    caption_new = []\n",
    "    t = caption[0]\n",
    "    rev = []\n",
    "    for w in t:\n",
    "        if w in train_dataset.wordtoix:\n",
    "            rev.append(train_dataset.wordtoix[w])\n",
    "    # rev.append(0)  # do not need '<end>' token\n",
    "    x, x_len = train_dataset.get_caption(rev)\n",
    "    caption_new.append(np.squeeze(x, axis=1))\n",
    "    return caption_new\n",
    "\n",
    "def ID2sent(sample_caption):\n",
    "    sentence = []\n",
    "    for ID in sample_caption:\n",
    "        if ID != train_dataset.ixtoword['<PAD>']:\n",
    "            sentence.append(train_dataset.ixtoword[ID])\n",
    "    return sentence\n",
    "\n",
    "def get_random_int(min=0, max=10, number=5):\n",
    "    \"\"\"Return a list of random integer by the given range and quantity.\n",
    "    Examples\n",
    "    ---------\n",
    "    >>> r = get_random_int(min=0, max=10, number=5)\n",
    "    ... [10, 2, 3, 3, 7]\n",
    "    \"\"\"\n",
    "    return [random.randint(min,max) for p in range(0,number)]\n",
    "\n",
    "## Save images\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "    return img\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return scipy.misc.imsave(path, merge(images, size))\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(images, size, image_path)\n",
    "\n",
    "# Data Augmentation reference: https://github.com/tensorlayer/tensorlayer/tree/master/tensorlayer\n",
    "def threading_data(data=None, fn=None, **kwargs):\n",
    "    def apply_fn(results, i, data, kwargs):\n",
    "        results[i] = fn(data, **kwargs)\n",
    "    ## start multi-threaded reading.\n",
    "    results = [None] * len(data) ## preallocate result list\n",
    "    threads = []\n",
    "    for i in range(len(data)):\n",
    "        t = threading.Thread(\n",
    "                        name='threading_and_return',\n",
    "                        target=apply_fn,\n",
    "                        args=(results, i, data[i], kwargs)\n",
    "                        )\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    return np.asarray(results)\n",
    "\n",
    "def apply_transform(x, transform_matrix, channel_index=2, fill_mode='nearest', cval=0., order=1):\n",
    "    x = np.rollaxis(x, channel_index, 0)\n",
    "    final_affine_matrix = transform_matrix[:2, :2]\n",
    "    final_offset = transform_matrix[:2, 2]\n",
    "    channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n",
    "                      final_offset, order=order, mode=fill_mode, cval=cval) for x_channel in x]\n",
    "    x = np.stack(channel_images, axis=0)\n",
    "    x = np.rollaxis(x, 0, channel_index + 1)\n",
    "    return x\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 + 0.5\n",
    "    o_y = float(y) / 2 + 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "def rotation(x, rg=20, is_random=False, row_index=0, col_index=1, channel_index=2,\n",
    "                    fill_mode='nearest', cval=0.):\n",
    "    if is_random:\n",
    "        theta = np.pi / 180 * np.random.uniform(-rg, rg)\n",
    "    else:\n",
    "        theta = np.pi / 180 * rg\n",
    "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                [np.sin(theta), np.cos(theta), 0],\n",
    "                                [0, 0, 1]])\n",
    "    h, w = x.shape[row_index], x.shape[col_index]\n",
    "    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\n",
    "    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n",
    "    return x\n",
    "\n",
    "def crop(x, wrg, hrg, is_random=False, row_index=0, col_index=1, channel_index=2):\n",
    "    h, w = x.shape[row_index], x.shape[col_index]\n",
    "    assert (h > hrg) and (w > wrg), \"The size of cropping should smaller than the original image\"\n",
    "    if is_random:\n",
    "        h_offset = int(np.random.uniform(0, h-hrg) - 1)\n",
    "        w_offset = int(np.random.uniform(0, w-wrg) - 1)\n",
    "        return x[h_offset: hrg + h_offset ,w_offset: wrg + w_offset]\n",
    "    else:   # central crop\n",
    "        h_offset = int(np.floor((h - hrg)/ 2.))\n",
    "        w_offset = int(np.floor((w - wrg)/ 2.))\n",
    "        h_end = h_offset + hrg\n",
    "        w_end = w_offset + wrg\n",
    "        return x[h_offset: h_end, w_offset: w_end]\n",
    "\n",
    "def flip_axis(x, axis, is_random=False):\n",
    "    if is_random:\n",
    "        factor = np.random.uniform(-1, 1)\n",
    "        if factor > 0:\n",
    "            x = np.asarray(x).swapaxes(axis, 0)\n",
    "            x = x[::-1, ...]\n",
    "            x = x.swapaxes(0, axis)\n",
    "            return x\n",
    "        else:\n",
    "            return x\n",
    "    else:\n",
    "        x = np.asarray(x).swapaxes(axis, 0)\n",
    "        x = x[::-1, ...]\n",
    "        x = x.swapaxes(0, axis)\n",
    "        return x\n",
    "\n",
    "def imresize(x, size=[100, 100], interp='bilinear', mode=None):\n",
    "    if x.shape[-1] == 1:\n",
    "        # greyscale\n",
    "        x = scipy.misc.imresize(x[:, :, 0], size, interp=interp, mode=mode)\n",
    "        return x[:, :, np.newaxis]\n",
    "    elif x.shape[-1] == 3:\n",
    "        # rgb, bgr ..\n",
    "        return scipy.misc.imresize(x, size, interp=interp, mode=mode)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported channel %d\" % x.shape[-1])\n",
    "\n",
    "def prepro_img(x, mode=None):\n",
    "    # rescale [0, 255] --> (-1, 1), random flip, crop, rotate\n",
    "    if mode=='train':\n",
    "        x = flip_axis(x, axis=1, is_random=True)\n",
    "        x = rotation(x, rg=16, is_random=True, fill_mode='nearest')\n",
    "        x = imresize(x, size=[64 + 15, 64 + 15], interp='bilinear', mode=None)\n",
    "        x = crop(x, wrg=64, hrg=64, is_random=True)\n",
    "        x = x / (255. / 2.)\n",
    "        x = x - 1.\n",
    "        # x = x * 0.9999\n",
    "    return x\n",
    "\n",
    "def combine_and_save_image_sets(image_sets, directory):\n",
    "    for i in range(len(image_sets[0])):\n",
    "        combined_image = []\n",
    "        for set_no in range(len(image_sets)):\n",
    "            combined_image.append(image_sets[set_no][i])\n",
    "            combined_image.append(np.zeros((image_sets[set_no][i].shape[0], 5, 3)))\n",
    "        combined_image = np.concatenate(combined_image, axis = 1)\n",
    "        scipy.misc.imsave(os.path.join(directory, 'combined_{}.jpg'.format(i)), combined_image)\n",
    "\n",
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print('The checkpoint has been created.')\n",
    "\n",
    "def load(saver, sess, ckpt_path):\n",
    "    saver.restore(sess, ckpt_path)\n",
    "    print(\"Restored model parameters from {}\".format(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train_samples_dir = 'train_samples'\n",
    "if os.path.exists(train_samples_dir) == False:\n",
    "    os.makedirs(train_samples_dir)\n",
    "\n",
    "lr = 0.0002\n",
    "lr_decay = 0.5      \n",
    "decay_every = 100  \n",
    "beta1 = 0.5\n",
    "checkpoint_dir = './checkpoint'\n",
    "z_dim = 512\n",
    "image_size = 64\n",
    "c_dim = 3\n",
    "batch_size = 64\n",
    "ni = int(np.ceil(np.sqrt(batch_size)))\n",
    "\n",
    "sample_size = batch_size\n",
    "sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, z_dim)).astype(np.float32)\n",
    "sample_sentence = [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni) + \\\n",
    "                  [\"a black bird with oily black feathers and rounded black beak.\"] * int(sample_size/ni)\n",
    "for i, sent in enumerate(sample_sentence):\n",
    "    sample_sentence[i] = sent2ID(sent)\n",
    "sample_sentence = np.asarray(sample_sentence)\n",
    "sample_sentence = np.reshape(sample_sentence, (sample_size, 20))\n",
    "print(sample_sentence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chszerg/final-project-deep-learning-19-tf/utils/model.py:206: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "----------Update_ops_D--------\n",
      "discriminator/d_h1/batchnorm/AssignMovingAvg\n",
      "discriminator/d_h1/batchnorm/AssignMovingAvg_1\n",
      "discriminator/d_h2/batchnorm/AssignMovingAvg\n",
      "discriminator/d_h2/batchnorm/AssignMovingAvg_1\n",
      "discriminator/d_h3/batchnorm/AssignMovingAvg\n",
      "discriminator/d_h3/batchnorm/AssignMovingAvg_1\n",
      "discriminator/d_h4_res/batchnorm/AssignMovingAvg\n",
      "discriminator/d_h4_res/batchnorm/AssignMovingAvg_1\n",
      "discriminator/d_h4_res/batchnorm2/AssignMovingAvg\n",
      "discriminator/d_h4_res/batchnorm2/AssignMovingAvg_1\n",
      "discriminator/d_h4_res/batchnorm3/AssignMovingAvg\n",
      "discriminator/d_h4_res/batchnorm3/AssignMovingAvg_1\n",
      "discriminator/d_h3/batch_norm_2/AssignMovingAvg\n",
      "discriminator/d_h3/batch_norm_2/AssignMovingAvg_1\n",
      "discriminator_1/d_h1/batchnorm/AssignMovingAvg\n",
      "discriminator_1/d_h1/batchnorm/AssignMovingAvg_1\n",
      "discriminator_1/d_h2/batchnorm/AssignMovingAvg\n",
      "discriminator_1/d_h2/batchnorm/AssignMovingAvg_1\n",
      "discriminator_1/d_h3/batchnorm/AssignMovingAvg\n",
      "discriminator_1/d_h3/batchnorm/AssignMovingAvg_1\n",
      "discriminator_1/d_h4_res/batchnorm/AssignMovingAvg\n",
      "discriminator_1/d_h4_res/batchnorm/AssignMovingAvg_1\n",
      "discriminator_1/d_h4_res/batchnorm2/AssignMovingAvg\n",
      "discriminator_1/d_h4_res/batchnorm2/AssignMovingAvg_1\n",
      "discriminator_1/d_h4_res/batchnorm3/AssignMovingAvg\n",
      "discriminator_1/d_h4_res/batchnorm3/AssignMovingAvg_1\n",
      "discriminator_1/d_h3/batch_norm_2/AssignMovingAvg\n",
      "discriminator_1/d_h3/batch_norm_2/AssignMovingAvg_1\n",
      "discriminator_2/d_h1/batchnorm/AssignMovingAvg\n",
      "discriminator_2/d_h1/batchnorm/AssignMovingAvg_1\n",
      "discriminator_2/d_h2/batchnorm/AssignMovingAvg\n",
      "discriminator_2/d_h2/batchnorm/AssignMovingAvg_1\n",
      "discriminator_2/d_h3/batchnorm/AssignMovingAvg\n",
      "discriminator_2/d_h3/batchnorm/AssignMovingAvg_1\n",
      "discriminator_2/d_h4_res/batchnorm/AssignMovingAvg\n",
      "discriminator_2/d_h4_res/batchnorm/AssignMovingAvg_1\n",
      "discriminator_2/d_h4_res/batchnorm2/AssignMovingAvg\n",
      "discriminator_2/d_h4_res/batchnorm2/AssignMovingAvg_1\n",
      "discriminator_2/d_h4_res/batchnorm3/AssignMovingAvg\n",
      "discriminator_2/d_h4_res/batchnorm3/AssignMovingAvg_1\n",
      "discriminator_2/d_h3/batch_norm_2/AssignMovingAvg\n",
      "discriminator_2/d_h3/batch_norm_2/AssignMovingAvg_1\n",
      "----------Update_ops_G--------\n",
      "generator/g_h0/batch_norm/AssignMovingAvg\n",
      "generator/g_h0/batch_norm/AssignMovingAvg_1\n",
      "generator/g_h1_res/batch_norm/AssignMovingAvg\n",
      "generator/g_h1_res/batch_norm/AssignMovingAvg_1\n",
      "generator/g_h1_res/batch_norm2/AssignMovingAvg\n",
      "generator/g_h1_res/batch_norm2/AssignMovingAvg_1\n",
      "generator/g_h1_res/batch_norm3/AssignMovingAvg\n",
      "generator/g_h1_res/batch_norm3/AssignMovingAvg_1\n",
      "generator/g_h2/batch_norm/AssignMovingAvg\n",
      "generator/g_h2/batch_norm/AssignMovingAvg_1\n",
      "generator/g_h3_res/batch_norm/AssignMovingAvg\n",
      "generator/g_h3_res/batch_norm/AssignMovingAvg_1\n",
      "generator/g_h3_res/batch_norm2/AssignMovingAvg\n",
      "generator/g_h3_res/batch_norm2/AssignMovingAvg_1\n",
      "generator/g_h3_res/batch_norm3/AssignMovingAvg\n",
      "generator/g_h3_res/batch_norm3/AssignMovingAvg_1\n",
      "generator/g_h4/batch_norm/AssignMovingAvg\n",
      "generator/g_h4/batch_norm/AssignMovingAvg_1\n",
      "generator/g_h5/batch_norm/AssignMovingAvg\n",
      "generator/g_h5/batch_norm/AssignMovingAvg_1\n",
      "----------Update_ops_CNN--------\n",
      "cnnencoder/cnnf/h1/batch_norm/AssignMovingAvg\n",
      "cnnencoder/cnnf/h1/batch_norm/AssignMovingAvg_1\n",
      "cnnencoder/cnnf/h2/batch_norm/AssignMovingAvg\n",
      "cnnencoder/cnnf/h2/batch_norm/AssignMovingAvg_1\n",
      "cnnencoder/cnnf/h3/batch_norm/AssignMovingAvg\n",
      "cnnencoder/cnnf/h3/batch_norm/AssignMovingAvg_1\n",
      "cnnencoder_1/cnnf/h1/batch_norm/AssignMovingAvg\n",
      "cnnencoder_1/cnnf/h1/batch_norm/AssignMovingAvg_1\n",
      "cnnencoder_1/cnnf/h2/batch_norm/AssignMovingAvg\n",
      "cnnencoder_1/cnnf/h2/batch_norm/AssignMovingAvg_1\n",
      "cnnencoder_1/cnnf/h3/batch_norm/AssignMovingAvg\n",
      "cnnencoder_1/cnnf/h3/batch_norm/AssignMovingAvg_1\n"
     ]
    }
   ],
   "source": [
    "t_real_image = tf.placeholder('float32', [batch_size, image_size, image_size, 3], name = 'real_image')\n",
    "t_wrong_image = tf.placeholder('float32', [batch_size ,image_size, image_size, 3], name = 'wrong_image')\n",
    "t_real_caption = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name='real_caption_input')\n",
    "t_wrong_caption = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name='wrong_caption_input')\n",
    "t_z = tf.placeholder(tf.float32, [batch_size, z_dim], name='z_noise')\n",
    "\n",
    "### Training Phase - CNN - RNN mapping\n",
    "net_cnn = CNN_ENCODER(t_real_image, is_training=True, reuse=False)\n",
    "x = net_cnn.outputs\n",
    "v = RNN_ENCODER(t_real_caption, is_training=True, reuse=False).outputs\n",
    "x_w = CNN_ENCODER(t_wrong_image, is_training=True, reuse=True).outputs\n",
    "v_w = RNN_ENCODER(t_wrong_caption, is_training=True, reuse=True).outputs\n",
    "\n",
    "alpha = 0.2 # margin alpha\n",
    "rnn_loss = tf.reduce_mean(tf.maximum(0., alpha - cosine_similarity(x, v) + cosine_similarity(x, v_w))) + \\\n",
    "            tf.reduce_mean(tf.maximum(0., alpha - cosine_similarity(x, v) + cosine_similarity(x_w, v)))\n",
    "\n",
    "### Training Phase - GAN\n",
    "net_rnn = RNN_ENCODER(t_real_caption, is_training=False, reuse=True)\n",
    "net_fake_image = GENERATOR(t_z, net_rnn.outputs, is_training=True, reuse=False)\n",
    "\n",
    "net_disc_fake = DISCRIMINATOR(net_fake_image.outputs, net_rnn.outputs, is_training=True, reuse=False)\n",
    "disc_fake_logits = net_disc_fake.logits\n",
    "\n",
    "net_disc_real = DISCRIMINATOR(t_real_image, net_rnn.outputs, is_training=True, reuse=True)\n",
    "disc_real_logits = net_disc_real.logits\n",
    "\n",
    "net_disc_mismatch = DISCRIMINATOR(t_real_image, RNN_ENCODER(t_wrong_caption, is_training=False, reuse=True).outputs,\n",
    "                                is_training=True, reuse=True)\n",
    "disc_mismatch_logits = net_disc_mismatch.logits\n",
    "\n",
    "d_loss1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_real_logits,     labels=tf.ones_like(disc_real_logits),      name='d1'))\n",
    "d_loss2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_mismatch_logits, labels=tf.zeros_like(disc_mismatch_logits), name='d2'))\n",
    "d_loss3 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits,     labels=tf.zeros_like(disc_fake_logits),     name='d3'))\n",
    "d_loss = d_loss1 + (d_loss2 + d_loss3) * 0.5\n",
    "\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits, labels=tf.ones_like(disc_fake_logits), name='g'))\n",
    "\n",
    "### Testing Phase\n",
    "net_g = GENERATOR(t_z, RNN_ENCODER(t_real_caption, is_training=False, reuse=True).outputs,\n",
    "                    is_training=False, reuse=True)\n",
    "\n",
    "rnn_vars = [var for var in tf.trainable_variables() if 'rnnencoder' in var.name]\n",
    "cnn_vars = [var for var in tf.trainable_variables() if 'cnnencoder' in var.name]\n",
    "d_vars = [var for var in tf.trainable_variables() if 'discriminator' in var.name]\n",
    "g_vars = [var for var in tf.trainable_variables() if 'generator' in var.name]\n",
    "\n",
    "update_ops_CNN = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'cnnencoder' in var.name]\n",
    "update_ops_D = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'discriminator' in var.name]\n",
    "update_ops_G = [var for var in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'generator' in var.name]\n",
    "\n",
    "print('----------Update_ops_D--------')\n",
    "for var in update_ops_D:\n",
    "    print(var.name)\n",
    "print('----------Update_ops_G--------')\n",
    "for var in update_ops_G:\n",
    "    print(var.name)\n",
    "print('----------Update_ops_CNN--------')\n",
    "for var in update_ops_CNN:\n",
    "    print(var.name)\n",
    "\n",
    "with tf.variable_scope('learning_rate'):\n",
    "    lr_v = tf.Variable(lr, trainable=False)\n",
    "\n",
    "with tf.control_dependencies(update_ops_CNN):\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(rnn_loss, rnn_vars + cnn_vars), 10)\n",
    "    optimizer = tf.train.AdamOptimizer(lr_v, beta1=beta1)\n",
    "    rnn_optim = optimizer.apply_gradients(zip(grads, rnn_vars + cnn_vars))\n",
    "\n",
    "with tf.control_dependencies(update_ops_D):\n",
    "    d_optim = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "with tf.control_dependencies(update_ops_G):\n",
    "    g_optim = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no checkpoints find.\n",
      " ** init lr: 0.000200  decay_every_epoch: 100, lr_decay: 0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py:155: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0/1000] time: 0.3975s, d_loss: 1.31753385, g_loss: 2.28362513, rnn_loss: 0.36068851\n",
      " ** Epoch 0 took 75.582170s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chszerg/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1/1000] time: 0.4020s, d_loss: 1.11479640, g_loss: 2.01116872, rnn_loss: 0.24469408\n",
      " ** Epoch 1 took 55.629773s\n",
      "Epoch: [ 2/1000] time: 0.4004s, d_loss: 1.36073446, g_loss: 1.45685649, rnn_loss: 0.24112934\n",
      " ** Epoch 2 took 55.422214s\n",
      "Epoch: [ 3/1000] time: 0.4016s, d_loss: 1.25851989, g_loss: 1.65432346, rnn_loss: 0.23627174\n",
      " ** Epoch 3 took 55.444503s\n",
      "Epoch: [ 4/1000] time: 0.4067s, d_loss: 1.18874502, g_loss: 1.00608802, rnn_loss: 0.25265095\n",
      " ** Epoch 4 took 55.700873s\n",
      "Epoch: [ 5/1000] time: 0.4046s, d_loss: 1.27227426, g_loss: 2.22307515, rnn_loss: 0.25973552\n",
      " ** Epoch 5 took 55.748305s\n",
      "Epoch: [ 6/1000] time: 0.4067s, d_loss: 1.00639820, g_loss: 1.52219772, rnn_loss: 0.23359019\n",
      " ** Epoch 6 took 56.257428s\n",
      "Epoch: [ 7/1000] time: 0.4040s, d_loss: 0.80261439, g_loss: 1.42177761, rnn_loss: 0.21547946\n",
      " ** Epoch 7 took 55.695372s\n",
      "Epoch: [ 8/1000] time: 0.4021s, d_loss: 1.27246976, g_loss: 1.76366532, rnn_loss: 0.22362310\n",
      " ** Epoch 8 took 56.014816s\n",
      "Epoch: [ 9/1000] time: 0.4061s, d_loss: 1.11545157, g_loss: 1.79354548, rnn_loss: 0.23341288\n",
      " ** Epoch 9 took 55.631672s\n",
      "Epoch: [10/1000] time: 0.4013s, d_loss: 1.37406981, g_loss: 0.96876192, rnn_loss: 0.19281782\n",
      " ** Epoch 10 took 55.575794s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [11/1000] time: 0.4040s, d_loss: 1.42480779, g_loss: 0.78146178, rnn_loss: 0.19955198\n",
      " ** Epoch 11 took 55.525699s\n",
      "Epoch: [12/1000] time: 0.4005s, d_loss: 1.23532438, g_loss: 1.08524191, rnn_loss: 0.18632713\n",
      " ** Epoch 12 took 56.062354s\n",
      "Epoch: [13/1000] time: 0.4033s, d_loss: 1.28432286, g_loss: 0.61149132, rnn_loss: 0.24906580\n",
      " ** Epoch 13 took 55.675776s\n",
      "Epoch: [14/1000] time: 0.4029s, d_loss: 0.98285115, g_loss: 0.69216365, rnn_loss: 0.21562883\n",
      " ** Epoch 14 took 55.328439s\n",
      "Epoch: [15/1000] time: 0.4037s, d_loss: 1.14430928, g_loss: 1.70662260, rnn_loss: 0.21553518\n",
      " ** Epoch 15 took 55.507897s\n",
      "Epoch: [16/1000] time: 0.4004s, d_loss: 0.99994314, g_loss: 1.22479486, rnn_loss: 0.18287842\n",
      " ** Epoch 16 took 55.332130s\n",
      "Epoch: [17/1000] time: 0.3973s, d_loss: 0.98466527, g_loss: 0.85544997, rnn_loss: 0.17390847\n",
      " ** Epoch 17 took 55.673398s\n",
      "Epoch: [18/1000] time: 0.3996s, d_loss: 1.10718977, g_loss: 1.34396064, rnn_loss: 0.18178129\n",
      " ** Epoch 18 took 55.262644s\n",
      "Epoch: [19/1000] time: 0.4002s, d_loss: 1.05103922, g_loss: 0.67513895, rnn_loss: 0.19438258\n",
      " ** Epoch 19 took 55.485032s\n",
      "Epoch: [20/1000] time: 0.4045s, d_loss: 1.08327091, g_loss: 0.57950485, rnn_loss: 0.14234725\n",
      " ** Epoch 20 took 55.187639s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [21/1000] time: 0.3995s, d_loss: 1.38491929, g_loss: 1.43845308, rnn_loss: 0.18879637\n",
      " ** Epoch 21 took 55.181703s\n",
      "Epoch: [22/1000] time: 0.3976s, d_loss: 0.74491453, g_loss: 0.96424335, rnn_loss: 0.14019333\n",
      " ** Epoch 22 took 55.248205s\n",
      "Epoch: [23/1000] time: 0.3946s, d_loss: 0.88363093, g_loss: 1.30363035, rnn_loss: 0.19472745\n",
      " ** Epoch 23 took 55.566998s\n",
      "Epoch: [24/1000] time: 0.3996s, d_loss: 0.98022366, g_loss: 1.26668596, rnn_loss: 0.15735000\n",
      " ** Epoch 24 took 55.212300s\n",
      "Epoch: [25/1000] time: 0.4016s, d_loss: 0.90444446, g_loss: 0.94400299, rnn_loss: 0.21990755\n",
      " ** Epoch 25 took 55.264806s\n",
      "Epoch: [26/1000] time: 0.3997s, d_loss: 0.78406686, g_loss: 0.61208087, rnn_loss: 0.15760474\n",
      " ** Epoch 26 took 55.216688s\n",
      "Epoch: [27/1000] time: 0.3991s, d_loss: 0.87754798, g_loss: 0.71777886, rnn_loss: 0.18981329\n",
      " ** Epoch 27 took 55.272006s\n",
      "Epoch: [28/1000] time: 0.4095s, d_loss: 0.76347375, g_loss: 1.72947288, rnn_loss: 0.17101654\n",
      " ** Epoch 28 took 55.256465s\n",
      "Epoch: [29/1000] time: 0.4014s, d_loss: 0.87226224, g_loss: 0.69077528, rnn_loss: 0.12021460\n",
      " ** Epoch 29 took 55.818010s\n",
      "Epoch: [30/1000] time: 0.4032s, d_loss: 1.12348080, g_loss: 0.66496754, rnn_loss: 0.14800614\n",
      " ** Epoch 30 took 55.632325s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [31/1000] time: 0.3958s, d_loss: 0.89469612, g_loss: 0.67714363, rnn_loss: 0.16892628\n",
      " ** Epoch 31 took 55.215993s\n",
      "Epoch: [32/1000] time: 0.4032s, d_loss: 0.90479547, g_loss: 0.66971624, rnn_loss: 0.17762521\n",
      " ** Epoch 32 took 55.203288s\n",
      "Epoch: [33/1000] time: 0.4000s, d_loss: 1.24747550, g_loss: 1.47333670, rnn_loss: 0.19773345\n",
      " ** Epoch 33 took 55.232691s\n",
      "Epoch: [34/1000] time: 0.4045s, d_loss: 1.36247194, g_loss: 2.30617642, rnn_loss: 0.14272135\n",
      " ** Epoch 34 took 55.895950s\n",
      "Epoch: [35/1000] time: 0.3947s, d_loss: 0.79407007, g_loss: 0.92222434, rnn_loss: 0.14075673\n",
      " ** Epoch 35 took 55.487484s\n",
      "Epoch: [36/1000] time: 0.4029s, d_loss: 1.14627504, g_loss: 0.80411482, rnn_loss: 0.15458058\n",
      " ** Epoch 36 took 55.064845s\n",
      "Epoch: [37/1000] time: 0.3983s, d_loss: 0.86886859, g_loss: 1.41541851, rnn_loss: 0.13595030\n",
      " ** Epoch 37 took 55.263465s\n",
      "Epoch: [38/1000] time: 0.3983s, d_loss: 0.63893425, g_loss: 0.91075867, rnn_loss: 0.19489768\n",
      " ** Epoch 38 took 55.112998s\n",
      "Epoch: [39/1000] time: 0.3984s, d_loss: 0.90646505, g_loss: 1.46297300, rnn_loss: 0.14780697\n",
      " ** Epoch 39 took 54.959763s\n",
      "Epoch: [40/1000] time: 0.4000s, d_loss: 0.87721395, g_loss: 0.72749382, rnn_loss: 0.19439769\n",
      " ** Epoch 40 took 55.477965s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [41/1000] time: 0.3993s, d_loss: 0.76500511, g_loss: 1.27287102, rnn_loss: 0.15451908\n",
      " ** Epoch 41 took 55.202239s\n",
      "Epoch: [42/1000] time: 0.4022s, d_loss: 0.61513615, g_loss: 2.14909124, rnn_loss: 0.14288351\n",
      " ** Epoch 42 took 54.983660s\n",
      "Epoch: [43/1000] time: 0.3966s, d_loss: 1.72274518, g_loss: 0.12908196, rnn_loss: 0.14857939\n",
      " ** Epoch 43 took 55.211815s\n",
      "Epoch: [44/1000] time: 0.4015s, d_loss: 0.96302009, g_loss: 0.65505856, rnn_loss: 0.13834199\n",
      " ** Epoch 44 took 55.249754s\n",
      "Epoch: [45/1000] time: 0.3960s, d_loss: 0.82725060, g_loss: 1.11850917, rnn_loss: 0.18122226\n",
      " ** Epoch 45 took 55.576523s\n",
      "Epoch: [46/1000] time: 0.4012s, d_loss: 0.84072012, g_loss: 1.10110235, rnn_loss: 0.17860311\n",
      " ** Epoch 46 took 55.434212s\n",
      "Epoch: [47/1000] time: 0.4012s, d_loss: 0.70054448, g_loss: 1.83041286, rnn_loss: 0.13208123\n",
      " ** Epoch 47 took 55.175277s\n",
      "Epoch: [48/1000] time: 0.4044s, d_loss: 0.71721989, g_loss: 1.54290009, rnn_loss: 0.07772413\n",
      " ** Epoch 48 took 55.269927s\n",
      "Epoch: [49/1000] time: 0.4136s, d_loss: 0.72222793, g_loss: 1.56471884, rnn_loss: 0.08540753\n",
      " ** Epoch 49 took 55.502146s\n",
      "Epoch: [50/1000] time: 0.4019s, d_loss: 1.12149930, g_loss: 0.25958443, rnn_loss: 0.14296742\n",
      " ** Epoch 50 took 55.476222s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [51/1000] time: 0.3993s, d_loss: 1.01388240, g_loss: 0.40092158, rnn_loss: 0.14448872\n",
      " ** Epoch 51 took 55.833329s\n",
      "Epoch: [52/1000] time: 0.4024s, d_loss: 0.66920477, g_loss: 0.88025194, rnn_loss: 0.15392515\n",
      " ** Epoch 52 took 55.642276s\n",
      "Epoch: [53/1000] time: 0.4043s, d_loss: 0.60656297, g_loss: 2.60670853, rnn_loss: 0.13709319\n",
      " ** Epoch 53 took 55.317945s\n",
      "Epoch: [54/1000] time: 0.4049s, d_loss: 0.92170209, g_loss: 2.52719116, rnn_loss: 0.12165894\n",
      " ** Epoch 54 took 55.311777s\n",
      "Epoch: [55/1000] time: 0.3965s, d_loss: 0.74637473, g_loss: 0.56819177, rnn_loss: 0.14195973\n",
      " ** Epoch 55 took 55.093780s\n",
      "Epoch: [56/1000] time: 0.4227s, d_loss: 0.68109006, g_loss: 1.66139805, rnn_loss: 0.12260538\n",
      " ** Epoch 56 took 55.308263s\n",
      "Epoch: [57/1000] time: 0.4054s, d_loss: 0.46225038, g_loss: 1.53277230, rnn_loss: 0.15288275\n",
      " ** Epoch 57 took 55.870929s\n",
      "Epoch: [58/1000] time: 0.4009s, d_loss: 0.52462310, g_loss: 0.84551489, rnn_loss: 0.12066653\n",
      " ** Epoch 58 took 55.423069s\n",
      "Epoch: [59/1000] time: 0.4039s, d_loss: 2.32168126, g_loss: 0.44063354, rnn_loss: 0.12075914\n",
      " ** Epoch 59 took 55.433997s\n",
      "Epoch: [60/1000] time: 0.3993s, d_loss: 0.74356920, g_loss: 2.12685823, rnn_loss: 0.12308879\n",
      " ** Epoch 60 took 55.084031s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [61/1000] time: 0.4039s, d_loss: 0.75599360, g_loss: 1.63619113, rnn_loss: 0.15380289\n",
      " ** Epoch 61 took 55.063383s\n",
      "Epoch: [62/1000] time: 0.4025s, d_loss: 0.80346799, g_loss: 2.11813688, rnn_loss: 0.13659993\n",
      " ** Epoch 62 took 55.927190s\n",
      "Epoch: [63/1000] time: 0.3974s, d_loss: 0.70607847, g_loss: 2.70694613, rnn_loss: 0.13426617\n",
      " ** Epoch 63 took 55.373080s\n",
      "Epoch: [64/1000] time: 0.4015s, d_loss: 0.41876897, g_loss: 1.92717087, rnn_loss: 0.11459020\n",
      " ** Epoch 64 took 55.224678s\n",
      "Epoch: [65/1000] time: 0.4004s, d_loss: 0.49934417, g_loss: 2.88805294, rnn_loss: 0.08692351\n",
      " ** Epoch 65 took 55.162311s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [66/1000] time: 0.3901s, d_loss: 0.85955441, g_loss: 1.68345225, rnn_loss: 0.11777584\n",
      " ** Epoch 66 took 55.067351s\n",
      "Epoch: [67/1000] time: 0.3996s, d_loss: 0.43970105, g_loss: 2.08832574, rnn_loss: 0.08496506\n",
      " ** Epoch 67 took 55.086880s\n",
      "Epoch: [68/1000] time: 0.3918s, d_loss: 0.67033273, g_loss: 1.92664027, rnn_loss: 0.14513549\n",
      " ** Epoch 68 took 56.223854s\n",
      "Epoch: [69/1000] time: 0.3962s, d_loss: 0.67560726, g_loss: 2.04417634, rnn_loss: 0.16112304\n",
      " ** Epoch 69 took 54.875975s\n",
      "Epoch: [70/1000] time: 0.4006s, d_loss: 0.66614962, g_loss: 2.11093903, rnn_loss: 0.13497972\n",
      " ** Epoch 70 took 54.873067s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [71/1000] time: 0.3958s, d_loss: 1.15587115, g_loss: 0.74617231, rnn_loss: 0.15278263\n",
      " ** Epoch 71 took 54.889474s\n",
      "Epoch: [72/1000] time: 0.3997s, d_loss: 0.98668432, g_loss: 2.45380425, rnn_loss: 0.12557690\n",
      " ** Epoch 72 took 54.964957s\n",
      "Epoch: [73/1000] time: 0.4005s, d_loss: 0.48215815, g_loss: 2.60706091, rnn_loss: 0.15018795\n",
      " ** Epoch 73 took 55.374815s\n",
      "Epoch: [74/1000] time: 0.3988s, d_loss: 0.52346885, g_loss: 2.02676964, rnn_loss: 0.09729733\n",
      " ** Epoch 74 took 55.467192s\n",
      "Epoch: [75/1000] time: 0.3981s, d_loss: 1.34534872, g_loss: 2.60669065, rnn_loss: 0.17039676\n",
      " ** Epoch 75 took 55.188014s\n",
      "Epoch: [76/1000] time: 0.3972s, d_loss: 0.54667717, g_loss: 1.73099840, rnn_loss: 0.13566738\n",
      " ** Epoch 76 took 55.081102s\n",
      "Epoch: [77/1000] time: 0.4004s, d_loss: 0.40646836, g_loss: 2.22694492, rnn_loss: 0.15987384\n",
      " ** Epoch 77 took 54.977114s\n",
      "Epoch: [78/1000] time: 0.4024s, d_loss: 0.42830849, g_loss: 1.45242310, rnn_loss: 0.13073954\n",
      " ** Epoch 78 took 55.078166s\n",
      "Epoch: [79/1000] time: 0.4009s, d_loss: 0.31336778, g_loss: 1.97073388, rnn_loss: 0.11849423\n",
      " ** Epoch 79 took 56.124833s\n",
      "Epoch: [80/1000] time: 0.3545s, d_loss: 0.51103640, g_loss: 1.49510705, rnn_loss: 0.00000000\n",
      " ** Epoch 80 took 49.034040s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [81/1000] time: 0.3552s, d_loss: 0.57049733, g_loss: 2.42683935, rnn_loss: 0.00000000\n",
      " ** Epoch 81 took 49.000538s\n",
      "Epoch: [82/1000] time: 0.3574s, d_loss: 0.64789951, g_loss: 1.79345632, rnn_loss: 0.00000000\n",
      " ** Epoch 82 took 48.910122s\n",
      "Epoch: [83/1000] time: 0.3582s, d_loss: 0.32759130, g_loss: 2.23322439, rnn_loss: 0.00000000\n",
      " ** Epoch 83 took 49.079826s\n",
      "Epoch: [84/1000] time: 0.3476s, d_loss: 0.83368158, g_loss: 0.89184511, rnn_loss: 0.00000000\n",
      " ** Epoch 84 took 48.968066s\n",
      "Epoch: [85/1000] time: 0.3818s, d_loss: 0.52403080, g_loss: 1.22071457, rnn_loss: 0.00000000\n",
      " ** Epoch 85 took 49.822073s\n",
      "Epoch: [86/1000] time: 0.3610s, d_loss: 0.52038383, g_loss: 1.64963126, rnn_loss: 0.00000000\n",
      " ** Epoch 86 took 49.120943s\n",
      "Epoch: [87/1000] time: 0.3468s, d_loss: 0.57187682, g_loss: 0.96057367, rnn_loss: 0.00000000\n",
      " ** Epoch 87 took 48.975980s\n",
      "Epoch: [88/1000] time: 0.3521s, d_loss: 0.54001856, g_loss: 2.96807432, rnn_loss: 0.00000000\n",
      " ** Epoch 88 took 49.015063s\n",
      "Epoch: [89/1000] time: 0.3467s, d_loss: 0.81849259, g_loss: 2.29809594, rnn_loss: 0.00000000\n",
      " ** Epoch 89 took 48.649009s\n",
      "Epoch: [90/1000] time: 0.3596s, d_loss: 0.61333394, g_loss: 1.34054637, rnn_loss: 0.00000000\n",
      " ** Epoch 90 took 49.152341s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [91/1000] time: 0.3686s, d_loss: 0.47678065, g_loss: 2.04787469, rnn_loss: 0.00000000\n",
      " ** Epoch 91 took 49.449702s\n",
      "Epoch: [92/1000] time: 0.3560s, d_loss: 1.41420615, g_loss: 2.01780653, rnn_loss: 0.00000000\n",
      " ** Epoch 92 took 49.346425s\n",
      "Epoch: [93/1000] time: 0.3568s, d_loss: 0.68407160, g_loss: 1.16686594, rnn_loss: 0.00000000\n",
      " ** Epoch 93 took 49.279734s\n",
      "Epoch: [94/1000] time: 0.3602s, d_loss: 0.58110869, g_loss: 2.42284012, rnn_loss: 0.00000000\n",
      " ** Epoch 94 took 49.224057s\n",
      "Epoch: [95/1000] time: 0.3547s, d_loss: 0.69479138, g_loss: 3.59333611, rnn_loss: 0.00000000\n",
      " ** Epoch 95 took 49.293333s\n",
      "Epoch: [96/1000] time: 0.3585s, d_loss: 0.74005103, g_loss: 1.71457148, rnn_loss: 0.00000000\n",
      " ** Epoch 96 took 49.342607s\n",
      "Epoch: [97/1000] time: 0.3585s, d_loss: 0.75913793, g_loss: 2.47836137, rnn_loss: 0.00000000\n",
      " ** Epoch 97 took 49.377409s\n",
      "Epoch: [98/1000] time: 0.3552s, d_loss: 0.42073986, g_loss: 3.07925415, rnn_loss: 0.00000000\n",
      " ** Epoch 98 took 50.202602s\n",
      "Epoch: [99/1000] time: 0.3569s, d_loss: 0.59578741, g_loss: 2.57897997, rnn_loss: 0.00000000\n",
      " ** Epoch 99 took 49.225971s\n",
      " ** new learning rate: 0.000100\n",
      "Epoch: [100/1000] time: 0.3542s, d_loss: 0.48852164, g_loss: 1.42997408, rnn_loss: 0.00000000\n",
      " ** Epoch 100 took 49.423747s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [101/1000] time: 0.3509s, d_loss: 0.31248489, g_loss: 2.31093955, rnn_loss: 0.00000000\n",
      " ** Epoch 101 took 48.776209s\n",
      "Epoch: [102/1000] time: 0.3553s, d_loss: 0.45628786, g_loss: 1.62042212, rnn_loss: 0.00000000\n",
      " ** Epoch 102 took 48.912969s\n",
      "Epoch: [103/1000] time: 0.3578s, d_loss: 0.30405161, g_loss: 2.43620825, rnn_loss: 0.00000000\n",
      " ** Epoch 103 took 49.112360s\n",
      "Epoch: [104/1000] time: 0.3546s, d_loss: 0.45944190, g_loss: 1.56075025, rnn_loss: 0.00000000\n",
      " ** Epoch 104 took 49.961036s\n",
      "Epoch: [105/1000] time: 0.3560s, d_loss: 0.32850236, g_loss: 2.74006200, rnn_loss: 0.00000000\n",
      " ** Epoch 105 took 49.106801s\n",
      "Epoch: [106/1000] time: 0.3609s, d_loss: 0.45466435, g_loss: 1.57926941, rnn_loss: 0.00000000\n",
      " ** Epoch 106 took 49.142519s\n",
      "Epoch: [107/1000] time: 0.3531s, d_loss: 0.60716230, g_loss: 2.61253500, rnn_loss: 0.00000000\n",
      " ** Epoch 107 took 49.595679s\n",
      "Epoch: [108/1000] time: 0.3537s, d_loss: 0.27886263, g_loss: 2.95440149, rnn_loss: 0.00000000\n",
      " ** Epoch 108 took 49.016828s\n",
      "Epoch: [109/1000] time: 0.3558s, d_loss: 0.29618472, g_loss: 1.98464072, rnn_loss: 0.00000000\n",
      " ** Epoch 109 took 48.930542s\n",
      "Epoch: [110/1000] time: 0.3533s, d_loss: 0.49081677, g_loss: 2.91171217, rnn_loss: 0.00000000\n",
      " ** Epoch 110 took 49.602093s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [111/1000] time: 0.3560s, d_loss: 0.22633296, g_loss: 1.47412455, rnn_loss: 0.00000000\n",
      " ** Epoch 111 took 48.680164s\n",
      "Epoch: [112/1000] time: 0.3523s, d_loss: 0.36262754, g_loss: 1.33671474, rnn_loss: 0.00000000\n",
      " ** Epoch 112 took 48.752409s\n",
      "Epoch: [113/1000] time: 0.3497s, d_loss: 0.26492989, g_loss: 2.68552351, rnn_loss: 0.00000000\n",
      " ** Epoch 113 took 48.788071s\n",
      "Epoch: [114/1000] time: 0.3582s, d_loss: 0.85478634, g_loss: 0.48617566, rnn_loss: 0.00000000\n",
      " ** Epoch 114 took 48.779668s\n",
      "Epoch: [115/1000] time: 0.3530s, d_loss: 0.41378129, g_loss: 2.13308406, rnn_loss: 0.00000000\n",
      " ** Epoch 115 took 48.668959s\n",
      "Epoch: [116/1000] time: 0.3773s, d_loss: 0.29425913, g_loss: 3.00159955, rnn_loss: 0.00000000\n",
      " ** Epoch 116 took 49.158770s\n",
      "Epoch: [117/1000] time: 0.3586s, d_loss: 1.07083094, g_loss: 3.62950873, rnn_loss: 0.00000000\n",
      " ** Epoch 117 took 49.451884s\n",
      "Epoch: [118/1000] time: 0.3565s, d_loss: 0.25703242, g_loss: 4.20506001, rnn_loss: 0.00000000\n",
      " ** Epoch 118 took 48.819885s\n",
      "Epoch: [119/1000] time: 0.3524s, d_loss: 0.29714990, g_loss: 2.39987516, rnn_loss: 0.00000000\n",
      " ** Epoch 119 took 48.732934s\n",
      "Epoch: [120/1000] time: 0.3535s, d_loss: 0.42177355, g_loss: 2.11561203, rnn_loss: 0.00000000\n",
      " ** Epoch 120 took 48.731642s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [121/1000] time: 0.3525s, d_loss: 0.24854243, g_loss: 3.63386989, rnn_loss: 0.00000000\n",
      " ** Epoch 121 took 48.740626s\n",
      "Epoch: [122/1000] time: 0.3589s, d_loss: 0.55779517, g_loss: 2.74412155, rnn_loss: 0.00000000\n",
      " ** Epoch 122 took 49.008532s\n",
      "Epoch: [123/1000] time: 0.3553s, d_loss: 0.45078140, g_loss: 2.48048019, rnn_loss: 0.00000000\n",
      " ** Epoch 123 took 49.896694s\n",
      "Epoch: [124/1000] time: 0.3568s, d_loss: 0.26433074, g_loss: 3.38140011, rnn_loss: 0.00000000\n",
      " ** Epoch 124 took 48.973902s\n",
      "Epoch: [125/1000] time: 0.3549s, d_loss: 0.41364413, g_loss: 2.39562893, rnn_loss: 0.00000000\n",
      " ** Epoch 125 took 49.029419s\n",
      "Epoch: [126/1000] time: 0.3594s, d_loss: 0.33807516, g_loss: 1.38358808, rnn_loss: 0.00000000\n",
      " ** Epoch 126 took 48.899226s\n",
      "Epoch: [127/1000] time: 0.3512s, d_loss: 0.39811030, g_loss: 2.27067089, rnn_loss: 0.00000000\n",
      " ** Epoch 127 took 48.955409s\n",
      "Epoch: [128/1000] time: 0.3497s, d_loss: 1.07629001, g_loss: 0.72313225, rnn_loss: 0.00000000\n",
      " ** Epoch 128 took 48.768024s\n",
      "Epoch: [129/1000] time: 0.3574s, d_loss: 0.37266442, g_loss: 2.11301303, rnn_loss: 0.00000000\n",
      " ** Epoch 129 took 49.971899s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [130/1000] time: 0.3579s, d_loss: 0.23242274, g_loss: 2.48273349, rnn_loss: 0.00000000\n",
      " ** Epoch 130 took 49.048067s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [131/1000] time: 0.3542s, d_loss: 0.72508621, g_loss: 0.63650680, rnn_loss: 0.00000000\n",
      " ** Epoch 131 took 48.951739s\n",
      "Epoch: [132/1000] time: 0.3549s, d_loss: 0.17070550, g_loss: 2.67076015, rnn_loss: 0.00000000\n",
      " ** Epoch 132 took 48.794750s\n",
      "Epoch: [133/1000] time: 0.3555s, d_loss: 0.11932614, g_loss: 3.50745010, rnn_loss: 0.00000000\n",
      " ** Epoch 133 took 48.914103s\n",
      "Epoch: [134/1000] time: 0.3528s, d_loss: 0.21271195, g_loss: 2.32354784, rnn_loss: 0.00000000\n",
      " ** Epoch 134 took 48.895077s\n",
      "Epoch: [135/1000] time: 0.3778s, d_loss: 1.01847219, g_loss: 0.25741497, rnn_loss: 0.00000000\n",
      " ** Epoch 135 took 49.565865s\n",
      "Epoch: [136/1000] time: 0.3575s, d_loss: 0.41197455, g_loss: 1.53678966, rnn_loss: 0.00000000\n",
      " ** Epoch 136 took 49.180703s\n",
      "Epoch: [137/1000] time: 0.3548s, d_loss: 0.17219006, g_loss: 3.39381599, rnn_loss: 0.00000000\n",
      " ** Epoch 137 took 48.854030s\n",
      "Epoch: [138/1000] time: 0.3547s, d_loss: 0.25176197, g_loss: 2.09277821, rnn_loss: 0.00000000\n",
      " ** Epoch 138 took 48.823915s\n",
      "Epoch: [139/1000] time: 0.3513s, d_loss: 0.20852861, g_loss: 2.91212845, rnn_loss: 0.00000000\n",
      " ** Epoch 139 took 48.903656s\n",
      "Epoch: [140/1000] time: 0.3550s, d_loss: 1.40083063, g_loss: 0.46822307, rnn_loss: 0.00000000\n",
      " ** Epoch 140 took 48.948585s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [141/1000] time: 0.3544s, d_loss: 0.25460163, g_loss: 2.95672464, rnn_loss: 0.00000000\n",
      " ** Epoch 141 took 49.128448s\n",
      "Epoch: [142/1000] time: 0.3547s, d_loss: 0.24673918, g_loss: 2.00980186, rnn_loss: 0.00000000\n",
      " ** Epoch 142 took 49.573550s\n",
      "Epoch: [143/1000] time: 0.3543s, d_loss: 0.11269612, g_loss: 4.36241674, rnn_loss: 0.00000000\n",
      " ** Epoch 143 took 48.940520s\n",
      "Epoch: [144/1000] time: 0.3569s, d_loss: 0.34753799, g_loss: 2.44711590, rnn_loss: 0.00000000\n",
      " ** Epoch 144 took 49.051588s\n",
      "Epoch: [145/1000] time: 0.3577s, d_loss: 1.13445401, g_loss: 3.64407492, rnn_loss: 0.00000000\n",
      " ** Epoch 145 took 49.054419s\n",
      "Epoch: [146/1000] time: 0.3561s, d_loss: 0.17779610, g_loss: 3.76714849, rnn_loss: 0.00000000\n",
      " ** Epoch 146 took 49.034011s\n",
      "Epoch: [147/1000] time: 0.3584s, d_loss: 0.25210595, g_loss: 3.08736086, rnn_loss: 0.00000000\n",
      " ** Epoch 147 took 49.393641s\n",
      "Epoch: [148/1000] time: 0.3545s, d_loss: 0.31911987, g_loss: 1.71404481, rnn_loss: 0.00000000\n",
      " ** Epoch 148 took 49.672522s\n",
      "Epoch: [149/1000] time: 0.3579s, d_loss: 0.92532349, g_loss: 1.61198115, rnn_loss: 0.00000000\n",
      " ** Epoch 149 took 49.142487s\n",
      "Epoch: [150/1000] time: 0.3568s, d_loss: 0.11680226, g_loss: 3.22273731, rnn_loss: 0.00000000\n",
      " ** Epoch 150 took 49.215220s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [151/1000] time: 0.3552s, d_loss: 0.23385108, g_loss: 2.65615892, rnn_loss: 0.00000000\n",
      " ** Epoch 151 took 49.103532s\n",
      "Epoch: [152/1000] time: 0.3570s, d_loss: 0.34248069, g_loss: 3.58523273, rnn_loss: 0.00000000\n",
      " ** Epoch 152 took 49.190980s\n",
      "Epoch: [153/1000] time: 0.3509s, d_loss: 0.12338212, g_loss: 2.32310319, rnn_loss: 0.00000000\n",
      " ** Epoch 153 took 49.197764s\n",
      "Epoch: [154/1000] time: 0.3551s, d_loss: 0.13079706, g_loss: 4.05103493, rnn_loss: 0.00000000\n",
      " ** Epoch 154 took 49.982178s\n",
      "Epoch: [155/1000] time: 0.3583s, d_loss: 0.16004041, g_loss: 3.39689016, rnn_loss: 0.00000000\n",
      " ** Epoch 155 took 49.119335s\n",
      "Epoch: [156/1000] time: 0.3572s, d_loss: 1.18288815, g_loss: 4.59935284, rnn_loss: 0.00000000\n",
      " ** Epoch 156 took 49.265896s\n",
      "Epoch: [157/1000] time: 0.3597s, d_loss: 0.31522635, g_loss: 2.74657536, rnn_loss: 0.00000000\n",
      " ** Epoch 157 took 49.302862s\n",
      "Epoch: [158/1000] time: 0.3495s, d_loss: 0.25640914, g_loss: 2.94203424, rnn_loss: 0.00000000\n",
      " ** Epoch 158 took 48.968971s\n",
      "Epoch: [159/1000] time: 0.3573s, d_loss: 0.48715878, g_loss: 5.55051327, rnn_loss: 0.00000000\n",
      " ** Epoch 159 took 49.045503s\n",
      "Epoch: [160/1000] time: 0.3553s, d_loss: 0.15672407, g_loss: 4.50461531, rnn_loss: 0.00000000\n",
      " ** Epoch 160 took 49.482074s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [161/1000] time: 0.3613s, d_loss: 0.31006199, g_loss: 3.06707668, rnn_loss: 0.00000000\n",
      " ** Epoch 161 took 49.745136s\n",
      "Epoch: [162/1000] time: 0.3545s, d_loss: 0.24926347, g_loss: 2.72970533, rnn_loss: 0.00000000\n",
      " ** Epoch 162 took 49.166984s\n",
      "Epoch: [163/1000] time: 0.3568s, d_loss: 0.22152002, g_loss: 3.11665297, rnn_loss: 0.00000000\n",
      " ** Epoch 163 took 49.216632s\n",
      "Epoch: [164/1000] time: 0.3566s, d_loss: 1.06318080, g_loss: 2.09932041, rnn_loss: 0.00000000\n",
      " ** Epoch 164 took 49.166085s\n",
      "Epoch: [165/1000] time: 0.3591s, d_loss: 0.67069614, g_loss: 1.00599623, rnn_loss: 0.00000000\n",
      " ** Epoch 165 took 49.265155s\n",
      "Epoch: [166/1000] time: 0.3571s, d_loss: 0.24924193, g_loss: 1.87378335, rnn_loss: 0.00000000\n",
      " ** Epoch 166 took 49.641931s\n",
      "Epoch: [167/1000] time: 0.3584s, d_loss: 0.20937614, g_loss: 2.64225340, rnn_loss: 0.00000000\n",
      " ** Epoch 167 took 49.874032s\n",
      "Epoch: [168/1000] time: 0.3583s, d_loss: 0.76905304, g_loss: 0.48543018, rnn_loss: 0.00000000\n",
      " ** Epoch 168 took 49.199265s\n",
      "Epoch: [169/1000] time: 0.3458s, d_loss: 0.28682780, g_loss: 3.45360136, rnn_loss: 0.00000000\n",
      " ** Epoch 169 took 49.138610s\n",
      "Epoch: [170/1000] time: 0.3578s, d_loss: 0.21204719, g_loss: 2.95849800, rnn_loss: 0.00000000\n",
      " ** Epoch 170 took 49.301514s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [171/1000] time: 0.3573s, d_loss: 0.42696965, g_loss: 3.85688090, rnn_loss: 0.00000000\n",
      " ** Epoch 171 took 49.160866s\n",
      "Epoch: [172/1000] time: 0.3594s, d_loss: 0.34842944, g_loss: 2.27964211, rnn_loss: 0.00000000\n",
      " ** Epoch 172 took 49.498194s\n",
      "Epoch: [173/1000] time: 0.3554s, d_loss: 0.10878290, g_loss: 3.33460617, rnn_loss: 0.00000000\n",
      " ** Epoch 173 took 49.879308s\n",
      "Epoch: [174/1000] time: 0.3577s, d_loss: 0.47685853, g_loss: 1.35630989, rnn_loss: 0.00000000\n",
      " ** Epoch 174 took 49.259515s\n",
      "Epoch: [175/1000] time: 0.3569s, d_loss: 1.11550653, g_loss: 6.04775906, rnn_loss: 0.00000000\n",
      " ** Epoch 175 took 49.290769s\n",
      "Epoch: [176/1000] time: 0.3588s, d_loss: 0.12405869, g_loss: 3.52828264, rnn_loss: 0.00000000\n",
      " ** Epoch 176 took 49.265930s\n",
      "Epoch: [177/1000] time: 0.3599s, d_loss: 0.23971891, g_loss: 3.48459339, rnn_loss: 0.00000000\n",
      " ** Epoch 177 took 49.313962s\n",
      "Epoch: [178/1000] time: 0.3602s, d_loss: 0.32723761, g_loss: 1.93679142, rnn_loss: 0.00000000\n",
      " ** Epoch 178 took 49.682418s\n",
      "Epoch: [179/1000] time: 0.3670s, d_loss: 0.14293168, g_loss: 3.86395168, rnn_loss: 0.00000000\n",
      " ** Epoch 179 took 49.825267s\n",
      "Epoch: [180/1000] time: 0.3600s, d_loss: 0.47838125, g_loss: 4.81600285, rnn_loss: 0.00000000\n",
      " ** Epoch 180 took 49.411719s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [181/1000] time: 0.3592s, d_loss: 0.14727727, g_loss: 2.60621572, rnn_loss: 0.00000000\n",
      " ** Epoch 181 took 49.325769s\n",
      "Epoch: [182/1000] time: 0.3590s, d_loss: 0.17678672, g_loss: 3.24249387, rnn_loss: 0.00000000\n",
      " ** Epoch 182 took 49.463046s\n",
      "Epoch: [183/1000] time: 0.3567s, d_loss: 1.37397397, g_loss: 2.47963786, rnn_loss: 0.00000000\n",
      " ** Epoch 183 took 49.304752s\n",
      "Epoch: [184/1000] time: 0.3574s, d_loss: 0.08846883, g_loss: 3.16743040, rnn_loss: 0.00000000\n",
      " ** Epoch 184 took 49.737876s\n",
      "Epoch: [185/1000] time: 0.3593s, d_loss: 0.23120967, g_loss: 3.53975630, rnn_loss: 0.00000000\n",
      " ** Epoch 185 took 49.452822s\n",
      "Epoch: [186/1000] time: 0.3613s, d_loss: 0.43391046, g_loss: 1.93678391, rnn_loss: 0.00000000\n",
      " ** Epoch 186 took 50.030432s\n",
      "Epoch: [187/1000] time: 0.3570s, d_loss: 0.22750656, g_loss: 2.42652369, rnn_loss: 0.00000000\n",
      " ** Epoch 187 took 49.441022s\n",
      "Epoch: [188/1000] time: 0.3608s, d_loss: 0.77595985, g_loss: 2.52870750, rnn_loss: 0.00000000\n",
      " ** Epoch 188 took 49.446953s\n",
      "Epoch: [189/1000] time: 0.3597s, d_loss: 0.23832405, g_loss: 3.57108092, rnn_loss: 0.00000000\n",
      " ** Epoch 189 took 49.307579s\n",
      "Epoch: [190/1000] time: 0.3835s, d_loss: 0.12590042, g_loss: 4.20364332, rnn_loss: 0.00000000\n",
      " ** Epoch 190 took 49.573403s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [191/1000] time: 0.3594s, d_loss: 0.34413239, g_loss: 1.83865833, rnn_loss: 0.00000000\n",
      " ** Epoch 191 took 49.415141s\n",
      "Epoch: [192/1000] time: 0.3601s, d_loss: 0.08895039, g_loss: 3.65966463, rnn_loss: 0.00000000\n",
      " ** Epoch 192 took 49.987157s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [193/1000] time: 0.3524s, d_loss: 0.24226700, g_loss: 3.65074825, rnn_loss: 0.00000000\n",
      " ** Epoch 193 took 49.370805s\n",
      "Epoch: [194/1000] time: 0.3533s, d_loss: 0.47249928, g_loss: 4.24387074, rnn_loss: 0.00000000\n",
      " ** Epoch 194 took 49.354253s\n",
      "Epoch: [195/1000] time: 0.3563s, d_loss: 0.18483321, g_loss: 2.44830441, rnn_loss: 0.00000000\n",
      " ** Epoch 195 took 49.353141s\n",
      "Epoch: [196/1000] time: 0.3556s, d_loss: 0.17762324, g_loss: 4.23771763, rnn_loss: 0.00000000\n",
      " ** Epoch 196 took 49.350209s\n",
      "Epoch: [197/1000] time: 0.3545s, d_loss: 0.14515185, g_loss: 4.47289276, rnn_loss: 0.00000000\n",
      " ** Epoch 197 took 49.664229s\n",
      "Epoch: [198/1000] time: 0.3592s, d_loss: 0.36177701, g_loss: 3.76405382, rnn_loss: 0.00000000\n",
      " ** Epoch 198 took 49.838691s\n",
      "Epoch: [199/1000] time: 0.3588s, d_loss: 0.16638196, g_loss: 2.72192311, rnn_loss: 0.00000000\n",
      " ** Epoch 199 took 49.337843s\n",
      " ** new learning rate: 0.000050\n",
      "Epoch: [200/1000] time: 0.3515s, d_loss: 0.07343477, g_loss: 4.79296875, rnn_loss: 0.00000000\n",
      " ** Epoch 200 took 49.660764s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [201/1000] time: 0.3569s, d_loss: 0.25184891, g_loss: 2.48295164, rnn_loss: 0.00000000\n",
      " ** Epoch 201 took 49.146144s\n",
      "Epoch: [202/1000] time: 0.3542s, d_loss: 0.13387898, g_loss: 2.81138706, rnn_loss: 0.00000000\n",
      " ** Epoch 202 took 49.268090s\n",
      "Epoch: [203/1000] time: 0.3585s, d_loss: 0.14020437, g_loss: 3.02232981, rnn_loss: 0.00000000\n",
      " ** Epoch 203 took 49.539073s\n",
      "Epoch: [204/1000] time: 0.3596s, d_loss: 0.16287494, g_loss: 3.21680832, rnn_loss: 0.00000000\n",
      " ** Epoch 204 took 49.851000s\n",
      "Epoch: [205/1000] time: 0.3570s, d_loss: 0.10849894, g_loss: 4.79007292, rnn_loss: 0.00000000\n",
      " ** Epoch 205 took 49.222089s\n",
      "Epoch: [206/1000] time: 0.3543s, d_loss: 0.10183705, g_loss: 3.17235851, rnn_loss: 0.00000000\n",
      " ** Epoch 206 took 49.117132s\n",
      "Epoch: [207/1000] time: 0.3532s, d_loss: 0.03886800, g_loss: 3.81720352, rnn_loss: 0.00000000\n",
      " ** Epoch 207 took 48.897864s\n",
      "Epoch: [208/1000] time: 0.3564s, d_loss: 0.01998631, g_loss: 4.15893126, rnn_loss: 0.00000000\n",
      " ** Epoch 208 took 48.511869s\n",
      "Epoch: [209/1000] time: 0.3570s, d_loss: 0.02833010, g_loss: 5.05562687, rnn_loss: 0.00000000\n",
      " ** Epoch 209 took 48.999266s\n",
      "Epoch: [210/1000] time: 0.3519s, d_loss: 0.13401642, g_loss: 4.79105902, rnn_loss: 0.00000000\n",
      " ** Epoch 210 took 48.907827s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [211/1000] time: 0.3554s, d_loss: 0.08438019, g_loss: 4.03595781, rnn_loss: 0.00000000\n",
      " ** Epoch 211 took 49.560629s\n",
      "Epoch: [212/1000] time: 0.3573s, d_loss: 0.11281011, g_loss: 3.54274321, rnn_loss: 0.00000000\n",
      " ** Epoch 212 took 49.116116s\n",
      "Epoch: [213/1000] time: 0.3459s, d_loss: 0.07222665, g_loss: 2.99857211, rnn_loss: 0.00000000\n",
      " ** Epoch 213 took 49.073558s\n",
      "Epoch: [214/1000] time: 0.3557s, d_loss: 0.15420265, g_loss: 2.22569299, rnn_loss: 0.00000000\n",
      " ** Epoch 214 took 48.870229s\n",
      "Epoch: [215/1000] time: 0.3546s, d_loss: 0.05352924, g_loss: 3.38619494, rnn_loss: 0.00000000\n",
      " ** Epoch 215 took 48.941412s\n",
      "Epoch: [216/1000] time: 0.3528s, d_loss: 0.03518825, g_loss: 3.78327036, rnn_loss: 0.00000000\n",
      " ** Epoch 216 took 49.100373s\n",
      "Epoch: [217/1000] time: 0.3545s, d_loss: 0.18299475, g_loss: 2.72060156, rnn_loss: 0.00000000\n",
      " ** Epoch 217 took 49.698323s\n",
      "Epoch: [218/1000] time: 0.3582s, d_loss: 0.01700115, g_loss: 4.52250957, rnn_loss: 0.00000000\n",
      " ** Epoch 218 took 49.090754s\n",
      "Epoch: [219/1000] time: 0.3596s, d_loss: 0.03546189, g_loss: 4.69603157, rnn_loss: 0.00000000\n",
      " ** Epoch 219 took 49.178595s\n",
      "Epoch: [220/1000] time: 0.3558s, d_loss: 0.09871643, g_loss: 4.95829535, rnn_loss: 0.00000000\n",
      " ** Epoch 220 took 49.177543s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [221/1000] time: 0.3570s, d_loss: 0.03030737, g_loss: 4.57697725, rnn_loss: 0.00000000\n",
      " ** Epoch 221 took 49.444433s\n",
      "Epoch: [222/1000] time: 0.3573s, d_loss: 0.03133327, g_loss: 5.16140079, rnn_loss: 0.00000000\n",
      " ** Epoch 222 took 49.201530s\n",
      "Epoch: [223/1000] time: 0.3586s, d_loss: 0.15529883, g_loss: 3.06068945, rnn_loss: 0.00000000\n",
      " ** Epoch 223 took 49.796527s\n",
      "Epoch: [224/1000] time: 0.3557s, d_loss: 0.40062410, g_loss: 7.04160881, rnn_loss: 0.00000000\n",
      " ** Epoch 224 took 49.164814s\n",
      "Epoch: [225/1000] time: 0.3604s, d_loss: 0.08587193, g_loss: 3.81935883, rnn_loss: 0.00000000\n",
      " ** Epoch 225 took 49.181217s\n",
      "Epoch: [226/1000] time: 0.3464s, d_loss: 0.06983501, g_loss: 4.08527756, rnn_loss: 0.00000000\n",
      " ** Epoch 226 took 49.125951s\n",
      "Epoch: [227/1000] time: 0.3785s, d_loss: 0.18511924, g_loss: 4.38235331, rnn_loss: 0.00000000\n",
      " ** Epoch 227 took 49.268465s\n",
      "Epoch: [228/1000] time: 0.3581s, d_loss: 0.17298374, g_loss: 2.31104183, rnn_loss: 0.00000000\n",
      " ** Epoch 228 took 49.313637s\n",
      "Epoch: [229/1000] time: 0.3786s, d_loss: 0.01999415, g_loss: 6.36328077, rnn_loss: 0.00000000\n",
      " ** Epoch 229 took 49.368581s\n",
      "Epoch: [230/1000] time: 0.3595s, d_loss: 0.04880120, g_loss: 4.67827511, rnn_loss: 0.00000000\n",
      " ** Epoch 230 took 49.591448s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [231/1000] time: 0.3586s, d_loss: 0.02242609, g_loss: 4.67248154, rnn_loss: 0.00000000\n",
      " ** Epoch 231 took 49.138786s\n",
      "Epoch: [232/1000] time: 0.3597s, d_loss: 0.20004548, g_loss: 3.78594208, rnn_loss: 0.00000000\n",
      " ** Epoch 232 took 49.324726s\n",
      "Epoch: [233/1000] time: 0.3610s, d_loss: 0.07781913, g_loss: 4.23129654, rnn_loss: 0.00000000\n",
      " ** Epoch 233 took 49.279536s\n",
      "Epoch: [234/1000] time: 0.3537s, d_loss: 0.03592488, g_loss: 6.05714464, rnn_loss: 0.00000000\n",
      " ** Epoch 234 took 49.560306s\n",
      "Epoch: [235/1000] time: 0.3603s, d_loss: 0.21468081, g_loss: 6.39760399, rnn_loss: 0.00000000\n",
      " ** Epoch 235 took 49.259955s\n",
      "Epoch: [236/1000] time: 0.3566s, d_loss: 0.03829632, g_loss: 3.94426966, rnn_loss: 0.00000000\n",
      " ** Epoch 236 took 49.805606s\n",
      "Epoch: [237/1000] time: 0.3584s, d_loss: 0.03352744, g_loss: 5.47397852, rnn_loss: 0.00000000\n",
      " ** Epoch 237 took 49.250337s\n",
      "Epoch: [238/1000] time: 0.3593s, d_loss: 0.07544164, g_loss: 3.59561205, rnn_loss: 0.00000000\n",
      " ** Epoch 238 took 49.316315s\n",
      "Epoch: [239/1000] time: 0.3457s, d_loss: 0.04259201, g_loss: 5.31147194, rnn_loss: 0.00000000\n",
      " ** Epoch 239 took 49.223998s\n",
      "Epoch: [240/1000] time: 0.3574s, d_loss: 0.03990929, g_loss: 4.08227921, rnn_loss: 0.00000000\n",
      " ** Epoch 240 took 49.518283s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [241/1000] time: 0.3526s, d_loss: 0.01423392, g_loss: 4.66937160, rnn_loss: 0.00000000\n",
      " ** Epoch 241 took 48.665271s\n",
      "Epoch: [242/1000] time: 0.3601s, d_loss: 0.03933005, g_loss: 6.76081181, rnn_loss: 0.00000000\n",
      " ** Epoch 242 took 49.590321s\n",
      "Epoch: [243/1000] time: 0.3628s, d_loss: 0.02514381, g_loss: 4.48969460, rnn_loss: 0.00000000\n",
      " ** Epoch 243 took 49.203605s\n",
      "Epoch: [244/1000] time: 0.3585s, d_loss: 0.11025830, g_loss: 3.75438595, rnn_loss: 0.00000000\n",
      " ** Epoch 244 took 49.398601s\n",
      "Epoch: [245/1000] time: 0.3552s, d_loss: 0.02251212, g_loss: 4.91747093, rnn_loss: 0.00000000\n",
      " ** Epoch 245 took 49.295908s\n",
      "Epoch: [246/1000] time: 0.3592s, d_loss: 0.02091333, g_loss: 4.58842945, rnn_loss: 0.00000000\n",
      " ** Epoch 246 took 49.623223s\n",
      "Epoch: [247/1000] time: 0.3562s, d_loss: 0.06659338, g_loss: 4.63075113, rnn_loss: 0.00000000\n",
      " ** Epoch 247 took 49.314869s\n",
      "Epoch: [248/1000] time: 0.3451s, d_loss: 0.07648382, g_loss: 5.48244238, rnn_loss: 0.00000000\n",
      " ** Epoch 248 took 49.653259s\n",
      "Epoch: [249/1000] time: 0.3523s, d_loss: 0.01998701, g_loss: 5.45964766, rnn_loss: 0.00000000\n",
      " ** Epoch 249 took 48.930625s\n",
      "Epoch: [250/1000] time: 0.3585s, d_loss: 0.04299979, g_loss: 4.44631863, rnn_loss: 0.00000000\n",
      " ** Epoch 250 took 48.991364s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [251/1000] time: 0.3553s, d_loss: 0.06268207, g_loss: 5.14948463, rnn_loss: 0.00000000\n",
      " ** Epoch 251 took 48.998070s\n",
      "Epoch: [252/1000] time: 0.3587s, d_loss: 0.08136518, g_loss: 3.41111279, rnn_loss: 0.00000000\n",
      " ** Epoch 252 took 49.415892s\n",
      "Epoch: [253/1000] time: 0.3563s, d_loss: 0.26261976, g_loss: 6.68711758, rnn_loss: 0.00000000\n",
      " ** Epoch 253 took 49.100505s\n",
      "Epoch: [254/1000] time: 0.3585s, d_loss: 0.02585346, g_loss: 3.85087419, rnn_loss: 0.00000000\n",
      " ** Epoch 254 took 48.920250s\n",
      "Epoch: [255/1000] time: 0.3581s, d_loss: 0.05286245, g_loss: 5.93549871, rnn_loss: 0.00000000\n",
      " ** Epoch 255 took 49.646984s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [256/1000] time: 0.3587s, d_loss: 0.02929157, g_loss: 6.30452108, rnn_loss: 0.00000000\n",
      " ** Epoch 256 took 49.119458s\n",
      "Epoch: [257/1000] time: 0.3564s, d_loss: 0.02269468, g_loss: 4.36610508, rnn_loss: 0.00000000\n",
      " ** Epoch 257 took 49.034746s\n",
      "Epoch: [258/1000] time: 0.3545s, d_loss: 0.07928374, g_loss: 4.06223392, rnn_loss: 0.00000000\n",
      " ** Epoch 258 took 49.259016s\n",
      "Epoch: [259/1000] time: 0.3552s, d_loss: 0.02693177, g_loss: 4.85687828, rnn_loss: 0.00000000\n",
      " ** Epoch 259 took 49.064179s\n",
      "Epoch: [260/1000] time: 0.3590s, d_loss: 0.01402922, g_loss: 4.55659819, rnn_loss: 0.00000000\n",
      " ** Epoch 260 took 49.049698s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [261/1000] time: 0.3571s, d_loss: 0.02790941, g_loss: 5.06291628, rnn_loss: 0.00000000\n",
      " ** Epoch 261 took 49.571910s\n",
      "Epoch: [262/1000] time: 0.3573s, d_loss: 0.04623189, g_loss: 5.50077295, rnn_loss: 0.00000000\n",
      " ** Epoch 262 took 49.152594s\n",
      "Epoch: [263/1000] time: 0.3434s, d_loss: 0.21928494, g_loss: 2.90811968, rnn_loss: 0.00000000\n",
      " ** Epoch 263 took 48.939154s\n",
      "Epoch: [264/1000] time: 0.3528s, d_loss: 0.03224153, g_loss: 4.81909180, rnn_loss: 0.00000000\n",
      " ** Epoch 264 took 48.937900s\n",
      "Epoch: [265/1000] time: 0.3558s, d_loss: 0.08292833, g_loss: 4.42887115, rnn_loss: 0.00000000\n",
      " ** Epoch 265 took 49.350886s\n",
      "Epoch: [266/1000] time: 0.3582s, d_loss: 0.04358484, g_loss: 3.87159967, rnn_loss: 0.00000000\n",
      " ** Epoch 266 took 49.110561s\n",
      "Epoch: [267/1000] time: 0.3611s, d_loss: 0.02528984, g_loss: 5.08334064, rnn_loss: 0.00000000\n",
      " ** Epoch 267 took 49.727635s\n",
      "Epoch: [268/1000] time: 0.3555s, d_loss: 0.03720768, g_loss: 4.29936790, rnn_loss: 0.00000000\n",
      " ** Epoch 268 took 49.195917s\n",
      "Epoch: [269/1000] time: 0.3559s, d_loss: 0.05999135, g_loss: 3.67404199, rnn_loss: 0.00000000\n",
      " ** Epoch 269 took 49.224252s\n",
      "Epoch: [270/1000] time: 0.3575s, d_loss: 0.05133600, g_loss: 5.58724499, rnn_loss: 0.00000000\n",
      " ** Epoch 270 took 49.197196s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [271/1000] time: 0.3600s, d_loss: 0.03511279, g_loss: 4.65423536, rnn_loss: 0.00000000\n",
      " ** Epoch 271 took 49.467308s\n",
      "Epoch: [272/1000] time: 0.3589s, d_loss: 0.01037364, g_loss: 4.56698036, rnn_loss: 0.00000000\n",
      " ** Epoch 272 took 49.352760s\n",
      "Epoch: [273/1000] time: 0.3812s, d_loss: 0.03815546, g_loss: 4.49866247, rnn_loss: 0.00000000\n",
      " ** Epoch 273 took 49.775691s\n",
      "Epoch: [274/1000] time: 0.3448s, d_loss: 0.05942777, g_loss: 4.28835583, rnn_loss: 0.00000000\n",
      " ** Epoch 274 took 49.260499s\n",
      "Epoch: [275/1000] time: 0.3567s, d_loss: 0.01016022, g_loss: 6.26540375, rnn_loss: 0.00000000\n",
      " ** Epoch 275 took 49.034290s\n",
      "Epoch: [276/1000] time: 0.3540s, d_loss: 0.02845693, g_loss: 4.47487164, rnn_loss: 0.00000000\n",
      " ** Epoch 276 took 49.099644s\n",
      "Epoch: [277/1000] time: 0.3521s, d_loss: 0.14138168, g_loss: 3.32819176, rnn_loss: 0.00000000\n",
      " ** Epoch 277 took 49.405194s\n",
      "Epoch: [278/1000] time: 0.3552s, d_loss: 0.00842766, g_loss: 5.07318783, rnn_loss: 0.00000000\n",
      " ** Epoch 278 took 49.107567s\n",
      "Epoch: [279/1000] time: 0.3552s, d_loss: 0.02980351, g_loss: 4.09241009, rnn_loss: 0.00000000\n",
      " ** Epoch 279 took 49.122218s\n",
      "Epoch: [280/1000] time: 0.3566s, d_loss: 0.08416469, g_loss: 4.41412926, rnn_loss: 0.00000000\n",
      " ** Epoch 280 took 49.735179s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [281/1000] time: 0.3570s, d_loss: 0.02445780, g_loss: 5.75148296, rnn_loss: 0.00000000\n",
      " ** Epoch 281 took 49.003857s\n",
      "Epoch: [282/1000] time: 0.3570s, d_loss: 0.00663376, g_loss: 6.45026255, rnn_loss: 0.00000000\n",
      " ** Epoch 282 took 49.171199s\n",
      "Epoch: [283/1000] time: 0.3562s, d_loss: 0.07217508, g_loss: 5.79061317, rnn_loss: 0.00000000\n",
      " ** Epoch 283 took 49.525438s\n",
      "Epoch: [284/1000] time: 0.3553s, d_loss: 0.16956794, g_loss: 3.45188761, rnn_loss: 0.00000000\n",
      " ** Epoch 284 took 49.336768s\n",
      "Epoch: [285/1000] time: 0.3585s, d_loss: 0.33283827, g_loss: 5.49645758, rnn_loss: 0.00000000\n",
      " ** Epoch 285 took 49.288064s\n",
      "Epoch: [286/1000] time: 0.3461s, d_loss: 0.11114054, g_loss: 4.70893955, rnn_loss: 0.00000000\n",
      " ** Epoch 286 took 49.911912s\n",
      "Epoch: [287/1000] time: 0.3581s, d_loss: 0.02476036, g_loss: 5.44220352, rnn_loss: 0.00000000\n",
      " ** Epoch 287 took 49.411463s\n",
      "Epoch: [288/1000] time: 0.3481s, d_loss: 0.09006211, g_loss: 3.72499180, rnn_loss: 0.00000000\n",
      " ** Epoch 288 took 48.837224s\n",
      "Epoch: [289/1000] time: 0.3606s, d_loss: 0.01856958, g_loss: 5.46328735, rnn_loss: 0.00000000\n",
      " ** Epoch 289 took 49.852803s\n",
      "Epoch: [290/1000] time: 0.3592s, d_loss: 0.03055307, g_loss: 4.18301153, rnn_loss: 0.00000000\n",
      " ** Epoch 290 took 49.559063s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [291/1000] time: 0.3574s, d_loss: 0.07003184, g_loss: 3.52920341, rnn_loss: 0.00000000\n",
      " ** Epoch 291 took 49.328304s\n",
      "Epoch: [292/1000] time: 0.3615s, d_loss: 0.02914597, g_loss: 5.15849543, rnn_loss: 0.00000000\n",
      " ** Epoch 292 took 49.893355s\n",
      "Epoch: [293/1000] time: 0.3529s, d_loss: 0.02921406, g_loss: 4.35163641, rnn_loss: 0.00000000\n",
      " ** Epoch 293 took 48.703917s\n",
      "Epoch: [294/1000] time: 0.3504s, d_loss: 0.00854009, g_loss: 6.24269485, rnn_loss: 0.00000000\n",
      " ** Epoch 294 took 49.071432s\n",
      "Epoch: [295/1000] time: 0.3565s, d_loss: 0.05032042, g_loss: 3.95485902, rnn_loss: 0.00000000\n",
      " ** Epoch 295 took 49.725873s\n",
      "Epoch: [296/1000] time: 0.3594s, d_loss: 3.08375502, g_loss: 0.02175253, rnn_loss: 0.00000000\n",
      " ** Epoch 296 took 49.408668s\n",
      "Epoch: [297/1000] time: 0.3608s, d_loss: 0.03183408, g_loss: 4.19380188, rnn_loss: 0.00000000\n",
      " ** Epoch 297 took 49.420167s\n",
      "Epoch: [298/1000] time: 0.3814s, d_loss: 0.17000273, g_loss: 2.78979635, rnn_loss: 0.00000000\n",
      " ** Epoch 298 took 49.564333s\n",
      "Epoch: [299/1000] time: 0.3584s, d_loss: 0.02444207, g_loss: 4.21986198, rnn_loss: 0.00000000\n",
      " ** Epoch 299 took 49.844911s\n",
      " ** new learning rate: 0.000025\n",
      "Epoch: [300/1000] time: 0.3597s, d_loss: 0.05088847, g_loss: 3.44045949, rnn_loss: 0.00000000\n",
      " ** Epoch 300 took 49.844186s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [301/1000] time: 0.3809s, d_loss: 0.02299467, g_loss: 4.96664143, rnn_loss: 0.00000000\n",
      " ** Epoch 301 took 49.551769s\n",
      "Epoch: [302/1000] time: 0.3606s, d_loss: 0.05487437, g_loss: 3.59573317, rnn_loss: 0.00000000\n",
      " ** Epoch 302 took 49.632896s\n",
      "Epoch: [303/1000] time: 0.3556s, d_loss: 0.06417684, g_loss: 3.80964565, rnn_loss: 0.00000000\n",
      " ** Epoch 303 took 49.365336s\n",
      "Epoch: [304/1000] time: 0.3593s, d_loss: 0.01373507, g_loss: 5.75169086, rnn_loss: 0.00000000\n",
      " ** Epoch 304 took 49.431444s\n",
      "Epoch: [305/1000] time: 0.3612s, d_loss: 0.01433030, g_loss: 4.55720425, rnn_loss: 0.00000000\n",
      " ** Epoch 305 took 49.866902s\n",
      "Epoch: [306/1000] time: 0.3558s, d_loss: 0.06293519, g_loss: 3.06011891, rnn_loss: 0.00000000\n",
      " ** Epoch 306 took 49.413467s\n",
      "Epoch: [307/1000] time: 0.3550s, d_loss: 0.00652675, g_loss: 6.86476851, rnn_loss: 0.00000000\n",
      " ** Epoch 307 took 49.132676s\n",
      "Epoch: [308/1000] time: 0.3578s, d_loss: 0.09846739, g_loss: 3.35817957, rnn_loss: 0.00000000\n",
      " ** Epoch 308 took 49.633860s\n",
      "Epoch: [309/1000] time: 0.3492s, d_loss: 0.12973841, g_loss: 5.64275551, rnn_loss: 0.00000000\n",
      " ** Epoch 309 took 49.248582s\n",
      "Epoch: [310/1000] time: 0.3574s, d_loss: 0.08754640, g_loss: 6.02603197, rnn_loss: 0.00000000\n",
      " ** Epoch 310 took 49.408512s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [311/1000] time: 0.3584s, d_loss: 0.01061590, g_loss: 7.37357712, rnn_loss: 0.00000000\n",
      " ** Epoch 311 took 49.850621s\n",
      "Epoch: [312/1000] time: 0.3576s, d_loss: 0.01288580, g_loss: 5.71531010, rnn_loss: 0.00000000\n",
      " ** Epoch 312 took 49.326481s\n",
      "Epoch: [313/1000] time: 0.3571s, d_loss: 0.02960008, g_loss: 4.00172424, rnn_loss: 0.00000000\n",
      " ** Epoch 313 took 49.276028s\n",
      "Epoch: [314/1000] time: 0.3594s, d_loss: 0.15067612, g_loss: 4.44778681, rnn_loss: 0.00000000\n",
      " ** Epoch 314 took 49.627968s\n",
      "Epoch: [315/1000] time: 0.3552s, d_loss: 0.02323813, g_loss: 4.19514942, rnn_loss: 0.00000000\n",
      " ** Epoch 315 took 49.144349s\n",
      "Epoch: [316/1000] time: 0.3582s, d_loss: 0.01318415, g_loss: 3.82007027, rnn_loss: 0.00000000\n",
      " ** Epoch 316 took 49.130996s\n",
      "Epoch: [317/1000] time: 0.3556s, d_loss: 0.05058475, g_loss: 5.54797077, rnn_loss: 0.00000000\n",
      " ** Epoch 317 took 49.676488s\n",
      "Epoch: [318/1000] time: 0.3524s, d_loss: 0.00290783, g_loss: 6.78932190, rnn_loss: 0.00000000\n",
      " ** Epoch 318 took 49.089004s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [319/1000] time: 0.3563s, d_loss: 0.07026637, g_loss: 5.01712894, rnn_loss: 0.00000000\n",
      " ** Epoch 319 took 49.130380s\n",
      "Epoch: [320/1000] time: 0.3576s, d_loss: 0.05841497, g_loss: 3.61343002, rnn_loss: 0.00000000\n",
      " ** Epoch 320 took 49.419571s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [321/1000] time: 0.3556s, d_loss: 0.03998955, g_loss: 3.84873462, rnn_loss: 0.00000000\n",
      " ** Epoch 321 took 49.243620s\n",
      "Epoch: [322/1000] time: 0.3572s, d_loss: 0.08237834, g_loss: 4.10806656, rnn_loss: 0.00000000\n",
      " ** Epoch 322 took 49.279921s\n",
      "Epoch: [323/1000] time: 0.3826s, d_loss: 0.05141971, g_loss: 3.29020929, rnn_loss: 0.00000000\n",
      " ** Epoch 323 took 49.479067s\n",
      "Epoch: [324/1000] time: 0.3518s, d_loss: 0.07603260, g_loss: 3.38384199, rnn_loss: 0.00000000\n",
      " ** Epoch 324 took 49.430808s\n",
      "Epoch: [325/1000] time: 0.3590s, d_loss: 0.14649418, g_loss: 2.48432660, rnn_loss: 0.00000000\n",
      " ** Epoch 325 took 49.217727s\n",
      "Epoch: [326/1000] time: 0.3577s, d_loss: 0.11269337, g_loss: 3.38909340, rnn_loss: 0.00000000\n",
      " ** Epoch 326 took 49.533759s\n",
      "Epoch: [327/1000] time: 0.3535s, d_loss: 0.02507387, g_loss: 5.59953070, rnn_loss: 0.00000000\n",
      " ** Epoch 327 took 49.189824s\n",
      "Epoch: [328/1000] time: 0.3562s, d_loss: 0.05605387, g_loss: 5.97580719, rnn_loss: 0.00000000\n",
      " ** Epoch 328 took 49.176315s\n",
      "Epoch: [329/1000] time: 0.3617s, d_loss: 0.11421226, g_loss: 3.92491174, rnn_loss: 0.00000000\n",
      " ** Epoch 329 took 49.270175s\n",
      "Epoch: [330/1000] time: 0.3588s, d_loss: 0.06533282, g_loss: 4.20845270, rnn_loss: 0.00000000\n",
      " ** Epoch 330 took 50.136477s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [331/1000] time: 0.3557s, d_loss: 0.05404080, g_loss: 3.66701317, rnn_loss: 0.00000000\n",
      " ** Epoch 331 took 49.354640s\n",
      "Epoch: [332/1000] time: 0.3579s, d_loss: 0.13117225, g_loss: 4.35374403, rnn_loss: 0.00000000\n",
      " ** Epoch 332 took 49.592615s\n",
      "Epoch: [333/1000] time: 0.3570s, d_loss: 0.02384370, g_loss: 4.99408102, rnn_loss: 0.00000000\n",
      " ** Epoch 333 took 49.284649s\n",
      "Epoch: [334/1000] time: 0.3552s, d_loss: 0.03202268, g_loss: 4.66134405, rnn_loss: 0.00000000\n",
      " ** Epoch 334 took 49.281476s\n",
      "Epoch: [335/1000] time: 0.3559s, d_loss: 0.10245834, g_loss: 3.68111062, rnn_loss: 0.00000000\n",
      " ** Epoch 335 took 49.267971s\n",
      "Epoch: [336/1000] time: 0.3557s, d_loss: 0.03405581, g_loss: 5.26974440, rnn_loss: 0.00000000\n",
      " ** Epoch 336 took 49.876681s\n",
      "Epoch: [337/1000] time: 0.3554s, d_loss: 0.05475466, g_loss: 4.21877098, rnn_loss: 0.00000000\n",
      " ** Epoch 337 took 49.378893s\n",
      "Epoch: [338/1000] time: 0.3794s, d_loss: 0.02977994, g_loss: 4.71941280, rnn_loss: 0.00000000\n",
      " ** Epoch 338 took 49.580396s\n",
      "Epoch: [339/1000] time: 0.3563s, d_loss: 0.02799140, g_loss: 4.28423595, rnn_loss: 0.00000000\n",
      " ** Epoch 339 took 49.185616s\n",
      "Epoch: [340/1000] time: 0.3523s, d_loss: 0.03333043, g_loss: 6.14156723, rnn_loss: 0.00000000\n",
      " ** Epoch 340 took 49.163244s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [341/1000] time: 0.3506s, d_loss: 0.01088659, g_loss: 4.94538975, rnn_loss: 0.00000000\n",
      " ** Epoch 341 took 48.943954s\n",
      "Epoch: [342/1000] time: 0.3569s, d_loss: 0.09936790, g_loss: 4.23158073, rnn_loss: 0.00000000\n",
      " ** Epoch 342 took 49.761854s\n",
      "Epoch: [343/1000] time: 0.3598s, d_loss: 0.09972245, g_loss: 3.95281172, rnn_loss: 0.00000000\n",
      " ** Epoch 343 took 49.292658s\n",
      "Epoch: [344/1000] time: 0.3635s, d_loss: 0.02231119, g_loss: 4.36544943, rnn_loss: 0.00000000\n",
      " ** Epoch 344 took 48.944421s\n",
      "Epoch: [345/1000] time: 0.3581s, d_loss: 0.03391442, g_loss: 4.67320824, rnn_loss: 0.00000000\n",
      " ** Epoch 345 took 49.965276s\n",
      "Epoch: [346/1000] time: 0.3594s, d_loss: 0.00797660, g_loss: 5.59631348, rnn_loss: 0.00000000\n",
      " ** Epoch 346 took 49.377365s\n",
      "Epoch: [347/1000] time: 0.3586s, d_loss: 0.01549747, g_loss: 4.42605400, rnn_loss: 0.00000000\n",
      " ** Epoch 347 took 49.450026s\n",
      "Epoch: [348/1000] time: 0.3816s, d_loss: 0.03714313, g_loss: 5.15955734, rnn_loss: 0.00000000\n",
      " ** Epoch 348 took 49.471700s\n",
      "Epoch: [349/1000] time: 0.3557s, d_loss: 0.02620073, g_loss: 4.46669292, rnn_loss: 0.00000000\n",
      " ** Epoch 349 took 49.806055s\n",
      "Epoch: [350/1000] time: 0.3564s, d_loss: 0.02175910, g_loss: 4.38010120, rnn_loss: 0.00000000\n",
      " ** Epoch 350 took 49.351945s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [351/1000] time: 0.3551s, d_loss: 0.01036561, g_loss: 4.86739922, rnn_loss: 0.00000000\n",
      " ** Epoch 351 took 49.537780s\n",
      "Epoch: [352/1000] time: 0.3564s, d_loss: 0.02142694, g_loss: 4.02204609, rnn_loss: 0.00000000\n",
      " ** Epoch 352 took 49.263022s\n",
      "Epoch: [353/1000] time: 0.3533s, d_loss: 0.04649858, g_loss: 4.89384556, rnn_loss: 0.00000000\n",
      " ** Epoch 353 took 49.335521s\n",
      "Epoch: [354/1000] time: 0.3562s, d_loss: 0.01343838, g_loss: 4.44012642, rnn_loss: 0.00000000\n",
      " ** Epoch 354 took 49.246280s\n",
      "Epoch: [355/1000] time: 0.3523s, d_loss: 0.01516358, g_loss: 5.64782810, rnn_loss: 0.00000000\n",
      " ** Epoch 355 took 49.778851s\n",
      "Epoch: [356/1000] time: 0.3570s, d_loss: 0.05514628, g_loss: 4.77903080, rnn_loss: 0.00000000\n",
      " ** Epoch 356 took 49.188227s\n",
      "Epoch: [357/1000] time: 0.3583s, d_loss: 0.00747022, g_loss: 4.83861065, rnn_loss: 0.00000000\n",
      " ** Epoch 357 took 49.424662s\n",
      "Epoch: [358/1000] time: 0.3535s, d_loss: 0.02210908, g_loss: 4.19874668, rnn_loss: 0.00000000\n",
      " ** Epoch 358 took 48.987562s\n",
      "Epoch: [359/1000] time: 0.3538s, d_loss: 0.01287689, g_loss: 5.54290152, rnn_loss: 0.00000000\n",
      " ** Epoch 359 took 48.968492s\n",
      "Epoch: [360/1000] time: 0.3556s, d_loss: 0.22158623, g_loss: 3.86343431, rnn_loss: 0.00000000\n",
      " ** Epoch 360 took 48.985848s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [361/1000] time: 0.3530s, d_loss: 0.03099819, g_loss: 4.82374763, rnn_loss: 0.00000000\n",
      " ** Epoch 361 took 49.592084s\n",
      "Epoch: [362/1000] time: 0.3556s, d_loss: 0.10175698, g_loss: 3.25734234, rnn_loss: 0.00000000\n",
      " ** Epoch 362 took 49.129514s\n",
      "Epoch: [363/1000] time: 0.3547s, d_loss: 0.03073797, g_loss: 4.02917576, rnn_loss: 0.00000000\n",
      " ** Epoch 363 took 49.346478s\n",
      "Epoch: [364/1000] time: 0.3565s, d_loss: 0.03410390, g_loss: 5.10266590, rnn_loss: 0.00000000\n",
      " ** Epoch 364 took 49.015178s\n",
      "Epoch: [365/1000] time: 0.3540s, d_loss: 0.01905430, g_loss: 7.32332373, rnn_loss: 0.00000000\n",
      " ** Epoch 365 took 49.086131s\n",
      "Epoch: [366/1000] time: 0.3533s, d_loss: 0.02376436, g_loss: 7.30681610, rnn_loss: 0.00000000\n",
      " ** Epoch 366 took 49.143979s\n",
      "Epoch: [367/1000] time: 0.3569s, d_loss: 0.01546596, g_loss: 4.91297436, rnn_loss: 0.00000000\n",
      " ** Epoch 367 took 49.730766s\n",
      "Epoch: [368/1000] time: 0.3584s, d_loss: 0.19080406, g_loss: 4.04841280, rnn_loss: 0.00000000\n",
      " ** Epoch 368 took 49.113016s\n",
      "Epoch: [369/1000] time: 0.3525s, d_loss: 0.03490566, g_loss: 3.93478537, rnn_loss: 0.00000000\n",
      " ** Epoch 369 took 49.487927s\n",
      "Epoch: [370/1000] time: 0.3550s, d_loss: 0.04437980, g_loss: 3.80307388, rnn_loss: 0.00000000\n",
      " ** Epoch 370 took 49.135937s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [371/1000] time: 0.3581s, d_loss: 0.08689603, g_loss: 6.21493721, rnn_loss: 0.00000000\n",
      " ** Epoch 371 took 49.070848s\n",
      "Epoch: [372/1000] time: 0.3546s, d_loss: 0.03182009, g_loss: 4.50711060, rnn_loss: 0.00000000\n",
      " ** Epoch 372 took 49.199002s\n",
      "Epoch: [373/1000] time: 0.3525s, d_loss: 0.00311120, g_loss: 6.21105099, rnn_loss: 0.00000000\n",
      " ** Epoch 373 took 49.211115s\n",
      "Epoch: [374/1000] time: 0.3547s, d_loss: 0.00790964, g_loss: 4.84136438, rnn_loss: 0.00000000\n",
      " ** Epoch 374 took 49.761158s\n",
      "Epoch: [375/1000] time: 0.3761s, d_loss: 0.00822055, g_loss: 6.11472607, rnn_loss: 0.00000000\n",
      " ** Epoch 375 took 50.111668s\n",
      "Epoch: [376/1000] time: 0.3527s, d_loss: 0.11394472, g_loss: 4.33470821, rnn_loss: 0.00000000\n",
      " ** Epoch 376 took 49.309710s\n",
      "Epoch: [377/1000] time: 0.3516s, d_loss: 0.01585466, g_loss: 3.75412464, rnn_loss: 0.00000000\n",
      " ** Epoch 377 took 49.040478s\n",
      "Epoch: [378/1000] time: 0.3509s, d_loss: 0.01122905, g_loss: 5.13417339, rnn_loss: 0.00000000\n",
      " ** Epoch 378 took 48.981530s\n",
      "Epoch: [379/1000] time: 0.3590s, d_loss: 0.00868847, g_loss: 5.54071569, rnn_loss: 0.00000000\n",
      " ** Epoch 379 took 49.137197s\n",
      "Epoch: [380/1000] time: 0.3566s, d_loss: 0.00796623, g_loss: 6.74116611, rnn_loss: 0.00000000\n",
      " ** Epoch 380 took 49.923047s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [381/1000] time: 0.3588s, d_loss: 0.54286194, g_loss: 10.43961334, rnn_loss: 0.00000000\n",
      " ** Epoch 381 took 49.333511s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [382/1000] time: 0.3590s, d_loss: 0.02136238, g_loss: 4.00496674, rnn_loss: 0.00000000\n",
      " ** Epoch 382 took 49.590140s\n",
      "Epoch: [383/1000] time: 0.3580s, d_loss: 0.02855474, g_loss: 5.09882355, rnn_loss: 0.00000000\n",
      " ** Epoch 383 took 49.291048s\n",
      "Epoch: [384/1000] time: 0.3563s, d_loss: 0.03658107, g_loss: 4.08952618, rnn_loss: 0.00000000\n",
      " ** Epoch 384 took 49.313726s\n",
      "Epoch: [385/1000] time: 0.3552s, d_loss: 0.11482263, g_loss: 4.05130100, rnn_loss: 0.00000000\n",
      " ** Epoch 385 took 49.278081s\n",
      "Epoch: [386/1000] time: 0.3573s, d_loss: 0.02786632, g_loss: 4.03718090, rnn_loss: 0.00000000\n",
      " ** Epoch 386 took 49.810915s\n",
      "Epoch: [387/1000] time: 0.3522s, d_loss: 0.09083295, g_loss: 4.01690912, rnn_loss: 0.00000000\n",
      " ** Epoch 387 took 49.070339s\n",
      "Epoch: [388/1000] time: 0.3525s, d_loss: 0.02575754, g_loss: 4.29257965, rnn_loss: 0.00000000\n",
      " ** Epoch 388 took 49.037310s\n",
      "Epoch: [389/1000] time: 0.3494s, d_loss: 0.03619905, g_loss: 6.42648792, rnn_loss: 0.00000000\n",
      " ** Epoch 389 took 48.836993s\n",
      "Epoch: [390/1000] time: 0.3531s, d_loss: 0.01194354, g_loss: 5.25083828, rnn_loss: 0.00000000\n",
      " ** Epoch 390 took 48.909276s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [391/1000] time: 0.3547s, d_loss: 0.05733112, g_loss: 3.98624611, rnn_loss: 0.00000000\n",
      " ** Epoch 391 took 48.836244s\n",
      "Epoch: [392/1000] time: 0.3735s, d_loss: 0.01676377, g_loss: 4.54284000, rnn_loss: 0.00000000\n",
      " ** Epoch 392 took 49.283693s\n",
      "Epoch: [393/1000] time: 0.3522s, d_loss: 0.03814856, g_loss: 4.20484829, rnn_loss: 0.00000000\n",
      " ** Epoch 393 took 49.111334s\n",
      "Epoch: [394/1000] time: 0.3521s, d_loss: 0.00721243, g_loss: 6.38062763, rnn_loss: 0.00000000\n",
      " ** Epoch 394 took 49.244777s\n",
      "Epoch: [395/1000] time: 0.3509s, d_loss: 0.07671991, g_loss: 5.50510120, rnn_loss: 0.00000000\n",
      " ** Epoch 395 took 48.938645s\n",
      "Epoch: [396/1000] time: 0.3556s, d_loss: 0.01165893, g_loss: 5.20855665, rnn_loss: 0.00000000\n",
      " ** Epoch 396 took 48.911182s\n",
      "Epoch: [397/1000] time: 0.3526s, d_loss: 0.04155042, g_loss: 4.23363113, rnn_loss: 0.00000000\n",
      " ** Epoch 397 took 48.840918s\n",
      "Epoch: [398/1000] time: 0.3518s, d_loss: 0.14003745, g_loss: 2.91663337, rnn_loss: 0.00000000\n",
      " ** Epoch 398 took 48.802821s\n",
      "Epoch: [399/1000] time: 0.3534s, d_loss: 0.03843243, g_loss: 3.57545567, rnn_loss: 0.00000000\n",
      " ** Epoch 399 took 49.343889s\n",
      " ** new learning rate: 0.000013\n",
      "Epoch: [400/1000] time: 0.3540s, d_loss: 0.01538634, g_loss: 5.05362415, rnn_loss: 0.00000000\n",
      " ** Epoch 400 took 49.409648s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [401/1000] time: 0.3566s, d_loss: 0.01345957, g_loss: 5.03583908, rnn_loss: 0.00000000\n",
      " ** Epoch 401 took 48.616235s\n",
      "Epoch: [402/1000] time: 0.3559s, d_loss: 0.01563141, g_loss: 4.38052225, rnn_loss: 0.00000000\n",
      " ** Epoch 402 took 48.695771s\n",
      "Epoch: [403/1000] time: 0.3511s, d_loss: 0.01097922, g_loss: 5.25773144, rnn_loss: 0.00000000\n",
      " ** Epoch 403 took 48.660619s\n",
      "Epoch: [404/1000] time: 0.3559s, d_loss: 0.05512851, g_loss: 3.93071103, rnn_loss: 0.00000000\n",
      " ** Epoch 404 took 48.749757s\n",
      "Epoch: [405/1000] time: 0.3557s, d_loss: 0.01653430, g_loss: 4.62964678, rnn_loss: 0.00000000\n",
      " ** Epoch 405 took 49.817486s\n",
      "Epoch: [406/1000] time: 0.3561s, d_loss: 0.13601206, g_loss: 3.64058089, rnn_loss: 0.00000000\n",
      " ** Epoch 406 took 49.116759s\n",
      "Epoch: [407/1000] time: 0.3528s, d_loss: 0.01169578, g_loss: 4.61891651, rnn_loss: 0.00000000\n",
      " ** Epoch 407 took 48.773403s\n",
      "Epoch: [408/1000] time: 0.3544s, d_loss: 0.01515371, g_loss: 5.15225935, rnn_loss: 0.00000000\n",
      " ** Epoch 408 took 48.858143s\n",
      "Epoch: [409/1000] time: 0.3519s, d_loss: 0.30263618, g_loss: 2.91409588, rnn_loss: 0.00000000\n",
      " ** Epoch 409 took 48.868808s\n",
      "Epoch: [410/1000] time: 0.3478s, d_loss: 0.01355166, g_loss: 4.85951424, rnn_loss: 0.00000000\n",
      " ** Epoch 410 took 48.685563s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [411/1000] time: 0.3737s, d_loss: 0.00279722, g_loss: 6.76392031, rnn_loss: 0.00000000\n",
      " ** Epoch 411 took 49.289558s\n",
      "Epoch: [412/1000] time: 0.3538s, d_loss: 0.03885914, g_loss: 4.77946329, rnn_loss: 0.00000000\n",
      " ** Epoch 412 took 48.753429s\n",
      "Epoch: [413/1000] time: 0.3506s, d_loss: 0.02750414, g_loss: 6.81302357, rnn_loss: 0.00000000\n",
      " ** Epoch 413 took 49.036644s\n",
      "Epoch: [414/1000] time: 0.3554s, d_loss: 0.01043504, g_loss: 5.12352037, rnn_loss: 0.00000000\n",
      " ** Epoch 414 took 48.425964s\n",
      "Epoch: [415/1000] time: 0.3583s, d_loss: 0.00880545, g_loss: 4.96175480, rnn_loss: 0.00000000\n",
      " ** Epoch 415 took 48.899678s\n",
      "Epoch: [416/1000] time: 0.3514s, d_loss: 0.01360927, g_loss: 4.99860191, rnn_loss: 0.00000000\n",
      " ** Epoch 416 took 49.179497s\n",
      "Epoch: [417/1000] time: 0.3580s, d_loss: 0.01092632, g_loss: 5.60514736, rnn_loss: 0.00000000\n",
      " ** Epoch 417 took 49.187173s\n",
      "Epoch: [418/1000] time: 0.3594s, d_loss: 0.00607012, g_loss: 5.74579859, rnn_loss: 0.00000000\n",
      " ** Epoch 418 took 49.855378s\n",
      "Epoch: [419/1000] time: 0.3607s, d_loss: 0.10336792, g_loss: 3.24735498, rnn_loss: 0.00000000\n",
      " ** Epoch 419 took 49.788814s\n",
      "Epoch: [420/1000] time: 0.3492s, d_loss: 0.00271954, g_loss: 6.67095709, rnn_loss: 0.00000000\n",
      " ** Epoch 420 took 49.374083s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [421/1000] time: 0.3555s, d_loss: 0.01195288, g_loss: 4.51694298, rnn_loss: 0.00000000\n",
      " ** Epoch 421 took 49.260567s\n",
      "Epoch: [422/1000] time: 0.3575s, d_loss: 0.00432130, g_loss: 5.74536133, rnn_loss: 0.00000000\n",
      " ** Epoch 422 took 49.520311s\n",
      "Epoch: [423/1000] time: 0.3568s, d_loss: 0.01803179, g_loss: 4.54940605, rnn_loss: 0.00000000\n",
      " ** Epoch 423 took 49.138641s\n",
      "Epoch: [424/1000] time: 0.3573s, d_loss: 0.03913411, g_loss: 4.26071882, rnn_loss: 0.00000000\n",
      " ** Epoch 424 took 49.828694s\n",
      "Epoch: [425/1000] time: 0.3595s, d_loss: 0.02701327, g_loss: 3.80089712, rnn_loss: 0.00000000\n",
      " ** Epoch 425 took 49.476765s\n",
      "Epoch: [426/1000] time: 0.3524s, d_loss: 0.00757668, g_loss: 5.79970312, rnn_loss: 0.00000000\n",
      " ** Epoch 426 took 48.987402s\n",
      "Epoch: [427/1000] time: 0.3549s, d_loss: 0.01811575, g_loss: 4.56726933, rnn_loss: 0.00000000\n",
      " ** Epoch 427 took 49.098969s\n",
      "Epoch: [428/1000] time: 0.3588s, d_loss: 0.03007159, g_loss: 4.34182072, rnn_loss: 0.00000000\n",
      " ** Epoch 428 took 49.135444s\n",
      "Epoch: [429/1000] time: 0.3557s, d_loss: 0.00953997, g_loss: 5.92041731, rnn_loss: 0.00000000\n",
      " ** Epoch 429 took 49.091345s\n",
      "Epoch: [430/1000] time: 0.3524s, d_loss: 0.00481982, g_loss: 5.46164179, rnn_loss: 0.00000000\n",
      " ** Epoch 430 took 49.575636s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [431/1000] time: 0.3498s, d_loss: 0.01935352, g_loss: 3.91678691, rnn_loss: 0.00000000\n",
      " ** Epoch 431 took 49.237296s\n",
      "Epoch: [432/1000] time: 0.3555s, d_loss: 0.09176577, g_loss: 4.54922581, rnn_loss: 0.00000000\n",
      " ** Epoch 432 took 48.943823s\n",
      "Epoch: [433/1000] time: 0.3542s, d_loss: 0.01348982, g_loss: 4.71408987, rnn_loss: 0.00000000\n",
      " ** Epoch 433 took 48.866379s\n",
      "Epoch: [434/1000] time: 0.3550s, d_loss: 0.00875067, g_loss: 6.06701851, rnn_loss: 0.00000000\n",
      " ** Epoch 434 took 48.842595s\n",
      "Epoch: [435/1000] time: 0.3605s, d_loss: 0.04835142, g_loss: 3.55681276, rnn_loss: 0.00000000\n",
      " ** Epoch 435 took 48.839907s\n",
      "Epoch: [436/1000] time: 0.3773s, d_loss: 0.04189585, g_loss: 4.17170477, rnn_loss: 0.00000000\n",
      " ** Epoch 436 took 49.062771s\n",
      "Epoch: [437/1000] time: 0.3559s, d_loss: 0.02558620, g_loss: 4.50816774, rnn_loss: 0.00000000\n",
      " ** Epoch 437 took 49.871913s\n",
      "Epoch: [438/1000] time: 0.3578s, d_loss: 0.00547132, g_loss: 5.58232117, rnn_loss: 0.00000000\n",
      " ** Epoch 438 took 49.006772s\n",
      "Epoch: [439/1000] time: 0.3584s, d_loss: 0.02090448, g_loss: 5.54638481, rnn_loss: 0.00000000\n",
      " ** Epoch 439 took 49.061313s\n",
      "Epoch: [440/1000] time: 0.3534s, d_loss: 0.08959585, g_loss: 3.20725107, rnn_loss: 0.00000000\n",
      " ** Epoch 440 took 49.061042s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [441/1000] time: 0.3591s, d_loss: 0.01051728, g_loss: 4.48916101, rnn_loss: 0.00000000\n",
      " ** Epoch 441 took 49.040114s\n",
      "Epoch: [442/1000] time: 0.3585s, d_loss: 0.02100856, g_loss: 4.08423424, rnn_loss: 0.00000000\n",
      " ** Epoch 442 took 49.167882s\n",
      "Epoch: [443/1000] time: 0.3803s, d_loss: 0.04980308, g_loss: 3.20438409, rnn_loss: 0.00000000\n",
      " ** Epoch 443 took 50.057034s\n",
      "Epoch: [444/1000] time: 0.3558s, d_loss: 0.04998011, g_loss: 3.97666216, rnn_loss: 0.00000000\n",
      " ** Epoch 444 took 49.348596s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [445/1000] time: 0.3544s, d_loss: 0.04542149, g_loss: 6.32717323, rnn_loss: 0.00000000\n",
      " ** Epoch 445 took 49.176899s\n",
      "Epoch: [446/1000] time: 0.3541s, d_loss: 0.04810356, g_loss: 3.42695999, rnn_loss: 0.00000000\n",
      " ** Epoch 446 took 49.247024s\n",
      "Epoch: [447/1000] time: 0.3561s, d_loss: 0.05019562, g_loss: 3.74522758, rnn_loss: 0.00000000\n",
      " ** Epoch 447 took 49.050780s\n",
      "Epoch: [448/1000] time: 0.3562s, d_loss: 0.01146937, g_loss: 6.31071138, rnn_loss: 0.00000000\n",
      " ** Epoch 448 took 49.013345s\n",
      "Epoch: [449/1000] time: 0.3543s, d_loss: 0.02502973, g_loss: 4.64680243, rnn_loss: 0.00000000\n",
      " ** Epoch 449 took 49.672044s\n",
      "Epoch: [450/1000] time: 0.3573s, d_loss: 0.03071034, g_loss: 3.83420420, rnn_loss: 0.00000000\n",
      " ** Epoch 450 took 49.413311s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [451/1000] time: 0.3532s, d_loss: 0.04982337, g_loss: 9.35076714, rnn_loss: 0.00000000\n",
      " ** Epoch 451 took 49.027356s\n",
      "Epoch: [452/1000] time: 0.3570s, d_loss: 0.01733837, g_loss: 7.21969509, rnn_loss: 0.00000000\n",
      " ** Epoch 452 took 49.204660s\n",
      "Epoch: [453/1000] time: 0.3528s, d_loss: 0.02048580, g_loss: 6.08690929, rnn_loss: 0.00000000\n",
      " ** Epoch 453 took 49.152972s\n",
      "Epoch: [454/1000] time: 0.3511s, d_loss: 0.02070677, g_loss: 3.63781834, rnn_loss: 0.00000000\n",
      " ** Epoch 454 took 49.495934s\n",
      "Epoch: [455/1000] time: 0.3608s, d_loss: 0.00376368, g_loss: 5.62118721, rnn_loss: 0.00000000\n",
      " ** Epoch 455 took 50.054351s\n",
      "Epoch: [456/1000] time: 0.3557s, d_loss: 0.03025078, g_loss: 4.75335264, rnn_loss: 0.00000000\n",
      " ** Epoch 456 took 49.839682s\n",
      "Epoch: [457/1000] time: 0.3567s, d_loss: 0.00402436, g_loss: 8.75554657, rnn_loss: 0.00000000\n",
      " ** Epoch 457 took 49.388510s\n",
      "Epoch: [458/1000] time: 0.3628s, d_loss: 0.01472548, g_loss: 5.00350761, rnn_loss: 0.00000000\n",
      " ** Epoch 458 took 49.395860s\n",
      "Epoch: [459/1000] time: 0.3604s, d_loss: 0.02952171, g_loss: 3.61905909, rnn_loss: 0.00000000\n",
      " ** Epoch 459 took 49.482794s\n",
      "Epoch: [460/1000] time: 0.3555s, d_loss: 0.10194533, g_loss: 2.43012452, rnn_loss: 0.00000000\n",
      " ** Epoch 460 took 49.442396s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [461/1000] time: 0.3611s, d_loss: 0.00436833, g_loss: 5.24416780, rnn_loss: 0.00000000\n",
      " ** Epoch 461 took 49.412049s\n",
      "Epoch: [462/1000] time: 0.3533s, d_loss: 0.02987148, g_loss: 5.12765598, rnn_loss: 0.00000000\n",
      " ** Epoch 462 took 50.342044s\n",
      "Epoch: [463/1000] time: 0.3565s, d_loss: 0.01027053, g_loss: 4.96842957, rnn_loss: 0.00000000\n",
      " ** Epoch 463 took 49.341136s\n",
      "Epoch: [464/1000] time: 0.3591s, d_loss: 0.11982970, g_loss: 3.44109440, rnn_loss: 0.00000000\n",
      " ** Epoch 464 took 49.110695s\n",
      "Epoch: [465/1000] time: 0.3533s, d_loss: 0.00606860, g_loss: 6.90162182, rnn_loss: 0.00000000\n",
      " ** Epoch 465 took 49.082795s\n",
      "Epoch: [466/1000] time: 0.3556s, d_loss: 0.08807142, g_loss: 4.84199095, rnn_loss: 0.00000000\n",
      " ** Epoch 466 took 49.165329s\n",
      "Epoch: [467/1000] time: 0.3562s, d_loss: 0.06647485, g_loss: 4.63031292, rnn_loss: 0.00000000\n",
      " ** Epoch 467 took 49.238244s\n",
      "Epoch: [468/1000] time: 0.3552s, d_loss: 0.02908241, g_loss: 5.66001225, rnn_loss: 0.00000000\n",
      " ** Epoch 468 took 50.008915s\n",
      "Epoch: [469/1000] time: 0.3604s, d_loss: 0.03014099, g_loss: 3.83588243, rnn_loss: 0.00000000\n",
      " ** Epoch 469 took 49.201679s\n",
      "Epoch: [470/1000] time: 0.3574s, d_loss: 0.01319831, g_loss: 7.37730646, rnn_loss: 0.00000000\n",
      " ** Epoch 470 took 49.207741s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [471/1000] time: 0.3532s, d_loss: 0.00659432, g_loss: 7.85309315, rnn_loss: 0.00000000\n",
      " ** Epoch 471 took 49.131200s\n",
      "Epoch: [472/1000] time: 0.3568s, d_loss: 0.01196993, g_loss: 4.63164091, rnn_loss: 0.00000000\n",
      " ** Epoch 472 took 49.131109s\n",
      "Epoch: [473/1000] time: 0.3521s, d_loss: 0.01037040, g_loss: 5.45103836, rnn_loss: 0.00000000\n",
      " ** Epoch 473 took 49.059239s\n",
      "Epoch: [474/1000] time: 0.3565s, d_loss: 0.02914816, g_loss: 3.85047865, rnn_loss: 0.00000000\n",
      " ** Epoch 474 took 50.027914s\n",
      "Epoch: [475/1000] time: 0.3606s, d_loss: 0.11229277, g_loss: 4.07328320, rnn_loss: 0.00000000\n",
      " ** Epoch 475 took 49.181814s\n",
      "Epoch: [476/1000] time: 0.3506s, d_loss: 0.02065081, g_loss: 7.20042181, rnn_loss: 0.00000000\n",
      " ** Epoch 476 took 49.329951s\n",
      "Epoch: [477/1000] time: 0.3569s, d_loss: 0.07186106, g_loss: 3.41841006, rnn_loss: 0.00000000\n",
      " ** Epoch 477 took 49.037693s\n",
      "Epoch: [478/1000] time: 0.3598s, d_loss: 0.01803924, g_loss: 4.93394279, rnn_loss: 0.00000000\n",
      " ** Epoch 478 took 49.131751s\n",
      "Epoch: [479/1000] time: 0.3531s, d_loss: 0.04933918, g_loss: 4.76483536, rnn_loss: 0.00000000\n",
      " ** Epoch 479 took 49.243198s\n",
      "Epoch: [480/1000] time: 0.3893s, d_loss: 0.05275494, g_loss: 7.59357691, rnn_loss: 0.00000000\n",
      " ** Epoch 480 took 49.613795s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [481/1000] time: 0.3560s, d_loss: 0.00932310, g_loss: 4.90674496, rnn_loss: 0.00000000\n",
      " ** Epoch 481 took 49.266384s\n",
      "Epoch: [482/1000] time: 0.3575s, d_loss: 0.04745887, g_loss: 3.91841888, rnn_loss: 0.00000000\n",
      " ** Epoch 482 took 49.227709s\n",
      "Epoch: [483/1000] time: 0.3564s, d_loss: 0.01847542, g_loss: 4.63332367, rnn_loss: 0.00000000\n",
      " ** Epoch 483 took 49.160580s\n",
      "Epoch: [484/1000] time: 0.3551s, d_loss: 0.15059470, g_loss: 7.99245119, rnn_loss: 0.00000000\n",
      " ** Epoch 484 took 49.233243s\n",
      "Epoch: [485/1000] time: 0.3612s, d_loss: 0.03548096, g_loss: 3.99742794, rnn_loss: 0.00000000\n",
      " ** Epoch 485 took 49.220425s\n",
      "Epoch: [486/1000] time: 0.3563s, d_loss: 0.02063507, g_loss: 4.22033310, rnn_loss: 0.00000000\n",
      " ** Epoch 486 took 49.308384s\n",
      "Epoch: [487/1000] time: 0.3605s, d_loss: 0.04308871, g_loss: 3.92750525, rnn_loss: 0.00000000\n",
      " ** Epoch 487 took 50.142835s\n",
      "Epoch: [488/1000] time: 0.3516s, d_loss: 0.02561270, g_loss: 4.36993980, rnn_loss: 0.00000000\n",
      " ** Epoch 488 took 49.365369s\n",
      "Epoch: [489/1000] time: 0.3569s, d_loss: 0.01252325, g_loss: 5.65712690, rnn_loss: 0.00000000\n",
      " ** Epoch 489 took 49.322482s\n",
      "Epoch: [490/1000] time: 0.3557s, d_loss: 0.02472807, g_loss: 4.47513628, rnn_loss: 0.00000000\n",
      " ** Epoch 490 took 49.216915s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [491/1000] time: 0.3581s, d_loss: 0.01250611, g_loss: 4.65223169, rnn_loss: 0.00000000\n",
      " ** Epoch 491 took 49.199203s\n",
      "Epoch: [492/1000] time: 0.3550s, d_loss: 0.12452135, g_loss: 5.00101471, rnn_loss: 0.00000000\n",
      " ** Epoch 492 took 49.311182s\n",
      "Epoch: [493/1000] time: 0.3581s, d_loss: 0.01451845, g_loss: 4.65635586, rnn_loss: 0.00000000\n",
      " ** Epoch 493 took 50.264098s\n",
      "Epoch: [494/1000] time: 0.3574s, d_loss: 0.02756122, g_loss: 4.93673992, rnn_loss: 0.00000000\n",
      " ** Epoch 494 took 49.194402s\n",
      "Epoch: [495/1000] time: 0.3555s, d_loss: 0.01861889, g_loss: 7.04007244, rnn_loss: 0.00000000\n",
      " ** Epoch 495 took 49.270754s\n",
      "Epoch: [496/1000] time: 0.3548s, d_loss: 0.00224029, g_loss: 6.17920399, rnn_loss: 0.00000000\n",
      " ** Epoch 496 took 49.291138s\n",
      "Epoch: [497/1000] time: 0.3585s, d_loss: 0.00425661, g_loss: 6.29781914, rnn_loss: 0.00000000\n",
      " ** Epoch 497 took 49.203520s\n",
      "Epoch: [498/1000] time: 0.3561s, d_loss: 0.00541581, g_loss: 4.71641636, rnn_loss: 0.00000000\n",
      " ** Epoch 498 took 49.294073s\n",
      "Epoch: [499/1000] time: 0.3579s, d_loss: 0.01073243, g_loss: 4.69336224, rnn_loss: 0.00000000\n",
      " ** Epoch 499 took 50.106658s\n",
      " ** new learning rate: 0.000006\n",
      "Epoch: [500/1000] time: 0.3578s, d_loss: 0.00253324, g_loss: 6.43721962, rnn_loss: 0.00000000\n",
      " ** Epoch 500 took 49.826452s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [501/1000] time: 0.3579s, d_loss: 0.00948094, g_loss: 4.63980341, rnn_loss: 0.00000000\n",
      " ** Epoch 501 took 49.422199s\n",
      "Epoch: [502/1000] time: 0.3555s, d_loss: 0.05335152, g_loss: 3.52828598, rnn_loss: 0.00000000\n",
      " ** Epoch 502 took 49.502055s\n",
      "Epoch: [503/1000] time: 0.3555s, d_loss: 0.02198957, g_loss: 4.74924660, rnn_loss: 0.00000000\n",
      " ** Epoch 503 took 49.484085s\n",
      "Epoch: [504/1000] time: 0.3583s, d_loss: 0.03014121, g_loss: 3.43388414, rnn_loss: 0.00000000\n",
      " ** Epoch 504 took 49.428180s\n",
      "Epoch: [505/1000] time: 0.3832s, d_loss: 0.01688564, g_loss: 2.89057064, rnn_loss: 0.00000000\n",
      " ** Epoch 505 took 50.274562s\n",
      "Epoch: [506/1000] time: 0.3601s, d_loss: 0.01775120, g_loss: 5.22944641, rnn_loss: 0.00000000\n",
      " ** Epoch 506 took 49.574087s\n",
      "Epoch: [507/1000] time: 0.3579s, d_loss: 0.02587262, g_loss: 3.97594905, rnn_loss: 0.00000000\n",
      " ** Epoch 507 took 49.465595s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [508/1000] time: 0.3554s, d_loss: 0.03068328, g_loss: 6.31540823, rnn_loss: 0.00000000\n",
      " ** Epoch 508 took 49.199937s\n",
      "Epoch: [509/1000] time: 0.3537s, d_loss: 0.05395509, g_loss: 4.65782547, rnn_loss: 0.00000000\n",
      " ** Epoch 509 took 49.190490s\n",
      "Epoch: [510/1000] time: 0.3564s, d_loss: 0.02360021, g_loss: 3.60581541, rnn_loss: 0.00000000\n",
      " ** Epoch 510 took 49.197985s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [511/1000] time: 0.3558s, d_loss: 0.01498693, g_loss: 4.44567108, rnn_loss: 0.00000000\n",
      " ** Epoch 511 took 49.586478s\n",
      "Epoch: [512/1000] time: 0.3624s, d_loss: 0.06969298, g_loss: 3.68043685, rnn_loss: 0.00000000\n",
      " ** Epoch 512 took 50.201531s\n",
      "Epoch: [513/1000] time: 0.3598s, d_loss: 0.00316942, g_loss: 6.02050352, rnn_loss: 0.00000000\n",
      " ** Epoch 513 took 49.676297s\n",
      "Epoch: [514/1000] time: 0.3576s, d_loss: 0.00934483, g_loss: 5.00657988, rnn_loss: 0.00000000\n",
      " ** Epoch 514 took 49.412100s\n",
      "Epoch: [515/1000] time: 0.3599s, d_loss: 0.05223550, g_loss: 3.39141893, rnn_loss: 0.00000000\n",
      " ** Epoch 515 took 49.837446s\n",
      "Epoch: [516/1000] time: 0.3698s, d_loss: 0.11552643, g_loss: 3.70515060, rnn_loss: 0.00000000\n",
      " ** Epoch 516 took 49.962285s\n",
      "Epoch: [517/1000] time: 0.3631s, d_loss: 0.00144851, g_loss: 6.77300692, rnn_loss: 0.00000000\n",
      " ** Epoch 517 took 50.525473s\n",
      "Epoch: [518/1000] time: 0.3573s, d_loss: 0.00887587, g_loss: 5.21826553, rnn_loss: 0.00000000\n",
      " ** Epoch 518 took 50.760302s\n",
      "Epoch: [519/1000] time: 0.3643s, d_loss: 0.04151838, g_loss: 3.43914557, rnn_loss: 0.00000000\n",
      " ** Epoch 519 took 50.169600s\n",
      "Epoch: [520/1000] time: 0.3610s, d_loss: 0.01261756, g_loss: 4.66296291, rnn_loss: 0.00000000\n",
      " ** Epoch 520 took 50.209256s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [521/1000] time: 0.3649s, d_loss: 0.03579276, g_loss: 4.10468626, rnn_loss: 0.00000000\n",
      " ** Epoch 521 took 50.088179s\n",
      "Epoch: [522/1000] time: 0.3674s, d_loss: 0.03252464, g_loss: 5.07510471, rnn_loss: 0.00000000\n",
      " ** Epoch 522 took 50.081020s\n",
      "Epoch: [523/1000] time: 0.3628s, d_loss: 0.05240505, g_loss: 3.60550785, rnn_loss: 0.00000000\n",
      " ** Epoch 523 took 50.349644s\n",
      "Epoch: [524/1000] time: 0.3649s, d_loss: 0.03908363, g_loss: 3.74800825, rnn_loss: 0.00000000\n",
      " ** Epoch 524 took 50.640208s\n",
      "Epoch: [525/1000] time: 0.3643s, d_loss: 0.01838609, g_loss: 6.51325703, rnn_loss: 0.00000000\n",
      " ** Epoch 525 took 49.867808s\n",
      "Epoch: [526/1000] time: 0.3602s, d_loss: 0.01930277, g_loss: 3.97800779, rnn_loss: 0.00000000\n",
      " ** Epoch 526 took 50.126359s\n",
      "Epoch: [527/1000] time: 0.3588s, d_loss: 0.00219115, g_loss: 6.41016722, rnn_loss: 0.00000000\n",
      " ** Epoch 527 took 50.120350s\n",
      "Epoch: [528/1000] time: 0.3643s, d_loss: 0.00406510, g_loss: 5.46014023, rnn_loss: 0.00000000\n",
      " ** Epoch 528 took 50.044322s\n",
      "Epoch: [529/1000] time: 0.3851s, d_loss: 0.01726302, g_loss: 4.16722775, rnn_loss: 0.00000000\n",
      " ** Epoch 529 took 50.266021s\n",
      "Epoch: [530/1000] time: 0.3614s, d_loss: 0.01372949, g_loss: 5.57809973, rnn_loss: 0.00000000\n",
      " ** Epoch 530 took 50.703555s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [531/1000] time: 0.3645s, d_loss: 0.00752515, g_loss: 4.83834076, rnn_loss: 0.00000000\n",
      " ** Epoch 531 took 49.990820s\n",
      "Epoch: [532/1000] time: 0.3578s, d_loss: 0.01444757, g_loss: 5.93648529, rnn_loss: 0.00000000\n",
      " ** Epoch 532 took 49.816727s\n",
      "Epoch: [533/1000] time: 0.3562s, d_loss: 0.00799958, g_loss: 6.53178883, rnn_loss: 0.00000000\n",
      " ** Epoch 533 took 49.221773s\n",
      "Epoch: [534/1000] time: 0.3566s, d_loss: 0.00345583, g_loss: 8.40619564, rnn_loss: 0.00000000\n",
      " ** Epoch 534 took 49.155519s\n",
      "Epoch: [535/1000] time: 0.3552s, d_loss: 0.01484848, g_loss: 6.69869423, rnn_loss: 0.00000000\n",
      " ** Epoch 535 took 49.125421s\n",
      "Epoch: [536/1000] time: 0.3769s, d_loss: 0.01627590, g_loss: 5.16654396, rnn_loss: 0.00000000\n",
      " ** Epoch 536 took 49.980010s\n",
      "Epoch: [537/1000] time: 0.3540s, d_loss: 0.00521282, g_loss: 6.44565010, rnn_loss: 0.00000000\n",
      " ** Epoch 537 took 49.497489s\n",
      "Epoch: [538/1000] time: 0.3592s, d_loss: 0.00917015, g_loss: 5.91426706, rnn_loss: 0.00000000\n",
      " ** Epoch 538 took 49.304981s\n",
      "Epoch: [539/1000] time: 0.3570s, d_loss: 0.01089846, g_loss: 3.86327267, rnn_loss: 0.00000000\n",
      " ** Epoch 539 took 49.268471s\n",
      "Epoch: [540/1000] time: 0.3518s, d_loss: 0.00526689, g_loss: 5.19365120, rnn_loss: 0.00000000\n",
      " ** Epoch 540 took 49.146149s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [541/1000] time: 0.3551s, d_loss: 0.00232598, g_loss: 6.22651196, rnn_loss: 0.00000000\n",
      " ** Epoch 541 took 49.176201s\n",
      "Epoch: [542/1000] time: 0.3577s, d_loss: 0.01392973, g_loss: 4.22876263, rnn_loss: 0.00000000\n",
      " ** Epoch 542 took 49.581180s\n",
      "Epoch: [543/1000] time: 0.3537s, d_loss: 0.02685491, g_loss: 4.99872923, rnn_loss: 0.00000000\n",
      " ** Epoch 543 took 49.903907s\n",
      "Epoch: [544/1000] time: 0.3578s, d_loss: 0.00827879, g_loss: 4.77751112, rnn_loss: 0.00000000\n",
      " ** Epoch 544 took 49.399233s\n",
      "Epoch: [545/1000] time: 0.3581s, d_loss: 0.03950566, g_loss: 3.81098557, rnn_loss: 0.00000000\n",
      " ** Epoch 545 took 49.343488s\n",
      "Epoch: [546/1000] time: 0.3617s, d_loss: 0.17186148, g_loss: 3.97167635, rnn_loss: 0.00000000\n",
      " ** Epoch 546 took 49.345730s\n",
      "Epoch: [547/1000] time: 0.3503s, d_loss: 0.01736629, g_loss: 4.57196474, rnn_loss: 0.00000000\n",
      " ** Epoch 547 took 49.168112s\n",
      "Epoch: [548/1000] time: 0.3584s, d_loss: 0.22218530, g_loss: 3.33332133, rnn_loss: 0.00000000\n",
      " ** Epoch 548 took 49.431098s\n",
      "Epoch: [549/1000] time: 0.3463s, d_loss: 0.05265231, g_loss: 5.35039520, rnn_loss: 0.00000000\n",
      " ** Epoch 549 took 49.538660s\n",
      "Epoch: [550/1000] time: 0.3563s, d_loss: 0.00596533, g_loss: 5.68396282, rnn_loss: 0.00000000\n",
      " ** Epoch 550 took 49.179871s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [551/1000] time: 0.3614s, d_loss: 0.00425619, g_loss: 6.14413071, rnn_loss: 0.00000000\n",
      " ** Epoch 551 took 49.096375s\n",
      "Epoch: [552/1000] time: 0.3637s, d_loss: 0.69815582, g_loss: 4.64785099, rnn_loss: 0.00000000\n",
      " ** Epoch 552 took 49.362237s\n",
      "Epoch: [553/1000] time: 0.3581s, d_loss: 0.02727626, g_loss: 3.78174782, rnn_loss: 0.00000000\n",
      " ** Epoch 553 took 49.482731s\n",
      "Epoch: [554/1000] time: 0.3537s, d_loss: 0.29549953, g_loss: 1.97845078, rnn_loss: 0.00000000\n",
      " ** Epoch 554 took 49.234355s\n",
      "Epoch: [555/1000] time: 0.3613s, d_loss: 0.00301057, g_loss: 5.97654438, rnn_loss: 0.00000000\n",
      " ** Epoch 555 took 49.671555s\n",
      "Epoch: [556/1000] time: 0.3632s, d_loss: 0.12481020, g_loss: 5.00586510, rnn_loss: 0.00000000\n",
      " ** Epoch 556 took 49.269627s\n",
      "Epoch: [557/1000] time: 0.3603s, d_loss: 0.02193095, g_loss: 4.66712141, rnn_loss: 0.00000000\n",
      " ** Epoch 557 took 49.619512s\n",
      "Epoch: [558/1000] time: 0.3592s, d_loss: 0.04970080, g_loss: 7.01101685, rnn_loss: 0.00000000\n",
      " ** Epoch 558 took 49.284158s\n",
      "Epoch: [559/1000] time: 0.3555s, d_loss: 0.07625011, g_loss: 2.92478704, rnn_loss: 0.00000000\n",
      " ** Epoch 559 took 49.394025s\n",
      "Epoch: [560/1000] time: 0.3557s, d_loss: 0.03998012, g_loss: 4.00886106, rnn_loss: 0.00000000\n",
      " ** Epoch 560 took 49.644811s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [561/1000] time: 0.3870s, d_loss: 0.01324763, g_loss: 4.70687199, rnn_loss: 0.00000000\n",
      " ** Epoch 561 took 50.329717s\n",
      "Epoch: [562/1000] time: 0.3616s, d_loss: 0.02848986, g_loss: 4.35343742, rnn_loss: 0.00000000\n",
      " ** Epoch 562 took 49.221416s\n",
      "Epoch: [563/1000] time: 0.3602s, d_loss: 0.04582262, g_loss: 3.87606621, rnn_loss: 0.00000000\n",
      " ** Epoch 563 took 49.441772s\n",
      "Epoch: [564/1000] time: 0.3561s, d_loss: 0.01845603, g_loss: 4.94867992, rnn_loss: 0.00000000\n",
      " ** Epoch 564 took 49.408284s\n",
      "Epoch: [565/1000] time: 0.3555s, d_loss: 0.01927196, g_loss: 5.96566391, rnn_loss: 0.00000000\n",
      " ** Epoch 565 took 49.369646s\n",
      "Epoch: [566/1000] time: 0.3549s, d_loss: 0.06088651, g_loss: 3.70321012, rnn_loss: 0.00000000\n",
      " ** Epoch 566 took 49.684922s\n",
      "Epoch: [567/1000] time: 0.3576s, d_loss: 0.02249724, g_loss: 3.71605229, rnn_loss: 0.00000000\n",
      " ** Epoch 567 took 49.351861s\n",
      "Epoch: [568/1000] time: 0.3570s, d_loss: 0.06692918, g_loss: 3.27437687, rnn_loss: 0.00000000\n",
      " ** Epoch 568 took 49.929603s\n",
      "Epoch: [569/1000] time: 0.3566s, d_loss: 0.01291796, g_loss: 7.20456314, rnn_loss: 0.00000000\n",
      " ** Epoch 569 took 49.379110s\n",
      "Epoch: [570/1000] time: 0.3574s, d_loss: 0.00674826, g_loss: 6.30667353, rnn_loss: 0.00000000\n",
      " ** Epoch 570 took 49.330030s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [571/1000] time: 0.3568s, d_loss: 0.03198540, g_loss: 3.89867258, rnn_loss: 0.00000000\n",
      " ** Epoch 571 took 49.468383s\n",
      "Epoch: [572/1000] time: 0.3805s, d_loss: 0.00715349, g_loss: 7.39869070, rnn_loss: 0.00000000\n",
      " ** Epoch 572 took 49.508871s\n",
      "Epoch: [573/1000] time: 0.3581s, d_loss: 0.01178999, g_loss: 5.52654743, rnn_loss: 0.00000000\n",
      " ** Epoch 573 took 49.331195s\n",
      "Epoch: [574/1000] time: 0.3609s, d_loss: 0.03817191, g_loss: 5.97525644, rnn_loss: 0.00000000\n",
      " ** Epoch 574 took 49.953021s\n",
      "Epoch: [575/1000] time: 0.3543s, d_loss: 0.00561364, g_loss: 5.31503677, rnn_loss: 0.00000000\n",
      " ** Epoch 575 took 49.230999s\n",
      "Epoch: [576/1000] time: 0.3604s, d_loss: 0.01203582, g_loss: 5.05919743, rnn_loss: 0.00000000\n",
      " ** Epoch 576 took 49.328655s\n",
      "Epoch: [577/1000] time: 0.3597s, d_loss: 0.03509007, g_loss: 7.09956264, rnn_loss: 0.00000000\n",
      " ** Epoch 577 took 49.496251s\n",
      "Epoch: [578/1000] time: 0.3542s, d_loss: 0.01853709, g_loss: 5.90747261, rnn_loss: 0.00000000\n",
      " ** Epoch 578 took 49.283321s\n",
      "Epoch: [579/1000] time: 0.3547s, d_loss: 0.01537271, g_loss: 5.26867628, rnn_loss: 0.00000000\n",
      " ** Epoch 579 took 49.524428s\n",
      "Epoch: [580/1000] time: 0.3610s, d_loss: 0.02560630, g_loss: 5.73903131, rnn_loss: 0.00000000\n",
      " ** Epoch 580 took 49.748819s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [581/1000] time: 0.3533s, d_loss: 0.00164524, g_loss: 7.58794022, rnn_loss: 0.00000000\n",
      " ** Epoch 581 took 49.089253s\n",
      "Epoch: [582/1000] time: 0.3585s, d_loss: 0.00492531, g_loss: 5.60481930, rnn_loss: 0.00000000\n",
      " ** Epoch 582 took 49.349031s\n",
      "Epoch: [583/1000] time: 0.3577s, d_loss: 0.03562941, g_loss: 3.71410799, rnn_loss: 0.00000000\n",
      " ** Epoch 583 took 49.269739s\n",
      "Epoch: [584/1000] time: 0.3581s, d_loss: 0.07046887, g_loss: 4.08481836, rnn_loss: 0.00000000\n",
      " ** Epoch 584 took 49.315171s\n",
      "Epoch: [585/1000] time: 0.3539s, d_loss: 0.00622739, g_loss: 5.25933361, rnn_loss: 0.00000000\n",
      " ** Epoch 585 took 49.530496s\n",
      "Epoch: [586/1000] time: 0.3790s, d_loss: 0.06350692, g_loss: 4.41017818, rnn_loss: 0.00000000\n",
      " ** Epoch 586 took 49.645703s\n",
      "Epoch: [587/1000] time: 0.3540s, d_loss: 0.04950146, g_loss: 5.61406517, rnn_loss: 0.00000000\n",
      " ** Epoch 587 took 49.393040s\n",
      "Epoch: [588/1000] time: 0.3615s, d_loss: 0.00811616, g_loss: 5.27128029, rnn_loss: 0.00000000\n",
      " ** Epoch 588 took 49.325758s\n",
      "Epoch: [589/1000] time: 0.3536s, d_loss: 0.01368283, g_loss: 6.40809584, rnn_loss: 0.00000000\n",
      " ** Epoch 589 took 49.356444s\n",
      "Epoch: [590/1000] time: 0.3560s, d_loss: 0.04835499, g_loss: 3.23345184, rnn_loss: 0.00000000\n",
      " ** Epoch 590 took 49.271093s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [591/1000] time: 0.3548s, d_loss: 0.00659328, g_loss: 6.62451124, rnn_loss: 0.00000000\n",
      " ** Epoch 591 took 49.557180s\n",
      "Epoch: [592/1000] time: 0.3537s, d_loss: 0.20011760, g_loss: 6.31511116, rnn_loss: 0.00000000\n",
      " ** Epoch 592 took 49.045669s\n",
      "Epoch: [593/1000] time: 0.3587s, d_loss: 0.00899910, g_loss: 4.96384621, rnn_loss: 0.00000000\n",
      " ** Epoch 593 took 49.845149s\n",
      "Epoch: [594/1000] time: 0.3570s, d_loss: 0.01146613, g_loss: 5.13383102, rnn_loss: 0.00000000\n",
      " ** Epoch 594 took 49.308097s\n",
      "Epoch: [595/1000] time: 0.3563s, d_loss: 0.09220772, g_loss: 5.12150478, rnn_loss: 0.00000000\n",
      " ** Epoch 595 took 49.347837s\n",
      "Epoch: [596/1000] time: 0.3559s, d_loss: 0.04019888, g_loss: 4.51763344, rnn_loss: 0.00000000\n",
      " ** Epoch 596 took 49.309993s\n",
      "Epoch: [597/1000] time: 0.3620s, d_loss: 0.00626687, g_loss: 4.78393841, rnn_loss: 0.00000000\n",
      " ** Epoch 597 took 49.595964s\n",
      "Epoch: [598/1000] time: 0.3571s, d_loss: 0.02317964, g_loss: 3.89189458, rnn_loss: 0.00000000\n",
      " ** Epoch 598 took 49.367187s\n",
      "Epoch: [599/1000] time: 0.3569s, d_loss: 0.05643217, g_loss: 4.92956591, rnn_loss: 0.00000000\n",
      " ** Epoch 599 took 49.918646s\n",
      " ** new learning rate: 0.000003\n",
      "Epoch: [600/1000] time: 0.3637s, d_loss: 0.01656890, g_loss: 4.55742836, rnn_loss: 0.00000000\n",
      " ** Epoch 600 took 49.716651s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [601/1000] time: 0.3519s, d_loss: 0.02977832, g_loss: 4.88825846, rnn_loss: 0.00000000\n",
      " ** Epoch 601 took 49.281452s\n",
      "Epoch: [602/1000] time: 0.3415s, d_loss: 0.40142167, g_loss: 5.83184338, rnn_loss: 0.00000000\n",
      " ** Epoch 602 took 49.086659s\n",
      "Epoch: [603/1000] time: 0.3530s, d_loss: 0.01851846, g_loss: 4.19940901, rnn_loss: 0.00000000\n",
      " ** Epoch 603 took 49.265337s\n",
      "Epoch: [604/1000] time: 0.3565s, d_loss: 0.00259320, g_loss: 6.14242268, rnn_loss: 0.00000000\n",
      " ** Epoch 604 took 49.278777s\n",
      "Epoch: [605/1000] time: 0.3588s, d_loss: 0.03324274, g_loss: 4.86860561, rnn_loss: 0.00000000\n",
      " ** Epoch 605 took 49.559215s\n",
      "Epoch: [606/1000] time: 0.3575s, d_loss: 0.00593539, g_loss: 5.47865343, rnn_loss: 0.00000000\n",
      " ** Epoch 606 took 48.917909s\n",
      "Epoch: [607/1000] time: 0.3538s, d_loss: 0.02621426, g_loss: 4.09706783, rnn_loss: 0.00000000\n",
      " ** Epoch 607 took 49.007287s\n",
      "Epoch: [608/1000] time: 0.3504s, d_loss: 0.00633920, g_loss: 4.88890553, rnn_loss: 0.00000000\n",
      " ** Epoch 608 took 48.911441s\n",
      "Epoch: [609/1000] time: 0.3754s, d_loss: 0.03472333, g_loss: 4.45414639, rnn_loss: 0.00000000\n",
      " ** Epoch 609 took 49.264691s\n",
      "Epoch: [610/1000] time: 0.3614s, d_loss: 0.15554821, g_loss: 7.75375891, rnn_loss: 0.00000000\n",
      " ** Epoch 610 took 49.028131s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [611/1000] time: 0.3785s, d_loss: 0.01086189, g_loss: 4.82186937, rnn_loss: 0.00000000\n",
      " ** Epoch 611 took 49.265749s\n",
      "Epoch: [612/1000] time: 0.3600s, d_loss: 0.10243608, g_loss: 2.58423638, rnn_loss: 0.00000000\n",
      " ** Epoch 612 took 49.341726s\n",
      "Epoch: [613/1000] time: 0.3566s, d_loss: 0.00626844, g_loss: 5.23460865, rnn_loss: 0.00000000\n",
      " ** Epoch 613 took 49.353291s\n",
      "Epoch: [614/1000] time: 0.3568s, d_loss: 0.02208227, g_loss: 5.26095057, rnn_loss: 0.00000000\n",
      " ** Epoch 614 took 49.485485s\n",
      "Epoch: [615/1000] time: 0.3594s, d_loss: 0.05786768, g_loss: 3.04853463, rnn_loss: 0.00000000\n",
      " ** Epoch 615 took 49.399227s\n",
      "Epoch: [616/1000] time: 0.3532s, d_loss: 0.02246304, g_loss: 4.22541904, rnn_loss: 0.00000000\n",
      " ** Epoch 616 took 49.586613s\n",
      "Epoch: [617/1000] time: 0.3562s, d_loss: 0.04353798, g_loss: 5.20324898, rnn_loss: 0.00000000\n",
      " ** Epoch 617 took 49.072804s\n",
      "Epoch: [618/1000] time: 0.3596s, d_loss: 0.01485318, g_loss: 4.18121099, rnn_loss: 0.00000000\n",
      " ** Epoch 618 took 49.879076s\n",
      "Epoch: [619/1000] time: 0.3567s, d_loss: 0.02808593, g_loss: 3.61852503, rnn_loss: 0.00000000\n",
      " ** Epoch 619 took 49.312964s\n",
      "Epoch: [620/1000] time: 0.3592s, d_loss: 0.02507404, g_loss: 4.57130718, rnn_loss: 0.00000000\n",
      " ** Epoch 620 took 49.334593s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [621/1000] time: 0.3545s, d_loss: 0.08283109, g_loss: 2.82921624, rnn_loss: 0.00000000\n",
      " ** Epoch 621 took 49.302801s\n",
      "Epoch: [622/1000] time: 0.3524s, d_loss: 0.01413257, g_loss: 4.86745119, rnn_loss: 0.00000000\n",
      " ** Epoch 622 took 49.629845s\n",
      "Epoch: [623/1000] time: 0.3571s, d_loss: 0.08655620, g_loss: 5.24074078, rnn_loss: 0.00000000\n",
      " ** Epoch 623 took 49.192880s\n",
      "Epoch: [624/1000] time: 0.3567s, d_loss: 0.02338008, g_loss: 5.53031874, rnn_loss: 0.00000000\n",
      " ** Epoch 624 took 49.840088s\n",
      "Epoch: [625/1000] time: 0.3555s, d_loss: 0.01841738, g_loss: 6.64293480, rnn_loss: 0.00000000\n",
      " ** Epoch 625 took 49.275373s\n",
      "Epoch: [626/1000] time: 0.3570s, d_loss: 0.01390089, g_loss: 6.11225796, rnn_loss: 0.00000000\n",
      " ** Epoch 626 took 49.274811s\n",
      "Epoch: [627/1000] time: 0.3594s, d_loss: 0.07266773, g_loss: 5.44499493, rnn_loss: 0.00000000\n",
      " ** Epoch 627 took 49.301978s\n",
      "Epoch: [628/1000] time: 0.3597s, d_loss: 0.04611062, g_loss: 5.22189617, rnn_loss: 0.00000000\n",
      " ** Epoch 628 took 49.623266s\n",
      "Epoch: [629/1000] time: 0.3596s, d_loss: 0.07842169, g_loss: 5.18322086, rnn_loss: 0.00000000\n",
      " ** Epoch 629 took 49.407464s\n",
      "Epoch: [630/1000] time: 0.3561s, d_loss: 0.01831134, g_loss: 4.97783566, rnn_loss: 0.00000000\n",
      " ** Epoch 630 took 49.743233s\n",
      "The checkpoint has been created.\n",
      "[*] Save checkpoints SUCCESS!\n",
      "Epoch: [631/1000] time: 0.3497s, d_loss: 0.04259717, g_loss: 4.00021887, rnn_loss: 0.00000000\n",
      " ** Epoch 631 took 49.006317s\n",
      "Epoch: [632/1000] time: 0.3562s, d_loss: 0.04449045, g_loss: 4.16894197, rnn_loss: 0.00000000\n",
      " ** Epoch 632 took 49.271733s\n",
      "Epoch: [633/1000] time: 0.3518s, d_loss: 0.08409755, g_loss: 3.81074476, rnn_loss: 0.00000000\n",
      " ** Epoch 633 took 49.151830s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [634/1000] time: 0.3568s, d_loss: 0.02254153, g_loss: 5.42447662, rnn_loss: 0.00000000\n",
      " ** Epoch 634 took 49.505482s\n",
      "Epoch: [635/1000] time: 0.3560s, d_loss: 0.05986887, g_loss: 5.43906975, rnn_loss: 0.00000000\n",
      " ** Epoch 635 took 49.211157s\n",
      "Epoch: [636/1000] time: 0.3703s, d_loss: 0.00843725, g_loss: 5.88516331, rnn_loss: 0.00000000\n",
      " ** Epoch 636 took 49.212684s\n",
      "Epoch: [637/1000] time: 0.3604s, d_loss: 0.01342466, g_loss: 4.67422056, rnn_loss: 0.00000000\n",
      " ** Epoch 637 took 49.656508s\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=10)\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "    load_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "    load(loader, sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print('no checkpoints find.')\n",
    "\n",
    "n_epoch = 1000\n",
    "n_batch_epoch = int(n_images_train / batch_size)\n",
    "for epoch in range(n_epoch):\n",
    "    start_time = time.time()\n",
    "    if epoch !=0 and (epoch % decay_every == 0):\n",
    "        new_lr_decay = lr_decay ** (epoch // decay_every)\n",
    "        sess.run(tf.assign(lr_v, lr * new_lr_decay))\n",
    "        log = \" ** new learning rate: %f\" % (lr * new_lr_decay)\n",
    "        print(log)\n",
    "    elif epoch == 0:\n",
    "        log = \" ** init lr: %f  decay_every_epoch: %d, lr_decay: %f\" % (lr, decay_every, lr_decay)\n",
    "        print(log)\n",
    "    for step in range(n_batch_epoch):\n",
    "        step_time = time.time()\n",
    "        idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\n",
    "        b_real_caption = train_captions[idexs]\n",
    "        b_real_images = train_images[np.floor(np.asarray(idexs).astype('float') / n_captions_per_image).astype('int')]\n",
    "        idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\n",
    "        b_wrong_caption = train_captions[idexs]\n",
    "        idexs2 = get_random_int(min=0, max=n_images_train-1, number=batch_size)\n",
    "        b_wrong_images = train_images[idexs2]\n",
    "        b_z = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, z_dim)).astype(np.float32)\n",
    "        b_real_images = threading_data(b_real_images, prepro_img, mode='train')\n",
    "        b_wrong_images = threading_data(b_wrong_images, prepro_img, mode='train')\n",
    "        if epoch < 80:\n",
    "            errRNN, _ = sess.run([rnn_loss, rnn_optim], feed_dict={\n",
    "                                            t_real_image : b_real_images,\n",
    "                                            t_wrong_image : b_wrong_images,\n",
    "                                            t_real_caption : b_real_caption,\n",
    "                                            t_wrong_caption : b_wrong_caption})\n",
    "        else:\n",
    "            errRNN = 0   \n",
    "        errD, _ = sess.run([d_loss, d_optim], feed_dict={\n",
    "                            t_real_image : b_real_images,\n",
    "                            t_wrong_caption : b_wrong_caption,\n",
    "                            t_real_caption : b_real_caption,\n",
    "                            t_z : b_z})\n",
    "        errG, _ = sess.run([g_loss, g_optim], feed_dict={\n",
    "                            t_real_caption : b_real_caption,\n",
    "                            t_z : b_z})\n",
    "    print(\"Epoch: [%2d/%2d] time: %4.4fs, d_loss: %.8f, g_loss: %.8f, rnn_loss: %.8f\" \\\n",
    "                        % (epoch, n_epoch, time.time() - step_time, errD, errG, errRNN))\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(\" ** Epoch %d took %fs\" % (epoch, time.time()-start_time))\n",
    "        img_gen, rnn_out = sess.run([net_g.outputs, net_rnn.outputs], feed_dict={\n",
    "                                        t_real_caption : sample_sentence,\n",
    "                                        t_z : sample_seed})\n",
    "        save_images(img_gen, [ni, ni], 'train_samples/train_{:02d}.png'.format(epoch))\n",
    "    if (epoch != 0) and (epoch % 10) == 0:\n",
    "        save(saver, sess, checkpoint_dir, epoch)\n",
    "        print(\"[*] Save checkpoints SUCCESS!\")\n",
    "checkpoint_path = os.path.join(cfg.CHECKPOINT_DIR, cfg.CHECKPOINT_NAME)\n",
    "saver.save(sess, checkpoint_path, global_step=epoch)\n",
    "print('The checkpoint has been created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(captions):\n",
    "    tf.reset_default_graph()\n",
    "    caption = []\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(captions[i])\n",
    "    caption = np.asarray(caption)\n",
    "    t_real_caption = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name='real_caption_input')\n",
    "    t_z = tf.placeholder(tf.float32, [batch_size, z_dim], name='z_noise')\n",
    "    net_g = GENERATOR(t_z, RNN_ENCODER(t_real_caption, is_training=False, reuse=False).outputs,\n",
    "                    is_training=False, reuse=False)\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.allow_soft_placement = True\n",
    "    sess = tf.Session(config=config)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "        load_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "        load(loader, sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        print('no checkpoints find.')\n",
    "    n_caption_test = len(caption)\n",
    "    n_batch_epoch = int(n_caption_test / batch_size) + 1\n",
    "    caption = np.tile(caption, (2, 1))\n",
    "    for i in range(n_batch_epoch):\n",
    "        test_cap = caption[i * batch_size: (i + 1) * batch_size]\n",
    "        z = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, z_dim)).astype(np.float32)\n",
    "        gen = sess.run(net_g.outputs, feed_dict={t_real_caption: test_cap, t_z: z})\n",
    "        save_images(gen, [ni, ni], 'inference/test_samples.png')\n",
    "        #for j in range(batch_size):\n",
    "        #    save_images(np.expand_dims(gen[j], axis=0), [ni, ni], 'inference/inference.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(sample_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_r_precision_data():\n",
    "    caption_ids = np.reshape(np.asarray(test_dataset.captions_ids), (-1, cfg.TEXT.WORDS_NUM))\n",
    "    captions_ids_wrong = np.reshape(test_dataset.random_wrong_captions(), (-1, cfg.WRONG_CAPTION, cfg.TEXT.WORDS_NUM))\n",
    "\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # load the trained checkpoint\n",
    "    checkpoint_dir = cfg.CHECKPOINT_DIR\n",
    "    if checkpoint_dir is not None:\n",
    "        loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "        ckpt_path = os.path.join(cfg.CHECKPOINT_DIR, CHECKPOINT_NAME)\n",
    "        loader.restore(sess, ckpt_path)\n",
    "        print(\"Restored model parameters from {}\".format(ckpt_path))\n",
    "    else:\n",
    "        print('no checkpoints find.')\n",
    "\n",
    "    n_caption_test = len(caption_ids)\n",
    "    num_batches = n_caption_test // cfg.BATCH_SIZE\n",
    "\n",
    "    true_cnn_features = np.zeros((num_batches, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "    true_rnn_features = np.zeros((num_batches, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "    wrong_rnn_features = np.zeros((num_batches, cfg.WRONG_CAPTION, cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM), dtype=float)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        test_cap = caption_ids[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "\n",
    "        z = np.random.normal(loc=0.0, scale=1.0, size=(cfg.BATCH_SIZE, cfg.GAN.Z_DIM)).astype(np.float32)\n",
    "        \n",
    "        rnn_features = sess.run(rnn_encoder.outputs, feed_dict={t_real_caption: test_cap})\n",
    "        gen = sess.run(generator.outputs, feed_dict={t_real_caption: test_cap, t_z: z})\n",
    "        cnn_features = sess.run(cnn_encoder.outputs, feed_dict={t_real_image: gen})\n",
    "\n",
    "        true_cnn_features[i] = cnn_features\n",
    "        true_rnn_features[i] = rnn_features\n",
    "\n",
    "        for per_wrong_caption in range(cfg.WRONG_CAPTION):\n",
    "            test_cap = captions_ids_wrong[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "            rnn_features = sess.run(rnn_encoder.outputs, feed_dict={t_real_caption: test_cap[:, per_wrong_caption]})\n",
    "            wrong_rnn_features[i, per_wrong_caption] = rnn_features\n",
    "    \n",
    "    # if exists, remove the existing file first\n",
    "    try:\n",
    "        os.remove(os.path.join(cfg.R_PRECISION_DIR, cfg.R_PRECISION_FILE))\n",
    "    except OSError:\n",
    "        pass\n",
    "    np.savez(os.path.join(cfg.R_PRECISION_DIR, cfg.R_PRECISION_FILE), true_cnn=true_cnn_features, true_rnn=true_rnn_features,\n",
    "             wrong_rnn=wrong_rnn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inception_score_data():\n",
    "    caption_ids = np.reshape(np.asarray(test_dataset.captions_ids),\n",
    "                             (-1, cfg.TEXT.CAPTIONS_PER_IMAGE, cfg.TEXT.WORDS_NUM))\n",
    "    \n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    checkpoint_dir = cfg.CHECKPOINT_DIR\n",
    "    if checkpoint_dir is not None:\n",
    "        loader = tf.train.Saver(var_list=tf.global_variables())\n",
    "        ckpt_path = os.path.join(cfg.CHECKPOINT_DIR, cfg.CHECKPOINT_NAME)\n",
    "        loader.restore(sess, ckpt_path)\n",
    "        print(\"Restored model parameters from {}\".format(ckpt_path))\n",
    "    else:\n",
    "        print('no checkpoints find.')\n",
    "\n",
    "    n_caption_test = len(caption_ids)\n",
    "    num_batches = n_caption_test // cfg.BATCH_SIZE\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        for per_caption in range(cfg.TEXT.CAPTIONS_PER_IMAGE):\n",
    "            test_cap = caption_ids[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE, per_caption]\n",
    "            test_directory = test_dataset.filenames[i * cfg.BATCH_SIZE: (i + 1) * cfg.BATCH_SIZE]\n",
    "\n",
    "            z = np.random.normal(loc=0.0, scale=1.0, size=(cfg.BATCH_SIZE, cfg.GAN.Z_DIM)).astype(np.float32)\n",
    "            gen = sess.run(generator.outputs, feed_dict={t_real_caption: test_cap, t_z: z})\n",
    "            \n",
    "            for j in range(cfg.BATCH_SIZE):\n",
    "                if not os.path.exists(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j].split('/')[0])):\n",
    "                    os.mkdir(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j].split('/')[0]))\n",
    "\n",
    "                scipy.misc.imsave(os.path.join(cfg.TEST.GENERATED_TEST_IMAGES, test_directory[j] + '_{}.png'.format(per_caption)), gen[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_r_precision_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_inception_score_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Measure Inception score and R-precision of given test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After set the config file as 'eval_birds.yml' and run the 'generate_inception_score_data()' and 'generate_r_precision_data()', the synthesized images based on given captions and set of image and caption features should be saved inside a 'evaluation' folder, specifically in 'evaluation/generated_images/..' and as 'evaluation/r_precision.npz' respectively.\n",
    "\n",
    "**Then, go to the 'evaluation' folder and run each 'inception_score.ipynb' and 'r_precision.ipynb' file in order to measure inception score and r-precision score.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
